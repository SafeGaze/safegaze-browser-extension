var __getOwnPropNames = Object.getOwnPropertyNames;
var __commonJS = (cb, mod) => function __require() {
  return mod || (0, cb[__getOwnPropNames(cb)[0]])((mod = { exports: {} }).exports, mod), mod.exports;
};

// (disabled):node_modules/node-fetch/browser.js
var require_browser = __commonJS({
  "(disabled):node_modules/node-fetch/browser.js"() {
  }
});

// (disabled):util
var require_util = __commonJS({
  "(disabled):util"() {
  }
});

// (disabled):crypto
var require_crypto = __commonJS({
  "(disabled):crypto"() {
  }
});

// node_modules/@tensorflow/tfjs-core/dist/tf-core.node.js
var require_tf_core_node = __commonJS({
  "node_modules/@tensorflow/tfjs-core/dist/tf-core.node.js"(exports) {
    "use strict";
    function _mergeNamespaces(n, m) {
      m.forEach(function(e) {
        e && typeof e !== "string" && !Array.isArray(e) && Object.keys(e).forEach(function(k) {
          if (k !== "default" && !(k in n)) {
            var d = Object.getOwnPropertyDescriptor(e, k);
            Object.defineProperty(n, k, d.get ? d : {
              enumerable: true,
              get: function() {
                return e[k];
              }
            });
          }
        });
      });
      return n;
    }
    var extendStatics = function(d, b) {
      extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(d2, b2) {
        d2.__proto__ = b2;
      } || function(d2, b2) {
        for (var p in b2)
          if (Object.prototype.hasOwnProperty.call(b2, p))
            d2[p] = b2[p];
      };
      return extendStatics(d, b);
    };
    function __extends(d, b) {
      if (typeof b !== "function" && b !== null)
        throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
      extendStatics(d, b);
      function __() {
        this.constructor = d;
      }
      d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    }
    function __awaiter(thisArg, _arguments, P, generator) {
      function adopt(value) {
        return value instanceof P ? value : new P(function(resolve) {
          resolve(value);
        });
      }
      return new (P || (P = Promise))(function(resolve, reject) {
        function fulfilled(value) {
          try {
            step2(generator.next(value));
          } catch (e) {
            reject(e);
          }
        }
        function rejected(value) {
          try {
            step2(generator["throw"](value));
          } catch (e) {
            reject(e);
          }
        }
        function step2(result) {
          result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step2((generator = generator.apply(thisArg, _arguments || [])).next());
      });
    }
    function __generator(thisArg, body) {
      var _ = { label: 0, sent: function() {
        if (t[0] & 1)
          throw t[1];
        return t[1];
      }, trys: [], ops: [] }, f, y, t, g;
      return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
      }), g;
      function verb(n) {
        return function(v) {
          return step2([n, v]);
        };
      }
      function step2(op2) {
        if (f)
          throw new TypeError("Generator is already executing.");
        while (_)
          try {
            if (f = 1, y && (t = op2[0] & 2 ? y["return"] : op2[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op2[1])).done)
              return t;
            if (y = 0, t)
              op2 = [op2[0] & 2, t.value];
            switch (op2[0]) {
              case 0:
              case 1:
                t = op2;
                break;
              case 4:
                _.label++;
                return { value: op2[1], done: false };
              case 5:
                _.label++;
                y = op2[1];
                op2 = [0];
                continue;
              case 7:
                op2 = _.ops.pop();
                _.trys.pop();
                continue;
              default:
                if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op2[0] === 6 || op2[0] === 2)) {
                  _ = 0;
                  continue;
                }
                if (op2[0] === 3 && (!t || op2[1] > t[0] && op2[1] < t[3])) {
                  _.label = op2[1];
                  break;
                }
                if (op2[0] === 6 && _.label < t[1]) {
                  _.label = t[1];
                  t = op2;
                  break;
                }
                if (t && _.label < t[2]) {
                  _.label = t[2];
                  _.ops.push(op2);
                  break;
                }
                if (t[2])
                  _.ops.pop();
                _.trys.pop();
                continue;
            }
            op2 = body.call(thisArg, _);
          } catch (e) {
            op2 = [6, e];
            y = 0;
          } finally {
            f = t = 0;
          }
        if (op2[0] & 5)
          throw op2[1];
        return { value: op2[0] ? op2[1] : void 0, done: true };
      }
    }
    function __values(o) {
      var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
      if (m)
        return m.call(o);
      if (o && typeof o.length === "number")
        return {
          next: function() {
            if (o && i >= o.length)
              o = void 0;
            return { value: o && o[i++], done: !o };
          }
        };
      throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
    }
    function __read(o, n) {
      var m = typeof Symbol === "function" && o[Symbol.iterator];
      if (!m)
        return o;
      var i = m.call(o), r, ar = [], e;
      try {
        while ((n === void 0 || n-- > 0) && !(r = i.next()).done)
          ar.push(r.value);
      } catch (error) {
        e = { error };
      } finally {
        try {
          if (r && !r.done && (m = i["return"]))
            m.call(i);
        } finally {
          if (e)
            throw e.error;
        }
      }
      return ar;
    }
    function __spreadArray(to, from, pack) {
      if (pack || arguments.length === 2)
        for (var i = 0, l = from.length, ar; i < l; i++) {
          if (ar || !(i in from)) {
            if (!ar)
              ar = Array.prototype.slice.call(from, 0, i);
            ar[i] = from[i];
          }
        }
      return to.concat(ar || Array.prototype.slice.call(from));
    }
    var EPSILON_FLOAT32 = 1e-7;
    var EPSILON_FLOAT16 = 1e-4;
    var DataStorage = (
      /** @class */
      function() {
        function DataStorage2(backend2, dataMover) {
          this.backend = backend2;
          this.dataMover = dataMover;
          this.data = /* @__PURE__ */ new WeakMap();
          this.dataIdsCount = 0;
        }
        DataStorage2.prototype.get = function(dataId) {
          if (!this.data.has(dataId)) {
            this.dataMover.moveData(this.backend, dataId);
          }
          return this.data.get(dataId);
        };
        DataStorage2.prototype.set = function(dataId, value) {
          this.dataIdsCount++;
          this.data.set(dataId, value);
        };
        DataStorage2.prototype.has = function(dataId) {
          return this.data.has(dataId);
        };
        DataStorage2.prototype.delete = function(dataId) {
          this.dataIdsCount--;
          return this.data.delete(dataId);
        };
        DataStorage2.prototype.numDataIds = function() {
          return this.dataIdsCount;
        };
        return DataStorage2;
      }()
    );
    var KernelBackend = (
      /** @class */
      function() {
        function KernelBackend2() {
        }
        KernelBackend2.prototype.refCount = function(dataId) {
          return notYetImplemented("refCount");
        };
        KernelBackend2.prototype.incRef = function(dataId) {
          return notYetImplemented("incRef");
        };
        KernelBackend2.prototype.timerAvailable = function() {
          return true;
        };
        KernelBackend2.prototype.time = function(f) {
          return notYetImplemented("time");
        };
        KernelBackend2.prototype.read = function(dataId) {
          return notYetImplemented("read");
        };
        KernelBackend2.prototype.readSync = function(dataId) {
          return notYetImplemented("readSync");
        };
        KernelBackend2.prototype.readToGPU = function(dataId, options) {
          return notYetImplemented("readToGPU");
        };
        KernelBackend2.prototype.numDataIds = function() {
          return notYetImplemented("numDataIds");
        };
        KernelBackend2.prototype.disposeData = function(dataId, force) {
          return notYetImplemented("disposeData");
        };
        KernelBackend2.prototype.write = function(values, shape, dtype) {
          return notYetImplemented("write");
        };
        KernelBackend2.prototype.move = function(dataId, values, shape, dtype, refCount) {
          return notYetImplemented("move");
        };
        KernelBackend2.prototype.createTensorFromGPUData = function(values, shape, dtype) {
          return notYetImplemented("createTensorFromGPUData");
        };
        KernelBackend2.prototype.memory = function() {
          return notYetImplemented("memory");
        };
        KernelBackend2.prototype.floatPrecision = function() {
          return notYetImplemented("floatPrecision");
        };
        KernelBackend2.prototype.epsilon = function() {
          return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;
        };
        KernelBackend2.prototype.dispose = function() {
          return notYetImplemented("dispose");
        };
        return KernelBackend2;
      }()
    );
    function notYetImplemented(kernelName) {
      throw new Error("'".concat(kernelName, "' not yet implemented or not found in the registry. ") + "This kernel may not be supported by the tfjs backend you have chosen");
    }
    function shuffle(array) {
      var counter = array.length;
      var index = 0;
      while (counter > 0) {
        index = Math.random() * counter | 0;
        counter--;
        swap(array, counter, index);
      }
    }
    function shuffleCombo(array, array2) {
      if (array.length !== array2.length) {
        throw new Error("Array sizes must match to be shuffled together " + "First array length was ".concat(array.length) + "Second array length was ".concat(array2.length));
      }
      var counter = array.length;
      var index = 0;
      while (counter > 0) {
        index = Math.random() * counter | 0;
        counter--;
        swap(array, counter, index);
        swap(array2, counter, index);
      }
    }
    function clamp(min2, x, max2) {
      return Math.max(min2, Math.min(x, max2));
    }
    function nearestLargerEven(val) {
      return val % 2 === 0 ? val : val + 1;
    }
    function swap(object, left, right) {
      var temp = object[left];
      object[left] = object[right];
      object[right] = temp;
    }
    function sum$1(arr) {
      var sum2 = 0;
      for (var i = 0; i < arr.length; i++) {
        sum2 += arr[i];
      }
      return sum2;
    }
    function randUniform(a, b) {
      var r = Math.random();
      return b * r + (1 - r) * a;
    }
    function distSquared(a, b) {
      var result = 0;
      for (var i = 0; i < a.length; i++) {
        var diff = Number(a[i]) - Number(b[i]);
        result += diff * diff;
      }
      return result;
    }
    function assert(expr, msg) {
      if (!expr) {
        throw new Error(typeof msg === "string" ? msg : msg());
      }
    }
    function assertShapesMatch(shapeA, shapeB, errorMessagePrefix) {
      if (errorMessagePrefix === void 0) {
        errorMessagePrefix = "";
      }
      assert(arraysEqual(shapeA, shapeB), function() {
        return errorMessagePrefix + " Shapes ".concat(shapeA, " and ").concat(shapeB, " must match");
      });
    }
    function assertNonNull(a) {
      assert(a != null, function() {
        return "The input to the tensor constructor must be a non-null value.";
      });
    }
    function sizeFromShape(shape) {
      if (shape.length === 0) {
        return 1;
      }
      var size = shape[0];
      for (var i = 1; i < shape.length; i++) {
        size *= shape[i];
      }
      return size;
    }
    function isScalarShape(shape) {
      return shape.length === 0;
    }
    function arraysEqualWithNull(n1, n2) {
      if (n1 === n2) {
        return true;
      }
      if (n1 == null || n2 == null) {
        return false;
      }
      if (n1.length !== n2.length) {
        return false;
      }
      for (var i = 0; i < n1.length; i++) {
        if (n1[i] !== null && n2[i] !== null && n1[i] !== n2[i]) {
          return false;
        }
      }
      return true;
    }
    function arraysEqual(n1, n2) {
      if (n1 === n2) {
        return true;
      }
      if (n1 == null || n2 == null) {
        return false;
      }
      if (n1.length !== n2.length) {
        return false;
      }
      for (var i = 0; i < n1.length; i++) {
        if (n1[i] !== n2[i]) {
          return false;
        }
      }
      return true;
    }
    function isInt(a) {
      return a % 1 === 0;
    }
    function tanh$1(x) {
      if (Math.tanh != null) {
        return Math.tanh(x);
      }
      if (x === Infinity) {
        return 1;
      } else if (x === -Infinity) {
        return -1;
      } else {
        var e2x = Math.exp(2 * x);
        return (e2x - 1) / (e2x + 1);
      }
    }
    function sizeToSquarishShape(size) {
      var width = Math.ceil(Math.sqrt(size));
      return [width, Math.ceil(size / width)];
    }
    function createShuffledIndices(n) {
      var shuffledIndices = new Uint32Array(n);
      for (var i = 0; i < n; ++i) {
        shuffledIndices[i] = i;
      }
      shuffle(shuffledIndices);
      return shuffledIndices;
    }
    function rightPad(a, size) {
      if (size <= a.length) {
        return a;
      }
      return a + " ".repeat(size - a.length);
    }
    function repeatedTry(checkFn, delayFn, maxCounter, scheduleFn) {
      if (delayFn === void 0) {
        delayFn = function(counter) {
          return 0;
        };
      }
      return new Promise(function(resolve, reject) {
        var tryCount = 0;
        var tryFn = function() {
          if (checkFn()) {
            resolve();
            return;
          }
          tryCount++;
          var nextBackoff = delayFn(tryCount);
          if (maxCounter != null && tryCount >= maxCounter) {
            reject();
            return;
          }
          if (scheduleFn != null) {
            scheduleFn(tryFn, nextBackoff);
          } else {
            setTimeout(tryFn, nextBackoff);
          }
        };
        tryFn();
      });
    }
    function inferFromImplicitShape(shape, size) {
      var shapeProd = 1;
      var implicitIdx = -1;
      for (var i = 0; i < shape.length; ++i) {
        if (shape[i] >= 0) {
          shapeProd *= shape[i];
        } else if (shape[i] === -1) {
          if (implicitIdx !== -1) {
            throw Error("Shapes can only have 1 implicit size. " + "Found -1 at dim ".concat(implicitIdx, " and dim ").concat(i));
          }
          implicitIdx = i;
        } else if (shape[i] < 0) {
          throw Error("Shapes can not be < 0. Found ".concat(shape[i], " at dim ").concat(i));
        }
      }
      if (implicitIdx === -1) {
        if (size > 0 && size !== shapeProd) {
          throw Error("Size(".concat(size, ") must match the product of shape ").concat(shape));
        }
        return shape;
      }
      if (shapeProd === 0) {
        throw Error("Cannot infer the missing size in [".concat(shape, "] when ") + "there are 0 elements");
      }
      if (size % shapeProd !== 0) {
        throw Error("The implicit shape can't be a fractional number. " + "Got ".concat(size, " / ").concat(shapeProd));
      }
      var newShape = shape.slice();
      newShape[implicitIdx] = size / shapeProd;
      return newShape;
    }
    function parseAxisParam(axis, shape) {
      var rank = shape.length;
      axis = axis == null ? shape.map(function(s, i) {
        return i;
      }) : [].concat(axis);
      assert(axis.every(function(ax) {
        return ax >= -rank && ax < rank;
      }), function() {
        return "All values in axis param must be in range [-".concat(rank, ", ").concat(rank, ") but ") + "got axis ".concat(axis);
      });
      assert(axis.every(function(ax) {
        return isInt(ax);
      }), function() {
        return "All values in axis param must be integers but " + "got axis ".concat(axis);
      });
      return axis.map(function(a) {
        return a < 0 ? rank + a : a;
      });
    }
    function squeezeShape(shape, axis) {
      var newShape = [];
      var keptDims = [];
      var isEmptyArray = axis != null && Array.isArray(axis) && axis.length === 0;
      var axes = axis == null || isEmptyArray ? null : parseAxisParam(axis, shape).sort();
      var j = 0;
      for (var i = 0; i < shape.length; ++i) {
        if (axes != null) {
          if (axes[j] === i && shape[i] !== 1) {
            throw new Error("Can't squeeze axis ".concat(i, " since its dim '").concat(shape[i], "' is not 1"));
          }
          if ((axes[j] == null || axes[j] > i) && shape[i] === 1) {
            newShape.push(shape[i]);
            keptDims.push(i);
          }
          if (axes[j] <= i) {
            j++;
          }
        }
        if (shape[i] !== 1) {
          newShape.push(shape[i]);
          keptDims.push(i);
        }
      }
      return { newShape, keptDims };
    }
    function getTypedArrayFromDType(dtype, size) {
      return getArrayFromDType(dtype, size);
    }
    function getArrayFromDType(dtype, size) {
      var values = null;
      if (dtype == null || dtype === "float32") {
        values = new Float32Array(size);
      } else if (dtype === "int32") {
        values = new Int32Array(size);
      } else if (dtype === "bool") {
        values = new Uint8Array(size);
      } else if (dtype === "string") {
        values = new Array(size);
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
      return values;
    }
    function checkConversionForErrors(vals, dtype) {
      for (var i = 0; i < vals.length; i++) {
        var num = vals[i];
        if (isNaN(num) || !isFinite(num)) {
          throw Error("A tensor of type ".concat(dtype, " being uploaded contains ").concat(num, "."));
        }
      }
    }
    function isValidDtype(dtype) {
      return dtype === "bool" || dtype === "complex64" || dtype === "float32" || dtype === "int32" || dtype === "string";
    }
    function hasEncodingLoss(oldType, newType) {
      if (newType === "complex64") {
        return false;
      }
      if (newType === "float32" && oldType !== "complex64") {
        return false;
      }
      if (newType === "int32" && oldType !== "float32" && oldType !== "complex64") {
        return false;
      }
      if (newType === "bool" && oldType === "bool") {
        return false;
      }
      return true;
    }
    function bytesPerElement(dtype) {
      if (dtype === "float32" || dtype === "int32") {
        return 4;
      } else if (dtype === "complex64") {
        return 8;
      } else if (dtype === "bool") {
        return 1;
      } else {
        throw new Error("Unknown dtype ".concat(dtype));
      }
    }
    function bytesFromStringArray(arr) {
      if (arr == null) {
        return 0;
      }
      var bytes = 0;
      arr.forEach(function(x) {
        return bytes += x.length;
      });
      return bytes;
    }
    function isString(value) {
      return typeof value === "string" || value instanceof String;
    }
    function isBoolean(value) {
      return typeof value === "boolean";
    }
    function isNumber(value) {
      return typeof value === "number";
    }
    function inferDtype(values) {
      if (Array.isArray(values)) {
        return inferDtype(values[0]);
      }
      if (values instanceof Float32Array) {
        return "float32";
      } else if (values instanceof Int32Array || values instanceof Uint8Array || values instanceof Uint8ClampedArray) {
        return "int32";
      } else if (isNumber(values)) {
        return "float32";
      } else if (isString(values)) {
        return "string";
      } else if (isBoolean(values)) {
        return "bool";
      }
      return "float32";
    }
    function isFunction(f) {
      return !!(f && f.constructor && f.call && f.apply);
    }
    function nearestDivisor(size, start) {
      for (var i = start; i < size; ++i) {
        if (size % i === 0) {
          return i;
        }
      }
      return size;
    }
    function computeStrides(shape) {
      var rank = shape.length;
      if (rank < 2) {
        return [];
      }
      var strides = new Array(rank - 1);
      strides[rank - 2] = shape[rank - 1];
      for (var i = rank - 3; i >= 0; --i) {
        strides[i] = strides[i + 1] * shape[i + 1];
      }
      return strides;
    }
    function createNestedArray(offset, shape, a, isComplex) {
      if (isComplex === void 0) {
        isComplex = false;
      }
      var ret = new Array();
      if (shape.length === 1) {
        var d = shape[0] * (isComplex ? 2 : 1);
        for (var i = 0; i < d; i++) {
          ret[i] = a[offset + i];
        }
      } else {
        var d = shape[0];
        var rest = shape.slice(1);
        var len = rest.reduce(function(acc, c) {
          return acc * c;
        }) * (isComplex ? 2 : 1);
        for (var i = 0; i < d; i++) {
          ret[i] = createNestedArray(offset + i * len, rest, a, isComplex);
        }
      }
      return ret;
    }
    function toNestedArray(shape, a, isComplex) {
      if (isComplex === void 0) {
        isComplex = false;
      }
      if (shape.length === 0) {
        return a[0];
      }
      var size = shape.reduce(function(acc, c) {
        return acc * c;
      }) * (isComplex ? 2 : 1);
      if (size === 0) {
        return [];
      }
      if (size !== a.length) {
        throw new Error("[".concat(shape, "] does not match the input size ").concat(a.length).concat(isComplex ? " for a complex tensor" : "", "."));
      }
      return createNestedArray(0, shape, a, isComplex);
    }
    function convertBackendValuesAndArrayBuffer(data, dtype) {
      if (Array.isArray(data)) {
        return data;
      }
      if (dtype === "float32") {
        return data instanceof Float32Array ? data : new Float32Array(data);
      } else if (dtype === "int32") {
        return data instanceof Int32Array ? data : new Int32Array(data);
      } else if (dtype === "bool" || dtype === "string") {
        return Uint8Array.from(new Int32Array(data));
      } else {
        throw new Error("Unknown dtype ".concat(dtype));
      }
    }
    function makeOnesTypedArray(size, dtype) {
      var array = makeZerosTypedArray(size, dtype);
      for (var i = 0; i < array.length; i++) {
        array[i] = 1;
      }
      return array;
    }
    function makeZerosTypedArray(size, dtype) {
      if (dtype == null || dtype === "float32" || dtype === "complex64") {
        return new Float32Array(size);
      } else if (dtype === "int32") {
        return new Int32Array(size);
      } else if (dtype === "bool") {
        return new Uint8Array(size);
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
    }
    function makeZerosNestedTypedArray(shape, dtype) {
      var size = shape.reduce(function(prev, curr) {
        return prev * curr;
      }, 1);
      if (dtype == null || dtype === "float32") {
        return toNestedArray(shape, new Float32Array(size));
      } else if (dtype === "int32") {
        return toNestedArray(shape, new Int32Array(size));
      } else if (dtype === "bool") {
        return toNestedArray(shape, new Uint8Array(size));
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
    }
    function assertNonNegativeIntegerDimensions(shape) {
      shape.forEach(function(dimSize) {
        assert(Number.isInteger(dimSize) && dimSize >= 0, function() {
          return "Tensor must have a shape comprised of positive integers but got " + "shape [".concat(shape, "].");
        });
      });
    }
    function locToIndex(locs, rank, strides) {
      if (rank === 0) {
        return 0;
      } else if (rank === 1) {
        return locs[0];
      }
      var index = locs[locs.length - 1];
      for (var i = 0; i < locs.length - 1; ++i) {
        index += strides[i] * locs[i];
      }
      return index;
    }
    function indexToLoc(index, rank, strides) {
      if (rank === 0) {
        return [];
      } else if (rank === 1) {
        return [index];
      }
      var locs = new Array(rank);
      for (var i = 0; i < locs.length - 1; ++i) {
        locs[i] = Math.floor(index / strides[i]);
        index -= locs[i] * strides[i];
      }
      locs[locs.length - 1] = index;
      return locs;
    }
    function isPromise(object) {
      return object && object.then && typeof object.then === "function";
    }
    var TENSORFLOWJS_FLAGS_PREFIX = "tfjsflags";
    var Environment = (
      /** @class */
      function() {
        function Environment2(global2) {
          this.global = global2;
          this.flags = {};
          this.flagRegistry = {};
          this.urlFlags = {};
          this.getQueryParams = getQueryParams;
          this.populateURLFlags();
        }
        Environment2.prototype.setPlatform = function(platformName, platform) {
          if (this.platform != null) {
            if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
              console.warn("Platform ".concat(this.platformName, " has already been set. ") + "Overwriting the platform with ".concat(platformName, "."));
            }
          }
          this.platformName = platformName;
          this.platform = platform;
        };
        Environment2.prototype.registerFlag = function(flagName, evaluationFn, setHook) {
          this.flagRegistry[flagName] = { evaluationFn, setHook };
          if (this.urlFlags[flagName] != null) {
            var flagValue = this.urlFlags[flagName];
            if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
              console.warn("Setting feature override from URL ".concat(flagName, ": ").concat(flagValue, "."));
            }
            this.set(flagName, flagValue);
          }
        };
        Environment2.prototype.getAsync = function(flagName) {
          return __awaiter(this, void 0, void 0, function() {
            var _a, _b;
            return __generator(this, function(_c) {
              switch (_c.label) {
                case 0:
                  if (flagName in this.flags) {
                    return [2, this.flags[flagName]];
                  }
                  _a = this.flags;
                  _b = flagName;
                  return [4, this.evaluateFlag(flagName)];
                case 1:
                  _a[_b] = _c.sent();
                  return [2, this.flags[flagName]];
              }
            });
          });
        };
        Environment2.prototype.get = function(flagName) {
          if (flagName in this.flags) {
            return this.flags[flagName];
          }
          var flagValue = this.evaluateFlag(flagName);
          if (isPromise(flagValue)) {
            throw new Error("Flag ".concat(flagName, " cannot be synchronously evaluated. ") + "Please use getAsync() instead.");
          }
          this.flags[flagName] = flagValue;
          return this.flags[flagName];
        };
        Environment2.prototype.getNumber = function(flagName) {
          return this.get(flagName);
        };
        Environment2.prototype.getBool = function(flagName) {
          return this.get(flagName);
        };
        Environment2.prototype.getString = function(flagName) {
          return this.get(flagName);
        };
        Environment2.prototype.getFlags = function() {
          return this.flags;
        };
        Object.defineProperty(Environment2.prototype, "features", {
          // For backwards compatibility.
          get: function() {
            return this.flags;
          },
          enumerable: false,
          configurable: true
        });
        Environment2.prototype.set = function(flagName, value) {
          if (this.flagRegistry[flagName] == null) {
            throw new Error("Cannot set flag ".concat(flagName, " as it has not been registered."));
          }
          this.flags[flagName] = value;
          if (this.flagRegistry[flagName].setHook != null) {
            this.flagRegistry[flagName].setHook(value);
          }
        };
        Environment2.prototype.evaluateFlag = function(flagName) {
          if (this.flagRegistry[flagName] == null) {
            throw new Error("Cannot evaluate flag '".concat(flagName, "': no evaluation function found."));
          }
          return this.flagRegistry[flagName].evaluationFn();
        };
        Environment2.prototype.setFlags = function(flags) {
          this.flags = Object.assign({}, flags);
        };
        Environment2.prototype.reset = function() {
          this.flags = {};
          this.urlFlags = {};
          this.populateURLFlags();
        };
        Environment2.prototype.populateURLFlags = function() {
          var _this = this;
          if (typeof this.global === "undefined" || typeof this.global.location === "undefined" || typeof this.global.location.search === "undefined") {
            return;
          }
          var urlParams = this.getQueryParams(this.global.location.search);
          if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {
            var keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(",");
            keyValues.forEach(function(keyValue) {
              var _a = __read(keyValue.split(":"), 2), key = _a[0], value = _a[1];
              _this.urlFlags[key] = parseValue(key, value);
            });
          }
        };
        return Environment2;
      }()
    );
    function getQueryParams(queryString) {
      var params = {};
      queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, function(s) {
        var t = [];
        for (var _i = 1; _i < arguments.length; _i++) {
          t[_i - 1] = arguments[_i];
        }
        decodeParam(params, t[0], t[1]);
        return t.join("=");
      });
      return params;
    }
    function decodeParam(params, name, value) {
      params[decodeURIComponent(name)] = decodeURIComponent(value || "");
    }
    function parseValue(flagName, value) {
      var lowerCaseValue = value.toLowerCase();
      if (lowerCaseValue === "true" || lowerCaseValue === "false") {
        return lowerCaseValue === "true";
      } else if ("".concat(+lowerCaseValue) === lowerCaseValue) {
        return +lowerCaseValue;
      } else {
        return value;
      }
    }
    function env() {
      return exports.ENV;
    }
    exports.ENV = null;
    function setEnvironmentGlobal(environment) {
      exports.ENV = environment;
    }
    var globalNameSpace;
    function getGlobalNamespace() {
      if (globalNameSpace == null) {
        var ns = void 0;
        if (typeof window !== "undefined") {
          ns = window;
        } else if (typeof global !== "undefined") {
          ns = global;
        } else if (typeof process !== "undefined") {
          ns = process;
        } else if (typeof self !== "undefined") {
          ns = self;
        } else {
          throw new Error("Could not find a global object");
        }
        globalNameSpace = ns;
      }
      return globalNameSpace;
    }
    function getGlobalMap() {
      var ns = getGlobalNamespace();
      if (ns._tfGlobals == null) {
        ns._tfGlobals = /* @__PURE__ */ new Map();
      }
      return ns._tfGlobals;
    }
    function getGlobal(key, init) {
      var globalMap = getGlobalMap();
      if (globalMap.has(key)) {
        return globalMap.get(key);
      } else {
        var singleton = init();
        globalMap.set(key, singleton);
        return globalMap.get(key);
      }
    }
    var Abs = "Abs";
    var Acos = "Acos";
    var Acosh = "Acosh";
    var Add = "Add";
    var AddN = "AddN";
    var All = "All";
    var Any = "Any";
    var ArgMax = "ArgMax";
    var ArgMin = "ArgMin";
    var Asin = "Asin";
    var Asinh = "Asinh";
    var Atan = "Atan";
    var Atanh = "Atanh";
    var Atan2 = "Atan2";
    var AvgPool = "AvgPool";
    var AvgPoolGrad = "AvgPoolGrad";
    var AvgPool3D = "AvgPool3D";
    var AvgPool3DGrad = "AvgPool3DGrad";
    var BatchMatMul = "BatchMatMul";
    var BatchToSpaceND = "BatchToSpaceND";
    var Bincount = "Bincount";
    var BitwiseAnd = "BitwiseAnd";
    var BroadcastTo = "BroadcastTo";
    var BroadcastArgs = "BroadcastArgs";
    var Cast = "Cast";
    var Ceil = "Ceil";
    var ClipByValue = "ClipByValue";
    var Complex = "Complex";
    var ComplexAbs = "ComplexAbs";
    var Concat = "Concat";
    var Conv2D = "Conv2D";
    var Conv2DBackpropFilter = "Conv2DBackpropFilter";
    var Conv2DBackpropInput = "Conv2DBackpropInput";
    var Conv3D = "Conv3D";
    var Conv3DBackpropFilterV2 = "Conv3DBackpropFilterV2";
    var Conv3DBackpropInputV2 = "Conv3DBackpropInputV2";
    var Cos = "Cos";
    var Cosh = "Cosh";
    var Cumprod = "Cumprod";
    var Cumsum = "Cumsum";
    var CropAndResize = "CropAndResize";
    var DenseBincount = "DenseBincount";
    var DepthToSpace = "DepthToSpace";
    var DepthwiseConv2dNative = "DepthwiseConv2dNative";
    var DepthwiseConv2dNativeBackpropFilter = "DepthwiseConv2dNativeBackpropFilter";
    var DepthwiseConv2dNativeBackpropInput = "DepthwiseConv2dNativeBackpropInput";
    var Diag = "Diag";
    var Dilation2D = "Dilation2D";
    var Dilation2DBackpropInput = "Dilation2DBackpropInput";
    var Dilation2DBackpropFilter = "Dilation2DBackpropFilter";
    var Draw = "Draw";
    var RealDiv = "RealDiv";
    var Einsum = "Einsum";
    var Elu = "Elu";
    var EluGrad = "EluGrad";
    var Erf = "Erf";
    var Equal = "Equal";
    var Exp = "Exp";
    var ExpandDims = "ExpandDims";
    var Expm1 = "Expm1";
    var FFT = "FFT";
    var Fill = "Fill";
    var FlipLeftRight = "FlipLeftRight";
    var Floor = "Floor";
    var FloorDiv = "FloorDiv";
    var FusedBatchNorm = "FusedBatchNorm";
    var GatherV2 = "GatherV2";
    var GatherNd = "GatherNd";
    var Greater = "Greater";
    var GreaterEqual = "GreaterEqual";
    var Identity = "Identity";
    var IFFT = "IFFT";
    var Imag = "Imag";
    var IsFinite = "IsFinite";
    var IsInf = "IsInf";
    var IsNan = "IsNan";
    var LeakyRelu = "LeakyRelu";
    var Less = "Less";
    var LessEqual = "LessEqual";
    var LinSpace = "LinSpace";
    var Log = "Log";
    var Log1p = "Log1p";
    var LogicalAnd = "LogicalAnd";
    var LogicalNot = "LogicalNot";
    var LogicalOr = "LogicalOr";
    var LogicalXor = "LogicalXor";
    var LogSoftmax = "LogSoftmax";
    var LowerBound = "LowerBound";
    var LRN = "LRN";
    var LRNGrad = "LRNGrad";
    var MatrixBandPart = "MatrixBandPart";
    var Max = "Max";
    var Maximum = "Maximum";
    var MaxPool = "MaxPool";
    var MaxPoolGrad = "MaxPoolGrad";
    var MaxPool3D = "MaxPool3D";
    var MaxPool3DGrad = "MaxPool3DGrad";
    var MaxPoolWithArgmax = "MaxPoolWithArgmax";
    var Mean = "Mean";
    var Min = "Min";
    var Minimum = "Minimum";
    var MirrorPad = "MirrorPad";
    var Mod = "Mod";
    var Multinomial = "Multinomial";
    var Multiply = "Multiply";
    var Neg = "Neg";
    var NotEqual = "NotEqual";
    var NonMaxSuppressionV3 = "NonMaxSuppressionV3";
    var NonMaxSuppressionV4 = "NonMaxSuppressionV4";
    var NonMaxSuppressionV5 = "NonMaxSuppressionV5";
    var OnesLike = "OnesLike";
    var OneHot = "OneHot";
    var Pack = "Pack";
    var PadV2 = "PadV2";
    var Pool = "Pool";
    var Pow = "Pow";
    var Prelu = "Prelu";
    var Prod = "Prod";
    var RaggedGather = "RaggedGather";
    var RaggedRange = "RaggedRange";
    var RaggedTensorToTensor = "RaggedTensorToTensor";
    var Range = "Range";
    var Real = "Real";
    var Reciprocal = "Reciprocal";
    var Relu = "Relu";
    var Reshape = "Reshape";
    var ResizeNearestNeighbor = "ResizeNearestNeighbor";
    var ResizeNearestNeighborGrad = "ResizeNearestNeighborGrad";
    var ResizeBilinear = "ResizeBilinear";
    var ResizeBilinearGrad = "ResizeBilinearGrad";
    var Relu6 = "Relu6";
    var Reverse = "Reverse";
    var Round = "Round";
    var Rsqrt = "Rsqrt";
    var ScatterNd = "ScatterNd";
    var TensorScatterUpdate = "TensorScatterUpdate";
    var SearchSorted = "SearchSorted";
    var Select = "Select";
    var Selu = "Selu";
    var Slice = "Slice";
    var Sin = "Sin";
    var Sinh = "Sinh";
    var Sign = "Sign";
    var Sigmoid = "Sigmoid";
    var Softplus = "Softplus";
    var Sqrt = "Sqrt";
    var Sum = "Sum";
    var SpaceToBatchND = "SpaceToBatchND";
    var SplitV = "SplitV";
    var Softmax = "Softmax";
    var SparseFillEmptyRows = "SparseFillEmptyRows";
    var SparseReshape = "SparseReshape";
    var SparseSegmentMean = "SparseSegmentMean";
    var SparseSegmentSum = "SparseSegmentSum";
    var SparseToDense = "SparseToDense";
    var SquaredDifference = "SquaredDifference";
    var Square = "Square";
    var StaticRegexReplace = "StaticRegexReplace";
    var StridedSlice = "StridedSlice";
    var StringNGrams = "StringNGrams";
    var StringSplit = "StringSplit";
    var StringToHashBucketFast = "StringToHashBucketFast";
    var Sub = "Sub";
    var Tan = "Tan";
    var Tanh = "Tanh";
    var Tile = "Tile";
    var TopK = "TopK";
    var Transform = "Transform";
    var Transpose = "Transpose";
    var Unique = "Unique";
    var Unpack = "Unpack";
    var UnsortedSegmentSum = "UnsortedSegmentSum";
    var UpperBound = "UpperBound";
    var ZerosLike = "ZerosLike";
    var Step = "Step";
    var FromPixels = "FromPixels";
    var RotateWithOffset = "RotateWithOffset";
    var _FusedMatMul = "_FusedMatMul";
    var FusedConv2D = "FusedConv2D";
    var FusedDepthwiseConv2D = "FusedDepthwiseConv2D";
    function warn() {
      var msg = [];
      for (var _i = 0; _i < arguments.length; _i++) {
        msg[_i] = arguments[_i];
      }
      if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
        console.warn.apply(console, __spreadArray([], __read(msg), false));
      }
    }
    function log$1() {
      var msg = [];
      for (var _i = 0; _i < arguments.length; _i++) {
        msg[_i] = arguments[_i];
      }
      if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
        console.log.apply(console, __spreadArray([], __read(msg), false));
      }
    }
    var kernelRegistry = getGlobal("kernelRegistry", function() {
      return /* @__PURE__ */ new Map();
    });
    var gradRegistry = getGlobal("gradRegistry", function() {
      return /* @__PURE__ */ new Map();
    });
    function getKernel(kernelName, backendName) {
      var key = makeKey(kernelName, backendName);
      return kernelRegistry.get(key);
    }
    function getGradient(kernelName) {
      return gradRegistry.get(kernelName);
    }
    function getKernelsForBackend(backendName) {
      var it = kernelRegistry.entries();
      var result = [];
      while (true) {
        var _a = it.next(), done = _a.done, value = _a.value;
        if (done) {
          break;
        }
        var _b = __read(value, 2), key = _b[0], config = _b[1];
        var _c = __read(key.split("_"), 1), backend2 = _c[0];
        if (backend2 === backendName) {
          result.push(config);
        }
      }
      return result;
    }
    function registerKernel(config) {
      var kernelName = config.kernelName, backendName = config.backendName;
      var key = makeKey(kernelName, backendName);
      if (kernelRegistry.has(key)) {
        warn("The kernel '".concat(kernelName, "' for backend ") + "'".concat(backendName, "' is already registered"));
      }
      kernelRegistry.set(key, config);
    }
    function registerGradient(config) {
      var kernelName = config.kernelName;
      if (gradRegistry.has(kernelName)) {
        if (env().getBool("DEBUG")) {
          warn("Overriding the gradient for '".concat(kernelName, "'"));
        }
      }
      gradRegistry.set(kernelName, config);
    }
    function unregisterKernel(kernelName, backendName) {
      var key = makeKey(kernelName, backendName);
      if (!kernelRegistry.has(key)) {
        throw new Error("The kernel '".concat(kernelName, "' for backend ") + "'".concat(backendName, "' is not registered"));
      }
      kernelRegistry.delete(key);
    }
    function unregisterGradient(kernelName) {
      if (!gradRegistry.has(kernelName)) {
        throw new Error("The gradient '".concat(kernelName, "' for backend is not registered"));
      }
      gradRegistry.delete(kernelName);
    }
    function copyRegisteredKernels(registeredBackendName, newBackendName) {
      var kernels = getKernelsForBackend(registeredBackendName);
      kernels.forEach(function(kernelConfig) {
        var newKernelConfig = Object.assign({}, kernelConfig, { backendName: newBackendName });
        registerKernel(newKernelConfig);
      });
    }
    function makeKey(kernelName, backendName) {
      return "".concat(backendName, "_").concat(kernelName);
    }
    function isTypedArrayBrowser(a) {
      return a instanceof Float32Array || a instanceof Int32Array || a instanceof Uint8Array || a instanceof Uint8ClampedArray;
    }
    var commonjsGlobal = typeof globalThis !== "undefined" ? globalThis : typeof window !== "undefined" ? window : typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : {};
    function getDefaultExportFromCjs(x) {
      return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, "default") ? x["default"] : x;
    }
    var long = Long$1;
    var wasm = null;
    try {
      wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([
        0,
        97,
        115,
        109,
        1,
        0,
        0,
        0,
        1,
        13,
        2,
        96,
        0,
        1,
        127,
        96,
        4,
        127,
        127,
        127,
        127,
        1,
        127,
        3,
        7,
        6,
        0,
        1,
        1,
        1,
        1,
        1,
        6,
        6,
        1,
        127,
        1,
        65,
        0,
        11,
        7,
        50,
        6,
        3,
        109,
        117,
        108,
        0,
        1,
        5,
        100,
        105,
        118,
        95,
        115,
        0,
        2,
        5,
        100,
        105,
        118,
        95,
        117,
        0,
        3,
        5,
        114,
        101,
        109,
        95,
        115,
        0,
        4,
        5,
        114,
        101,
        109,
        95,
        117,
        0,
        5,
        8,
        103,
        101,
        116,
        95,
        104,
        105,
        103,
        104,
        0,
        0,
        10,
        191,
        1,
        6,
        4,
        0,
        35,
        0,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        126,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        127,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        128,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        129,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        130,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11
      ])), {}).exports;
    } catch (e) {
    }
    function Long$1(low, high, unsigned) {
      this.low = low | 0;
      this.high = high | 0;
      this.unsigned = !!unsigned;
    }
    Long$1.prototype.__isLong__;
    Object.defineProperty(Long$1.prototype, "__isLong__", { value: true });
    function isLong(obj) {
      return (obj && obj["__isLong__"]) === true;
    }
    Long$1.isLong = isLong;
    var INT_CACHE = {};
    var UINT_CACHE = {};
    function fromInt(value, unsigned) {
      var obj, cachedObj, cache;
      if (unsigned) {
        value >>>= 0;
        if (cache = 0 <= value && value < 256) {
          cachedObj = UINT_CACHE[value];
          if (cachedObj)
            return cachedObj;
        }
        obj = fromBits(value, (value | 0) < 0 ? -1 : 0, true);
        if (cache)
          UINT_CACHE[value] = obj;
        return obj;
      } else {
        value |= 0;
        if (cache = -128 <= value && value < 128) {
          cachedObj = INT_CACHE[value];
          if (cachedObj)
            return cachedObj;
        }
        obj = fromBits(value, value < 0 ? -1 : 0, false);
        if (cache)
          INT_CACHE[value] = obj;
        return obj;
      }
    }
    Long$1.fromInt = fromInt;
    function fromNumber(value, unsigned) {
      if (isNaN(value))
        return unsigned ? UZERO : ZERO;
      if (unsigned) {
        if (value < 0)
          return UZERO;
        if (value >= TWO_PWR_64_DBL)
          return MAX_UNSIGNED_VALUE;
      } else {
        if (value <= -TWO_PWR_63_DBL)
          return MIN_VALUE;
        if (value + 1 >= TWO_PWR_63_DBL)
          return MAX_VALUE;
      }
      if (value < 0)
        return fromNumber(-value, unsigned).neg();
      return fromBits(value % TWO_PWR_32_DBL | 0, value / TWO_PWR_32_DBL | 0, unsigned);
    }
    Long$1.fromNumber = fromNumber;
    function fromBits(lowBits, highBits, unsigned) {
      return new Long$1(lowBits, highBits, unsigned);
    }
    Long$1.fromBits = fromBits;
    var pow_dbl = Math.pow;
    function fromString(str, unsigned, radix) {
      if (str.length === 0)
        throw Error("empty string");
      if (str === "NaN" || str === "Infinity" || str === "+Infinity" || str === "-Infinity")
        return ZERO;
      if (typeof unsigned === "number") {
        radix = unsigned, unsigned = false;
      } else {
        unsigned = !!unsigned;
      }
      radix = radix || 10;
      if (radix < 2 || 36 < radix)
        throw RangeError("radix");
      var p;
      if ((p = str.indexOf("-")) > 0)
        throw Error("interior hyphen");
      else if (p === 0) {
        return fromString(str.substring(1), unsigned, radix).neg();
      }
      var radixToPower = fromNumber(pow_dbl(radix, 8));
      var result = ZERO;
      for (var i = 0; i < str.length; i += 8) {
        var size = Math.min(8, str.length - i), value = parseInt(str.substring(i, i + size), radix);
        if (size < 8) {
          var power = fromNumber(pow_dbl(radix, size));
          result = result.mul(power).add(fromNumber(value));
        } else {
          result = result.mul(radixToPower);
          result = result.add(fromNumber(value));
        }
      }
      result.unsigned = unsigned;
      return result;
    }
    Long$1.fromString = fromString;
    function fromValue(val, unsigned) {
      if (typeof val === "number")
        return fromNumber(val, unsigned);
      if (typeof val === "string")
        return fromString(val, unsigned);
      return fromBits(val.low, val.high, typeof unsigned === "boolean" ? unsigned : val.unsigned);
    }
    Long$1.fromValue = fromValue;
    var TWO_PWR_16_DBL = 1 << 16;
    var TWO_PWR_24_DBL = 1 << 24;
    var TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;
    var TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;
    var TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;
    var TWO_PWR_24 = fromInt(TWO_PWR_24_DBL);
    var ZERO = fromInt(0);
    Long$1.ZERO = ZERO;
    var UZERO = fromInt(0, true);
    Long$1.UZERO = UZERO;
    var ONE = fromInt(1);
    Long$1.ONE = ONE;
    var UONE = fromInt(1, true);
    Long$1.UONE = UONE;
    var NEG_ONE = fromInt(-1);
    Long$1.NEG_ONE = NEG_ONE;
    var MAX_VALUE = fromBits(4294967295 | 0, 2147483647 | 0, false);
    Long$1.MAX_VALUE = MAX_VALUE;
    var MAX_UNSIGNED_VALUE = fromBits(4294967295 | 0, 4294967295 | 0, true);
    Long$1.MAX_UNSIGNED_VALUE = MAX_UNSIGNED_VALUE;
    var MIN_VALUE = fromBits(0, 2147483648 | 0, false);
    Long$1.MIN_VALUE = MIN_VALUE;
    var LongPrototype = Long$1.prototype;
    LongPrototype.toInt = function toInt() {
      return this.unsigned ? this.low >>> 0 : this.low;
    };
    LongPrototype.toNumber = function toNumber() {
      if (this.unsigned)
        return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);
      return this.high * TWO_PWR_32_DBL + (this.low >>> 0);
    };
    LongPrototype.toString = function toString(radix) {
      radix = radix || 10;
      if (radix < 2 || 36 < radix)
        throw RangeError("radix");
      if (this.isZero())
        return "0";
      if (this.isNegative()) {
        if (this.eq(MIN_VALUE)) {
          var radixLong = fromNumber(radix), div2 = this.div(radixLong), rem1 = div2.mul(radixLong).sub(this);
          return div2.toString(radix) + rem1.toInt().toString(radix);
        } else
          return "-" + this.neg().toString(radix);
      }
      var radixToPower = fromNumber(pow_dbl(radix, 6), this.unsigned), rem = this;
      var result = "";
      while (true) {
        var remDiv = rem.div(radixToPower), intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0, digits = intval.toString(radix);
        rem = remDiv;
        if (rem.isZero())
          return digits + result;
        else {
          while (digits.length < 6)
            digits = "0" + digits;
          result = "" + digits + result;
        }
      }
    };
    LongPrototype.getHighBits = function getHighBits() {
      return this.high;
    };
    LongPrototype.getHighBitsUnsigned = function getHighBitsUnsigned() {
      return this.high >>> 0;
    };
    LongPrototype.getLowBits = function getLowBits() {
      return this.low;
    };
    LongPrototype.getLowBitsUnsigned = function getLowBitsUnsigned() {
      return this.low >>> 0;
    };
    LongPrototype.getNumBitsAbs = function getNumBitsAbs() {
      if (this.isNegative())
        return this.eq(MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();
      var val = this.high != 0 ? this.high : this.low;
      for (var bit = 31; bit > 0; bit--)
        if ((val & 1 << bit) != 0)
          break;
      return this.high != 0 ? bit + 33 : bit + 1;
    };
    LongPrototype.isZero = function isZero() {
      return this.high === 0 && this.low === 0;
    };
    LongPrototype.eqz = LongPrototype.isZero;
    LongPrototype.isNegative = function isNegative() {
      return !this.unsigned && this.high < 0;
    };
    LongPrototype.isPositive = function isPositive() {
      return this.unsigned || this.high >= 0;
    };
    LongPrototype.isOdd = function isOdd() {
      return (this.low & 1) === 1;
    };
    LongPrototype.isEven = function isEven() {
      return (this.low & 1) === 0;
    };
    LongPrototype.equals = function equals(other) {
      if (!isLong(other))
        other = fromValue(other);
      if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1)
        return false;
      return this.high === other.high && this.low === other.low;
    };
    LongPrototype.eq = LongPrototype.equals;
    LongPrototype.notEquals = function notEquals(other) {
      return !this.eq(
        /* validates */
        other
      );
    };
    LongPrototype.neq = LongPrototype.notEquals;
    LongPrototype.ne = LongPrototype.notEquals;
    LongPrototype.lessThan = function lessThan(other) {
      return this.comp(
        /* validates */
        other
      ) < 0;
    };
    LongPrototype.lt = LongPrototype.lessThan;
    LongPrototype.lessThanOrEqual = function lessThanOrEqual(other) {
      return this.comp(
        /* validates */
        other
      ) <= 0;
    };
    LongPrototype.lte = LongPrototype.lessThanOrEqual;
    LongPrototype.le = LongPrototype.lessThanOrEqual;
    LongPrototype.greaterThan = function greaterThan(other) {
      return this.comp(
        /* validates */
        other
      ) > 0;
    };
    LongPrototype.gt = LongPrototype.greaterThan;
    LongPrototype.greaterThanOrEqual = function greaterThanOrEqual(other) {
      return this.comp(
        /* validates */
        other
      ) >= 0;
    };
    LongPrototype.gte = LongPrototype.greaterThanOrEqual;
    LongPrototype.ge = LongPrototype.greaterThanOrEqual;
    LongPrototype.compare = function compare(other) {
      if (!isLong(other))
        other = fromValue(other);
      if (this.eq(other))
        return 0;
      var thisNeg = this.isNegative(), otherNeg = other.isNegative();
      if (thisNeg && !otherNeg)
        return -1;
      if (!thisNeg && otherNeg)
        return 1;
      if (!this.unsigned)
        return this.sub(other).isNegative() ? -1 : 1;
      return other.high >>> 0 > this.high >>> 0 || other.high === this.high && other.low >>> 0 > this.low >>> 0 ? -1 : 1;
    };
    LongPrototype.comp = LongPrototype.compare;
    LongPrototype.negate = function negate() {
      if (!this.unsigned && this.eq(MIN_VALUE))
        return MIN_VALUE;
      return this.not().add(ONE);
    };
    LongPrototype.neg = LongPrototype.negate;
    LongPrototype.add = function add2(addend) {
      if (!isLong(addend))
        addend = fromValue(addend);
      var a48 = this.high >>> 16;
      var a32 = this.high & 65535;
      var a16 = this.low >>> 16;
      var a00 = this.low & 65535;
      var b48 = addend.high >>> 16;
      var b32 = addend.high & 65535;
      var b16 = addend.low >>> 16;
      var b00 = addend.low & 65535;
      var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
      c00 += a00 + b00;
      c16 += c00 >>> 16;
      c00 &= 65535;
      c16 += a16 + b16;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c32 += a32 + b32;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c48 += a48 + b48;
      c48 &= 65535;
      return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
    };
    LongPrototype.subtract = function subtract(subtrahend) {
      if (!isLong(subtrahend))
        subtrahend = fromValue(subtrahend);
      return this.add(subtrahend.neg());
    };
    LongPrototype.sub = LongPrototype.subtract;
    LongPrototype.multiply = function multiply(multiplier) {
      if (this.isZero())
        return ZERO;
      if (!isLong(multiplier))
        multiplier = fromValue(multiplier);
      if (wasm) {
        var low = wasm.mul(this.low, this.high, multiplier.low, multiplier.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      if (multiplier.isZero())
        return ZERO;
      if (this.eq(MIN_VALUE))
        return multiplier.isOdd() ? MIN_VALUE : ZERO;
      if (multiplier.eq(MIN_VALUE))
        return this.isOdd() ? MIN_VALUE : ZERO;
      if (this.isNegative()) {
        if (multiplier.isNegative())
          return this.neg().mul(multiplier.neg());
        else
          return this.neg().mul(multiplier).neg();
      } else if (multiplier.isNegative())
        return this.mul(multiplier.neg()).neg();
      if (this.lt(TWO_PWR_24) && multiplier.lt(TWO_PWR_24))
        return fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned);
      var a48 = this.high >>> 16;
      var a32 = this.high & 65535;
      var a16 = this.low >>> 16;
      var a00 = this.low & 65535;
      var b48 = multiplier.high >>> 16;
      var b32 = multiplier.high & 65535;
      var b16 = multiplier.low >>> 16;
      var b00 = multiplier.low & 65535;
      var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
      c00 += a00 * b00;
      c16 += c00 >>> 16;
      c00 &= 65535;
      c16 += a16 * b00;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c16 += a00 * b16;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c32 += a32 * b00;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c32 += a16 * b16;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c32 += a00 * b32;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;
      c48 &= 65535;
      return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
    };
    LongPrototype.mul = LongPrototype.multiply;
    LongPrototype.divide = function divide(divisor) {
      if (!isLong(divisor))
        divisor = fromValue(divisor);
      if (divisor.isZero())
        throw Error("division by zero");
      if (wasm) {
        if (!this.unsigned && this.high === -2147483648 && divisor.low === -1 && divisor.high === -1) {
          return this;
        }
        var low = (this.unsigned ? wasm.div_u : wasm.div_s)(this.low, this.high, divisor.low, divisor.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      if (this.isZero())
        return this.unsigned ? UZERO : ZERO;
      var approx, rem, res;
      if (!this.unsigned) {
        if (this.eq(MIN_VALUE)) {
          if (divisor.eq(ONE) || divisor.eq(NEG_ONE))
            return MIN_VALUE;
          else if (divisor.eq(MIN_VALUE))
            return ONE;
          else {
            var halfThis = this.shr(1);
            approx = halfThis.div(divisor).shl(1);
            if (approx.eq(ZERO)) {
              return divisor.isNegative() ? ONE : NEG_ONE;
            } else {
              rem = this.sub(divisor.mul(approx));
              res = approx.add(rem.div(divisor));
              return res;
            }
          }
        } else if (divisor.eq(MIN_VALUE))
          return this.unsigned ? UZERO : ZERO;
        if (this.isNegative()) {
          if (divisor.isNegative())
            return this.neg().div(divisor.neg());
          return this.neg().div(divisor).neg();
        } else if (divisor.isNegative())
          return this.div(divisor.neg()).neg();
        res = ZERO;
      } else {
        if (!divisor.unsigned)
          divisor = divisor.toUnsigned();
        if (divisor.gt(this))
          return UZERO;
        if (divisor.gt(this.shru(1)))
          return UONE;
        res = UZERO;
      }
      rem = this;
      while (rem.gte(divisor)) {
        approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));
        var log2 = Math.ceil(Math.log(approx) / Math.LN2), delta = log2 <= 48 ? 1 : pow_dbl(2, log2 - 48), approxRes = fromNumber(approx), approxRem = approxRes.mul(divisor);
        while (approxRem.isNegative() || approxRem.gt(rem)) {
          approx -= delta;
          approxRes = fromNumber(approx, this.unsigned);
          approxRem = approxRes.mul(divisor);
        }
        if (approxRes.isZero())
          approxRes = ONE;
        res = res.add(approxRes);
        rem = rem.sub(approxRem);
      }
      return res;
    };
    LongPrototype.div = LongPrototype.divide;
    LongPrototype.modulo = function modulo(divisor) {
      if (!isLong(divisor))
        divisor = fromValue(divisor);
      if (wasm) {
        var low = (this.unsigned ? wasm.rem_u : wasm.rem_s)(this.low, this.high, divisor.low, divisor.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      return this.sub(this.div(divisor).mul(divisor));
    };
    LongPrototype.mod = LongPrototype.modulo;
    LongPrototype.rem = LongPrototype.modulo;
    LongPrototype.not = function not() {
      return fromBits(~this.low, ~this.high, this.unsigned);
    };
    LongPrototype.and = function and(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low & other.low, this.high & other.high, this.unsigned);
    };
    LongPrototype.or = function or(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low | other.low, this.high | other.high, this.unsigned);
    };
    LongPrototype.xor = function xor(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);
    };
    LongPrototype.shiftLeft = function shiftLeft(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      if ((numBits &= 63) === 0)
        return this;
      else if (numBits < 32)
        return fromBits(this.low << numBits, this.high << numBits | this.low >>> 32 - numBits, this.unsigned);
      else
        return fromBits(0, this.low << numBits - 32, this.unsigned);
    };
    LongPrototype.shl = LongPrototype.shiftLeft;
    LongPrototype.shiftRight = function shiftRight(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      if ((numBits &= 63) === 0)
        return this;
      else if (numBits < 32)
        return fromBits(this.low >>> numBits | this.high << 32 - numBits, this.high >> numBits, this.unsigned);
      else
        return fromBits(this.high >> numBits - 32, this.high >= 0 ? 0 : -1, this.unsigned);
    };
    LongPrototype.shr = LongPrototype.shiftRight;
    LongPrototype.shiftRightUnsigned = function shiftRightUnsigned(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      numBits &= 63;
      if (numBits === 0)
        return this;
      else {
        var high = this.high;
        if (numBits < 32) {
          var low = this.low;
          return fromBits(low >>> numBits | high << 32 - numBits, high >>> numBits, this.unsigned);
        } else if (numBits === 32)
          return fromBits(high, 0, this.unsigned);
        else
          return fromBits(high >>> numBits - 32, 0, this.unsigned);
      }
    };
    LongPrototype.shru = LongPrototype.shiftRightUnsigned;
    LongPrototype.shr_u = LongPrototype.shiftRightUnsigned;
    LongPrototype.toSigned = function toSigned() {
      if (!this.unsigned)
        return this;
      return fromBits(this.low, this.high, false);
    };
    LongPrototype.toUnsigned = function toUnsigned() {
      if (this.unsigned)
        return this;
      return fromBits(this.low, this.high, true);
    };
    LongPrototype.toBytes = function toBytes(le) {
      return le ? this.toBytesLE() : this.toBytesBE();
    };
    LongPrototype.toBytesLE = function toBytesLE() {
      var hi = this.high, lo = this.low;
      return [
        lo & 255,
        lo >>> 8 & 255,
        lo >>> 16 & 255,
        lo >>> 24,
        hi & 255,
        hi >>> 8 & 255,
        hi >>> 16 & 255,
        hi >>> 24
      ];
    };
    LongPrototype.toBytesBE = function toBytesBE() {
      var hi = this.high, lo = this.low;
      return [
        hi >>> 24,
        hi >>> 16 & 255,
        hi >>> 8 & 255,
        hi & 255,
        lo >>> 24,
        lo >>> 16 & 255,
        lo >>> 8 & 255,
        lo & 255
      ];
    };
    Long$1.fromBytes = function fromBytes(bytes, unsigned, le) {
      return le ? Long$1.fromBytesLE(bytes, unsigned) : Long$1.fromBytesBE(bytes, unsigned);
    };
    Long$1.fromBytesLE = function fromBytesLE(bytes, unsigned) {
      return new Long$1(bytes[0] | bytes[1] << 8 | bytes[2] << 16 | bytes[3] << 24, bytes[4] | bytes[5] << 8 | bytes[6] << 16 | bytes[7] << 24, unsigned);
    };
    Long$1.fromBytesBE = function fromBytesBE(bytes, unsigned) {
      return new Long$1(bytes[4] << 24 | bytes[5] << 16 | bytes[6] << 8 | bytes[7], bytes[0] << 24 | bytes[1] << 16 | bytes[2] << 8 | bytes[3], unsigned);
    };
    var long$1 = /* @__PURE__ */ getDefaultExportFromCjs(long);
    var LongExports = /* @__PURE__ */ _mergeNamespaces({
      __proto__: null,
      default: long$1
    }, [long]);
    var Long = (
      // tslint:disable-next-line
      long$1 || LongExports
    );
    function hexToLong(hex) {
      return Long.fromString(hex, true, 16);
    }
    var k0 = hexToLong("c3a5c85c97cb3127");
    var k1 = hexToLong("b492b66fbe98f273");
    var k2 = hexToLong("9ae16a3b2f90404f");
    function shiftMix(val) {
      return val.xor(val.shru(47));
    }
    function fetch$2(s, offset, numBytes) {
      var bytes = s.slice(offset, offset + numBytes);
      return Long.fromBytes(Array.from(bytes), true, true);
    }
    function fetch64(s, offset) {
      return fetch$2(s, offset, 8);
    }
    function fetch32(s, offset) {
      return fetch$2(s, offset, 4);
    }
    function rotate64(val, shift) {
      return shift === 0 ? val : val.shru(shift).or(val.shl(64 - shift));
    }
    function hashLen16(u, v, mul2) {
      if (mul2 === void 0) {
        mul2 = hexToLong("9ddfea08eb382d69");
      }
      var a = u.xor(v).mul(mul2);
      a = a.xor(a.shru(47));
      var b = v.xor(a).mul(mul2);
      b = b.xor(b.shru(47));
      b = b.mul(mul2);
      return b;
    }
    function weakHashLen32WithSeeds(w, x, y, z, a, b) {
      a = a.add(w);
      b = rotate64(b.add(a).add(z), 21);
      var c = a;
      a = a.add(x);
      a = a.add(y);
      b = b.add(rotate64(a, 44));
      return [a.add(z), b.add(c)];
    }
    function weakHashLen32WithSeedsStr(s, offset, a, b) {
      return weakHashLen32WithSeeds(fetch64(s, offset), fetch64(s, offset + 8), fetch64(s, offset + 16), fetch64(s, offset + 24), a, b);
    }
    function hashLen0to16(s, len) {
      if (len === void 0) {
        len = s.length;
      }
      if (len >= 8) {
        var mul2 = k2.add(len * 2);
        var a = fetch64(s, 0).add(k2);
        var b = fetch64(s, len - 8);
        var c = rotate64(b, 37).mul(mul2).add(a);
        var d = rotate64(a, 25).add(b).mul(mul2);
        return hashLen16(c, d, mul2);
      }
      if (len >= 4) {
        var mul2 = k2.add(len * 2);
        var a = fetch32(s, 0);
        return hashLen16(a.shl(3).add(len), fetch32(s, len - 4), mul2);
      }
      if (len > 0) {
        var a = s[0];
        var b = s[len >> 1];
        var c = s[len - 1];
        var y = a + (b << 8);
        var z = len + (c << 2);
        return shiftMix(k2.mul(y).xor(k0.mul(z))).mul(k2);
      }
      return k2;
    }
    function hashLen17to32(s, len) {
      if (len === void 0) {
        len = s.length;
      }
      var mul2 = k2.add(len * 2);
      var a = fetch64(s, 0).mul(k1);
      var b = fetch64(s, 8);
      var c = fetch64(s, len - 8).mul(mul2);
      var d = fetch64(s, len - 16).mul(k2);
      return hashLen16(rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d), a.add(rotate64(b.add(k2), 18)).add(c), mul2);
    }
    function hashLen33to64(s, len) {
      if (len === void 0) {
        len = s.length;
      }
      var mul2 = k2.add(len * 2);
      var a = fetch64(s, 0).mul(k2);
      var b = fetch64(s, 8);
      var c = fetch64(s, len - 8).mul(mul2);
      var d = fetch64(s, len - 16).mul(k2);
      var y = rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d);
      var z = hashLen16(y, a.add(rotate64(b.add(k2), 18)).add(c), mul2);
      var e = fetch64(s, 16).mul(mul2);
      var f = fetch64(s, 24);
      var g = y.add(fetch64(s, len - 32)).mul(mul2);
      var h = z.add(fetch64(s, len - 24)).mul(mul2);
      return hashLen16(rotate64(e.add(f), 43).add(rotate64(g, 30)).add(h), e.add(rotate64(f.add(a), 18)).add(g), mul2);
    }
    function fingerPrint64(s, len) {
      var _a, _b;
      if (len === void 0) {
        len = s.length;
      }
      var seed = Long.fromNumber(81, true);
      if (len <= 32) {
        if (len <= 16) {
          return hashLen0to16(s, len);
        } else {
          return hashLen17to32(s, len);
        }
      } else if (len <= 64) {
        return hashLen33to64(s, len);
      }
      var x = seed;
      var y = seed.mul(k1).add(113);
      var z = shiftMix(y.mul(k2).add(113)).mul(k2);
      var v = [Long.UZERO, Long.UZERO];
      var w = [Long.UZERO, Long.UZERO];
      x = x.mul(k2).add(fetch64(s, 0));
      var offset = 0;
      var end = (len - 1 >> 6) * 64;
      var last64 = end + (len - 1 & 63) - 63;
      do {
        x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(k1);
        y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(k1);
        x = x.xor(w[1]);
        y = y.add(v[0]).add(fetch64(s, offset + 40));
        z = rotate64(z.add(w[0]), 33).mul(k1);
        v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(k1), x.add(w[0]));
        w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));
        _a = __read([x, z], 2), z = _a[0], x = _a[1];
        offset += 64;
      } while (offset !== end);
      var mul2 = k1.add(z.and(255).shl(1));
      offset = last64;
      w[0] = w[0].add(len - 1 & 63);
      v[0] = v[0].add(w[0]);
      w[0] = w[0].add(v[0]);
      x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(mul2);
      y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(mul2);
      x = x.xor(w[1].mul(9));
      y = y.add(v[0].mul(9).add(fetch64(s, offset + 40)));
      z = rotate64(z.add(w[0]), 33).mul(mul2);
      v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(mul2), x.add(w[0]));
      w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));
      _b = __read([x, z], 2), z = _b[0], x = _b[1];
      return hashLen16(hashLen16(v[0], w[0], mul2).add(shiftMix(y).mul(k0)).add(z), hashLen16(v[1], w[1], mul2).add(x), mul2);
    }
    function createScalarValue(value, dtype) {
      if (dtype === "string") {
        return encodeString(value);
      }
      return toTypedArray([value], dtype);
    }
    function noConversionNeeded(a, dtype) {
      return a instanceof Float32Array && dtype === "float32" || a instanceof Int32Array && dtype === "int32" || a instanceof Uint8Array && dtype === "bool";
    }
    function toTypedArray(a, dtype) {
      if (dtype === "string") {
        throw new Error("Cannot convert a string[] to a TypedArray");
      }
      if (Array.isArray(a)) {
        a = flatten(a);
      }
      if (env().getBool("DEBUG")) {
        checkConversionForErrors(a, dtype);
      }
      if (noConversionNeeded(a, dtype)) {
        return a;
      }
      if (dtype == null || dtype === "float32" || dtype === "complex64") {
        return new Float32Array(a);
      } else if (dtype === "int32") {
        return new Int32Array(a);
      } else if (dtype === "bool") {
        var bool = new Uint8Array(a.length);
        for (var i = 0; i < bool.length; ++i) {
          if (Math.round(a[i]) !== 0) {
            bool[i] = 1;
          }
        }
        return bool;
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
    }
    function now() {
      return env().platform.now();
    }
    function fetch$1(path, requestInits) {
      return env().platform.fetch(path, requestInits);
    }
    function encodeString(s, encoding) {
      if (encoding === void 0) {
        encoding = "utf-8";
      }
      encoding = encoding || "utf-8";
      return env().platform.encode(s, encoding);
    }
    function decodeString(bytes, encoding) {
      if (encoding === void 0) {
        encoding = "utf-8";
      }
      encoding = encoding || "utf-8";
      return env().platform.decode(bytes, encoding);
    }
    function isTypedArray(a) {
      if (env().platform.isTypedArray != null) {
        return env().platform.isTypedArray(a);
      } else {
        return isTypedArrayBrowser(a);
      }
    }
    function flatten(arr, result, skipTypedArray) {
      var e_1, _a;
      if (result === void 0) {
        result = [];
      }
      if (skipTypedArray === void 0) {
        skipTypedArray = false;
      }
      if (result == null) {
        result = [];
      }
      if (typeof arr === "boolean" || typeof arr === "number" || typeof arr === "string" || isPromise(arr) || arr == null || isTypedArray(arr) && skipTypedArray) {
        result.push(arr);
      } else if (Array.isArray(arr) || isTypedArray(arr)) {
        for (var i = 0; i < arr.length; ++i) {
          flatten(arr[i], result, skipTypedArray);
        }
      } else {
        var maxIndex = -1;
        try {
          for (var _b = __values(Object.keys(arr)), _c = _b.next(); !_c.done; _c = _b.next()) {
            var key = _c.value;
            if (/^([1-9]+[0-9]*|0)$/.test(key)) {
              maxIndex = Math.max(maxIndex, Number(key));
            }
          }
        } catch (e_1_1) {
          e_1 = { error: e_1_1 };
        } finally {
          try {
            if (_c && !_c.done && (_a = _b.return))
              _a.call(_b);
          } finally {
            if (e_1)
              throw e_1.error;
          }
        }
        for (var i = 0; i <= maxIndex; i++) {
          flatten(arr[i], result, skipTypedArray);
        }
      }
      return result;
    }
    var util = {
      __proto__: null,
      arraysEqual,
      arraysEqualWithNull,
      assert,
      assertNonNegativeIntegerDimensions,
      assertNonNull,
      assertShapesMatch,
      bytesFromStringArray,
      bytesPerElement,
      checkConversionForErrors,
      clamp,
      computeStrides,
      convertBackendValuesAndArrayBuffer,
      createScalarValue,
      createShuffledIndices,
      decodeString,
      distSquared,
      encodeString,
      fetch: fetch$1,
      fingerPrint64,
      flatten,
      getArrayFromDType,
      getTypedArrayFromDType,
      hasEncodingLoss,
      hexToLong,
      indexToLoc,
      inferDtype,
      inferFromImplicitShape,
      isBoolean,
      isFunction,
      isInt,
      isNumber,
      isPromise,
      isScalarShape,
      isString,
      isTypedArray,
      isValidDtype,
      locToIndex,
      makeOnesTypedArray,
      makeZerosNestedTypedArray,
      makeZerosTypedArray,
      nearestDivisor,
      nearestLargerEven,
      now,
      parseAxisParam,
      randUniform,
      repeatedTry,
      rightPad,
      shuffle,
      shuffleCombo,
      sizeFromShape,
      sizeToSquarishShape,
      squeezeShape,
      sum: sum$1,
      swap,
      tanh: tanh$1,
      toNestedArray,
      toTypedArray
    };
    var Profiler = (
      /** @class */
      function() {
        function Profiler2(backendTimer, logger) {
          this.backendTimer = backendTimer;
          this.logger = logger;
          if (logger == null) {
            this.logger = new Logger();
          }
        }
        Profiler2.prototype.profileKernel = function(kernelName, inputs, f) {
          var e_1, _a;
          var outputs;
          var holdResultWrapperFn = function() {
            outputs = f();
          };
          var timer;
          var start = now();
          if (this.backendTimer.timerAvailable()) {
            timer = this.backendTimer.time(holdResultWrapperFn);
          } else {
            holdResultWrapperFn();
            try {
              for (var outputs_1 = __values(outputs), outputs_1_1 = outputs_1.next(); !outputs_1_1.done; outputs_1_1 = outputs_1.next()) {
                var output = outputs_1_1.value;
                output.dataSync();
              }
            } catch (e_1_1) {
              e_1 = { error: e_1_1 };
            } finally {
              try {
                if (outputs_1_1 && !outputs_1_1.done && (_a = outputs_1.return))
                  _a.call(outputs_1);
              } finally {
                if (e_1)
                  throw e_1.error;
              }
            }
            timer = Promise.resolve({ kernelMs: now() - start });
          }
          if (env().getBool("CHECK_COMPUTATION_FOR_ERRORS")) {
            var _loop_1 = function(i2) {
              var output2 = outputs[i2];
              output2.data().then(function(tensorVals) {
                checkComputationForErrors(tensorVals, output2.dtype, kernelName);
              });
            };
            for (var i = 0; i < outputs.length; i++) {
              _loop_1(i);
            }
          }
          var kernelProfile = {
            kernelName,
            outputs,
            inputs,
            timeMs: timer.then(function(timing) {
              return timing.kernelMs;
            }),
            extraInfo: timer.then(function(timing) {
              return timing.getExtraProfileInfo != null ? timing.getExtraProfileInfo() : "";
            })
          };
          return kernelProfile;
        };
        Profiler2.prototype.logKernelProfile = function(kernelProfile) {
          var _this = this;
          var kernelName = kernelProfile.kernelName, outputs = kernelProfile.outputs, timeMs = kernelProfile.timeMs, inputs = kernelProfile.inputs, extraInfo = kernelProfile.extraInfo;
          outputs.forEach(function(result) {
            Promise.all([result.data(), timeMs, extraInfo]).then(function(valueContainer) {
              _this.logger.logKernelProfile(kernelName, result, valueContainer[0], valueContainer[1], inputs, valueContainer[2]);
            });
          });
        };
        return Profiler2;
      }()
    );
    function checkComputationForErrors(vals, dtype, kernelName) {
      if (dtype !== "float32") {
        return false;
      }
      for (var i = 0; i < vals.length; i++) {
        var num = vals[i];
        if (isNaN(num) || !isFinite(num)) {
          console.warn("Found ".concat(num, " in the result of '").concat(kernelName, "'"));
          return true;
        }
      }
      return false;
    }
    var Logger = (
      /** @class */
      function() {
        function Logger2() {
        }
        Logger2.prototype.logKernelProfile = function(name, result, vals, timeMs, inputs, extraInfo) {
          var time2 = typeof timeMs === "number" ? rightPad("".concat(timeMs, "ms"), 9) : timeMs["error"];
          var paddedName = rightPad(name, 25);
          var rank = result.rank;
          var size = result.size;
          var shape = rightPad(result.shape.toString(), 14);
          var inputShapesDescription = "";
          for (var name_1 in inputs) {
            var input = inputs[name_1];
            if (input != null) {
              var inputShape = input.shape || result.shape;
              var inputRank = inputShape.length;
              inputShapesDescription += "".concat(name_1, ": ").concat(inputRank, "D ").concat(inputRank > 0 ? inputShape : "", " ");
            }
          }
          console.log("%c".concat(paddedName, "	%c").concat(time2, "	%c").concat(rank, "D ").concat(shape, "	%c").concat(size, "	%c").concat(inputShapesDescription, "	%c").concat(extraInfo), "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
        };
        return Logger2;
      }()
    );
    function getFilteredNodesXToY(tape, xs, y) {
      var tensorsFromX = {};
      var nodesFromX = {};
      for (var i = 0; i < xs.length; i++) {
        tensorsFromX[xs[i].id] = true;
      }
      for (var i = 0; i < tape.length; i++) {
        var node = tape[i];
        var nodeInputs = node.inputs;
        for (var inputName in nodeInputs) {
          var input = nodeInputs[inputName];
          var anyInputFromX = false;
          for (var j = 0; j < xs.length; j++) {
            if (tensorsFromX[input.id]) {
              node.outputs.forEach(function(output) {
                return tensorsFromX[output.id] = true;
              });
              anyInputFromX = true;
              nodesFromX[node.id] = true;
              break;
            }
          }
          if (anyInputFromX) {
            break;
          }
        }
      }
      var tensorsLeadToY = {};
      tensorsLeadToY[y.id] = true;
      var nodesToY = {};
      for (var i = tape.length - 1; i >= 0; i--) {
        var node = tape[i];
        var nodeInputs = node.inputs;
        for (var j = 0; j < node.outputs.length; j++) {
          if (tensorsLeadToY[node.outputs[j].id]) {
            for (var inputName in nodeInputs) {
              tensorsLeadToY[nodeInputs[inputName].id] = true;
              nodesToY[node.id] = true;
            }
            break;
          }
        }
      }
      var filteredTape = [];
      for (var i = 0; i < tape.length; i++) {
        var node = tape[i];
        if (nodesFromX[node.id] && nodesToY[node.id]) {
          var prunedInputs = {};
          for (var inputName in node.inputs) {
            var nodeInput = node.inputs[inputName];
            if (tensorsFromX[nodeInput.id]) {
              prunedInputs[inputName] = nodeInput;
            }
          }
          var prunedNode = Object.assign({}, node);
          prunedNode.inputs = prunedInputs;
          prunedNode.outputs = node.outputs;
          filteredTape.push(prunedNode);
        }
      }
      return filteredTape;
    }
    function backpropagateGradients(tensorAccumulatedGradientMap, filteredTape, tidy2, add2) {
      var _loop_1 = function(i2) {
        var node = filteredTape[i2];
        var dys = [];
        node.outputs.forEach(function(o) {
          var gradTensor = tensorAccumulatedGradientMap[o.id];
          if (gradTensor != null) {
            dys.push(gradTensor);
          } else {
            dys.push(null);
          }
        });
        if (node.gradient == null) {
          throw new Error("Cannot compute gradient: gradient function not found " + "for ".concat(node.kernelName, "."));
        }
        var inputGradients = node.gradient(dys);
        var _loop_2 = function(inputName2) {
          if (!(inputName2 in inputGradients)) {
            throw new Error("Cannot backprop through input ".concat(inputName2, ". ") + "Available gradients found: ".concat(Object.keys(inputGradients), "."));
          }
          var dx = tidy2(function() {
            return inputGradients[inputName2]();
          });
          if (dx.dtype !== "float32") {
            throw new Error("Error in gradient for op ".concat(node.kernelName, ". The gradient of input ") + "".concat(inputName2, " must have 'float32' dtype, but has '").concat(dx.dtype, "'"));
          }
          var x = node.inputs[inputName2];
          if (!arraysEqual(dx.shape, x.shape)) {
            throw new Error("Error in gradient for op ".concat(node.kernelName, ". The gradient of input ") + "'".concat(inputName2, "' has shape '").concat(dx.shape, "', which does not match ") + "the shape of the input '".concat(x.shape, "'"));
          }
          if (tensorAccumulatedGradientMap[x.id] == null) {
            tensorAccumulatedGradientMap[x.id] = dx;
          } else {
            var curGradient = tensorAccumulatedGradientMap[x.id];
            tensorAccumulatedGradientMap[x.id] = add2(curGradient, dx);
            curGradient.dispose();
          }
        };
        for (var inputName in node.inputs) {
          _loop_2(inputName);
        }
      };
      for (var i = filteredTape.length - 1; i >= 0; i--) {
        _loop_1(i);
      }
    }
    var FORMAT_LIMIT_NUM_VALS = 20;
    var FORMAT_NUM_FIRST_LAST_VALS = 3;
    var FORMAT_NUM_SIG_DIGITS = 7;
    function tensorToString(vals, shape, dtype, verbose) {
      var strides = computeStrides(shape);
      var padPerCol = computeMaxSizePerColumn(vals, shape, dtype, strides);
      var rank = shape.length;
      var valsLines = subTensorToString(vals, shape, dtype, strides, padPerCol);
      var lines = ["Tensor"];
      if (verbose) {
        lines.push("  dtype: ".concat(dtype));
        lines.push("  rank: ".concat(rank));
        lines.push("  shape: [".concat(shape, "]"));
        lines.push("  values:");
      }
      lines.push(valsLines.map(function(l) {
        return "    " + l;
      }).join("\n"));
      return lines.join("\n");
    }
    function computeMaxSizePerColumn(vals, shape, dtype, strides) {
      var n = sizeFromShape(shape);
      var numCols = strides[strides.length - 1];
      var padPerCol = new Array(numCols).fill(0);
      var rank = shape.length;
      var valuesOrTuples = dtype === "complex64" ? createComplexTuples(vals) : vals;
      if (rank > 1) {
        for (var row = 0; row < n / numCols; row++) {
          var offset = row * numCols;
          for (var j = 0; j < numCols; j++) {
            padPerCol[j] = Math.max(padPerCol[j], valToString(valuesOrTuples[offset + j], 0, dtype).length);
          }
        }
      }
      return padPerCol;
    }
    function valToString(val, pad2, dtype) {
      var valStr;
      if (Array.isArray(val)) {
        valStr = "".concat(parseFloat(val[0].toFixed(FORMAT_NUM_SIG_DIGITS)), " + ") + "".concat(parseFloat(val[1].toFixed(FORMAT_NUM_SIG_DIGITS)), "j");
      } else if (isString(val)) {
        valStr = "'".concat(val, "'");
      } else if (dtype === "bool") {
        valStr = boolNumToString(val);
      } else {
        valStr = parseFloat(val.toFixed(FORMAT_NUM_SIG_DIGITS)).toString();
      }
      return rightPad(valStr, pad2);
    }
    function boolNumToString(v) {
      return v === 0 ? "false" : "true";
    }
    function subTensorToString(vals, shape, dtype, strides, padPerCol, isLast) {
      if (isLast === void 0) {
        isLast = true;
      }
      var storagePerElement = dtype === "complex64" ? 2 : 1;
      var size = shape[0];
      var rank = shape.length;
      if (rank === 0) {
        if (dtype === "complex64") {
          var complexTuple = createComplexTuples(vals);
          return [valToString(complexTuple[0], 0, dtype)];
        }
        if (dtype === "bool") {
          return [boolNumToString(vals[0])];
        }
        return [vals[0].toString()];
      }
      if (rank === 1) {
        if (size > FORMAT_LIMIT_NUM_VALS) {
          var firstValsSize = FORMAT_NUM_FIRST_LAST_VALS * storagePerElement;
          var firstVals = Array.from(vals.slice(0, firstValsSize));
          var lastVals = Array.from(vals.slice((size - FORMAT_NUM_FIRST_LAST_VALS) * storagePerElement, size * storagePerElement));
          if (dtype === "complex64") {
            firstVals = createComplexTuples(firstVals);
            lastVals = createComplexTuples(lastVals);
          }
          return [
            "[" + firstVals.map(function(x, i2) {
              return valToString(x, padPerCol[i2], dtype);
            }).join(", ") + ", ..., " + lastVals.map(function(x, i2) {
              return valToString(x, padPerCol[size - FORMAT_NUM_FIRST_LAST_VALS + i2], dtype);
            }).join(", ") + "]"
          ];
        }
        var displayVals = dtype === "complex64" ? createComplexTuples(vals) : Array.from(vals);
        return [
          "[" + displayVals.map(function(x, i2) {
            return valToString(x, padPerCol[i2], dtype);
          }).join(", ") + "]"
        ];
      }
      var subshape = shape.slice(1);
      var substrides = strides.slice(1);
      var stride = strides[0] * storagePerElement;
      var lines = [];
      if (size > FORMAT_LIMIT_NUM_VALS) {
        for (var i = 0; i < FORMAT_NUM_FIRST_LAST_VALS; i++) {
          var start = i * stride;
          var end = start + stride;
          lines.push.apply(lines, __spreadArray([], __read(subTensorToString(
            vals.slice(start, end),
            subshape,
            dtype,
            substrides,
            padPerCol,
            false
            /* isLast */
          )), false));
        }
        lines.push("...");
        for (var i = size - FORMAT_NUM_FIRST_LAST_VALS; i < size; i++) {
          var start = i * stride;
          var end = start + stride;
          lines.push.apply(lines, __spreadArray([], __read(subTensorToString(
            vals.slice(start, end),
            subshape,
            dtype,
            substrides,
            padPerCol,
            i === size - 1
            /* isLast */
          )), false));
        }
      } else {
        for (var i = 0; i < size; i++) {
          var start = i * stride;
          var end = start + stride;
          lines.push.apply(lines, __spreadArray([], __read(subTensorToString(
            vals.slice(start, end),
            subshape,
            dtype,
            substrides,
            padPerCol,
            i === size - 1
            /* isLast */
          )), false));
        }
      }
      var sep = rank === 2 ? "," : "";
      lines[0] = "[" + (size > 0 ? lines[0] + sep : "");
      for (var i = 1; i < lines.length - 1; i++) {
        lines[i] = " " + lines[i] + sep;
      }
      var newLineSep = ",\n";
      for (var i = 2; i < rank; i++) {
        newLineSep += "\n";
      }
      lines[lines.length - 1] = " " + lines[lines.length - 1] + "]" + (isLast ? "" : newLineSep);
      return lines;
    }
    function createComplexTuples(vals) {
      var complexTuples = [];
      for (var i = 0; i < vals.length; i += 2) {
        complexTuples.push([vals[i], vals[i + 1]]);
      }
      return complexTuples;
    }
    var TensorBuffer = (
      /** @class */
      function() {
        function TensorBuffer2(shape, dtype, values) {
          var _this = this;
          this.dtype = dtype;
          this.shape = shape.slice();
          this.size = sizeFromShape(shape);
          if (values != null) {
            var n_1 = values.length;
            assert(n_1 === this.size, function() {
              return "Length of values '".concat(n_1, "' does not match the size ") + "inferred by the shape '".concat(_this.size, "'.");
            });
          }
          if (dtype === "complex64") {
            throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");
          }
          this.values = values || getArrayFromDType(dtype, this.size);
          this.strides = computeStrides(shape);
        }
        TensorBuffer2.prototype.set = function(value) {
          var _this = this;
          var locs = [];
          for (var _i = 1; _i < arguments.length; _i++) {
            locs[_i - 1] = arguments[_i];
          }
          if (locs.length === 0) {
            locs = [0];
          }
          assert(locs.length === this.rank, function() {
            return "The number of provided coordinates (".concat(locs.length, ") must ") + "match the rank (".concat(_this.rank, ")");
          });
          var index = this.locToIndex(locs);
          this.values[index] = value;
        };
        TensorBuffer2.prototype.get = function() {
          var e_1, _b;
          var locs = [];
          for (var _i = 0; _i < arguments.length; _i++) {
            locs[_i] = arguments[_i];
          }
          if (locs.length === 0) {
            locs = [0];
          }
          var i = 0;
          try {
            for (var locs_1 = __values(locs), locs_1_1 = locs_1.next(); !locs_1_1.done; locs_1_1 = locs_1.next()) {
              var loc = locs_1_1.value;
              if (loc < 0 || loc >= this.shape[i]) {
                var msg = "Requested out of range element at ".concat(locs, ". ") + "  Buffer shape=".concat(this.shape);
                throw new Error(msg);
              }
              i++;
            }
          } catch (e_1_1) {
            e_1 = { error: e_1_1 };
          } finally {
            try {
              if (locs_1_1 && !locs_1_1.done && (_b = locs_1.return))
                _b.call(locs_1);
            } finally {
              if (e_1)
                throw e_1.error;
            }
          }
          var index = locs[locs.length - 1];
          for (var i_1 = 0; i_1 < locs.length - 1; ++i_1) {
            index += this.strides[i_1] * locs[i_1];
          }
          return this.values[index];
        };
        TensorBuffer2.prototype.locToIndex = function(locs) {
          if (this.rank === 0) {
            return 0;
          } else if (this.rank === 1) {
            return locs[0];
          }
          var index = locs[locs.length - 1];
          for (var i = 0; i < locs.length - 1; ++i) {
            index += this.strides[i] * locs[i];
          }
          return index;
        };
        TensorBuffer2.prototype.indexToLoc = function(index) {
          if (this.rank === 0) {
            return [];
          } else if (this.rank === 1) {
            return [index];
          }
          var locs = new Array(this.shape.length);
          for (var i = 0; i < locs.length - 1; ++i) {
            locs[i] = Math.floor(index / this.strides[i]);
            index -= locs[i] * this.strides[i];
          }
          locs[locs.length - 1] = index;
          return locs;
        };
        Object.defineProperty(TensorBuffer2.prototype, "rank", {
          get: function() {
            return this.shape.length;
          },
          enumerable: false,
          configurable: true
        });
        TensorBuffer2.prototype.toTensor = function() {
          return trackerFn().makeTensor(this.values, this.shape, this.dtype);
        };
        return TensorBuffer2;
      }()
    );
    var trackerFn = null;
    var opHandler$1 = null;
    function setTensorTracker(fn) {
      trackerFn = fn;
    }
    function setOpHandler(handler) {
      opHandler$1 = handler;
    }
    var Tensor = (
      /** @class */
      function() {
        function Tensor2(shape, dtype, dataId, id) {
          this.kept = false;
          this.isDisposedInternal = false;
          this.shape = shape.slice();
          this.dtype = dtype || "float32";
          this.size = sizeFromShape(shape);
          this.strides = computeStrides(shape);
          this.dataId = dataId;
          this.id = id;
          this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
        }
        Object.defineProperty(Tensor2.prototype, "rank", {
          get: function() {
            return this.shape.length;
          },
          enumerable: false,
          configurable: true
        });
        Tensor2.prototype.buffer = function() {
          return __awaiter(this, void 0, void 0, function() {
            var vals;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  return [4, this.data()];
                case 1:
                  vals = _b.sent();
                  return [2, opHandler$1.buffer(this.shape, this.dtype, vals)];
              }
            });
          });
        };
        Tensor2.prototype.bufferSync = function() {
          return opHandler$1.buffer(this.shape, this.dtype, this.dataSync());
        };
        Tensor2.prototype.array = function() {
          return __awaiter(this, void 0, void 0, function() {
            var vals;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  return [4, this.data()];
                case 1:
                  vals = _b.sent();
                  return [2, toNestedArray(this.shape, vals, this.dtype === "complex64")];
              }
            });
          });
        };
        Tensor2.prototype.arraySync = function() {
          return toNestedArray(this.shape, this.dataSync(), this.dtype === "complex64");
        };
        Tensor2.prototype.data = function() {
          return __awaiter(this, void 0, void 0, function() {
            var data, bytes;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  this.throwIfDisposed();
                  data = trackerFn().read(this.dataId);
                  if (!(this.dtype === "string"))
                    return [3, 2];
                  return [4, data];
                case 1:
                  bytes = _b.sent();
                  try {
                    return [2, bytes.map(function(b) {
                      return decodeString(b);
                    })];
                  } catch (_a) {
                    throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
                  }
                  _b.label = 2;
                case 2:
                  return [2, data];
              }
            });
          });
        };
        Tensor2.prototype.dataToGPU = function(options) {
          this.throwIfDisposed();
          return trackerFn().readToGPU(this.dataId, options);
        };
        Tensor2.prototype.dataSync = function() {
          this.throwIfDisposed();
          var data = trackerFn().readSync(this.dataId);
          if (this.dtype === "string") {
            try {
              return data.map(function(b) {
                return decodeString(b);
              });
            } catch (_a) {
              throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
            }
          }
          return data;
        };
        Tensor2.prototype.bytes = function() {
          return __awaiter(this, void 0, void 0, function() {
            var data;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  this.throwIfDisposed();
                  return [4, trackerFn().read(this.dataId)];
                case 1:
                  data = _b.sent();
                  if (this.dtype === "string") {
                    return [2, data];
                  } else {
                    return [2, new Uint8Array(data.buffer)];
                  }
              }
            });
          });
        };
        Tensor2.prototype.dispose = function() {
          if (this.isDisposed) {
            return;
          }
          if (this.kerasMask) {
            this.kerasMask.dispose();
          }
          trackerFn().disposeTensor(this);
          this.isDisposedInternal = true;
        };
        Object.defineProperty(Tensor2.prototype, "isDisposed", {
          get: function() {
            return this.isDisposedInternal;
          },
          enumerable: false,
          configurable: true
        });
        Tensor2.prototype.throwIfDisposed = function() {
          if (this.isDisposed) {
            throw new Error("Tensor is disposed.");
          }
        };
        Tensor2.prototype.print = function(verbose) {
          if (verbose === void 0) {
            verbose = false;
          }
          return opHandler$1.print(this, verbose);
        };
        Tensor2.prototype.clone = function() {
          this.throwIfDisposed();
          return opHandler$1.clone(this);
        };
        Tensor2.prototype.toString = function(verbose) {
          if (verbose === void 0) {
            verbose = false;
          }
          var vals = this.dataSync();
          return tensorToString(vals, this.shape, this.dtype, verbose);
        };
        Tensor2.prototype.cast = function(dtype) {
          this.throwIfDisposed();
          return opHandler$1.cast(this, dtype);
        };
        Tensor2.prototype.variable = function(trainable, name, dtype) {
          if (trainable === void 0) {
            trainable = true;
          }
          this.throwIfDisposed();
          return trackerFn().makeVariable(this, trainable, name, dtype);
        };
        return Tensor2;
      }()
    );
    Object.defineProperty(Tensor, Symbol.hasInstance, {
      value: function(instance) {
        return !!instance && instance.data != null && instance.dataSync != null && instance.throwIfDisposed != null;
      }
    });
    function getGlobalTensorClass() {
      return getGlobal("Tensor", function() {
        return Tensor;
      });
    }
    getGlobalTensorClass();
    var Variable = (
      /** @class */
      function(_super) {
        __extends(Variable2, _super);
        function Variable2(initialValue, trainable, name, tensorId) {
          var _this = _super.call(this, initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId) || this;
          _this.trainable = trainable;
          _this.name = name;
          return _this;
        }
        Variable2.prototype.assign = function(newValue) {
          if (newValue.dtype !== this.dtype) {
            throw new Error("dtype of the new value (".concat(newValue.dtype, ") and ") + "previous value (".concat(this.dtype, ") must match"));
          }
          if (!arraysEqual(newValue.shape, this.shape)) {
            throw new Error("shape of the new value (".concat(newValue.shape, ") and ") + "previous value (".concat(this.shape, ") must match"));
          }
          trackerFn().disposeTensor(this);
          this.dataId = newValue.dataId;
          trackerFn().incRef(
            this,
            null
            /* backend */
          );
        };
        Variable2.prototype.dispose = function() {
          trackerFn().disposeVariable(this);
          this.isDisposedInternal = true;
        };
        return Variable2;
      }(Tensor)
    );
    Object.defineProperty(Variable, Symbol.hasInstance, {
      value: function(instance) {
        return instance instanceof Tensor && instance.assign != null && instance.assign instanceof Function;
      }
    });
    exports.Rank = void 0;
    (function(Rank) {
      Rank["R0"] = "R0";
      Rank["R1"] = "R1";
      Rank["R2"] = "R2";
      Rank["R3"] = "R3";
      Rank["R4"] = "R4";
      Rank["R5"] = "R5";
      Rank["R6"] = "R6";
    })(exports.Rank || (exports.Rank = {}));
    var UpcastInt32AndMap;
    (function(UpcastInt32AndMap2) {
      UpcastInt32AndMap2["float32"] = "float32";
      UpcastInt32AndMap2["int32"] = "int32";
      UpcastInt32AndMap2["bool"] = "int32";
      UpcastInt32AndMap2["complex64"] = "complex64";
    })(UpcastInt32AndMap || (UpcastInt32AndMap = {}));
    var UpcastBoolAndMap;
    (function(UpcastBoolAndMap2) {
      UpcastBoolAndMap2["float32"] = "float32";
      UpcastBoolAndMap2["int32"] = "int32";
      UpcastBoolAndMap2["bool"] = "bool";
      UpcastBoolAndMap2["complex64"] = "complex64";
    })(UpcastBoolAndMap || (UpcastBoolAndMap = {}));
    var UpcastFloat32AndMap;
    (function(UpcastFloat32AndMap2) {
      UpcastFloat32AndMap2["float32"] = "float32";
      UpcastFloat32AndMap2["int32"] = "float32";
      UpcastFloat32AndMap2["bool"] = "float32";
      UpcastFloat32AndMap2["complex64"] = "complex64";
    })(UpcastFloat32AndMap || (UpcastFloat32AndMap = {}));
    var UpcastComplex64AndMap;
    (function(UpcastComplex64AndMap2) {
      UpcastComplex64AndMap2["float32"] = "complex64";
      UpcastComplex64AndMap2["int32"] = "complex64";
      UpcastComplex64AndMap2["bool"] = "complex64";
      UpcastComplex64AndMap2["complex64"] = "complex64";
    })(UpcastComplex64AndMap || (UpcastComplex64AndMap = {}));
    var upcastTypeMap = {
      "float32": UpcastFloat32AndMap,
      "int32": UpcastInt32AndMap,
      "bool": UpcastBoolAndMap,
      "complex64": UpcastComplex64AndMap
    };
    function upcastType(typeA, typeB) {
      if (typeA === "string" || typeB === "string") {
        if (typeA === "string" && typeB === "string") {
          return "string";
        }
        throw new Error("Can not upcast ".concat(typeA, " with ").concat(typeB));
      }
      return upcastTypeMap[typeA][typeB];
    }
    function sumOutType(type) {
      return upcastType(type, "int32");
    }
    function isWebGLData(values) {
      return values != null && typeof values === "object" && "texture" in values && values.texture instanceof WebGLTexture;
    }
    function isWebGPUData(values) {
      return typeof GPUBuffer !== "undefined" && values != null && typeof values === "object" && "buffer" in values && values.buffer instanceof GPUBuffer;
    }
    function makeTypesMatch(a, b) {
      if (a.dtype === b.dtype) {
        return [a, b];
      }
      var dtype = upcastType(a.dtype, b.dtype);
      return [a.cast(dtype), b.cast(dtype)];
    }
    function assertTypesMatch(a, b) {
      assert(a.dtype === b.dtype, function() {
        return "The dtypes of the first(".concat(a.dtype, ") and") + " second(".concat(b.dtype, ") input must match");
      });
    }
    function isTensorInList(tensor2, tensorList) {
      return tensorList.some(function(x) {
        return x.id === tensor2.id;
      });
    }
    function getTensorsInContainer(result) {
      var list = [];
      var seen = /* @__PURE__ */ new Set();
      walkTensorContainer(result, list, seen);
      return list;
    }
    function walkTensorContainer(container, list, seen) {
      if (container == null) {
        return;
      }
      if (container instanceof Tensor) {
        list.push(container);
        return;
      }
      if (!isIterable(container)) {
        return;
      }
      var iterable = container;
      for (var k in iterable) {
        var val = iterable[k];
        if (!seen.has(val)) {
          seen.add(val);
          walkTensorContainer(val, list, seen);
        }
      }
    }
    function isIterable(obj) {
      return Array.isArray(obj) || typeof obj === "object";
    }
    var tensor_util = {
      __proto__: null,
      assertTypesMatch,
      getTensorsInContainer,
      isTensorInList,
      makeTypesMatch
    };
    function isRegisteredKernelInvocation(kernelInvocation) {
      return kernelInvocation.kernelName != null;
    }
    var EngineState = (
      /** @class */
      function() {
        function EngineState2() {
          this.registeredVariables = {};
          this.nextTapeNodeId = 0;
          this.numBytes = 0;
          this.numTensors = 0;
          this.numStringTensors = 0;
          this.numDataBuffers = 0;
          this.gradientDepth = 0;
          this.kernelDepth = 0;
          this.scopeStack = [];
          this.numDataMovesStack = [];
          this.nextScopeId = 0;
          this.tensorInfo = /* @__PURE__ */ new WeakMap();
          this.profiling = false;
          this.activeProfile = {
            newBytes: 0,
            newTensors: 0,
            peakBytes: 0,
            kernels: [],
            result: null,
            get kernelNames() {
              return Array.from(new Set(this.kernels.map(function(k) {
                return k.name;
              })));
            }
          };
        }
        EngineState2.prototype.dispose = function() {
          for (var variableName in this.registeredVariables) {
            this.registeredVariables[variableName].dispose();
          }
        };
        return EngineState2;
      }()
    );
    var Engine = (
      /** @class */
      function() {
        function Engine2(ENV2) {
          this.ENV = ENV2;
          this.registry = {};
          this.registryFactory = {};
          this.pendingBackendInitId = 0;
          this.state = new EngineState();
        }
        Engine2.prototype.ready = function() {
          return __awaiter(this, void 0, void 0, function() {
            var sortedBackends, i, backendName, success;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  if (this.pendingBackendInit != null) {
                    return [2, this.pendingBackendInit.then(function() {
                    })];
                  }
                  if (this.backendInstance != null) {
                    return [
                      2
                      /*return*/
                    ];
                  }
                  sortedBackends = this.getSortedBackends();
                  i = 0;
                  _a.label = 1;
                case 1:
                  if (!(i < sortedBackends.length))
                    return [3, 5];
                  backendName = sortedBackends[i];
                  return [4, this.initializeBackend(backendName).success];
                case 2:
                  success = _a.sent();
                  if (!success)
                    return [3, 4];
                  return [4, this.setBackend(backendName)];
                case 3:
                  _a.sent();
                  return [
                    2
                    /*return*/
                  ];
                case 4:
                  i++;
                  return [3, 1];
                case 5:
                  throw new Error("Could not initialize any backends, all backend initializations failed.");
              }
            });
          });
        };
        Object.defineProperty(Engine2.prototype, "backend", {
          get: function() {
            if (this.pendingBackendInit != null) {
              throw new Error("Backend '".concat(this.backendName, "' has not yet been initialized. Make ") + "sure to await tf.ready() or await tf.setBackend() before calling other methods");
            }
            if (this.backendInstance == null) {
              var _a = this.initializeBackendsAndReturnBest(), name = _a.name, asyncInit = _a.asyncInit;
              if (asyncInit) {
                throw new Error("The highest priority backend '".concat(name, "' has not yet been ") + "initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods");
              }
              this.setBackend(name);
            }
            return this.backendInstance;
          },
          enumerable: false,
          configurable: true
        });
        Engine2.prototype.backendNames = function() {
          return Object.keys(this.registryFactory);
        };
        Engine2.prototype.findBackend = function(backendName) {
          if (!(backendName in this.registry)) {
            if (backendName in this.registryFactory) {
              var asyncInit = this.initializeBackend(backendName).asyncInit;
              if (asyncInit) {
                return null;
              }
            } else {
              return null;
            }
          }
          return this.registry[backendName];
        };
        Engine2.prototype.findBackendFactory = function(backendName) {
          if (!(backendName in this.registryFactory)) {
            return null;
          }
          return this.registryFactory[backendName].factory;
        };
        Engine2.prototype.registerBackend = function(backendName, factory, priority) {
          if (priority === void 0) {
            priority = 1;
          }
          if (backendName in this.registryFactory) {
            warn("".concat(backendName, " backend was already registered. ") + "Reusing existing backend factory.");
            return false;
          }
          this.registryFactory[backendName] = { factory, priority };
          return true;
        };
        Engine2.prototype.setBackend = function(backendName) {
          return __awaiter(this, void 0, void 0, function() {
            var _a, success, asyncInit, result, _b;
            return __generator(this, function(_c) {
              switch (_c.label) {
                case 0:
                  if (this.registryFactory[backendName] == null) {
                    throw new Error("Backend name '".concat(backendName, "' not found in registry"));
                  }
                  this.backendName = backendName;
                  if (!(this.registry[backendName] == null))
                    return [3, 4];
                  this.backendInstance = null;
                  _a = this.initializeBackend(backendName), success = _a.success, asyncInit = _a.asyncInit;
                  if (!asyncInit)
                    return [3, 2];
                  return [4, success];
                case 1:
                  _b = _c.sent();
                  return [3, 3];
                case 2:
                  _b = success;
                  _c.label = 3;
                case 3:
                  result = _b;
                  if (!result) {
                    return [2, false];
                  }
                  _c.label = 4;
                case 4:
                  this.backendInstance = this.registry[backendName];
                  this.setupRegisteredKernels();
                  this.profiler = new Profiler(this.backendInstance);
                  return [2, true];
              }
            });
          });
        };
        Engine2.prototype.setupRegisteredKernels = function() {
          var _this = this;
          var kernels = getKernelsForBackend(this.backendName);
          kernels.forEach(function(kernel) {
            if (kernel.setupFunc != null) {
              kernel.setupFunc(_this.backendInstance);
            }
          });
        };
        Engine2.prototype.disposeRegisteredKernels = function(backendName) {
          var _this = this;
          var kernels = getKernelsForBackend(backendName);
          kernels.forEach(function(kernel) {
            if (kernel.disposeFunc != null) {
              kernel.disposeFunc(_this.registry[backendName]);
            }
          });
        };
        Engine2.prototype.initializeBackend = function(backendName) {
          var _this = this;
          var registryFactoryEntry = this.registryFactory[backendName];
          if (registryFactoryEntry == null) {
            throw new Error("Cannot initialize backend ".concat(backendName, ", no registration found."));
          }
          try {
            var backend2 = registryFactoryEntry.factory();
            if (backend2 && !(backend2 instanceof KernelBackend) && typeof backend2.then === "function") {
              var promiseId_1 = ++this.pendingBackendInitId;
              var success = backend2.then(function(backendInstance) {
                if (promiseId_1 < _this.pendingBackendInitId) {
                  return false;
                }
                _this.registry[backendName] = backendInstance;
                _this.pendingBackendInit = null;
                return true;
              }).catch(function(err) {
                if (promiseId_1 < _this.pendingBackendInitId) {
                  return false;
                }
                _this.pendingBackendInit = null;
                warn("Initialization of backend ".concat(backendName, " failed"));
                warn(err.stack || err.message);
                return false;
              });
              this.pendingBackendInit = success;
              return { success, asyncInit: true };
            } else {
              this.registry[backendName] = backend2;
              return { success: true, asyncInit: false };
            }
          } catch (err) {
            warn("Initialization of backend ".concat(backendName, " failed"));
            warn(err.stack || err.message);
            return { success: false, asyncInit: false };
          }
        };
        Engine2.prototype.removeBackend = function(backendName) {
          if (!(backendName in this.registryFactory)) {
            throw new Error("".concat(backendName, " backend not found in registry"));
          }
          if (this.backendName === backendName && this.pendingBackendInit != null) {
            this.pendingBackendInitId++;
          }
          if (backendName in this.registry) {
            this.disposeRegisteredKernels(backendName);
            this.registry[backendName].dispose();
            delete this.registry[backendName];
          }
          delete this.registryFactory[backendName];
          if (this.backendName === backendName) {
            this.pendingBackendInit = null;
            this.backendName = null;
            this.backendInstance = null;
          }
        };
        Engine2.prototype.getSortedBackends = function() {
          var _this = this;
          if (Object.keys(this.registryFactory).length === 0) {
            throw new Error("No backend found in registry.");
          }
          return Object.keys(this.registryFactory).sort(function(a, b) {
            return _this.registryFactory[b].priority - _this.registryFactory[a].priority;
          });
        };
        Engine2.prototype.initializeBackendsAndReturnBest = function() {
          var sortedBackends = this.getSortedBackends();
          for (var i = 0; i < sortedBackends.length; i++) {
            var backendName = sortedBackends[i];
            var _a = this.initializeBackend(backendName), success = _a.success, asyncInit = _a.asyncInit;
            if (asyncInit || success) {
              return { name: backendName, asyncInit };
            }
          }
          throw new Error("Could not initialize any backends, all backend initializations failed.");
        };
        Engine2.prototype.moveData = function(backend2, dataId) {
          var info = this.state.tensorInfo.get(dataId);
          var srcBackend = info.backend;
          var values = this.readSync(dataId);
          var refCount = srcBackend.refCount(dataId);
          srcBackend.disposeData(dataId, true);
          info.backend = backend2;
          backend2.move(dataId, values, info.shape, info.dtype, refCount);
          if (this.shouldCheckForMemLeaks()) {
            this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
          }
        };
        Engine2.prototype.tidy = function(nameOrFn, fn) {
          var _this = this;
          var name = null;
          if (fn == null) {
            if (typeof nameOrFn !== "function") {
              throw new Error("Please provide a function to tidy()");
            }
            fn = nameOrFn;
          } else {
            if (typeof nameOrFn !== "string" && !(nameOrFn instanceof String)) {
              throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
            }
            if (typeof fn !== "function") {
              throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
            }
            name = nameOrFn;
          }
          var result;
          return this.scopedRun(function() {
            return _this.startScope(name);
          }, function() {
            return _this.endScope(result);
          }, function() {
            result = fn();
            if (result instanceof Promise) {
              console.error("Cannot return a Promise inside of tidy.");
            }
            return result;
          });
        };
        Engine2.prototype.scopedRun = function(start, end, f) {
          start();
          try {
            var res = f();
            end();
            return res;
          } catch (ex) {
            end();
            throw ex;
          }
        };
        Engine2.prototype.nextTensorId = function() {
          return Engine2.nextTensorId++;
        };
        Engine2.prototype.nextVariableId = function() {
          return Engine2.nextVariableId++;
        };
        Engine2.prototype.clone = function(x) {
          var y = ENGINE.runKernel(Identity, { x });
          var inputs = { x };
          var grad2 = function(dy) {
            return {
              x: function() {
                var dtype = "float32";
                var gradInputs = { x: dy };
                var attrs = { dtype };
                return ENGINE.runKernel(
                  Cast,
                  gradInputs,
                  // tslint:disable-next-line: no-unnecessary-type-assertion
                  attrs
                );
              }
            };
          };
          var saved = [];
          this.addTapeNode(this.state.activeScope.name, inputs, [y], grad2, saved, {});
          return y;
        };
        Engine2.prototype.runKernel = function(kernelName, inputs, attrs) {
          if (this.backendName == null) {
            this.backend;
          }
          var hasKernel = getKernel(kernelName, this.backendName) != null;
          if (!hasKernel) {
            throw new Error("Kernel '".concat(kernelName, "' not registered for backend '").concat(this.backendName, "'"));
          }
          return this.runKernelFunc({ kernelName, inputs, attrs });
        };
        Engine2.prototype.shouldCheckForMemLeaks = function() {
          return this.ENV.getBool("IS_TEST");
        };
        Engine2.prototype.checkKernelForMemLeak = function(kernelName, numDataIdsBefore, outInfos) {
          var numDataIdsAfter = this.backend.numDataIds();
          var numOutputDataIds = 0;
          outInfos.forEach(function(info) {
            numOutputDataIds += info.dtype === "complex64" ? 3 : 1;
          });
          var numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];
          var dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;
          if (dataIdsLeaked > 0) {
            throw new Error("Backend '".concat(this.backendName, "' has an internal memory leak ") + "(".concat(dataIdsLeaked, " data ids) after running '").concat(kernelName, "'"));
          }
        };
        Engine2.prototype.runKernelFunc = function(kernelParams) {
          var _this = this;
          var outputs;
          var saved = [];
          var isTapeOn = this.isTapeOn();
          var startingBytecount = this.state.numBytes;
          var startingNumTensors = this.state.numTensors;
          if (this.shouldCheckForMemLeaks()) {
            this.state.numDataMovesStack.push(0);
          }
          var kernelFunc;
          if (this.backendName == null) {
            this.backend;
          }
          var out;
          var kernelOrScopeName = isRegisteredKernelInvocation(kernelParams) ? kernelParams.kernelName : this.state.activeScope != null ? this.state.activeScope.name : "";
          if (isRegisteredKernelInvocation(kernelParams)) {
            var kernelName_1 = kernelParams.kernelName, inputs_1 = kernelParams.inputs, attrs_1 = kernelParams.attrs;
            if (this.backendName == null) {
              this.backend;
            }
            var kernel_1 = getKernel(kernelName_1, this.backendName);
            assert(kernel_1 != null, function() {
              return "Cannot find registered kernel '".concat(kernelName_1, "' for backend '").concat(_this.backendName, "'");
            });
            kernelFunc = function() {
              var numDataIdsBefore = _this.backend.numDataIds();
              out = kernel_1.kernelFunc({ inputs: inputs_1, attrs: attrs_1, backend: _this.backend });
              var outInfos = Array.isArray(out) ? out : [out];
              if (_this.shouldCheckForMemLeaks()) {
                _this.checkKernelForMemLeak(kernelName_1, numDataIdsBefore, outInfos);
              }
              var outTensors = outInfos.map(function(outInfo) {
                if (outInfo.rank != null) {
                  return outInfo;
                }
                return _this.makeTensorFromTensorInfo(outInfo);
              });
              if (isTapeOn) {
                var tensorsToSave = _this.getTensorsForGradient(kernelName_1, inputs_1, outTensors);
                saved = _this.saveTensorsForBackwardMode(tensorsToSave);
              }
              return outTensors;
            };
          } else {
            var forwardFunc_1 = kernelParams.forwardFunc;
            var saveFunc_1 = function(tensors) {
              if (!isTapeOn) {
                return;
              }
              saved = tensors.map(function(tensor2) {
                return _this.keep(_this.clone(tensor2));
              });
            };
            kernelFunc = function() {
              var numDataIdsBefore = _this.backend.numDataIds();
              out = _this.tidy(function() {
                return forwardFunc_1(_this.backend, saveFunc_1);
              });
              var outs = Array.isArray(out) ? out : [out];
              if (_this.shouldCheckForMemLeaks()) {
                _this.checkKernelForMemLeak(kernelOrScopeName, numDataIdsBefore, outs);
              }
              return outs;
            };
          }
          var inputs = kernelParams.inputs, attrs = kernelParams.attrs;
          var backwardsFunc = isRegisteredKernelInvocation(kernelParams) ? null : kernelParams.backwardsFunc;
          var kernelProfile;
          this.scopedRun(
            // Stop recording to a tape when running a kernel.
            function() {
              return _this.state.kernelDepth++;
            },
            function() {
              return _this.state.kernelDepth--;
            },
            function() {
              if (!_this.ENV.getBool("DEBUG") && !_this.state.profiling) {
                outputs = kernelFunc();
              } else {
                kernelProfile = _this.profiler.profileKernel(kernelOrScopeName, inputs, function() {
                  return kernelFunc();
                });
                if (_this.ENV.getBool("DEBUG")) {
                  _this.profiler.logKernelProfile(kernelProfile);
                }
                outputs = kernelProfile.outputs;
              }
            }
          );
          if (isTapeOn) {
            this.addTapeNode(kernelOrScopeName, inputs, outputs, backwardsFunc, saved, attrs);
          }
          if (this.state.profiling) {
            this.state.activeProfile.kernels.push({
              name: kernelOrScopeName,
              bytesAdded: this.state.numBytes - startingBytecount,
              totalBytesSnapshot: this.state.numBytes,
              tensorsAdded: this.state.numTensors - startingNumTensors,
              totalTensorsSnapshot: this.state.numTensors,
              inputShapes: Object.keys(inputs).map(function(key) {
                return inputs[key] != null ? inputs[key].shape : null;
              }),
              outputShapes: outputs.map(function(item) {
                return item.shape;
              }),
              kernelTimeMs: kernelProfile.timeMs,
              extraInfo: kernelProfile.extraInfo
            });
          }
          return Array.isArray(out) ? outputs : outputs[0];
        };
        Engine2.prototype.saveTensorsForBackwardMode = function(tensors) {
          var _this = this;
          var saved = tensors.map(function(tensor2) {
            return _this.keep(_this.clone(tensor2));
          });
          return saved;
        };
        Engine2.prototype.getTensorsForGradient = function(kernelName, inputs, outputs) {
          var gradConfig = getGradient(kernelName);
          if (gradConfig != null) {
            var inputsToSave = gradConfig.inputsToSave || [];
            var outputsToSave_1 = gradConfig.outputsToSave || [];
            var inputTensorsToSave = void 0;
            if (gradConfig.saveAllInputs) {
              assert(Array.isArray(inputs), function() {
                return "saveAllInputs is true, expected inputs to be an array.";
              });
              inputTensorsToSave = Object.keys(inputs).map(function(key) {
                return inputs[key];
              });
            } else {
              inputTensorsToSave = inputsToSave.map(function(inputName) {
                return inputs[inputName];
              });
            }
            var outputTensorsToSave = outputs.filter(function(_, i) {
              return outputsToSave_1[i];
            });
            return inputTensorsToSave.concat(outputTensorsToSave);
          }
          return [];
        };
        Engine2.prototype.makeTensor = function(values, shape, dtype, backend2) {
          if (values == null) {
            throw new Error("Values passed to engine.makeTensor() are null");
          }
          dtype = dtype || "float32";
          backend2 = backend2 || this.backend;
          var backendVals = values;
          if (dtype === "string" && isString(values[0])) {
            backendVals = values.map(function(d) {
              return encodeString(d);
            });
          }
          var dataId = backend2.write(backendVals, shape, dtype);
          var t = new Tensor(shape, dtype, dataId, this.nextTensorId());
          this.trackTensor(t, backend2);
          if (dtype === "string") {
            var info = this.state.tensorInfo.get(dataId);
            var newBytes = bytesFromStringArray(backendVals);
            this.state.numBytes += newBytes - info.bytes;
            info.bytes = newBytes;
          }
          return t;
        };
        Engine2.prototype.makeTensorFromDataId = function(dataId, shape, dtype, backend2) {
          dtype = dtype || "float32";
          var tensorInfo = { dataId, shape, dtype };
          return this.makeTensorFromTensorInfo(tensorInfo, backend2);
        };
        Engine2.prototype.makeTensorFromTensorInfo = function(tensorInfo, backend2) {
          var dataId = tensorInfo.dataId, shape = tensorInfo.shape, dtype = tensorInfo.dtype;
          var t = new Tensor(shape, dtype, dataId, this.nextTensorId());
          this.trackTensor(t, backend2);
          return t;
        };
        Engine2.prototype.makeVariable = function(initialValue, trainable, name, dtype) {
          if (trainable === void 0) {
            trainable = true;
          }
          name = name || this.nextVariableId().toString();
          if (dtype != null && dtype !== initialValue.dtype) {
            initialValue = initialValue.cast(dtype);
          }
          var v = new Variable(initialValue, trainable, name, this.nextTensorId());
          if (this.state.registeredVariables[v.name] != null) {
            throw new Error("Variable with name ".concat(v.name, " was already registered"));
          }
          this.state.registeredVariables[v.name] = v;
          this.incRef(v, this.backend);
          return v;
        };
        Engine2.prototype.trackTensor = function(a, backend2) {
          this.state.numTensors++;
          if (a.dtype === "string") {
            this.state.numStringTensors++;
          }
          var bytes = 0;
          if (a.dtype !== "complex64" && a.dtype !== "string") {
            bytes = a.size * bytesPerElement(a.dtype);
          }
          this.state.numBytes += bytes;
          if (!this.state.tensorInfo.has(a.dataId)) {
            this.state.numDataBuffers++;
            this.state.tensorInfo.set(a.dataId, {
              backend: backend2 || this.backend,
              dtype: a.dtype,
              shape: a.shape,
              bytes
            });
          }
          if (!(a instanceof Variable)) {
            this.track(a);
          }
        };
        Engine2.prototype.incRef = function(a, backend2) {
          this.trackTensor(a, backend2);
          this.backend.incRef(a.dataId);
        };
        Engine2.prototype.removeDataId = function(dataId, backend2) {
          if (this.state.tensorInfo.has(dataId) && this.state.tensorInfo.get(dataId).backend === backend2) {
            this.state.tensorInfo.delete(dataId);
            this.state.numDataBuffers--;
          }
        };
        Engine2.prototype.disposeTensor = function(a) {
          if (!this.state.tensorInfo.has(a.dataId)) {
            return;
          }
          var info = this.state.tensorInfo.get(a.dataId);
          this.state.numTensors--;
          if (a.dtype === "string") {
            this.state.numStringTensors--;
            this.state.numBytes -= info.bytes;
          }
          if (a.dtype !== "complex64" && a.dtype !== "string") {
            var bytes = a.size * bytesPerElement(a.dtype);
            this.state.numBytes -= bytes;
          }
          if (info.backend.disposeData(a.dataId)) {
            this.removeDataId(a.dataId, info.backend);
          }
        };
        Engine2.prototype.disposeVariables = function() {
          for (var varName in this.state.registeredVariables) {
            var v = this.state.registeredVariables[varName];
            this.disposeVariable(v);
          }
        };
        Engine2.prototype.disposeVariable = function(v) {
          this.disposeTensor(v);
          if (this.state.registeredVariables[v.name] != null) {
            delete this.state.registeredVariables[v.name];
          }
        };
        Engine2.prototype.memory = function() {
          var info = this.backend.memory();
          info.numTensors = this.state.numTensors;
          info.numDataBuffers = this.state.numDataBuffers;
          info.numBytes = this.state.numBytes;
          if (this.state.numStringTensors > 0) {
            info.unreliable = true;
            if (info.reasons == null) {
              info.reasons = [];
            }
            info.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)");
          }
          return info;
        };
        Engine2.prototype.profile = function(query) {
          return __awaiter(this, void 0, void 0, function() {
            var startBytes, startNumTensors, _a, _b, _c, kernel, _d, _e, e_1_1;
            var e_1, _f;
            return __generator(this, function(_g) {
              switch (_g.label) {
                case 0:
                  this.state.profiling = true;
                  startBytes = this.state.numBytes;
                  startNumTensors = this.state.numTensors;
                  this.state.activeProfile.kernels = [];
                  _a = this.state.activeProfile;
                  return [4, query()];
                case 1:
                  _a.result = _g.sent();
                  this.state.profiling = false;
                  this.state.activeProfile.peakBytes = Math.max.apply(Math, __spreadArray([], __read(this.state.activeProfile.kernels.map(function(d) {
                    return d.totalBytesSnapshot;
                  })), false));
                  this.state.activeProfile.newBytes = this.state.numBytes - startBytes;
                  this.state.activeProfile.newTensors = this.state.numTensors - startNumTensors;
                  _g.label = 2;
                case 2:
                  _g.trys.push([2, 8, 9, 10]);
                  _b = __values(this.state.activeProfile.kernels), _c = _b.next();
                  _g.label = 3;
                case 3:
                  if (!!_c.done)
                    return [3, 7];
                  kernel = _c.value;
                  _d = kernel;
                  return [4, kernel.kernelTimeMs];
                case 4:
                  _d.kernelTimeMs = _g.sent();
                  _e = kernel;
                  return [4, kernel.extraInfo];
                case 5:
                  _e.extraInfo = _g.sent();
                  _g.label = 6;
                case 6:
                  _c = _b.next();
                  return [3, 3];
                case 7:
                  return [3, 10];
                case 8:
                  e_1_1 = _g.sent();
                  e_1 = { error: e_1_1 };
                  return [3, 10];
                case 9:
                  try {
                    if (_c && !_c.done && (_f = _b.return))
                      _f.call(_b);
                  } finally {
                    if (e_1)
                      throw e_1.error;
                  }
                  return [
                    7
                    /*endfinally*/
                  ];
                case 10:
                  return [2, this.state.activeProfile];
              }
            });
          });
        };
        Engine2.prototype.isTapeOn = function() {
          return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;
        };
        Engine2.prototype.addTapeNode = function(kernelName, inputs, outputs, gradientsFunc, saved, attrs) {
          var _this = this;
          var tapeNode = { id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved };
          var gradConfig = getGradient(kernelName);
          if (gradConfig != null) {
            gradientsFunc = gradConfig.gradFunc;
          }
          if (gradientsFunc != null) {
            tapeNode.gradient = function(dys) {
              dys = dys.map(function(dy, i) {
                if (dy == null) {
                  var output = outputs[i];
                  var vals = makeZerosTypedArray(output.size, output.dtype);
                  return _this.makeTensor(vals, output.shape, output.dtype);
                }
                return dy;
              });
              return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);
            };
          }
          this.state.activeTape.push(tapeNode);
        };
        Engine2.prototype.keep = function(result) {
          result.kept = true;
          return result;
        };
        Engine2.prototype.startTape = function() {
          if (this.state.gradientDepth === 0) {
            this.state.activeTape = [];
          }
          this.state.gradientDepth++;
        };
        Engine2.prototype.endTape = function() {
          this.state.gradientDepth--;
        };
        Engine2.prototype.startScope = function(name) {
          var scopeInfo = {
            track: [],
            name: "unnamed scope",
            id: this.state.nextScopeId++
          };
          if (name) {
            scopeInfo.name = name;
          }
          this.state.scopeStack.push(scopeInfo);
          this.state.activeScope = scopeInfo;
        };
        Engine2.prototype.endScope = function(result) {
          var _this = this;
          var tensorsToTrackInParent = getTensorsInContainer(result);
          var tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map(function(t) {
            return t.id;
          }));
          for (var i = 0; i < this.state.activeScope.track.length; i++) {
            var tensor2 = this.state.activeScope.track[i];
            if (!tensor2.kept && !tensorsToTrackInParentSet.has(tensor2.id)) {
              tensor2.dispose();
            }
          }
          var oldScope = this.state.scopeStack.pop();
          this.state.activeScope = this.state.scopeStack.length === 0 ? null : this.state.scopeStack[this.state.scopeStack.length - 1];
          tensorsToTrackInParent.forEach(function(tensor3) {
            if (!tensor3.kept && tensor3.scopeId === oldScope.id) {
              _this.track(tensor3);
            }
          });
        };
        Engine2.prototype.gradients = function(f, xs, dy, allowNoGradients) {
          var _this = this;
          if (allowNoGradients === void 0) {
            allowNoGradients = false;
          }
          assert(xs.length > 0, function() {
            return "gradients() received an empty list of xs.";
          });
          if (dy != null && dy.dtype !== "float32") {
            throw new Error("dy must have 'float32' dtype, but has '".concat(dy.dtype, "'"));
          }
          var y = this.scopedRun(function() {
            return _this.startTape();
          }, function() {
            return _this.endTape();
          }, function() {
            return _this.tidy("forward", f);
          });
          assert(y instanceof Tensor, function() {
            return "The result y returned by f() must be a tensor.";
          });
          var filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);
          if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {
            throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
          }
          return this.tidy("backward", function() {
            var accumulatedGradientMap = {};
            accumulatedGradientMap[y.id] = dy == null ? ones$1(y.shape) : dy;
            backpropagateGradients(
              accumulatedGradientMap,
              filteredTape,
              // Pass the tidy function to avoid circular dep with `tape.ts`.
              function(f2) {
                return _this.tidy(f2);
              },
              // Pass an add function to avoide a circular dep with `tape.ts`.
              add$1
            );
            var grads2 = xs.map(function(x) {
              return accumulatedGradientMap[x.id];
            });
            if (_this.state.gradientDepth === 0) {
              _this.state.activeTape.forEach(function(node) {
                var e_2, _a;
                try {
                  for (var _b = __values(node.saved), _c = _b.next(); !_c.done; _c = _b.next()) {
                    var tensor2 = _c.value;
                    tensor2.dispose();
                  }
                } catch (e_2_1) {
                  e_2 = { error: e_2_1 };
                } finally {
                  try {
                    if (_c && !_c.done && (_a = _b.return))
                      _a.call(_b);
                  } finally {
                    if (e_2)
                      throw e_2.error;
                  }
                }
              });
              _this.state.activeTape = null;
            }
            return { value: y, grads: grads2 };
          });
        };
        Engine2.prototype.customGrad = function(f) {
          var _this = this;
          assert(isFunction(f), function() {
            return "The f passed in customGrad(f) must be a function.";
          });
          return function() {
            var inputs = [];
            for (var _i = 0; _i < arguments.length; _i++) {
              inputs[_i] = arguments[_i];
            }
            assert(inputs.every(function(t) {
              return t instanceof Tensor;
            }), function() {
              return "The args passed in customGrad(f)(x1, x2,...) must all be tensors";
            });
            var res;
            var inputMap = {};
            inputs.forEach(function(input, i) {
              inputMap[i] = input;
            });
            var forwardFunc = function(_, save) {
              res = f.apply(void 0, __spreadArray([], __read(__spreadArray(__spreadArray([], __read(inputs), false), [save], false)), false));
              assert(res.value instanceof Tensor, function() {
                return "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor";
              });
              assert(isFunction(res.gradFunc), function() {
                return "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.";
              });
              return res.value;
            };
            var backwardsFunc = function(dy, saved) {
              var gradRes = res.gradFunc(dy, saved);
              var grads2 = Array.isArray(gradRes) ? gradRes : [gradRes];
              assert(grads2.length === inputs.length, function() {
                return "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).";
              });
              assert(grads2.every(function(t) {
                return t instanceof Tensor;
              }), function() {
                return "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.";
              });
              var gradMap = {};
              grads2.forEach(function(grad2, i) {
                gradMap[i] = function() {
                  return grad2;
                };
              });
              return gradMap;
            };
            return _this.runKernelFunc({
              forwardFunc,
              backwardsFunc,
              inputs: inputMap
            });
          };
        };
        Engine2.prototype.readSync = function(dataId) {
          var info = this.state.tensorInfo.get(dataId);
          return info.backend.readSync(dataId);
        };
        Engine2.prototype.read = function(dataId) {
          var info = this.state.tensorInfo.get(dataId);
          return info.backend.read(dataId);
        };
        Engine2.prototype.readToGPU = function(dataId, options) {
          var info = this.state.tensorInfo.get(dataId);
          return info.backend.readToGPU(dataId, options);
        };
        Engine2.prototype.time = function(query) {
          return __awaiter(this, void 0, void 0, function() {
            var start, timingInfo;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  start = now();
                  return [4, this.backend.time(query)];
                case 1:
                  timingInfo = _a.sent();
                  timingInfo.wallMs = now() - start;
                  return [2, timingInfo];
              }
            });
          });
        };
        Engine2.prototype.track = function(result) {
          if (this.state.activeScope != null) {
            result.scopeId = this.state.activeScope.id;
            this.state.activeScope.track.push(result);
          }
          return result;
        };
        Object.defineProperty(Engine2.prototype, "registeredVariables", {
          get: function() {
            return this.state.registeredVariables;
          },
          enumerable: false,
          configurable: true
        });
        Engine2.prototype.reset = function() {
          this.pendingBackendInitId++;
          this.state.dispose();
          this.ENV.reset();
          this.state = new EngineState();
          for (var backendName in this.registry) {
            this.disposeRegisteredKernels(backendName);
            this.registry[backendName].dispose();
            delete this.registry[backendName];
          }
          this.backendName = null;
          this.backendInstance = null;
          this.pendingBackendInit = null;
        };
        return Engine2;
      }()
    );
    Engine.nextTensorId = 0;
    Engine.nextVariableId = 0;
    function ones$1(shape) {
      var values = makeOnesTypedArray(sizeFromShape(shape), "float32");
      return ENGINE.makeTensor(values, shape, "float32");
    }
    function getOrMakeEngine() {
      var ns = getGlobalNamespace();
      if (ns._tfengine == null) {
        var environment = new Environment(ns);
        ns._tfengine = new Engine(environment);
      }
      setEnvironmentGlobal(ns._tfengine.ENV);
      setTensorTracker(function() {
        return ns._tfengine;
      });
      return ns._tfengine;
    }
    var ENGINE = getOrMakeEngine();
    function add$1(a, b) {
      var inputs = { a, b };
      return ENGINE.runKernel(Add, inputs);
    }
    function _isNavigatorDefined() {
      return typeof navigator !== "undefined" && navigator != null;
    }
    var isMobileMockValue;
    function mockIsMobile(value) {
      isMobileMockValue = value;
    }
    function isMobile(nav) {
      if (isMobileMockValue !== void 0) {
        return isMobileMockValue;
      }
      if (nav || _isNavigatorDefined()) {
        if (!nav) {
          nav = navigator;
        }
        if (nav.product === "ReactNative") {
          return true;
        }
        var a = nav.userAgent || nav.vendor || // tslint:disable-next-line:no-any
        (typeof window !== "undefined" ? window.opera : "");
        if (!a) {
          var navAny = nav;
          return navAny.userAgentData && navAny.userAgentData.mobile;
        }
        return /(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(a) || // tslint:disable-next-line:max-line-length
        /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4));
      }
      return false;
    }
    function isBrowser() {
      return typeof window !== "undefined" && window.document != null || //@ts-ignore
      typeof WorkerGlobalScope !== "undefined";
    }
    var device_util = {
      __proto__: null,
      isBrowser,
      isMobile,
      mockIsMobile
    };
    var ENV = env();
    ENV.registerFlag("DEBUG", function() {
      return false;
    }, function(debugValue) {
      if (debugValue) {
        console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.");
      }
    });
    ENV.registerFlag("IS_BROWSER", function() {
      return isBrowser();
    });
    ENV.registerFlag("IS_NODE", function() {
      return typeof process !== "undefined" && typeof process.versions !== "undefined" && typeof process.versions.node !== "undefined";
    });
    ENV.registerFlag("IS_CHROME", function() {
      return typeof navigator !== "undefined" && navigator != null && navigator.userAgent != null && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor);
    });
    ENV.registerFlag("IS_SAFARI", function() {
      return typeof navigator !== "undefined" && navigator != null && navigator.userAgent != null && /Safari/.test(navigator.userAgent) && /Apple/.test(navigator.vendor);
    });
    ENV.registerFlag("PROD", function() {
      return false;
    });
    ENV.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY", function() {
      return ENV.getBool("DEBUG");
    });
    ENV.registerFlag("DEPRECATION_WARNINGS_ENABLED", function() {
      return true;
    });
    ENV.registerFlag("IS_TEST", function() {
      return false;
    });
    ENV.registerFlag("CHECK_COMPUTATION_FOR_ERRORS", function() {
      return ENV.getBool("DEBUG");
    });
    ENV.registerFlag("WRAP_TO_IMAGEBITMAP", function() {
      return false;
    });
    ENV.registerFlag("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU", function() {
      return false;
    });
    ENV.registerFlag("USE_SETTIMEOUTCUSTOM", function() {
      return false;
    });
    function inferShape(val, dtype) {
      var firstElem = val;
      if (isTypedArray(val)) {
        return dtype === "string" ? [] : [val.length];
      }
      if (isWebGLData(val)) {
        var usedChannels = val.channels || "RGBA";
        return [val.height, val.width * usedChannels.length];
      } else if (isWebGPUData(val)) {
        return [val.buffer.size / (dtype == null ? 4 : bytesPerElement(dtype))];
      }
      if (!Array.isArray(val)) {
        return [];
      }
      var shape = [];
      while (Array.isArray(firstElem) || isTypedArray(firstElem) && dtype !== "string") {
        shape.push(firstElem.length);
        firstElem = firstElem[0];
      }
      if (Array.isArray(val) && env().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")) {
        deepAssertShapeConsistency(val, shape, []);
      }
      return shape;
    }
    function deepAssertShapeConsistency(val, shape, indices) {
      indices = indices || [];
      if (!Array.isArray(val) && !isTypedArray(val)) {
        assert(shape.length === 0, function() {
          return "Element arr[".concat(indices.join("]["), "] is a primitive, ") + "but should be an array/TypedArray of ".concat(shape[0], " elements");
        });
        return;
      }
      assert(shape.length > 0, function() {
        return "Element arr[".concat(indices.join("]["), "] should be a primitive, ") + "but is an array of ".concat(val.length, " elements");
      });
      assert(val.length === shape[0], function() {
        return "Element arr[".concat(indices.join("]["), "] should have ").concat(shape[0], " ") + "elements, but has ".concat(val.length, " elements");
      });
      var subShape = shape.slice(1);
      for (var i = 0; i < val.length; ++i) {
        deepAssertShapeConsistency(val[i], subShape, indices.concat(i));
      }
    }
    function assertDtype(expectedDtype, actualDType, argName, functionName) {
      if (expectedDtype === "string_or_numeric") {
        return;
      }
      if (expectedDtype == null) {
        throw new Error("Expected dtype cannot be null.");
      }
      if (expectedDtype !== "numeric" && expectedDtype !== actualDType || expectedDtype === "numeric" && actualDType === "string") {
        throw new Error("Argument '".concat(argName, "' passed to '").concat(functionName, "' must ") + "be ".concat(expectedDtype, " tensor, but got ").concat(actualDType, " tensor"));
      }
    }
    function convertToTensor(x, argName, functionName, parseAsDtype) {
      if (parseAsDtype === void 0) {
        parseAsDtype = "numeric";
      }
      if (x instanceof getGlobalTensorClass()) {
        assertDtype(parseAsDtype, x.dtype, argName, functionName);
        return x;
      }
      var inferredDtype = inferDtype(x);
      if (inferredDtype !== "string" && ["bool", "int32", "float32"].indexOf(parseAsDtype) >= 0) {
        inferredDtype = parseAsDtype;
      }
      assertDtype(parseAsDtype, inferredDtype, argName, functionName);
      if (x == null || !isTypedArray(x) && !Array.isArray(x) && typeof x !== "number" && typeof x !== "boolean" && typeof x !== "string") {
        var type = x == null ? "null" : x.constructor.name;
        throw new Error("Argument '".concat(argName, "' passed to '").concat(functionName, "' must be a ") + "Tensor or TensorLike, but got '".concat(type, "'"));
      }
      var inferredShape = inferShape(x, inferredDtype);
      if (!isTypedArray(x) && !Array.isArray(x)) {
        x = [x];
      }
      var skipTypedArray = true;
      var values = inferredDtype !== "string" ? toTypedArray(x, inferredDtype) : flatten(x, [], skipTypedArray);
      return ENGINE.makeTensor(values, inferredShape, inferredDtype);
    }
    function convertToTensorArray(arg, argName, functionName, parseAsDtype) {
      if (parseAsDtype === void 0) {
        parseAsDtype = "numeric";
      }
      if (!Array.isArray(arg)) {
        throw new Error("Argument ".concat(argName, " passed to ").concat(functionName, " must be a ") + "`Tensor[]` or `TensorLike[]`");
      }
      var tensors = arg;
      return tensors.map(function(t, i) {
        return convertToTensor(t, "".concat(argName, "[").concat(i, "]"), functionName, parseAsDtype);
      });
    }
    var OP_SCOPE_SUFFIX = "__op";
    function op(f) {
      var keys = Object.keys(f);
      if (keys.length !== 1) {
        throw new Error("Please provide an object with a single key (operation name) mapping to a function. Got an object with " + "".concat(keys.length, " keys."));
      }
      var opName = keys[0];
      var fn = f[opName];
      if (opName.endsWith("_")) {
        opName = opName.substring(0, opName.length - 1);
      }
      opName = opName + OP_SCOPE_SUFFIX;
      var f2 = function() {
        var args = [];
        for (var _i = 0; _i < arguments.length; _i++) {
          args[_i] = arguments[_i];
        }
        ENGINE.startScope(opName);
        try {
          var result = fn.apply(void 0, __spreadArray([], __read(args), false));
          if (isPromise(result)) {
            console.error("Cannot return a Promise inside of tidy.");
          }
          ENGINE.endScope(result);
          return result;
        } catch (ex) {
          ENGINE.endScope(null);
          throw ex;
        }
      };
      Object.defineProperty(f2, "name", { value: opName, configurable: true });
      return f2;
    }
    function complex_(real2, imag2) {
      var $real = convertToTensor(real2, "real", "complex");
      var $imag = convertToTensor(imag2, "imag", "complex");
      assertShapesMatch($real.shape, $imag.shape, "real and imag shapes, ".concat($real.shape, " and ").concat($imag.shape, ", ") + "must match in call to tf.complex().");
      var inputs = { real: $real, imag: $imag };
      return ENGINE.runKernel(Complex, inputs);
    }
    var complex = /* @__PURE__ */ op({ complex_ });
    function makeTensor(values, shape, inferredShape, dtype) {
      if (dtype == null) {
        dtype = inferDtype(values);
      } else if (dtype === "complex64") {
        throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");
      }
      if (isWebGPUData(values) || isWebGLData(values)) {
        if (dtype !== "float32" && dtype !== "int32") {
          throw new Error("Creating tensor from GPU data only supports " + "'float32'|'int32' dtype, while the dtype is ".concat(dtype, "."));
        }
        return ENGINE.backend.createTensorFromGPUData(values, shape || inferredShape, dtype);
      }
      if (!isTypedArray(values) && !Array.isArray(values) && typeof values !== "number" && typeof values !== "boolean" && typeof values !== "string") {
        throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");
      }
      if (shape != null) {
        assertNonNegativeIntegerDimensions(shape);
        var providedSize_1 = sizeFromShape(shape);
        var inferredSize_1 = sizeFromShape(inferredShape);
        assert(providedSize_1 === inferredSize_1, function() {
          return "Based on the provided shape, [".concat(shape, "], the tensor should have ") + "".concat(providedSize_1, " values but has ").concat(inferredSize_1);
        });
        for (var i = 0; i < inferredShape.length; ++i) {
          var inferred = inferredShape[i];
          var flatDimsDontMatch = i === inferredShape.length - 1 ? inferred !== sizeFromShape(shape.slice(i)) : true;
          assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, function() {
            return "Error creating a new Tensor. Inferred shape " + "(".concat(inferredShape, ") does not match the provided ") + "shape (".concat(shape, "). ");
          });
        }
      }
      if (!isTypedArray(values) && !Array.isArray(values)) {
        values = [values];
      }
      shape = shape || inferredShape;
      values = dtype !== "string" ? toTypedArray(values, dtype) : flatten(values, [], true);
      return ENGINE.makeTensor(values, shape, dtype);
    }
    function tensor(values, shape, dtype) {
      var inferredShape = inferShape(values, dtype);
      return makeTensor(values, shape, inferredShape, dtype);
    }
    var DTYPE_VALUE_SIZE_MAP = {
      "float32": 4,
      "float16": 2,
      "int32": 4,
      "uint16": 2,
      "uint8": 1,
      "bool": 1,
      "complex64": 8
    };
    var CompositeArrayBuffer = (
      /** @class */
      function() {
        function CompositeArrayBuffer2(buffers) {
          this.shards = [];
          this.previousShardIndex = 0;
          if (buffers == null) {
            return;
          }
          if (!(buffers instanceof Array)) {
            buffers = [buffers];
          }
          buffers = buffers.map(function(bufferOrTypedArray) {
            if (isTypedArray(bufferOrTypedArray)) {
              return bufferOrTypedArray.buffer;
            }
            return bufferOrTypedArray;
          });
          if (buffers.length === 0) {
            return;
          }
          this.bufferUniformSize = buffers[0].byteLength;
          var start = 0;
          for (var i = 0; i < buffers.length; i++) {
            var buffer2 = buffers[i];
            if (i !== buffers.length - 1 && buffer2.byteLength !== this.bufferUniformSize) {
              this.bufferUniformSize = void 0;
            }
            var end = start + buffer2.byteLength;
            this.shards.push({ buffer: buffer2, start, end });
            start = end;
          }
          if (this.shards.length === 0) {
            this.byteLength = 0;
          }
          this.byteLength = this.shards[this.shards.length - 1].end;
        }
        CompositeArrayBuffer2.join = function(buffers) {
          return new CompositeArrayBuffer2(buffers).slice();
        };
        CompositeArrayBuffer2.prototype.slice = function(start, end) {
          if (start === void 0) {
            start = 0;
          }
          if (end === void 0) {
            end = this.byteLength;
          }
          if (this.shards.length === 0) {
            return new ArrayBuffer(0);
          }
          start = isNaN(Number(start)) ? 0 : start;
          end = isNaN(Number(end)) ? 0 : end;
          start = Math.max(0, start);
          end = Math.min(this.byteLength, end);
          if (end <= start) {
            return new ArrayBuffer(0);
          }
          var startShardIndex = this.findShardForByte(start);
          if (startShardIndex === -1) {
            throw new Error("Could not find start shard for byte ".concat(start));
          }
          var size = end - start;
          var outputBuffer = new ArrayBuffer(size);
          var outputArray = new Uint8Array(outputBuffer);
          var sliced = 0;
          for (var i = startShardIndex; i < this.shards.length; i++) {
            var shard = this.shards[i];
            var globalStart = start + sliced;
            var localStart = globalStart - shard.start;
            var outputStart = sliced;
            var globalEnd = Math.min(end, shard.end);
            var localEnd = globalEnd - shard.start;
            var outputSlice = new Uint8Array(shard.buffer, localStart, localEnd - localStart);
            outputArray.set(outputSlice, outputStart);
            sliced += outputSlice.length;
            if (end < shard.end) {
              break;
            }
          }
          return outputBuffer;
        };
        CompositeArrayBuffer2.prototype.findShardForByte = function(byteIndex) {
          if (this.shards.length === 0 || byteIndex < 0 || byteIndex >= this.byteLength) {
            return -1;
          }
          if (this.bufferUniformSize != null) {
            this.previousShardIndex = Math.floor(byteIndex / this.bufferUniformSize);
            return this.previousShardIndex;
          }
          function check(shard) {
            if (byteIndex < shard.start) {
              return -1;
            }
            if (byteIndex >= shard.end) {
              return 1;
            }
            return 0;
          }
          if (check(this.shards[this.previousShardIndex]) === 0) {
            return this.previousShardIndex;
          }
          var index = search(this.shards, check);
          if (index === -1) {
            return -1;
          }
          this.previousShardIndex = index;
          return this.previousShardIndex;
        };
        return CompositeArrayBuffer2;
      }()
    );
    function search(sortedArray, compare) {
      var min2 = 0;
      var max2 = sortedArray.length;
      while (min2 <= max2) {
        var middle = Math.floor((max2 - min2) / 2) + min2;
        var side = compare(sortedArray[middle]);
        if (side === 0) {
          return middle;
        } else if (side < 0) {
          max2 = middle;
        } else {
          min2 = middle + 1;
        }
      }
      return -1;
    }
    function enableProdMode() {
      env().set("PROD", true);
    }
    function enableDebugMode() {
      env().set("DEBUG", true);
    }
    function disableDeprecationWarnings() {
      env().set("DEPRECATION_WARNINGS_ENABLED", false);
      console.warn("TensorFlow.js deprecation warnings have been disabled.");
    }
    function deprecationWarn(msg) {
      if (env().getBool("DEPRECATION_WARNINGS_ENABLED")) {
        console.warn(msg + " You can disable deprecation warnings with tf.disableDeprecationWarnings().");
      }
    }
    function disposeVariables() {
      ENGINE.disposeVariables();
    }
    function engine() {
      return ENGINE;
    }
    function memory() {
      return ENGINE.memory();
    }
    function profile(f) {
      return ENGINE.profile(f);
    }
    function tidy(nameOrFn, fn) {
      return ENGINE.tidy(nameOrFn, fn);
    }
    function dispose(container) {
      var tensors = getTensorsInContainer(container);
      tensors.forEach(function(tensor2) {
        return tensor2.dispose();
      });
    }
    function keep(result) {
      return ENGINE.keep(result);
    }
    function time(f) {
      return ENGINE.time(f);
    }
    function setBackend(backendName) {
      return ENGINE.setBackend(backendName);
    }
    function ready() {
      return ENGINE.ready();
    }
    function getBackend() {
      return ENGINE.backendName;
    }
    function removeBackend(name) {
      ENGINE.removeBackend(name);
    }
    function findBackend(name) {
      return ENGINE.findBackend(name);
    }
    function findBackendFactory(name) {
      return ENGINE.findBackendFactory(name);
    }
    function registerBackend(name, factory, priority) {
      if (priority === void 0) {
        priority = 1;
      }
      return ENGINE.registerBackend(name, factory, priority);
    }
    function backend() {
      return ENGINE.backend;
    }
    function setPlatform(platformName, platform) {
      env().setPlatform(platformName, platform);
    }
    var NUM_BYTES_STRING_LENGTH = 4;
    function encodeWeights(tensors, group) {
      return __awaiter(this, void 0, void 0, function() {
        var specs, dataPromises, names, _loop_1, i, tensorValues;
        var _this = this;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              specs = [];
              dataPromises = [];
              names = Array.isArray(tensors) ? tensors.map(function(tensor2) {
                return tensor2.name;
              }) : Object.keys(tensors);
              _loop_1 = function(i2) {
                var name = names[i2];
                var t = Array.isArray(tensors) ? tensors[i2].tensor : tensors[name];
                if (t.dtype !== "float32" && t.dtype !== "int32" && t.dtype !== "bool" && t.dtype !== "string" && t.dtype !== "complex64") {
                  throw new Error("Unsupported dtype in weight '".concat(name, "': ").concat(t.dtype));
                }
                var spec = { name, shape: t.shape, dtype: t.dtype };
                if (t.dtype === "string") {
                  var utf8bytes = new Promise(function(resolve) {
                    return __awaiter(_this, void 0, void 0, function() {
                      var vals, totalNumBytes, bytes, offset, i_1, val, bytesOfLength;
                      return __generator(this, function(_a2) {
                        switch (_a2.label) {
                          case 0:
                            return [4, t.bytes()];
                          case 1:
                            vals = _a2.sent();
                            totalNumBytes = vals.reduce(function(p, c) {
                              return p + c.length;
                            }, 0) + NUM_BYTES_STRING_LENGTH * vals.length;
                            bytes = new Uint8Array(totalNumBytes);
                            offset = 0;
                            for (i_1 = 0; i_1 < vals.length; i_1++) {
                              val = vals[i_1];
                              bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);
                              bytes.set(bytesOfLength, offset);
                              offset += NUM_BYTES_STRING_LENGTH;
                              bytes.set(val, offset);
                              offset += val.length;
                            }
                            resolve(bytes);
                            return [
                              2
                              /*return*/
                            ];
                        }
                      });
                    });
                  });
                  dataPromises.push(utf8bytes);
                } else {
                  dataPromises.push(t.data());
                }
                if (group != null) {
                  spec.group = group;
                }
                specs.push(spec);
              };
              for (i = 0; i < names.length; ++i) {
                _loop_1(i);
              }
              return [4, Promise.all(dataPromises)];
            case 1:
              tensorValues = _a.sent();
              return [2, { data: concatenateTypedArrays(tensorValues), specs }];
          }
        });
      });
    }
    function decodeWeights(weightData, specs) {
      var e_1, _a;
      var compositeBuffer = new CompositeArrayBuffer(weightData);
      var out = {};
      var offset = 0;
      try {
        for (var specs_1 = __values(specs), specs_1_1 = specs_1.next(); !specs_1_1.done; specs_1_1 = specs_1.next()) {
          var spec = specs_1_1.value;
          var byteLength = getWeightBytelength(spec, function(start, end) {
            return compositeBuffer.slice(offset + start, offset + end);
          });
          out[spec.name] = decodeWeight(spec, compositeBuffer.slice(offset, offset + byteLength));
          offset += byteLength;
        }
      } catch (e_1_1) {
        e_1 = { error: e_1_1 };
      } finally {
        try {
          if (specs_1_1 && !specs_1_1.done && (_a = specs_1.return))
            _a.call(specs_1);
        } finally {
          if (e_1)
            throw e_1.error;
        }
      }
      return out;
    }
    function getWeightBytelength(spec, slice2) {
      var size = sizeFromShape(spec.shape);
      var bytesPerValue;
      if ("quantization" in spec) {
        var quantization = spec.quantization;
        bytesPerValue = DTYPE_VALUE_SIZE_MAP[quantization.dtype];
      } else if (spec.dtype === "string") {
        var byteLength = 0;
        for (var i = 0; i < size; i++) {
          byteLength += NUM_BYTES_STRING_LENGTH + new Uint32Array(slice2(byteLength, byteLength + NUM_BYTES_STRING_LENGTH))[0];
        }
        return byteLength;
      } else {
        bytesPerValue = DTYPE_VALUE_SIZE_MAP[spec.dtype];
      }
      return size * bytesPerValue;
    }
    function getWeightBytelengthAsync(spec, slice2) {
      return __awaiter(this, void 0, void 0, function() {
        var size, bytesPerValue, quantization, byteLength, i, _a, _b, _c;
        return __generator(this, function(_d) {
          switch (_d.label) {
            case 0:
              size = sizeFromShape(spec.shape);
              if (!("quantization" in spec))
                return [3, 1];
              quantization = spec.quantization;
              bytesPerValue = DTYPE_VALUE_SIZE_MAP[quantization.dtype];
              return [3, 7];
            case 1:
              if (!(spec.dtype === "string"))
                return [3, 6];
              byteLength = 0;
              i = 0;
              _d.label = 2;
            case 2:
              if (!(i < size))
                return [3, 5];
              _a = byteLength;
              _b = NUM_BYTES_STRING_LENGTH;
              _c = Uint32Array.bind;
              return [4, slice2(byteLength, byteLength + NUM_BYTES_STRING_LENGTH)];
            case 3:
              byteLength = _a + (_b + new (_c.apply(Uint32Array, [void 0, _d.sent()]))()[0]);
              _d.label = 4;
            case 4:
              i++;
              return [3, 2];
            case 5:
              return [2, byteLength];
            case 6:
              bytesPerValue = DTYPE_VALUE_SIZE_MAP[spec.dtype];
              _d.label = 7;
            case 7:
              return [2, size * bytesPerValue];
          }
        });
      });
    }
    function decodeWeight(spec, byteBuffer) {
      var name = spec.name;
      var dtype = spec.dtype;
      var shape = spec.shape;
      var size = sizeFromShape(shape);
      var values;
      var offset = 0;
      if ("quantization" in spec) {
        var quantization = spec.quantization;
        if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
          if (!("min" in quantization && "scale" in quantization)) {
            throw new Error("Weight ".concat(spec.name, " with quantization ").concat(quantization.dtype, " ") + "doesn't have corresponding metadata min and scale.");
          }
        } else if (quantization.dtype === "float16") {
          if (dtype !== "float32") {
            throw new Error("Weight ".concat(spec.name, " is quantized with ").concat(quantization.dtype, " ") + "which only supports weights of type float32 not ".concat(dtype, "."));
          }
        } else {
          throw new Error("Weight ".concat(spec.name, " has unknown ") + "quantization dtype ".concat(quantization.dtype, ". ") + "Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.");
        }
        var quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];
        var quantizedArray = quantization.dtype === "uint8" ? new Uint8Array(byteBuffer) : new Uint16Array(byteBuffer);
        if (dtype === "float32") {
          if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
            values = new Float32Array(quantizedArray.length);
            for (var i = 0; i < quantizedArray.length; i++) {
              var v = quantizedArray[i];
              values[i] = v * quantization.scale + quantization.min;
            }
          } else if (quantization.dtype === "float16") {
            var float16Decode = getFloat16Decoder();
            values = float16Decode(quantizedArray);
          } else {
            throw new Error("Unsupported quantization type ".concat(quantization.dtype, " ") + "for weight type float32.");
          }
        } else if (dtype === "int32") {
          if (quantization.dtype !== "uint8" && quantization.dtype !== "uint16") {
            throw new Error("Unsupported quantization type ".concat(quantization.dtype, " ") + "for weight type int32.");
          }
          values = new Int32Array(quantizedArray.length);
          for (var i = 0; i < quantizedArray.length; i++) {
            var v = quantizedArray[i];
            values[i] = Math.round(v * quantization.scale + quantization.min);
          }
        } else {
          throw new Error("Unsupported dtype in weight '".concat(name, "': ").concat(dtype));
        }
        offset += size * quantizationSizeFactor;
      } else if (dtype === "string") {
        var size_1 = sizeFromShape(spec.shape);
        values = [];
        for (var i = 0; i < size_1; i++) {
          var byteLength = new Uint32Array(byteBuffer.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];
          offset += NUM_BYTES_STRING_LENGTH;
          var bytes = new Uint8Array(byteBuffer.slice(offset, offset + byteLength));
          values.push(bytes);
          offset += byteLength;
        }
      } else {
        var dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];
        if (dtype === "float32") {
          values = new Float32Array(byteBuffer);
        } else if (dtype === "int32") {
          values = new Int32Array(byteBuffer);
        } else if (dtype === "bool") {
          values = new Uint8Array(byteBuffer);
        } else if (dtype === "complex64") {
          values = new Float32Array(byteBuffer);
          var real2 = new Float32Array(values.length / 2);
          var image2 = new Float32Array(values.length / 2);
          for (var i = 0; i < real2.length; i++) {
            real2[i] = values[i * 2];
            image2[i] = values[i * 2 + 1];
          }
          var realTensor = tensor(real2, shape, "float32");
          var imageTensor = tensor(image2, shape, "float32");
          var complexTensor = complex(realTensor, imageTensor);
          realTensor.dispose();
          imageTensor.dispose();
          return complexTensor;
        } else {
          throw new Error("Unsupported dtype in weight '".concat(name, "': ").concat(dtype));
        }
        offset += size * dtypeFactor;
      }
      return tensor(values, shape, dtype);
    }
    function readToLength(reader, initialData, length) {
      return __awaiter(this, void 0, void 0, function() {
        var data, _a, done, value, missing, newData;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              data = new Uint8Array(initialData);
              _b.label = 1;
            case 1:
              if (!(data.byteLength < length))
                return [3, 3];
              return [4, reader.read()];
            case 2:
              _a = _b.sent(), done = _a.done, value = _a.value;
              if (done && value == null) {
                missing = length - data.byteLength;
                throw new Error("Reader is done but ".concat(missing, " bytes are still expected"));
              }
              newData = new Uint8Array(data.length + value.byteLength);
              newData.set(data, 0);
              newData.set(new Uint8Array(value), data.length);
              data = newData;
              return [3, 1];
            case 3:
              return [2, data.buffer];
          }
        });
      });
    }
    function decodeWeightsStream(weightStream, specs) {
      return __awaiter(this, void 0, void 0, function() {
        var tensors, reader, data, specs_2, specs_2_1, spec, byteLength, tensorData, weightTensor, b, e_2_1;
        var e_2, _a;
        var _this = this;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              tensors = {};
              reader = weightStream.getReader();
              data = new ArrayBuffer(0);
              _b.label = 1;
            case 1:
              _b.trys.push([1, 7, 8, 9]);
              specs_2 = __values(specs), specs_2_1 = specs_2.next();
              _b.label = 2;
            case 2:
              if (!!specs_2_1.done)
                return [3, 6];
              spec = specs_2_1.value;
              return [4, getWeightBytelengthAsync(spec, function(start, end) {
                return __awaiter(_this, void 0, void 0, function() {
                  return __generator(this, function(_a2) {
                    switch (_a2.label) {
                      case 0:
                        return [4, readToLength(reader, data, end)];
                      case 1:
                        data = _a2.sent();
                        return [2, data.slice(start, end)];
                    }
                  });
                });
              })];
            case 3:
              byteLength = _b.sent();
              return [4, readToLength(reader, data, byteLength)];
            case 4:
              data = _b.sent();
              tensorData = data.slice(0, byteLength);
              data = data.slice(byteLength);
              weightTensor = decodeWeight(spec, tensorData);
              tensors[spec.name] = weightTensor;
              if (getBackend() === "webgpu") {
                b = backend();
                if ("uploadToGPU" in b && sizeFromShape(weightTensor.shape) >= env().get("WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD")) {
                  b.uploadToGPU(weightTensor.dataId);
                }
              }
              _b.label = 5;
            case 5:
              specs_2_1 = specs_2.next();
              return [3, 2];
            case 6:
              return [3, 9];
            case 7:
              e_2_1 = _b.sent();
              e_2 = { error: e_2_1 };
              return [3, 9];
            case 8:
              try {
                if (specs_2_1 && !specs_2_1.done && (_a = specs_2.return))
                  _a.call(specs_2);
              } finally {
                if (e_2)
                  throw e_2.error;
              }
              return [
                7
                /*endfinally*/
              ];
            case 9:
              return [2, tensors];
          }
        });
      });
    }
    function concatenateTypedArrays(xs) {
      if (xs === null) {
        throw new Error("Invalid input value: ".concat(JSON.stringify(xs)));
      }
      var totalByteLength = 0;
      var normalizedXs = [];
      xs.forEach(function(x) {
        totalByteLength += x.byteLength;
        normalizedXs.push(x.byteLength === x.buffer.byteLength ? x : new x.constructor(x));
        if (!(x instanceof Float32Array || x instanceof Int32Array || x instanceof Uint8Array)) {
          throw new Error("Unsupported TypedArray subtype: ".concat(x.constructor.name));
        }
      });
      var y = new Uint8Array(totalByteLength);
      var offset = 0;
      normalizedXs.forEach(function(x) {
        y.set(new Uint8Array(x.buffer), offset);
        offset += x.byteLength;
      });
      return y.buffer;
    }
    var useNodeBuffer = typeof Buffer !== "undefined" && (typeof Blob === "undefined" || typeof atob === "undefined" || typeof btoa === "undefined");
    function stringByteLength(str) {
      if (useNodeBuffer) {
        return Buffer.byteLength(str, "utf8");
      }
      return new Blob([str]).size;
    }
    function arrayBufferToBase64String(buffer2) {
      if (useNodeBuffer) {
        return Buffer.from(buffer2).toString("base64");
      }
      var buf = new Uint8Array(buffer2);
      var s = "";
      for (var i = 0, l = buf.length; i < l; i++) {
        s += String.fromCharCode(buf[i]);
      }
      return btoa(s);
    }
    function base64StringToArrayBuffer(str) {
      if (useNodeBuffer) {
        var buf = Buffer.from(str, "base64");
        return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);
      }
      var s = atob(str);
      var buffer2 = new Uint8Array(s.length);
      for (var i = 0; i < s.length; ++i) {
        buffer2.set([s.charCodeAt(i)], i);
      }
      return buffer2.buffer;
    }
    function concatenateArrayBuffers(buffers) {
      return CompositeArrayBuffer.join(buffers);
    }
    function basename(path) {
      var SEPARATOR = "/";
      path = path.trim();
      while (path.endsWith(SEPARATOR)) {
        path = path.slice(0, path.length - 1);
      }
      var items = path.split(SEPARATOR);
      return items[items.length - 1];
    }
    function getModelJSONForModelArtifacts(artifacts, manifest) {
      var result = {
        modelTopology: artifacts.modelTopology,
        format: artifacts.format,
        generatedBy: artifacts.generatedBy,
        convertedBy: artifacts.convertedBy,
        weightsManifest: manifest
      };
      if (artifacts.signature != null) {
        result.signature = artifacts.signature;
      }
      if (artifacts.userDefinedMetadata != null) {
        result.userDefinedMetadata = artifacts.userDefinedMetadata;
      }
      if (artifacts.modelInitializer != null) {
        result.modelInitializer = artifacts.modelInitializer;
      }
      if (artifacts.initializerSignature != null) {
        result.initializerSignature = artifacts.initializerSignature;
      }
      if (artifacts.trainingConfig != null) {
        result.trainingConfig = artifacts.trainingConfig;
      }
      return result;
    }
    function getModelArtifactsForJSONSync(modelJSON, weightSpecs, weightData) {
      var modelArtifacts = {
        modelTopology: modelJSON.modelTopology,
        format: modelJSON.format,
        generatedBy: modelJSON.generatedBy,
        convertedBy: modelJSON.convertedBy
      };
      if (modelJSON.trainingConfig != null) {
        modelArtifacts.trainingConfig = modelJSON.trainingConfig;
      }
      if (modelJSON.weightsManifest != null) {
        if (!weightSpecs) {
          throw new Error("modelJSON has weightsManifest but weightSpecs is null");
        }
        if (!weightData) {
          throw new Error("modelJSON has weightsManifest but weightData is null");
        }
        modelArtifacts.weightSpecs = weightSpecs;
        modelArtifacts.weightData = weightData;
      }
      if (modelJSON.signature != null) {
        modelArtifacts.signature = modelJSON.signature;
      }
      if (modelJSON.userDefinedMetadata != null) {
        modelArtifacts.userDefinedMetadata = modelJSON.userDefinedMetadata;
      }
      if (modelJSON.modelInitializer != null) {
        modelArtifacts.modelInitializer = modelJSON.modelInitializer;
      }
      if (modelJSON.initializerSignature != null) {
        modelArtifacts.initializerSignature = modelJSON.initializerSignature;
      }
      return modelArtifacts;
    }
    function getModelArtifactsForJSON(modelJSON, loadWeights2) {
      return __awaiter(this, void 0, void 0, function() {
        var weightSpecs, weightData;
        var _a;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              if (!(modelJSON.weightsManifest != null))
                return [3, 2];
              return [4, loadWeights2(modelJSON.weightsManifest)];
            case 1:
              _a = __read.apply(void 0, [_b.sent(), 2]), weightSpecs = _a[0], weightData = _a[1];
              _b.label = 2;
            case 2:
              return [2, getModelArtifactsForJSONSync(modelJSON, weightSpecs, weightData)];
          }
        });
      });
    }
    function getModelArtifactsInfoForJSON(modelArtifacts) {
      if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
        throw new Error("Expected JSON model topology, received ArrayBuffer.");
      }
      return {
        dateSaved: /* @__PURE__ */ new Date(),
        modelTopologyType: "JSON",
        modelTopologyBytes: modelArtifacts.modelTopology == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),
        weightSpecsBytes: modelArtifacts.weightSpecs == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),
        weightDataBytes: modelArtifacts.weightData == null ? 0 : new CompositeArrayBuffer(modelArtifacts.weightData).byteLength
      };
    }
    function getWeightSpecs(weightsManifest) {
      var e_3, _a;
      var weightSpecs = [];
      try {
        for (var weightsManifest_1 = __values(weightsManifest), weightsManifest_1_1 = weightsManifest_1.next(); !weightsManifest_1_1.done; weightsManifest_1_1 = weightsManifest_1.next()) {
          var entry = weightsManifest_1_1.value;
          weightSpecs.push.apply(weightSpecs, __spreadArray([], __read(entry.weights), false));
        }
      } catch (e_3_1) {
        e_3 = { error: e_3_1 };
      } finally {
        try {
          if (weightsManifest_1_1 && !weightsManifest_1_1.done && (_a = weightsManifest_1.return))
            _a.call(weightsManifest_1);
        } finally {
          if (e_3)
            throw e_3.error;
        }
      }
      return weightSpecs;
    }
    function computeFloat16MantisaTable() {
      var convertMantissa = function(i2) {
        var m = i2 << 13;
        var e = 0;
        while ((m & 8388608) === 0) {
          e -= 8388608;
          m <<= 1;
        }
        m &= ~8388608;
        e += 947912704;
        return m | e;
      };
      var mantisaTable = new Uint32Array(2048);
      mantisaTable[0] = 0;
      for (var i = 1; i < 1024; i++) {
        mantisaTable[i] = convertMantissa(i);
      }
      for (var i = 1024; i < 2048; i++) {
        mantisaTable[i] = 939524096 + (i - 1024 << 13);
      }
      return mantisaTable;
    }
    function computeFloat16ExponentTable() {
      var exponentTable = new Uint32Array(64);
      exponentTable[0] = 0;
      exponentTable[31] = 1199570944;
      exponentTable[32] = 2147483648;
      exponentTable[63] = 3347054592;
      for (var i = 1; i < 31; i++) {
        exponentTable[i] = i << 23;
      }
      for (var i = 33; i < 63; i++) {
        exponentTable[i] = 2147483648 + (i - 32 << 23);
      }
      return exponentTable;
    }
    function computeFloat16OffsetTable() {
      var offsetTable = new Uint32Array(64);
      for (var i = 0; i < 64; i++) {
        offsetTable[i] = 1024;
      }
      offsetTable[0] = offsetTable[32] = 0;
      return offsetTable;
    }
    function getFloat16Decoder() {
      var mantisaTable = computeFloat16MantisaTable();
      var exponentTable = computeFloat16ExponentTable();
      var offsetTable = computeFloat16OffsetTable();
      return function(quantizedArray) {
        var buffer2 = new ArrayBuffer(4 * quantizedArray.length);
        var bufferUint32View = new Uint32Array(buffer2);
        for (var index = 0; index < quantizedArray.length; index++) {
          var float16Bits = quantizedArray[index];
          var float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 1023)] + exponentTable[float16Bits >> 10];
          bufferUint32View[index] = float32Bits;
        }
        return new Float32Array(buffer2);
      };
    }
    var IORouterRegistry = (
      /** @class */
      function() {
        function IORouterRegistry2() {
          this.saveRouters = [];
          this.loadRouters = [];
        }
        IORouterRegistry2.getInstance = function() {
          if (IORouterRegistry2.instance == null) {
            IORouterRegistry2.instance = new IORouterRegistry2();
          }
          return IORouterRegistry2.instance;
        };
        IORouterRegistry2.registerSaveRouter = function(saveRouter) {
          IORouterRegistry2.getInstance().saveRouters.push(saveRouter);
        };
        IORouterRegistry2.registerLoadRouter = function(loadRouter) {
          IORouterRegistry2.getInstance().loadRouters.push(loadRouter);
        };
        IORouterRegistry2.getSaveHandlers = function(url) {
          return IORouterRegistry2.getHandlers(url, "save");
        };
        IORouterRegistry2.getLoadHandlers = function(url, loadOptions) {
          return IORouterRegistry2.getHandlers(url, "load", loadOptions);
        };
        IORouterRegistry2.getHandlers = function(url, handlerType, loadOptions) {
          var validHandlers = [];
          var routers = handlerType === "load" ? IORouterRegistry2.getInstance().loadRouters : IORouterRegistry2.getInstance().saveRouters;
          routers.forEach(function(router) {
            var handler = router(url, loadOptions);
            if (handler !== null) {
              validHandlers.push(handler);
            }
          });
          return validHandlers;
        };
        return IORouterRegistry2;
      }()
    );
    var registerSaveRouter = function(loudRouter) {
      return IORouterRegistry.registerSaveRouter(loudRouter);
    };
    var registerLoadRouter = function(loudRouter) {
      return IORouterRegistry.registerLoadRouter(loudRouter);
    };
    var getSaveHandlers = function(url) {
      return IORouterRegistry.getSaveHandlers(url);
    };
    var getLoadHandlers = function(url, loadOptions) {
      return IORouterRegistry.getLoadHandlers(url, loadOptions);
    };
    var DATABASE_NAME = "tensorflowjs";
    var DATABASE_VERSION = 1;
    var MODEL_STORE_NAME = "models_store";
    var INFO_STORE_NAME = "model_info_store";
    function getIndexedDBFactory() {
      if (!env().getBool("IS_BROWSER")) {
        throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");
      }
      var theWindow = typeof window === "undefined" ? self : window;
      var factory = theWindow.indexedDB || theWindow.mozIndexedDB || theWindow.webkitIndexedDB || theWindow.msIndexedDB || theWindow.shimIndexedDB;
      if (factory == null) {
        throw new Error("The current browser does not appear to support IndexedDB.");
      }
      return factory;
    }
    function setUpDatabase(openRequest) {
      var db = openRequest.result;
      db.createObjectStore(MODEL_STORE_NAME, { keyPath: "modelPath" });
      db.createObjectStore(INFO_STORE_NAME, { keyPath: "modelPath" });
    }
    var BrowserIndexedDB = (
      /** @class */
      function() {
        function BrowserIndexedDB2(modelPath) {
          this.indexedDB = getIndexedDBFactory();
          if (modelPath == null || !modelPath) {
            throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");
          }
          this.modelPath = modelPath;
        }
        BrowserIndexedDB2.prototype.save = function(modelArtifacts) {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
                throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
              }
              return [2, this.databaseAction(this.modelPath, modelArtifacts)];
            });
          });
        };
        BrowserIndexedDB2.prototype.load = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              return [2, this.databaseAction(this.modelPath)];
            });
          });
        };
        BrowserIndexedDB2.prototype.databaseAction = function(modelPath, modelArtifacts) {
          var _this = this;
          return new Promise(function(resolve, reject) {
            var openRequest = _this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
            openRequest.onupgradeneeded = function() {
              return setUpDatabase(openRequest);
            };
            openRequest.onsuccess = function() {
              var db = openRequest.result;
              if (modelArtifacts == null) {
                var modelTx = db.transaction(MODEL_STORE_NAME, "readonly");
                var modelStore = modelTx.objectStore(MODEL_STORE_NAME);
                var getRequest_1 = modelStore.get(_this.modelPath);
                getRequest_1.onsuccess = function() {
                  if (getRequest_1.result == null) {
                    db.close();
                    return reject(new Error("Cannot find model with path '".concat(_this.modelPath, "' ") + "in IndexedDB."));
                  } else {
                    resolve(getRequest_1.result.modelArtifacts);
                  }
                };
                getRequest_1.onerror = function(error) {
                  db.close();
                  return reject(getRequest_1.error);
                };
                modelTx.oncomplete = function() {
                  return db.close();
                };
              } else {
                modelArtifacts.weightData = CompositeArrayBuffer.join(modelArtifacts.weightData);
                var modelArtifactsInfo_1 = getModelArtifactsInfoForJSON(modelArtifacts);
                var infoTx_1 = db.transaction(INFO_STORE_NAME, "readwrite");
                var infoStore_1 = infoTx_1.objectStore(INFO_STORE_NAME);
                var putInfoRequest_1;
                try {
                  putInfoRequest_1 = infoStore_1.put({ modelPath: _this.modelPath, modelArtifactsInfo: modelArtifactsInfo_1 });
                } catch (error) {
                  return reject(error);
                }
                var modelTx_1;
                putInfoRequest_1.onsuccess = function() {
                  modelTx_1 = db.transaction(MODEL_STORE_NAME, "readwrite");
                  var modelStore2 = modelTx_1.objectStore(MODEL_STORE_NAME);
                  var putModelRequest;
                  try {
                    putModelRequest = modelStore2.put({
                      modelPath: _this.modelPath,
                      modelArtifacts,
                      modelArtifactsInfo: modelArtifactsInfo_1
                    });
                  } catch (error) {
                    return reject(error);
                  }
                  putModelRequest.onsuccess = function() {
                    return resolve({ modelArtifactsInfo: modelArtifactsInfo_1 });
                  };
                  putModelRequest.onerror = function(error) {
                    infoStore_1 = infoTx_1.objectStore(INFO_STORE_NAME);
                    var deleteInfoRequest = infoStore_1.delete(_this.modelPath);
                    deleteInfoRequest.onsuccess = function() {
                      db.close();
                      return reject(putModelRequest.error);
                    };
                    deleteInfoRequest.onerror = function(error2) {
                      db.close();
                      return reject(putModelRequest.error);
                    };
                  };
                };
                putInfoRequest_1.onerror = function(error) {
                  db.close();
                  return reject(putInfoRequest_1.error);
                };
                infoTx_1.oncomplete = function() {
                  if (modelTx_1 == null) {
                    db.close();
                  } else {
                    modelTx_1.oncomplete = function() {
                      return db.close();
                    };
                  }
                };
              }
            };
            openRequest.onerror = function(error) {
              return reject(openRequest.error);
            };
          });
        };
        return BrowserIndexedDB2;
      }()
    );
    BrowserIndexedDB.URL_SCHEME = "indexeddb://";
    var indexedDBRouter = function(url) {
      if (!env().getBool("IS_BROWSER")) {
        return null;
      } else {
        if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB.URL_SCHEME)) {
          return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length));
        } else {
          return null;
        }
      }
    };
    IORouterRegistry.registerSaveRouter(indexedDBRouter);
    IORouterRegistry.registerLoadRouter(indexedDBRouter);
    function browserIndexedDB(modelPath) {
      return new BrowserIndexedDB(modelPath);
    }
    function maybeStripScheme$1(key) {
      return key.startsWith(BrowserIndexedDB.URL_SCHEME) ? key.slice(BrowserIndexedDB.URL_SCHEME.length) : key;
    }
    var BrowserIndexedDBManager = (
      /** @class */
      function() {
        function BrowserIndexedDBManager2() {
          this.indexedDB = getIndexedDBFactory();
        }
        BrowserIndexedDBManager2.prototype.listModels = function() {
          return __awaiter(this, void 0, void 0, function() {
            var _this = this;
            return __generator(this, function(_a) {
              return [2, new Promise(function(resolve, reject) {
                var openRequest = _this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
                openRequest.onupgradeneeded = function() {
                  return setUpDatabase(openRequest);
                };
                openRequest.onsuccess = function() {
                  var db = openRequest.result;
                  var tx = db.transaction(INFO_STORE_NAME, "readonly");
                  var store = tx.objectStore(INFO_STORE_NAME);
                  var getAllInfoRequest = store.getAll();
                  getAllInfoRequest.onsuccess = function() {
                    var e_1, _a2;
                    var out = {};
                    try {
                      for (var _b = __values(getAllInfoRequest.result), _c = _b.next(); !_c.done; _c = _b.next()) {
                        var item = _c.value;
                        out[item.modelPath] = item.modelArtifactsInfo;
                      }
                    } catch (e_1_1) {
                      e_1 = { error: e_1_1 };
                    } finally {
                      try {
                        if (_c && !_c.done && (_a2 = _b.return))
                          _a2.call(_b);
                      } finally {
                        if (e_1)
                          throw e_1.error;
                      }
                    }
                    resolve(out);
                  };
                  getAllInfoRequest.onerror = function(error) {
                    db.close();
                    return reject(getAllInfoRequest.error);
                  };
                  tx.oncomplete = function() {
                    return db.close();
                  };
                };
                openRequest.onerror = function(error) {
                  return reject(openRequest.error);
                };
              })];
            });
          });
        };
        BrowserIndexedDBManager2.prototype.removeModel = function(path) {
          return __awaiter(this, void 0, void 0, function() {
            var _this = this;
            return __generator(this, function(_a) {
              path = maybeStripScheme$1(path);
              return [2, new Promise(function(resolve, reject) {
                var openRequest = _this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
                openRequest.onupgradeneeded = function() {
                  return setUpDatabase(openRequest);
                };
                openRequest.onsuccess = function() {
                  var db = openRequest.result;
                  var infoTx = db.transaction(INFO_STORE_NAME, "readwrite");
                  var infoStore = infoTx.objectStore(INFO_STORE_NAME);
                  var getInfoRequest = infoStore.get(path);
                  var modelTx;
                  getInfoRequest.onsuccess = function() {
                    if (getInfoRequest.result == null) {
                      db.close();
                      return reject(new Error("Cannot find model with path '".concat(path, "' ") + "in IndexedDB."));
                    } else {
                      var deleteInfoRequest = infoStore.delete(path);
                      var deleteModelData_1 = function() {
                        modelTx = db.transaction(MODEL_STORE_NAME, "readwrite");
                        var modelStore = modelTx.objectStore(MODEL_STORE_NAME);
                        var deleteModelRequest = modelStore.delete(path);
                        deleteModelRequest.onsuccess = function() {
                          return resolve(getInfoRequest.result.modelArtifactsInfo);
                        };
                        deleteModelRequest.onerror = function(error) {
                          return reject(getInfoRequest.error);
                        };
                      };
                      deleteInfoRequest.onsuccess = deleteModelData_1;
                      deleteInfoRequest.onerror = function(error) {
                        deleteModelData_1();
                        db.close();
                        return reject(getInfoRequest.error);
                      };
                    }
                  };
                  getInfoRequest.onerror = function(error) {
                    db.close();
                    return reject(getInfoRequest.error);
                  };
                  infoTx.oncomplete = function() {
                    if (modelTx == null) {
                      db.close();
                    } else {
                      modelTx.oncomplete = function() {
                        return db.close();
                      };
                    }
                  };
                };
                openRequest.onerror = function(error) {
                  return reject(openRequest.error);
                };
              })];
            });
          });
        };
        return BrowserIndexedDBManager2;
      }()
    );
    var PATH_SEPARATOR = "/";
    var PATH_PREFIX = "tensorflowjs_models";
    var INFO_SUFFIX = "info";
    var MODEL_TOPOLOGY_SUFFIX = "model_topology";
    var WEIGHT_SPECS_SUFFIX = "weight_specs";
    var WEIGHT_DATA_SUFFIX = "weight_data";
    var MODEL_METADATA_SUFFIX = "model_metadata";
    function getModelKeys(path) {
      return {
        info: [PATH_PREFIX, path, INFO_SUFFIX].join(PATH_SEPARATOR),
        topology: [PATH_PREFIX, path, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),
        weightSpecs: [PATH_PREFIX, path, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),
        weightData: [PATH_PREFIX, path, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),
        modelMetadata: [PATH_PREFIX, path, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)
      };
    }
    function removeItems(keys) {
      var e_1, _a;
      try {
        for (var _b = __values(Object.values(keys)), _c = _b.next(); !_c.done; _c = _b.next()) {
          var key = _c.value;
          window.localStorage.removeItem(key);
        }
      } catch (e_1_1) {
        e_1 = { error: e_1_1 };
      } finally {
        try {
          if (_c && !_c.done && (_a = _b.return))
            _a.call(_b);
        } finally {
          if (e_1)
            throw e_1.error;
        }
      }
    }
    function getModelPathFromKey(key) {
      var items = key.split(PATH_SEPARATOR);
      if (items.length < 3) {
        throw new Error("Invalid key format: ".concat(key));
      }
      return items.slice(1, items.length - 1).join(PATH_SEPARATOR);
    }
    function maybeStripScheme(key) {
      return key.startsWith(BrowserLocalStorage.URL_SCHEME) ? key.slice(BrowserLocalStorage.URL_SCHEME.length) : key;
    }
    var BrowserLocalStorage = (
      /** @class */
      function() {
        function BrowserLocalStorage2(modelPath) {
          if (!env().getBool("IS_BROWSER") || typeof window === "undefined" || typeof window.localStorage === "undefined") {
            throw new Error("The current environment does not support local storage.");
          }
          this.LS = window.localStorage;
          if (modelPath == null || !modelPath) {
            throw new Error("For local storage, modelPath must not be null, undefined or empty.");
          }
          this.modelPath = modelPath;
          this.keys = getModelKeys(this.modelPath);
        }
        BrowserLocalStorage2.prototype.save = function(modelArtifacts) {
          return __awaiter(this, void 0, void 0, function() {
            var topology, weightSpecs, modelArtifactsInfo, weightBuffer, metadata;
            return __generator(this, function(_a) {
              if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
                throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
              } else {
                topology = JSON.stringify(modelArtifacts.modelTopology);
                weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);
                modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);
                weightBuffer = CompositeArrayBuffer.join(modelArtifacts.weightData);
                try {
                  this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));
                  this.LS.setItem(this.keys.topology, topology);
                  this.LS.setItem(this.keys.weightSpecs, weightSpecs);
                  this.LS.setItem(this.keys.weightData, arrayBufferToBase64String(weightBuffer));
                  metadata = {
                    format: modelArtifacts.format,
                    generatedBy: modelArtifacts.generatedBy,
                    convertedBy: modelArtifacts.convertedBy,
                    signature: modelArtifacts.signature != null ? modelArtifacts.signature : void 0,
                    userDefinedMetadata: modelArtifacts.userDefinedMetadata != null ? modelArtifacts.userDefinedMetadata : void 0,
                    modelInitializer: modelArtifacts.modelInitializer != null ? modelArtifacts.modelInitializer : void 0,
                    initializerSignature: modelArtifacts.initializerSignature != null ? modelArtifacts.initializerSignature : void 0,
                    trainingConfig: modelArtifacts.trainingConfig != null ? modelArtifacts.trainingConfig : void 0
                  };
                  this.LS.setItem(this.keys.modelMetadata, JSON.stringify(metadata));
                  return [2, { modelArtifactsInfo }];
                } catch (err) {
                  removeItems(this.keys);
                  throw new Error("Failed to save model '".concat(this.modelPath, "' to local storage: ") + "size quota being exceeded is a possible cause of this failure: " + "modelTopologyBytes=".concat(modelArtifactsInfo.modelTopologyBytes, ", ") + "weightSpecsBytes=".concat(modelArtifactsInfo.weightSpecsBytes, ", ") + "weightDataBytes=".concat(modelArtifactsInfo.weightDataBytes, "."));
                }
              }
              return [
                2
                /*return*/
              ];
            });
          });
        };
        BrowserLocalStorage2.prototype.load = function() {
          return __awaiter(this, void 0, void 0, function() {
            var info, out, topology, weightSpecs, metadataString, metadata, weightDataBase64;
            return __generator(this, function(_a) {
              info = JSON.parse(this.LS.getItem(this.keys.info));
              if (info == null) {
                throw new Error("In local storage, there is no model with name '".concat(this.modelPath, "'"));
              }
              if (info.modelTopologyType !== "JSON") {
                throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");
              }
              out = {};
              topology = JSON.parse(this.LS.getItem(this.keys.topology));
              if (topology == null) {
                throw new Error("In local storage, the topology of model '".concat(this.modelPath, "' ") + "is missing.");
              }
              out.modelTopology = topology;
              weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));
              if (weightSpecs == null) {
                throw new Error("In local storage, the weight specs of model '".concat(this.modelPath, "' ") + "are missing.");
              }
              out.weightSpecs = weightSpecs;
              metadataString = this.LS.getItem(this.keys.modelMetadata);
              if (metadataString != null) {
                metadata = JSON.parse(metadataString);
                out.format = metadata.format;
                out.generatedBy = metadata.generatedBy;
                out.convertedBy = metadata.convertedBy;
                if (metadata.signature != null) {
                  out.signature = metadata.signature;
                }
                if (metadata.userDefinedMetadata != null) {
                  out.userDefinedMetadata = metadata.userDefinedMetadata;
                }
                if (metadata.modelInitializer != null) {
                  out.modelInitializer = metadata.modelInitializer;
                }
                if (metadata.initializerSignature != null) {
                  out.initializerSignature = metadata.initializerSignature;
                }
                if (metadata.trainingConfig != null) {
                  out.trainingConfig = metadata.trainingConfig;
                }
              }
              weightDataBase64 = this.LS.getItem(this.keys.weightData);
              if (weightDataBase64 == null) {
                throw new Error("In local storage, the binary weight values of model " + "'".concat(this.modelPath, "' are missing."));
              }
              out.weightData = base64StringToArrayBuffer(weightDataBase64);
              return [2, out];
            });
          });
        };
        return BrowserLocalStorage2;
      }()
    );
    BrowserLocalStorage.URL_SCHEME = "localstorage://";
    var localStorageRouter = function(url) {
      if (!env().getBool("IS_BROWSER")) {
        return null;
      } else {
        if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage.URL_SCHEME)) {
          return browserLocalStorage(url.slice(BrowserLocalStorage.URL_SCHEME.length));
        } else {
          return null;
        }
      }
    };
    IORouterRegistry.registerSaveRouter(localStorageRouter);
    IORouterRegistry.registerLoadRouter(localStorageRouter);
    function browserLocalStorage(modelPath) {
      return new BrowserLocalStorage(modelPath);
    }
    var BrowserLocalStorageManager = (
      /** @class */
      function() {
        function BrowserLocalStorageManager2() {
          assert(env().getBool("IS_BROWSER"), function() {
            return "Current environment is not a web browser";
          });
          assert(typeof window === "undefined" || typeof window.localStorage !== "undefined", function() {
            return "Current browser does not appear to support localStorage";
          });
          this.LS = window.localStorage;
        }
        BrowserLocalStorageManager2.prototype.listModels = function() {
          return __awaiter(this, void 0, void 0, function() {
            var out, prefix, suffix, i, key, modelPath;
            return __generator(this, function(_a) {
              out = {};
              prefix = PATH_PREFIX + PATH_SEPARATOR;
              suffix = PATH_SEPARATOR + INFO_SUFFIX;
              for (i = 0; i < this.LS.length; ++i) {
                key = this.LS.key(i);
                if (key.startsWith(prefix) && key.endsWith(suffix)) {
                  modelPath = getModelPathFromKey(key);
                  out[modelPath] = JSON.parse(this.LS.getItem(key));
                }
              }
              return [2, out];
            });
          });
        };
        BrowserLocalStorageManager2.prototype.removeModel = function(path) {
          return __awaiter(this, void 0, void 0, function() {
            var keys, info;
            return __generator(this, function(_a) {
              path = maybeStripScheme(path);
              keys = getModelKeys(path);
              if (this.LS.getItem(keys.info) == null) {
                throw new Error("Cannot find model at path '".concat(path, "'"));
              }
              info = JSON.parse(this.LS.getItem(keys.info));
              removeItems(keys);
              return [2, info];
            });
          });
        };
        return BrowserLocalStorageManager2;
      }()
    );
    var URL_SCHEME_SUFFIX = "://";
    var ModelStoreManagerRegistry = (
      /** @class */
      function() {
        function ModelStoreManagerRegistry2() {
          this.managers = {};
        }
        ModelStoreManagerRegistry2.getInstance = function() {
          if (ModelStoreManagerRegistry2.instance == null) {
            ModelStoreManagerRegistry2.instance = new ModelStoreManagerRegistry2();
          }
          return ModelStoreManagerRegistry2.instance;
        };
        ModelStoreManagerRegistry2.registerManager = function(scheme, manager) {
          assert(scheme != null, function() {
            return "scheme must not be undefined or null.";
          });
          if (scheme.endsWith(URL_SCHEME_SUFFIX)) {
            scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX));
          }
          assert(scheme.length > 0, function() {
            return "scheme must not be an empty string.";
          });
          var registry = ModelStoreManagerRegistry2.getInstance();
          assert(registry.managers[scheme] == null, function() {
            return "A model store manager is already registered for scheme '".concat(scheme, "'.");
          });
          registry.managers[scheme] = manager;
        };
        ModelStoreManagerRegistry2.getManager = function(scheme) {
          var manager = ModelStoreManagerRegistry2.getInstance().managers[scheme];
          if (manager == null) {
            throw new Error("Cannot find model manager for scheme '".concat(scheme, "'"));
          }
          return manager;
        };
        ModelStoreManagerRegistry2.getSchemes = function() {
          return Object.keys(ModelStoreManagerRegistry2.getInstance().managers);
        };
        return ModelStoreManagerRegistry2;
      }()
    );
    function parseURL(url) {
      if (url.indexOf(URL_SCHEME_SUFFIX) === -1) {
        throw new Error("The url string provided does not contain a scheme. Supported schemes are: " + "".concat(ModelStoreManagerRegistry.getSchemes().join(",")));
      }
      return {
        scheme: url.split(URL_SCHEME_SUFFIX)[0],
        path: url.split(URL_SCHEME_SUFFIX)[1]
      };
    }
    function cloneModelInternal(sourceURL, destURL, deleteSource) {
      if (deleteSource === void 0) {
        deleteSource = false;
      }
      return __awaiter(this, void 0, void 0, function() {
        var loadHandlers, loadHandler, saveHandlers, saveHandler, sourceScheme, sourcePath, sameMedium, modelArtifacts, saveResult;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              assert(sourceURL !== destURL, function() {
                return "Old path and new path are the same: '".concat(sourceURL, "'");
              });
              loadHandlers = IORouterRegistry.getLoadHandlers(sourceURL);
              assert(loadHandlers.length > 0, function() {
                return "Copying failed because no load handler is found for source URL ".concat(sourceURL, ".");
              });
              assert(loadHandlers.length < 2, function() {
                return "Copying failed because more than one (".concat(loadHandlers.length, ") ") + "load handlers for source URL ".concat(sourceURL, ".");
              });
              loadHandler = loadHandlers[0];
              saveHandlers = IORouterRegistry.getSaveHandlers(destURL);
              assert(saveHandlers.length > 0, function() {
                return "Copying failed because no save handler is found for destination " + "URL ".concat(destURL, ".");
              });
              assert(saveHandlers.length < 2, function() {
                return "Copying failed because more than one (".concat(loadHandlers.length, ") ") + "save handlers for destination URL ".concat(destURL, ".");
              });
              saveHandler = saveHandlers[0];
              sourceScheme = parseURL(sourceURL).scheme;
              sourcePath = parseURL(sourceURL).path;
              sameMedium = sourceScheme === parseURL(sourceURL).scheme;
              return [4, loadHandler.load()];
            case 1:
              modelArtifacts = _a.sent();
              if (!(deleteSource && sameMedium))
                return [3, 3];
              return [4, ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath)];
            case 2:
              _a.sent();
              _a.label = 3;
            case 3:
              return [4, saveHandler.save(modelArtifacts)];
            case 4:
              saveResult = _a.sent();
              if (!(deleteSource && !sameMedium))
                return [3, 6];
              return [4, ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath)];
            case 5:
              _a.sent();
              _a.label = 6;
            case 6:
              return [2, saveResult.modelArtifactsInfo];
          }
        });
      });
    }
    function listModels() {
      return __awaiter(this, void 0, void 0, function() {
        var schemes, out, schemes_1, schemes_1_1, scheme, schemeOut, path, url, e_1_1;
        var e_1, _a;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              schemes = ModelStoreManagerRegistry.getSchemes();
              out = {};
              _b.label = 1;
            case 1:
              _b.trys.push([1, 6, 7, 8]);
              schemes_1 = __values(schemes), schemes_1_1 = schemes_1.next();
              _b.label = 2;
            case 2:
              if (!!schemes_1_1.done)
                return [3, 5];
              scheme = schemes_1_1.value;
              return [4, ModelStoreManagerRegistry.getManager(scheme).listModels()];
            case 3:
              schemeOut = _b.sent();
              for (path in schemeOut) {
                url = scheme + URL_SCHEME_SUFFIX + path;
                out[url] = schemeOut[path];
              }
              _b.label = 4;
            case 4:
              schemes_1_1 = schemes_1.next();
              return [3, 2];
            case 5:
              return [3, 8];
            case 6:
              e_1_1 = _b.sent();
              e_1 = { error: e_1_1 };
              return [3, 8];
            case 7:
              try {
                if (schemes_1_1 && !schemes_1_1.done && (_a = schemes_1.return))
                  _a.call(schemes_1);
              } finally {
                if (e_1)
                  throw e_1.error;
              }
              return [
                7
                /*endfinally*/
              ];
            case 8:
              return [2, out];
          }
        });
      });
    }
    function removeModel(url) {
      return __awaiter(this, void 0, void 0, function() {
        var schemeAndPath, manager;
        return __generator(this, function(_a) {
          schemeAndPath = parseURL(url);
          manager = ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);
          return [2, manager.removeModel(schemeAndPath.path)];
        });
      });
    }
    function copyModel(sourceURL, destURL) {
      return __awaiter(this, void 0, void 0, function() {
        var deleteSource;
        return __generator(this, function(_a) {
          deleteSource = false;
          return [2, cloneModelInternal(sourceURL, destURL, deleteSource)];
        });
      });
    }
    function moveModel(sourceURL, destURL) {
      return __awaiter(this, void 0, void 0, function() {
        var deleteSource;
        return __generator(this, function(_a) {
          deleteSource = true;
          return [2, cloneModelInternal(sourceURL, destURL, deleteSource)];
        });
      });
    }
    var PlatformBrowser = (
      /** @class */
      function() {
        function PlatformBrowser2() {
          this.messageName = "setTimeoutCustom";
          this.functionRefs = [];
          this.handledMessageCount = 0;
          this.hasEventListener = false;
        }
        PlatformBrowser2.prototype.fetch = function(path, init) {
          return fetch(path, init);
        };
        PlatformBrowser2.prototype.now = function() {
          return performance.now();
        };
        PlatformBrowser2.prototype.encode = function(text, encoding) {
          if (encoding !== "utf-8" && encoding !== "utf8") {
            throw new Error("Browser's encoder only supports utf-8, but got ".concat(encoding));
          }
          if (this.textEncoder == null) {
            this.textEncoder = new TextEncoder();
          }
          return this.textEncoder.encode(text);
        };
        PlatformBrowser2.prototype.decode = function(bytes, encoding) {
          return new TextDecoder(encoding).decode(bytes);
        };
        PlatformBrowser2.prototype.setTimeoutCustom = function(functionRef, delay) {
          var _this = this;
          if (typeof window === "undefined" || !env().getBool("USE_SETTIMEOUTCUSTOM")) {
            setTimeout(functionRef, delay);
            return;
          }
          this.functionRefs.push(functionRef);
          setTimeout(function() {
            window.postMessage({ name: _this.messageName, index: _this.functionRefs.length - 1 }, "*");
          }, delay);
          if (!this.hasEventListener) {
            this.hasEventListener = true;
            window.addEventListener("message", function(event) {
              if (event.source === window && event.data.name === _this.messageName) {
                event.stopPropagation();
                var functionRef_1 = _this.functionRefs[event.data.index];
                functionRef_1();
                _this.handledMessageCount++;
                if (_this.handledMessageCount === _this.functionRefs.length) {
                  _this.functionRefs = [];
                  _this.handledMessageCount = 0;
                }
              }
            }, true);
          }
        };
        PlatformBrowser2.prototype.isTypedArray = function(a) {
          return isTypedArrayBrowser(a);
        };
        return PlatformBrowser2;
      }()
    );
    if (env().get("IS_BROWSER")) {
      env().setPlatform("browser", new PlatformBrowser());
      try {
        ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());
      } catch (err) {
      }
      try {
        ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());
      } catch (err) {
      }
    }
    var getNodeFetch = {
      // tslint:disable-next-line:no-require-imports
      importFetch: function() {
        return require_browser();
      }
    };
    var systemFetch;
    var PlatformNode = (
      /** @class */
      function() {
        function PlatformNode2() {
          this.util = require_util();
          this.textEncoder = new this.util.TextEncoder();
        }
        PlatformNode2.prototype.fetch = function(path, requestInits) {
          if (env().global.fetch != null) {
            return env().global.fetch(path, requestInits);
          }
          if (systemFetch == null) {
            systemFetch = getNodeFetch.importFetch();
          }
          return systemFetch(path, requestInits);
        };
        PlatformNode2.prototype.now = function() {
          var time2 = process.hrtime();
          return time2[0] * 1e3 + time2[1] / 1e6;
        };
        PlatformNode2.prototype.encode = function(text, encoding) {
          if (encoding !== "utf-8" && encoding !== "utf8") {
            throw new Error("Node built-in encoder only supports utf-8, but got ".concat(encoding));
          }
          return this.textEncoder.encode(text);
        };
        PlatformNode2.prototype.decode = function(bytes, encoding) {
          if (bytes.length === 0) {
            return "";
          }
          return new this.util.TextDecoder(encoding).decode(bytes);
        };
        PlatformNode2.prototype.isTypedArray = function(a) {
          return this.util.types.isFloat32Array(a) || this.util.types.isInt32Array(a) || this.util.types.isUint8Array(a) || this.util.types.isUint8ClampedArray(a);
        };
        return PlatformNode2;
      }()
    );
    if (env().get("IS_NODE") && !env().get("IS_BROWSER")) {
      env().setPlatform("node", new PlatformNode());
    }
    function buffer(shape, dtype, values) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      dtype = dtype || "float32";
      assertNonNegativeIntegerDimensions(shape);
      return new TensorBuffer(shape, dtype, values);
    }
    function cast_(x, dtype) {
      var $x = convertToTensor(x, "x", "cast");
      if (!isValidDtype(dtype)) {
        throw new Error("Failed to cast to unknown dtype ".concat(dtype));
      }
      if (dtype === "string" && $x.dtype !== "string" || dtype !== "string" && $x.dtype === "string") {
        throw new Error("Only strings can be casted to strings");
      }
      var inputs = { x: $x };
      var attrs = { dtype };
      return ENGINE.runKernel(Cast, inputs, attrs);
    }
    var cast = /* @__PURE__ */ op({ cast_ });
    function clone_(x) {
      var $x = convertToTensor(x, "x", "clone", "string_or_numeric");
      var inputs = { x: $x };
      return ENGINE.runKernel(Identity, inputs);
    }
    var clone = /* @__PURE__ */ op({ clone_ });
    function print(x, verbose) {
      if (verbose === void 0) {
        verbose = false;
      }
      console.log(x.toString(verbose));
    }
    getOrMakeEngine();
    var opHandler = {
      buffer,
      cast,
      clone,
      print
    };
    setOpHandler(opHandler);
    function add_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "add");
      var $b = convertToTensor(b, "b", "add");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Add, inputs);
    }
    var add = /* @__PURE__ */ op({ add_ });
    function floorDiv_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "floorDiv");
      var $b = convertToTensor(b, "b", "floorDiv");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(FloorDiv, inputs);
    }
    var floorDiv = /* @__PURE__ */ op({ floorDiv_ });
    function div_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "div");
      var $b = convertToTensor(b, "b", "div");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      if ($a.dtype === "int32" && $b.dtype === "int32") {
        return floorDiv($a, $b);
      }
      var inputs = { a: $a, b: $b };
      var attrs = {};
      return ENGINE.runKernel(RealDiv, inputs, attrs);
    }
    var div = /* @__PURE__ */ op({ div_ });
    function mul_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "mul");
      var $b = convertToTensor(b, "b", "mul");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Multiply, inputs);
    }
    var mul = /* @__PURE__ */ op({ mul_ });
    function abs_(x) {
      var $x = convertToTensor(x, "x", "abs");
      if ($x.dtype === "complex64") {
        var inputs = { x: $x };
        return ENGINE.runKernel(ComplexAbs, inputs);
      } else {
        var inputs = { x: $x };
        return ENGINE.runKernel(Abs, inputs);
      }
    }
    var abs = /* @__PURE__ */ op({ abs_ });
    function acos_(x) {
      var $x = convertToTensor(x, "x", "acos");
      var inputs = { x: $x };
      return ENGINE.runKernel(Acos, inputs);
    }
    var acos = /* @__PURE__ */ op({ acos_ });
    function acosh_(x) {
      var $x = convertToTensor(x, "x", "acosh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Acosh, inputs);
    }
    var acosh = /* @__PURE__ */ op({ acosh_ });
    function addN_(tensors) {
      assert(Array.isArray(tensors), function() {
        return "The argument passed to tf.addN() must be a list of tensors";
      });
      assert(tensors.length >= 1, function() {
        return "Must pass at least one tensor to tf.addN(), but got " + "".concat(tensors.length);
      });
      var $tensors = tensors.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "addN");
      });
      var firstTensor = $tensors[0];
      $tensors.forEach(function(t) {
        if (t.dtype !== firstTensor.dtype) {
          throw new Error("All tensors passed to tf.addN() must have the same dtype");
        }
      });
      $tensors.forEach(function(t) {
        if (!arraysEqual(t.shape, firstTensor.shape)) {
          throw new Error("All tensors passed to tf.addN() must have the same shape");
        }
      });
      var inputs = $tensors;
      return ENGINE.runKernel(AddN, inputs);
    }
    var addN = /* @__PURE__ */ op({ addN_ });
    function all_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "all", "bool");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(All, inputs, attrs);
    }
    var all = /* @__PURE__ */ op({ all_ });
    function any_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "any", "bool");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Any, inputs, attrs);
    }
    var any = /* @__PURE__ */ op({ any_ });
    function argMax_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "argMax");
      var inputs = { x: $x };
      var attrs = { axis };
      return ENGINE.runKernel(ArgMax, inputs, attrs);
    }
    var argMax = /* @__PURE__ */ op({ argMax_ });
    function argMin_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "argMin");
      var inputs = { x: $x };
      var attrs = { axis };
      return ENGINE.runKernel(ArgMin, inputs, attrs);
    }
    var argMin = /* @__PURE__ */ op({ argMin_ });
    function asin_(x) {
      var $x = convertToTensor(x, "x", "asin");
      var inputs = { x: $x };
      return ENGINE.runKernel(Asin, inputs);
    }
    var asin = /* @__PURE__ */ op({ asin_ });
    function asinh_(x) {
      var $x = convertToTensor(x, "x", "asinh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Asinh, inputs);
    }
    var asinh = /* @__PURE__ */ op({ asinh_ });
    function atan_(x) {
      var $x = convertToTensor(x, "x", "atan");
      var inputs = { x: $x };
      return ENGINE.runKernel(Atan, inputs);
    }
    var atan = /* @__PURE__ */ op({ atan_ });
    function atan2_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "atan2");
      var $b = convertToTensor(b, "b", "atan2");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Atan2, inputs);
    }
    var atan2 = /* @__PURE__ */ op({ atan2_ });
    function atanh_(x) {
      var $x = convertToTensor(x, "x", "atanh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Atanh, inputs);
    }
    var atanh = /* @__PURE__ */ op({ atanh_ });
    function computeDilation2DInfo(inputShape, filterShape, strides, pad2, dataFormat, dilations) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var inputChannels = inputShape[3];
      var $filterShape = __spreadArray(__spreadArray([], __read(filterShape), false), [inputChannels], false);
      var $dataFormat = convertConv2DDataFormat(dataFormat);
      return computeConv2DInfo(inputShape, $filterShape, strides, dilations, pad2, null, null, $dataFormat);
    }
    function computePool2DInfo(inShape, filterSize, strides, dilations, pad2, roundingMode, dataFormat) {
      if (dataFormat === void 0) {
        dataFormat = "channelsLast";
      }
      var _a = __read(parseTupleParam(filterSize), 2), filterHeight = _a[0], filterWidth = _a[1];
      var filterShape;
      if (dataFormat === "channelsLast") {
        filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];
      } else if (dataFormat === "channelsFirst") {
        filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];
      } else {
        throw new Error("Unknown dataFormat ".concat(dataFormat));
      }
      return computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, false, dataFormat);
    }
    function computePool3DInfo(inShape, filterSize, strides, dilations, pad2, roundingMode, dataFormat) {
      if (dataFormat === void 0) {
        dataFormat = "NDHWC";
      }
      var _a = __read(parse3TupleParam(filterSize), 3), filterDepth = _a[0], filterHeight = _a[1], filterWidth = _a[2];
      var filterShape;
      var $dataFormat;
      if (dataFormat === "NDHWC") {
        $dataFormat = "channelsLast";
        filterShape = [filterDepth, filterHeight, filterWidth, inShape[4], inShape[4]];
      } else if (dataFormat === "NCDHW") {
        $dataFormat = "channelsFirst";
        filterShape = [filterDepth, filterHeight, filterWidth, inShape[1], inShape[1]];
      } else {
        throw new Error("Unknown dataFormat ".concat(dataFormat));
      }
      return computeConv3DInfo(inShape, filterShape, strides, dilations, pad2, false, $dataFormat, roundingMode);
    }
    function computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, depthwise, dataFormat) {
      var _a, _b;
      if (depthwise === void 0) {
        depthwise = false;
      }
      if (dataFormat === void 0) {
        dataFormat = "channelsLast";
      }
      var _c = __read([-1, -1, -1, -1], 4), batchSize = _c[0], inHeight = _c[1], inWidth = _c[2], inChannels = _c[3];
      if (dataFormat === "channelsLast") {
        _a = __read(inShape, 4), batchSize = _a[0], inHeight = _a[1], inWidth = _a[2], inChannels = _a[3];
      } else if (dataFormat === "channelsFirst") {
        _b = __read(inShape, 4), batchSize = _b[0], inChannels = _b[1], inHeight = _b[2], inWidth = _b[3];
      } else {
        throw new Error("Unknown dataFormat ".concat(dataFormat));
      }
      var _d = __read(filterShape, 4), filterHeight = _d[0], filterWidth = _d[1], filterChannels = _d[3];
      var _e = __read(parseTupleParam(strides), 2), strideHeight = _e[0], strideWidth = _e[1];
      var _f = __read(parseTupleParam(dilations), 2), dilationHeight = _f[0], dilationWidth = _f[1];
      var effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
      var effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
      var _g = getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode, dataFormat), padInfo = _g.padInfo, outHeight = _g.outHeight, outWidth = _g.outWidth;
      var outChannels = depthwise ? filterChannels * inChannels : filterChannels;
      var outShape;
      if (dataFormat === "channelsFirst") {
        outShape = [batchSize, outChannels, outHeight, outWidth];
      } else if (dataFormat === "channelsLast") {
        outShape = [batchSize, outHeight, outWidth, outChannels];
      }
      return {
        batchSize,
        dataFormat,
        inHeight,
        inWidth,
        inChannels,
        outHeight,
        outWidth,
        outChannels,
        padInfo,
        strideHeight,
        strideWidth,
        filterHeight,
        filterWidth,
        effectiveFilterHeight,
        effectiveFilterWidth,
        dilationHeight,
        dilationWidth,
        inShape,
        outShape,
        filterShape
      };
    }
    function computeConv3DInfo(inShape, filterShape, strides, dilations, pad2, depthwise, dataFormat, roundingMode) {
      var _a, _b;
      if (depthwise === void 0) {
        depthwise = false;
      }
      if (dataFormat === void 0) {
        dataFormat = "channelsLast";
      }
      var _c = __read([-1, -1, -1, -1, -1], 5), batchSize = _c[0], inDepth = _c[1], inHeight = _c[2], inWidth = _c[3], inChannels = _c[4];
      if (dataFormat === "channelsLast") {
        _a = __read(inShape, 5), batchSize = _a[0], inDepth = _a[1], inHeight = _a[2], inWidth = _a[3], inChannels = _a[4];
      } else if (dataFormat === "channelsFirst") {
        _b = __read(inShape, 5), batchSize = _b[0], inChannels = _b[1], inDepth = _b[2], inHeight = _b[3], inWidth = _b[4];
      } else {
        throw new Error("Unknown dataFormat ".concat(dataFormat));
      }
      var _d = __read(filterShape, 5), filterDepth = _d[0], filterHeight = _d[1], filterWidth = _d[2], filterChannels = _d[4];
      var _e = __read(parse3TupleParam(strides), 3), strideDepth = _e[0], strideHeight = _e[1], strideWidth = _e[2];
      var _f = __read(parse3TupleParam(dilations), 3), dilationDepth = _f[0], dilationHeight = _f[1], dilationWidth = _f[2];
      var effectiveFilterDepth = getEffectiveFilterSize(filterDepth, dilationDepth);
      var effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
      var effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
      var _g = get3DPadAndOutInfo(pad2, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth, roundingMode), padInfo = _g.padInfo, outDepth = _g.outDepth, outHeight = _g.outHeight, outWidth = _g.outWidth;
      var outChannels = depthwise ? filterChannels * inChannels : filterChannels;
      var outShape;
      if (dataFormat === "channelsFirst") {
        outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];
      } else if (dataFormat === "channelsLast") {
        outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];
      }
      return {
        batchSize,
        dataFormat,
        inDepth,
        inHeight,
        inWidth,
        inChannels,
        outDepth,
        outHeight,
        outWidth,
        outChannels,
        padInfo,
        strideDepth,
        strideHeight,
        strideWidth,
        filterDepth,
        filterHeight,
        filterWidth,
        effectiveFilterDepth,
        effectiveFilterHeight,
        effectiveFilterWidth,
        dilationDepth,
        dilationHeight,
        dilationWidth,
        inShape,
        outShape,
        filterShape
      };
    }
    function computeOutputShape2D(inShape, fieldSize, stride, zeroPad, roundingMode) {
      if (zeroPad == null) {
        zeroPad = computeDefaultPad(inShape, fieldSize, stride);
      }
      var inputRows = inShape[0];
      var inputCols = inShape[1];
      var outputRows = round$1((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
      var outputCols = round$1((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
      return [outputRows, outputCols];
    }
    function computeOutputShape4D(inShape, filterShape, outChannels, strides, zeroPad, roundingMode) {
      if (zeroPad == null) {
        zeroPad = computeDefaultPad(inShape, filterShape[0], strides[0]);
      }
      var outShape = [0, 0, 0, outChannels];
      for (var index = 0; index < 3; index++) {
        if (inShape[index] + 2 * zeroPad >= filterShape[index]) {
          outShape[index] = round$1((inShape[index] - filterShape[index] + 2 * zeroPad) / strides[index] + 1, roundingMode);
        }
      }
      return outShape;
    }
    function computeDefaultPad(inputShape, fieldSize, stride, dilation) {
      if (dilation === void 0) {
        dilation = 1;
      }
      var effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);
      return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);
    }
    function parseTupleParam(param) {
      if (typeof param === "number") {
        return [param, param, param];
      }
      if (param.length === 2) {
        return [param[0], param[1], 1];
      }
      return param;
    }
    function parse3TupleParam(param) {
      return typeof param === "number" ? [param, param, param] : param;
    }
    function getEffectiveFilterSize(filterSize, dilation) {
      if (dilation <= 1) {
        return filterSize;
      }
      return filterSize + (filterSize - 1) * (dilation - 1);
    }
    function getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode, dataFormat) {
      var padInfo;
      var outHeight;
      var outWidth;
      if (typeof pad2 === "number") {
        var padType = pad2 === 0 ? "VALID" : "NUMBER";
        padInfo = { top: pad2, bottom: pad2, left: pad2, right: pad2, type: padType };
        var outShape = computeOutputShape2D([inHeight, inWidth], filterHeight, strideHeight, pad2, roundingMode);
        outHeight = outShape[0];
        outWidth = outShape[1];
      } else if (pad2 === "same") {
        outHeight = Math.ceil(inHeight / strideHeight);
        outWidth = Math.ceil(inWidth / strideWidth);
        var padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);
        var padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);
        var top = Math.floor(padAlongHeight / 2);
        var bottom = padAlongHeight - top;
        var left = Math.floor(padAlongWidth / 2);
        var right = padAlongWidth - left;
        padInfo = { top, bottom, left, right, type: "SAME" };
      } else if (pad2 === "valid") {
        padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: "VALID" };
        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);
        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);
      } else if (typeof pad2 === "object") {
        var top = dataFormat === "channelsLast" ? pad2[1][0] : pad2[2][0];
        var bottom = dataFormat === "channelsLast" ? pad2[1][1] : pad2[2][1];
        var left = dataFormat === "channelsLast" ? pad2[2][0] : pad2[3][0];
        var right = dataFormat === "channelsLast" ? pad2[2][1] : pad2[3][1];
        var padType = top === 0 && bottom === 0 && left === 0 && right === 0 ? "VALID" : "EXPLICIT";
        padInfo = { top, bottom, left, right, type: padType };
        outHeight = round$1((inHeight - filterHeight + top + bottom) / strideHeight + 1, roundingMode);
        outWidth = round$1((inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);
      } else {
        throw Error("Unknown padding parameter: ".concat(pad2));
      }
      return { padInfo, outHeight, outWidth };
    }
    function get3DPadAndOutInfo(pad2, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, filterDepth, filterHeight, filterWidth, roundingMode) {
      var padInfo;
      var outDepth;
      var outHeight;
      var outWidth;
      if (pad2 === "valid") {
        pad2 = 0;
      }
      if (typeof pad2 === "number") {
        var padType = pad2 === 0 ? "VALID" : "NUMBER";
        padInfo = {
          top: pad2,
          bottom: pad2,
          left: pad2,
          right: pad2,
          front: pad2,
          back: pad2,
          type: padType
        };
        var outShape = computeOutputShape4D([inDepth, inHeight, inWidth, 1], [filterDepth, filterHeight, filterWidth], 1, [strideDepth, strideHeight, strideWidth], pad2, roundingMode);
        outDepth = outShape[0];
        outHeight = outShape[1];
        outWidth = outShape[2];
      } else if (pad2 === "same") {
        outDepth = Math.ceil(inDepth / strideDepth);
        outHeight = Math.ceil(inHeight / strideHeight);
        outWidth = Math.ceil(inWidth / strideWidth);
        var padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;
        var padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;
        var padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;
        var front = Math.floor(padAlongDepth / 2);
        var back = padAlongDepth - front;
        var top = Math.floor(padAlongHeight / 2);
        var bottom = padAlongHeight - top;
        var left = Math.floor(padAlongWidth / 2);
        var right = padAlongWidth - left;
        padInfo = { top, bottom, left, right, front, back, type: "SAME" };
      } else {
        throw Error("Unknown padding parameter: ".concat(pad2));
      }
      return { padInfo, outDepth, outHeight, outWidth };
    }
    function round$1(value, roundingMode) {
      if (!roundingMode) {
        return Math.trunc(value);
      }
      switch (roundingMode) {
        case "round":
          return Math.round(value);
        case "ceil":
          return Math.ceil(value);
        case "floor":
          return Math.floor(value);
        default:
          throw new Error("Unknown roundingMode ".concat(roundingMode));
      }
    }
    function tupleValuesAreOne(param) {
      var _a = __read(parseTupleParam(param), 3), dimA = _a[0], dimB = _a[1], dimC = _a[2];
      return dimA === 1 && dimB === 1 && dimC === 1;
    }
    function eitherStridesOrDilationsAreOne(strides, dilations) {
      return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);
    }
    function stridesOrDilationsArePositive(values) {
      return parseTupleParam(values).every(function(value) {
        return value > 0;
      });
    }
    function convertConv2DDataFormat(dataFormat) {
      if (dataFormat === "NHWC") {
        return "channelsLast";
      } else if (dataFormat === "NCHW") {
        return "channelsFirst";
      } else {
        throw new Error("Unknown dataFormat ".concat(dataFormat));
      }
    }
    function checkPadOnDimRoundingMode(opDesc, pad2, dimRoundingMode) {
      if (dimRoundingMode != null) {
        if (typeof pad2 === "string") {
          throw Error("Error in ".concat(opDesc, ": pad must be an integer when using ") + "dimRoundingMode ".concat(dimRoundingMode, " but got pad ").concat(pad2, "."));
        } else if (typeof pad2 === "number") {
          assert(isInt(pad2), function() {
            return "Error in ".concat(opDesc, ": pad must be an integer when using ") + "dimRoundingMode ".concat(dimRoundingMode, " but got pad ").concat(pad2, ".");
          });
        } else if (typeof pad2 === "object") {
          pad2.forEach(function(p) {
            p.forEach(function(v) {
              assert(isInt(v), function() {
                return "Error in ".concat(opDesc, ": pad must be an integer when using ") + "dimRoundingMode ".concat(dimRoundingMode, " but got pad ").concat(v, ".");
              });
            });
          });
        } else {
          throw Error("Error in ".concat(opDesc, ": Unknown padding parameter: ").concat(pad2));
        }
      }
    }
    function reshape_(x, shape) {
      var $x = convertToTensor(x, "x", "reshape", "string_or_numeric");
      var inputs = { x: $x };
      var attrs = { shape };
      return ENGINE.runKernel(Reshape, inputs, attrs);
    }
    var reshape = /* @__PURE__ */ op({ reshape_ });
    function avgPool_(x, filterSize, strides, pad2, dimRoundingMode) {
      var $x = convertToTensor(x, "x", "avgPool", "float32");
      var dilations = 1;
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in avgPool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in avgPool: x must be rank 4 but got rank ".concat(x4D.rank, ".");
      });
      checkPadOnDimRoundingMode("avgPool", pad2, dimRoundingMode);
      var inputs = { x: x4D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
      var res = ENGINE.runKernel(AvgPool, inputs, attrs);
      res = cast(res, $x.dtype);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var avgPool = /* @__PURE__ */ op({ avgPool_ });
    function avgPool3d_(x, filterSize, strides, pad2, dimRoundingMode, dataFormat) {
      if (dataFormat === void 0) {
        dataFormat = "NDHWC";
      }
      var $x = convertToTensor(x, "x", "avgPool3d", "float32");
      var x5D = $x;
      var reshapedTo5D = false;
      if ($x.rank === 4) {
        reshapedTo5D = true;
        x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
      }
      assert(x5D.rank === 5, function() {
        return "Error in avgPool3d: x must be rank 5 but got rank ".concat(x5D.rank, ".");
      });
      assert(dataFormat === "NDHWC", function() {
        return "Error in avgPool3d: Only NDHWC is currently supported, " + "but got dataFormat of ".concat(dataFormat);
      });
      assert(typeof strides === "number" && strides > 0 || Array.isArray(strides) && strides[0] > 0 && strides[1] > 0 && strides[2] > 0, function() {
        return "Error in avgPool3d: Stride must be > 0, but got '".concat(strides, "'");
      });
      checkPadOnDimRoundingMode("avgPool3d", pad2, dimRoundingMode);
      var inputs = { x: x5D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat };
      var res = ENGINE.runKernel(AvgPool3D, inputs, attrs);
      res = cast(res, x5D.dtype);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var avgPool3d = /* @__PURE__ */ op({ avgPool3d_ });
    function concat_(tensors, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      assert(tensors.length >= 1, function() {
        return "Pass at least one tensor to concat";
      });
      var $tensors = convertToTensorArray(tensors, "tensors", "concat", "string_or_numeric");
      if ($tensors[0].dtype === "complex64") {
        $tensors.forEach(function(tensor2) {
          if (tensor2.dtype !== "complex64") {
            throw new Error("Cannot concatenate complex64 tensors with a tensor\n          with dtype ".concat(tensor2.dtype, ". "));
          }
        });
      }
      if ($tensors.length === 1) {
        return clone($tensors[0]);
      }
      var inputs = $tensors;
      var attr = { axis };
      return ENGINE.runKernel(Concat, inputs, attr);
    }
    var concat = /* @__PURE__ */ op({ concat_ });
    function matMul_(a, b, transposeA, transposeB) {
      var _a;
      if (transposeA === void 0) {
        transposeA = false;
      }
      if (transposeB === void 0) {
        transposeB = false;
      }
      var $a = convertToTensor(a, "a", "matMul");
      var $b = convertToTensor(b, "b", "matMul");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      var attrs = { transposeA, transposeB };
      return ENGINE.runKernel(BatchMatMul, inputs, attrs);
    }
    var matMul$1 = /* @__PURE__ */ op({ matMul_ });
    function sigmoid_(x) {
      var $x = convertToTensor(x, "x", "sigmoid", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sigmoid, inputs);
    }
    var sigmoid = /* @__PURE__ */ op({ sigmoid_ });
    function slice_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice", "string_or_numeric");
      if ($x.rank === 0) {
        throw new Error("Slicing scalar is not possible");
      }
      var inputs = { x: $x };
      var attrs = { begin, size };
      return ENGINE.runKernel(Slice, inputs, attrs);
    }
    var slice = /* @__PURE__ */ op({ slice_ });
    function tanh_(x) {
      var $x = convertToTensor(x, "x", "tanh", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Tanh, inputs);
    }
    var tanh = /* @__PURE__ */ op({ tanh_ });
    function basicLSTMCell_(forgetBias, lstmKernel, lstmBias, data, c, h) {
      var $forgetBias = convertToTensor(forgetBias, "forgetBias", "basicLSTMCell");
      var $lstmKernel = convertToTensor(lstmKernel, "lstmKernel", "basicLSTMCell");
      var $lstmBias = convertToTensor(lstmBias, "lstmBias", "basicLSTMCell");
      var $data = convertToTensor(data, "data", "basicLSTMCell");
      var $c = convertToTensor(c, "c", "basicLSTMCell");
      var $h = convertToTensor(h, "h", "basicLSTMCell");
      var combined = concat([$data, $h], 1);
      var weighted = matMul$1(combined, $lstmKernel);
      var res = add(weighted, $lstmBias);
      var batchSize = res.shape[0];
      var sliceCols = res.shape[1] / 4;
      var sliceSize = [batchSize, sliceCols];
      var i = slice(res, [0, 0], sliceSize);
      var j = slice(res, [0, sliceCols], sliceSize);
      var f = slice(res, [0, sliceCols * 2], sliceSize);
      var o = slice(res, [0, sliceCols * 3], sliceSize);
      var newC = add(mul(sigmoid(i), tanh(j)), mul($c, sigmoid(add($forgetBias, f))));
      var newH = mul(tanh(newC), sigmoid(o));
      return [newC, newH];
    }
    var basicLSTMCell = /* @__PURE__ */ op({ basicLSTMCell_ });
    function batchToSpaceND_(x, blockShape, crops) {
      var $x = convertToTensor(x, "x", "batchToSpaceND");
      var prod2 = blockShape.reduce(function(a, b) {
        return a * b;
      });
      assert($x.rank >= 1 + blockShape.length, function() {
        return "input rank is ".concat($x.rank, " but should be > than blockShape.length ").concat(blockShape.length);
      });
      assert(crops.length === blockShape.length, function() {
        return "crops.length is ".concat(crops.length, " but should be equal to blockShape.length  ").concat(blockShape.length);
      });
      assert($x.shape[0] % prod2 === 0, function() {
        return "input tensor batch is ".concat($x.shape[0], " but is not divisible by the product of ") + "the elements of blockShape ".concat(blockShape.join(" * "), " === ").concat(prod2);
      });
      var inputs = { x: $x };
      var attrs = { blockShape, crops };
      return ENGINE.runKernel(BatchToSpaceND, inputs, attrs);
    }
    var batchToSpaceND = /* @__PURE__ */ op({ batchToSpaceND_ });
    function xAs4D(x) {
      var x4D;
      if (x.rank === 0 || x.rank === 1) {
        x4D = reshape(x, [1, 1, 1, x.size]);
      } else if (x.rank === 2) {
        x4D = reshape(x, [1, 1, x.shape[0], x.shape[1]]);
      } else if (x.rank === 3) {
        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
      } else {
        x4D = x;
      }
      return x4D;
    }
    function batchNorm_(x, mean2, variance, offset, scale, varianceEpsilon) {
      if (varianceEpsilon == null) {
        varianceEpsilon = 1e-3;
      }
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($mean.rank === $variance.rank, function() {
        return "Batch normalization gradient requires mean and variance to have equal ranks.";
      });
      assert($offset == null || $mean.rank === $offset.rank, function() {
        return "Batch normalization gradient requires mean and offset to have equal ranks.";
      });
      assert($scale == null || $mean.rank === $scale.rank, function() {
        return "Batch normalization gradient requires mean and scale to have equal ranks.";
      });
      var x4D = xAs4D($x);
      var inputs = {
        x: x4D,
        scale: $scale,
        offset: $offset,
        mean: $mean,
        variance: $variance
      };
      var attrs = { varianceEpsilon };
      var res = ENGINE.runKernel(FusedBatchNorm, inputs, attrs);
      return reshape(res, $x.shape);
    }
    var batchNorm = /* @__PURE__ */ op({ batchNorm_ });
    function batchNorm2d_(x, mean2, variance, offset, scale, varianceEpsilon) {
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($x.rank === 2, function() {
        return "Error in batchNorm2D: x must be rank 2 but got rank " + "".concat($x.rank, ".");
      });
      assert($mean.rank === 2 || $mean.rank === 1, function() {
        return "Error in batchNorm2D: mean must be rank 2 or rank 1 but " + "got rank ".concat($mean.rank, ".");
      });
      assert($variance.rank === 2 || $variance.rank === 1, function() {
        return "Error in batchNorm2D: variance must be rank 2 or rank 1 " + "but got rank ".concat($variance.rank, ".");
      });
      if ($scale != null) {
        assert($scale.rank === 2 || $scale.rank === 1, function() {
          return "Error in batchNorm2D: scale must be rank 2 or rank 1 " + "but got rank ".concat($scale.rank, ".");
        });
      }
      if ($offset != null) {
        assert($offset.rank === 2 || $offset.rank === 1, function() {
          return "Error in batchNorm2D: offset must be rank 2 or rank 1 " + "but got rank ".concat($offset.rank, ".");
        });
      }
      return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
    }
    var batchNorm2d = /* @__PURE__ */ op({ batchNorm2d_ });
    function batchNorm3d_(x, mean2, variance, offset, scale, varianceEpsilon) {
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($x.rank === 3, function() {
        return "Error in batchNorm3D: x must be rank 3 but got rank " + "".concat($x.rank, ".");
      });
      assert($mean.rank === 3 || $mean.rank === 1, function() {
        return "Error in batchNorm3D: mean must be rank 3 or rank 1 but " + "got rank ".concat($mean.rank, ".");
      });
      assert($variance.rank === 3 || $variance.rank === 1, function() {
        return "Error in batchNorm3D: variance must be rank 3 or rank 1 " + "but got rank ".concat($variance.rank, ".");
      });
      if ($scale != null) {
        assert($scale.rank === 3 || $scale.rank === 1, function() {
          return "Error in batchNorm3D: scale must be rank 3 or rank 1 " + "but got rank ".concat($scale.rank, ".");
        });
      }
      if ($offset != null) {
        assert($offset.rank === 3 || $offset.rank === 1, function() {
          return "Error in batchNorm3D: offset must be rank 3 or rank 1 " + "but got rank ".concat($offset.rank, ".");
        });
      }
      return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
    }
    var batchNorm3d = /* @__PURE__ */ op({ batchNorm3d_ });
    function batchNorm4d_(x, mean2, variance, offset, scale, varianceEpsilon) {
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($x.rank === 4, function() {
        return "Error in batchNorm4D: x must be rank 4 but got rank " + "".concat($x.rank, ".");
      });
      assert($mean.rank === 4 || $mean.rank === 1, function() {
        return "Error in batchNorm4D: mean must be rank 4 or rank 1 but " + "got rank ".concat($mean.rank, ".");
      });
      assert($variance.rank === 4 || $variance.rank === 1, function() {
        return "Error in batchNorm4D: variance must be rank 4 or rank 1 " + "but got rank ".concat($variance.rank, ".");
      });
      if ($scale != null) {
        assert($scale.rank === 4 || $scale.rank === 1, function() {
          return "Error in batchNorm4D: scale must be rank 4 or rank 1 " + "but got rank ".concat($scale.rank, ".");
        });
      }
      if ($offset != null) {
        assert($offset.rank === 4 || $offset.rank === 1, function() {
          return "Error in batchNorm4D: offset must be rank 4 or rank 1 " + "but got rank ".concat($offset.rank, ".");
        });
      }
      return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
    }
    var batchNorm4d = /* @__PURE__ */ op({ batchNorm4d_ });
    function bincount_(x, weights, size) {
      var $x = convertToTensor(x, "x", "bincount");
      var $weights = convertToTensor(weights, "weights", "bincount");
      assert($x.dtype === "int32", function() {
        return "Error in bincount: input " + "dtype must be int32, but got ".concat($x.dtype);
      });
      assert(size >= 0, function() {
        return "size must be non-negative, but got ".concat(size, ".");
      });
      assert($weights.size === $x.size || $weights.size === 0, function() {
        return "Error in bincount: weights must have the same size as input or" + "0-length, but got input shape: ".concat($x.shape, ", weights shape: ") + "".concat($weights.shape, ".");
      });
      var inputs = { x: $x, weights: $weights };
      var attrs = { size };
      return ENGINE.runKernel(Bincount, inputs, attrs);
    }
    var bincount = /* @__PURE__ */ op({ bincount_ });
    function bitwiseAnd_(x, y) {
      var $x = convertToTensor(x, "x", "bitwiseAnd");
      var $y = convertToTensor(y, "y", "bitwiseAnd");
      if (!arraysEqual($x.shape, $y.shape)) {
        throw new Error("BitwiseAnd: Tensors must have the same shape. x: ".concat($x.shape, ", y: ").concat($y.shape));
      }
      if ($x.dtype !== "int32" || $y.dtype !== "int32") {
        throw new Error("BitwiseAnd: Only supports 'int32' values in tensor, found type of x: ".concat($x.dtype, " and type of y: ").concat($y.dtype));
      }
      var inputs = { a: $x, b: $y };
      return ENGINE.runKernel(BitwiseAnd, inputs);
    }
    var bitwiseAnd = /* @__PURE__ */ op({ bitwiseAnd_ });
    function broadcastArgs_(s0, s1) {
      var shape1Input = convertToTensor(s0, "s0", "broadcastArgs", "int32");
      var shape2Input = convertToTensor(s1, "s1", "broadcastArgs", "int32");
      if (shape1Input.rank !== 1) {
        throw new Error("broadcastArgs(): first input must be a vector (rank=1). " + "Has rank ".concat(shape1Input.rank));
      }
      if (shape2Input.rank !== 1) {
        throw new Error("broadcastArgs(): second input must be a vector (rank=1). " + "Has rank ".concat(shape2Input.rank));
      }
      var inputs = { s0: shape1Input, s1: shape2Input };
      return ENGINE.runKernel(BroadcastArgs, inputs);
    }
    var broadcastArgs = /* @__PURE__ */ op({ broadcastArgs_ });
    function broadcastTo_(x, shape) {
      var input = convertToTensor(x, "broadcastTo", "x");
      var xShape = input.shape;
      assertNonNegativeIntegerDimensions(shape);
      if (shape.length < input.rank) {
        throw new Error("broadcastTo(): shape.length=".concat(shape.length, " < input.rank=").concat(input.rank, "."));
      }
      if (shape.length > input.rank) {
        var newShape = input.shape.slice();
        while (newShape.length < shape.length) {
          newShape.unshift(1);
        }
        input = reshape(input, newShape);
      }
      var inputShape = input.shape;
      var reps = Array.from(shape);
      for (var i = shape.length - 1; i >= 0; i--) {
        if (inputShape[i] === shape[i]) {
          reps[i] = 1;
        } else if (input.shape[i] !== 1) {
          throw new Error("broadcastTo(): [".concat(xShape, "] cannot be broadcast to [").concat(shape, "]."));
        }
      }
      var axes = reps.map(function(n, i2) {
        return n > 1 ? i2 : -1;
      }).filter(function(i2) {
        return i2 >= 0;
      });
      if (axes.length === 0) {
        return clone(input);
      }
      var inputs = { x: input };
      var attrs = { reps };
      return ENGINE.runKernel(Tile, inputs, attrs);
    }
    var broadcastTo = /* @__PURE__ */ op({ broadcastTo_ });
    function ceil_(x) {
      var $x = convertToTensor(x, "x", "ceil", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Ceil, inputs);
    }
    var ceil = /* @__PURE__ */ op({ ceil_ });
    function fill(shape, value, dtype) {
      assertNonNegativeIntegerDimensions(shape);
      dtype = dtype || inferDtype(value);
      var attrs = { shape, value, dtype };
      return ENGINE.runKernel(Fill, {}, attrs);
    }
    function clipByValue_(x, clipValueMin, clipValueMax) {
      var $x = convertToTensor(x, "x", "clipByValue");
      assert(clipValueMin <= clipValueMax, function() {
        return "Error in clip: min (".concat(clipValueMin, ") must be ") + "less than or equal to max (".concat(clipValueMax, ").");
      });
      if (clipValueMin === clipValueMax) {
        return fill($x.shape, clipValueMin, $x.dtype);
      }
      var inputs = { x: $x };
      var attrs = { clipValueMin, clipValueMax };
      return ENGINE.runKernel(ClipByValue, inputs, attrs);
    }
    var clipByValue = /* @__PURE__ */ op({ clipByValue_ });
    function concat1d_(tensors) {
      return concat(
        tensors,
        0
        /* axis */
      );
    }
    var concat1d = /* @__PURE__ */ op({ concat1d_ });
    function concat2d_(tensors, axis) {
      return concat(tensors, axis);
    }
    var concat2d = /* @__PURE__ */ op({ concat2d_ });
    function concat3d_(tensors, axis) {
      return concat(tensors, axis);
    }
    var concat3d = /* @__PURE__ */ op({ concat3d_ });
    function concat4d_(tensors, axis) {
      return concat(tensors, axis);
    }
    var concat4d = /* @__PURE__ */ op({ concat4d_ });
    function conv2d_(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var $x = convertToTensor(x, "x", "conv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "conv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in conv2d: input must be rank 4, but got rank ".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in conv2d: filter must be rank 4, but got rank " + "".concat($filter.rank, ".");
      });
      checkPadOnDimRoundingMode("conv2d", pad2, dimRoundingMode);
      var inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      assert(inDepth === $filter.shape[2], function() {
        return "Error in conv2d: depth of input (".concat(inDepth, ") must match ") + "input depth for filter ".concat($filter.shape[2], ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in conv2D: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      assert(stridesOrDilationsArePositive(dilations), function() {
        return "Error in conv2D: Dilated rates should be larger than 0.";
      });
      assert(stridesOrDilationsArePositive(strides), function() {
        return "Error in conv2D: Strides should be larger than 0.";
      });
      var inputs = { x: x4D, filter: $filter };
      var attrs = { strides, pad: pad2, dataFormat, dilations, dimRoundingMode };
      var res = ENGINE.runKernel(Conv2D, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var conv2d$1 = /* @__PURE__ */ op({ conv2d_ });
    function conv1d_(x, filter, stride, pad2, dataFormat, dilation, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NWC";
      }
      if (dilation === void 0) {
        dilation = 1;
      }
      var $x = convertToTensor(x, "x", "conv1d");
      var $filter = convertToTensor(filter, "filter", "conv1d");
      var x3D = $x;
      var reshapedTo3D = false;
      if ($x.rank === 2) {
        reshapedTo3D = true;
        x3D = reshape($x, [1, $x.shape[0], $x.shape[1]]);
      }
      assert(x3D.rank === 3, function() {
        return "Error in conv1d: input must be rank 3, but got rank ".concat(x3D.rank, ".");
      });
      assert($filter.rank === 3, function() {
        return "Error in conv1d: filter must be rank 3, but got rank " + "".concat($filter.rank, ".");
      });
      checkPadOnDimRoundingMode("conv1d", pad2, dimRoundingMode);
      assert(x3D.shape[2] === $filter.shape[1], function() {
        return "Error in conv1d: depth of input (".concat(x3D.shape[2], ") must match ") + "input depth for filter ".concat($filter.shape[1], ".");
      });
      assert(eitherStridesOrDilationsAreOne(stride, dilation), function() {
        return "Error in conv1D: Either stride or dilation must be 1. " + "Got stride ".concat(stride, " and dilation '").concat(dilation, "'");
      });
      assert(stridesOrDilationsArePositive(dilation), function() {
        return "Error in conv1D: Dilated rates should be larger than 0.";
      });
      assert(stridesOrDilationsArePositive(stride), function() {
        return "Error in conv1D: Stride should be larger than 0.";
      });
      assert(dataFormat === "NWC", function() {
        return "Error in conv1d: got dataFormat of ".concat(dataFormat, " but only NWC is currently supported.");
      });
      var filter4D = reshape($filter, [1, $filter.shape[0], $filter.shape[1], $filter.shape[2]]);
      var input4D = reshape(x3D, [x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]]);
      var strides = [1, stride];
      var dilations = [1, dilation];
      var conv2dDataFormat = "NHWC";
      var res = conv2d$1(input4D, filter4D, strides, pad2, conv2dDataFormat, dilations, dimRoundingMode);
      if (reshapedTo3D) {
        return reshape(res, [res.shape[2], res.shape[3]]);
      }
      return reshape(res, [res.shape[0], res.shape[2], res.shape[3]]);
    }
    var conv1d = /* @__PURE__ */ op({ conv1d_ });
    function conv2DBackpropInput_(xShape, dy, filter, strides, pad2, dataFormat, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      assert(xShape.length === dy.rank, function() {
        return "Length of inShape " + "(".concat(xShape.length, ") and rank of dy (").concat(dy.rank, ") must match");
      });
      var xShape4D = xShape;
      var dy4D = dy;
      var reshapedTo4D = false;
      if (dy.rank === 3) {
        reshapedTo4D = true;
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
        xShape4D = [1, xShape[0], xShape[1], xShape[2]];
      }
      assert(xShape4D.length === 4, function() {
        return "Error in conv2dDerInput: inShape must be length 4, but got length " + "".concat(xShape4D.length, ".");
      });
      assert(dy4D.rank === 4, function() {
        return "Error in conv2dDerInput: dy must be rank 4, but got " + "rank ".concat(dy4D.rank);
      });
      assert(filter.rank === 4, function() {
        return "Error in conv2dDerInput: filter must be rank 4, but got " + "rank ".concat(filter.rank);
      });
      var inDepth = dataFormat === "NHWC" ? xShape4D[3] : xShape4D[1];
      var outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
      assert(inDepth === filter.shape[2], function() {
        return "Error in conv2dDerInput: depth of input (".concat(inDepth, ") must ") + "match input depth for filter ".concat(filter.shape[2], ".");
      });
      assert(outDepth === filter.shape[3], function() {
        return "Error in conv2dDerInput: depth of output (".concat(outDepth, ") must ") + "match output depth for filter ".concat(filter.shape[3], ".");
      });
      checkPadOnDimRoundingMode("conv2dDerInput", pad2, dimRoundingMode);
      var inputs = { dy: dy4D, filter };
      var attrs = { strides, pad: pad2, dataFormat, dimRoundingMode, inputShape: xShape4D };
      var res = ENGINE.runKernel(Conv2DBackpropInput, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var conv2DBackpropInput = /* @__PURE__ */ op({ conv2DBackpropInput_ });
    function conv2dTranspose_(x, filter, outputShape, strides, pad2, dimRoundingMode) {
      var $x = convertToTensor(x, "x", "conv2dTranspose");
      var $filter = convertToTensor(filter, "filter", "conv2dTranspose");
      return conv2DBackpropInput(outputShape, $x, $filter, strides, pad2, "NHWC", dimRoundingMode);
    }
    var conv2dTranspose = /* @__PURE__ */ op({ conv2dTranspose_ });
    function conv3d_(x, filter, strides, pad2, dataFormat, dilations) {
      if (dataFormat === void 0) {
        dataFormat = "NDHWC";
      }
      if (dilations === void 0) {
        dilations = [1, 1, 1];
      }
      var $x = convertToTensor(x, "x", "conv3d");
      var $filter = convertToTensor(filter, "filter", "conv3d");
      var x5D = $x;
      var reshapedTo5D = false;
      if ($x.rank === 4) {
        reshapedTo5D = true;
        x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
      }
      assert(x5D.rank === 5, function() {
        return "Error in conv3d: input must be rank 5, but got rank ".concat(x5D.rank, ".");
      });
      assert($filter.rank === 5, function() {
        return "Error in conv3d: filter must be rank 5, but got rank " + "".concat($filter.rank, ".");
      });
      assert(x5D.shape[4] === $filter.shape[3], function() {
        return "Error in conv3d: depth of input (".concat(x5D.shape[4], ") must match ") + "input depth for filter ".concat($filter.shape[3], ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in conv3D: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      assert(dataFormat === "NDHWC", function() {
        return "Error in conv3d: got dataFormat of ".concat(dataFormat, " but only NDHWC is currently supported.");
      });
      assert(stridesOrDilationsArePositive(dilations), function() {
        return "Error in conv3D: Dilated rates should be larger than 0.";
      });
      assert(stridesOrDilationsArePositive(strides), function() {
        return "Error in conv3D: Strides should be larger than 0.";
      });
      var inputs = { x: x5D, filter: $filter };
      var attrs = { strides, pad: pad2, dataFormat, dilations };
      var res = ENGINE.runKernel(Conv3D, inputs, attrs);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var conv3d = /* @__PURE__ */ op({ conv3d_ });
    function conv3DBackpropInput_(xShape, dy, filter, strides, pad2) {
      assert(xShape.length === dy.rank, function() {
        return "Length of inShape " + "(".concat(xShape.length, ") and rank of dy (").concat(dy.rank, ") must match");
      });
      var xShape5D = xShape;
      var dy5D = dy;
      var reshapedTo5D = false;
      if (dy.rank === 4) {
        reshapedTo5D = true;
        dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);
        xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];
      }
      var inDepth = xShape5D[4];
      var outDepth = dy5D.shape[4];
      assert(xShape5D.length === 5, function() {
        return "Error in conv3dDerInput: inShape must be length 5, but got length " + "".concat(xShape5D.length, ".");
      });
      assert(dy5D.rank === 5, function() {
        return "Error in conv3dDerInput: dy must be rank 5, but got " + "rank ".concat(dy5D.rank);
      });
      assert(filter.rank === 5, function() {
        return "Error in conv3dDerInput: filter must be rank 5, but got " + "rank ".concat(filter.rank);
      });
      assert(inDepth === filter.shape[3], function() {
        return "Error in conv3dDerInput: depth of input (".concat(inDepth, ") must ") + "match input depth for filter ".concat(filter.shape[3], ".");
      });
      assert(outDepth === filter.shape[4], function() {
        return "Error in conv3dDerInput: depth of output (".concat(outDepth, ") must ") + "match output depth for filter ".concat(filter.shape[4], ".");
      });
      var inputs = { dy: dy5D, filter };
      var attrs = { pad: pad2, strides, inputShape: xShape5D };
      var res = ENGINE.runKernel(Conv3DBackpropInputV2, inputs, attrs);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var conv3DBackpropInput = /* @__PURE__ */ op({ conv3DBackpropInput_ });
    function conv3dTranspose_(x, filter, outputShape, strides, pad2) {
      var $x = convertToTensor(x, "x", "conv3dTranspose");
      var $filter = convertToTensor(filter, "filter", "conv3dTranspose");
      return conv3DBackpropInput(outputShape, $x, $filter, strides, pad2);
    }
    var conv3dTranspose = /* @__PURE__ */ op({ conv3dTranspose_ });
    function cos_(x) {
      var $x = convertToTensor(x, "x", "cos", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Cos, inputs);
    }
    var cos = /* @__PURE__ */ op({ cos_ });
    function cosh_(x) {
      var $x = convertToTensor(x, "x", "cosh", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Cosh, inputs);
    }
    var cosh = /* @__PURE__ */ op({ cosh_ });
    function cumprod_(x, axis, exclusive, reverse2) {
      if (axis === void 0) {
        axis = 0;
      }
      if (exclusive === void 0) {
        exclusive = false;
      }
      if (reverse2 === void 0) {
        reverse2 = false;
      }
      var $x = convertToTensor(x, "x", "cumprod");
      var inputs = { x: $x };
      var attrs = { axis, exclusive, reverse: reverse2 };
      return ENGINE.runKernel(Cumprod, inputs, attrs);
    }
    var cumprod = /* @__PURE__ */ op({ cumprod_ });
    function cumsum_(x, axis, exclusive, reverse2) {
      if (axis === void 0) {
        axis = 0;
      }
      if (exclusive === void 0) {
        exclusive = false;
      }
      if (reverse2 === void 0) {
        reverse2 = false;
      }
      var $x = convertToTensor(x, "x", "cumsum");
      var inputs = { x: $x };
      var attrs = { axis, exclusive, reverse: reverse2 };
      return ENGINE.runKernel(Cumsum, inputs, attrs);
    }
    var cumsum = /* @__PURE__ */ op({ cumsum_ });
    function denseBincount_(x, weights, size, binaryOutput) {
      if (binaryOutput === void 0) {
        binaryOutput = false;
      }
      var $x = convertToTensor(x, "x", "denseBincount");
      var $weights = convertToTensor(weights, "weights", "denseBincount");
      assert($x.dtype === "int32", function() {
        return "Error in denseBincount: input " + "dtype must be int32, but got ".concat($x.dtype);
      });
      assert($x.rank <= 2, function() {
        return "Error in denseBincount: input must be at most rank 2, but got " + "rank ".concat($x.rank, ".");
      });
      assert(size >= 0, function() {
        return "size must be non-negative, but got ".concat(size, ".");
      });
      assert($weights.size === $x.size || $weights.size === 0, function() {
        return "Error in denseBincount: weights must have the same shape as x or " + "0-length, but got x shape: ".concat($x.shape, ", weights shape: ") + "".concat($weights.shape, ".");
      });
      var inputs = { x: $x, weights: $weights };
      var attrs = { size, binaryOutput };
      return ENGINE.runKernel(DenseBincount, inputs, attrs);
    }
    var denseBincount = /* @__PURE__ */ op({ denseBincount_ });
    function depthToSpace_(x, blockSize, dataFormat) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var $x = convertToTensor(x, "x", "depthToSpace", "float32");
      var inputHeight = dataFormat === "NHWC" ? $x.shape[1] : $x.shape[2];
      var inputWidth = dataFormat === "NHWC" ? $x.shape[2] : $x.shape[3];
      var inputDepth = dataFormat === "NHWC" ? $x.shape[3] : $x.shape[1];
      assert(blockSize > 1, function() {
        return "blockSize should be > 1 for depthToSpace, but was: ".concat(blockSize);
      });
      assert(inputHeight * blockSize >= 0, function() {
        return "Negative dimension size caused by overflow when multiplying\n    ".concat(inputHeight, " and ").concat(blockSize, "  for depthToSpace with input shape\n    ").concat($x.shape);
      });
      assert(inputWidth * blockSize >= 0, function() {
        return "Negative dimension size caused by overflow when multiplying\n    ".concat(inputWidth, " and ").concat(blockSize, " for depthToSpace with input shape\n        ").concat($x.shape);
      });
      assert(inputDepth % (blockSize * blockSize) === 0, function() {
        return "Dimension size must be evenly divisible by ".concat(blockSize * blockSize, " but is ").concat(inputDepth, " for depthToSpace with input shape ").concat($x.shape);
      });
      var inputs = { x: $x };
      var attrs = { blockSize, dataFormat };
      return ENGINE.runKernel(DepthToSpace, inputs, attrs);
    }
    var depthToSpace = /* @__PURE__ */ op({ depthToSpace_ });
    function depthwiseConv2d_(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in depthwiseConv2d: input must be rank 4, but got " + "rank ".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in depthwiseConv2d: filter must be rank 4, but got rank " + "".concat($filter.rank, ".");
      });
      var inChannels = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      assert(inChannels === $filter.shape[2], function() {
        return "Error in depthwiseConv2d: number of input channels " + "(".concat(inChannels, ") must match the inChannels dimension in ") + "filter ".concat($filter.shape[2], ".");
      });
      checkPadOnDimRoundingMode("depthwiseConv2d", pad2, dimRoundingMode);
      var inputs = { x: x4D, filter: $filter };
      var attrs = { strides, pad: pad2, dataFormat, dilations, dimRoundingMode };
      var res = ENGINE.runKernel(DepthwiseConv2dNative, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var depthwiseConv2d$1 = /* @__PURE__ */ op({ depthwiseConv2d_ });
    function diag_(x) {
      var $x = convertToTensor(x, "x", "diag");
      var inputs = { x: $x };
      return ENGINE.runKernel(Diag, inputs);
    }
    var diag = /* @__PURE__ */ op({ diag_ });
    function dilation2d_(x, filter, strides, pad2, dilations, dataFormat) {
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var $x = convertToTensor(x, "x", "dilation2d");
      var $filter = convertToTensor(filter, "filter", "dilation2d");
      assert($x.rank === 3 || $x.rank === 4, function() {
        return "Error in dilation2d: input must be rank 3 or 4, but got rank " + "".concat($x.rank, ".");
      });
      assert($filter.rank === 3, function() {
        return "Error in dilation2d: filter must be rank 3, but got rank " + "".concat($filter.rank, ".");
      });
      assert(dataFormat === "NHWC", function() {
        return "Error in dilation2d: Only NHWC is currently supported, " + "but got dataFormat of ".concat(dataFormat);
      });
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
        reshapedTo4D = true;
      }
      assert(x4D.shape[3] === $filter.shape[2], function() {
        return "Error in dilation2d:  input and filter must have the same depth: ".concat(x4D.shape[3], " vs ").concat($filter.shape[2]);
      });
      var inputs = { x: x4D, filter: $filter };
      var attrs = { strides, pad: pad2, dilations };
      var res = ENGINE.runKernel(Dilation2D, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var dilation2d = /* @__PURE__ */ op({ dilation2d_ });
    function getBroadcastDims(inShape, outShape) {
      var inRank = inShape.length;
      var dims = [];
      for (var i = 0; i < inRank; i++) {
        var dim = inRank - 1 - i;
        var a = inShape[dim] || 1;
        var b = outShape[outShape.length - 1 - i] || 1;
        if (b > 1 && a === 1) {
          dims.unshift(dim);
        }
      }
      return dims;
    }
    function getReductionAxes(inShape, outShape) {
      var result = [];
      for (var i = 0; i < outShape.length; i++) {
        var inDim = inShape[inShape.length - i - 1];
        var outAxis = outShape.length - i - 1;
        var outDim = outShape[outAxis];
        if (inDim == null || inDim === 1 && outDim > 1) {
          result.unshift(outAxis);
        }
      }
      return result;
    }
    function assertAndGetBroadcastShape(shapeA, shapeB) {
      var l = Math.max(shapeA.length, shapeB.length);
      var result = new Array(l);
      for (var i = 0; i < l; i++) {
        var a = shapeA[shapeA.length - i - 1];
        if (a == null) {
          a = 1;
        }
        var b = shapeB[shapeB.length - i - 1];
        if (b == null) {
          b = 1;
        }
        if (a === 1) {
          result[l - i - 1] = b;
        } else if (b === 1) {
          result[l - i - 1] = a;
        } else if (a !== b) {
          var errMsg = "Operands could not be broadcast together with shapes " + "".concat(shapeA, " and ").concat(shapeB, ".");
          throw Error(errMsg);
        } else {
          result[l - i - 1] = a;
        }
      }
      return result;
    }
    var broadcast_util = {
      __proto__: null,
      assertAndGetBroadcastShape,
      getBroadcastDims,
      getReductionAxes
    };
    function equal_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "equal", "string_or_numeric");
      var $b = convertToTensor(b, "b", "equal", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Equal, inputs);
    }
    var equal = /* @__PURE__ */ op({ equal_ });
    function where_(condition, a, b) {
      var $a = convertToTensor(a, "a", "where");
      var $b = convertToTensor(b, "b", "where");
      var $condition = convertToTensor(condition, "condition", "where", "bool");
      var broadcastShape = assertAndGetBroadcastShape(assertAndGetBroadcastShape($condition.shape, $a.shape), $b.shape);
      var $broadcastedCondition = broadcastTo($condition, broadcastShape);
      var $broadcastedA = broadcastTo($a, broadcastShape);
      var $broadcastedB = broadcastTo($b, broadcastShape);
      var inputs = {
        condition: $broadcastedCondition,
        t: $broadcastedA,
        e: $broadcastedB
      };
      return ENGINE.runKernel(Select, inputs);
    }
    var where = /* @__PURE__ */ op({ where_ });
    function zerosLike_(x) {
      var $x = convertToTensor(x, "x", "zerosLike");
      var inputs = { x: $x };
      return ENGINE.runKernel(ZerosLike, inputs);
    }
    var zerosLike = /* @__PURE__ */ op({ zerosLike_ });
    function divNoNan_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "div");
      var $b = convertToTensor(b, "b", "div");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var divResult = div($a, $b);
      var zeros2 = zerosLike(divResult);
      var bEqualsZero = equal($b, zeros2);
      return where(bEqualsZero, zeros2, divResult);
    }
    var divNoNan = /* @__PURE__ */ op({ divNoNan_ });
    function dot_(t1, t2) {
      var $t1 = convertToTensor(t1, "t1", "dot");
      var $t2 = convertToTensor(t2, "t2", "dot");
      assert(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), function() {
        return "Error in dot: inputs must all be rank 1 or 2, but got ranks " + "".concat($t1.rank, " and ").concat($t2.rank, ".");
      });
      var t1Inner = $t1.rank === 1 ? $t1.size : $t1.shape[1];
      var t2Inner = $t2.rank === 1 ? $t2.size : $t2.shape[0];
      assert(t1Inner === t2Inner, function() {
        return "Error in dot: inner dimensions of inputs must match, but got " + "".concat(t1Inner, " and ").concat(t2Inner, ".");
      });
      if ($t1.rank === 1 && $t2.rank === 1) {
        var t12D = reshape($t1, [1, -1]);
        var t22D = reshape($t2, [-1, 1]);
        var t1t2 = matMul$1(t12D, t22D);
        return reshape(t1t2, []);
      } else if ($t1.rank === 1 && $t2.rank === 2) {
        var t12D = reshape($t1, [1, -1]);
        var t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
        var t1t2 = matMul$1(t12D, t22D);
        return reshape(t1t2, [t1t2.size]);
      } else if ($t1.rank === 2 && $t2.rank === 1) {
        var t22D = reshape($t2, [-1, 1]);
        var t1t2 = matMul$1($t1, t22D);
        return reshape(t1t2, [t1t2.size]);
      } else {
        var t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
        var t1t2 = matMul$1($t1, t22D);
        return t1t2;
      }
    }
    var dot = /* @__PURE__ */ op({ dot_ });
    function einsum_(equation) {
      var tensors = [];
      for (var _i = 1; _i < arguments.length; _i++) {
        tensors[_i - 1] = arguments[_i];
      }
      var $tensors = tensors.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "einsum");
      });
      var attrs = { equation };
      return ENGINE.runKernel(Einsum, $tensors, attrs);
    }
    var einsum = /* @__PURE__ */ op({ einsum_ });
    function elu_(x) {
      var $x = convertToTensor(x, "x", "elu", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Elu, inputs);
    }
    var elu = /* @__PURE__ */ op({ elu_ });
    function ensureShape_(x, shape) {
      var $x = convertToTensor(x, "x", "ensureShape", "string_or_numeric");
      if (!arraysEqualWithNull($x.shape, shape)) {
        throw new Error("EnsureShape: Shape of tensor ".concat($x.shape, " is not compatible with expected shape ").concat(shape));
      }
      return x;
    }
    var ensureShape = /* @__PURE__ */ op({ ensureShape_ });
    function erf_(x) {
      var $x = convertToTensor(x, "x", "erf");
      assert($x.dtype === "int32" || $x.dtype === "float32", function() {
        return "Input dtype must be `int32` or `float32`.";
      });
      if ($x.dtype === "int32") {
        $x = cast($x, "float32");
      }
      var inputs = { x: $x };
      return ENGINE.runKernel(Erf, inputs);
    }
    var erf = /* @__PURE__ */ op({ erf_ });
    function axesAreInnerMostDims(axes, rank) {
      for (var i = 0; i < axes.length; ++i) {
        if (axes[axes.length - i - 1] !== rank - 1 - i) {
          return false;
        }
      }
      return true;
    }
    function combineLocations(outputLoc, reduceLoc, axes) {
      var rank = outputLoc.length + reduceLoc.length;
      var loc = [];
      var outIdx = 0;
      var reduceIdx = 0;
      for (var dim = 0; dim < rank; dim++) {
        if (axes.indexOf(dim) === -1) {
          loc.push(outputLoc[outIdx++]);
        } else {
          loc.push(reduceLoc[reduceIdx++]);
        }
      }
      return loc;
    }
    function computeOutAndReduceShapes(aShape, axes) {
      var outShape = [];
      var rank = aShape.length;
      for (var dim = 0; dim < rank; dim++) {
        if (axes.indexOf(dim) === -1) {
          outShape.push(aShape[dim]);
        }
      }
      var reduceShape = axes.map(function(dim2) {
        return aShape[dim2];
      });
      return [outShape, reduceShape];
    }
    function expandShapeToKeepDim(shape, axes) {
      var reduceSubShape = axes.map(function(x) {
        return 1;
      });
      return combineLocations(shape, reduceSubShape, axes);
    }
    function assertAxesAreInnerMostDims(msg, axes, rank) {
      assert(axesAreInnerMostDims(axes, rank), function() {
        return "".concat(msg, " supports only inner-most axes for now. ") + "Got axes ".concat(axes, " and rank-").concat(rank, " input.");
      });
    }
    function getAxesPermutation(axes, rank) {
      if (axesAreInnerMostDims(axes, rank)) {
        return null;
      }
      var result = [];
      for (var i = 0; i < rank; ++i) {
        if (axes.indexOf(i) === -1) {
          result.push(i);
        }
      }
      axes.forEach(function(axis) {
        return result.push(axis);
      });
      return result;
    }
    function getUndoAxesPermutation(axes) {
      return axes.map(function(axis, i) {
        return [i, axis];
      }).sort(function(a, b) {
        return a[1] - b[1];
      }).map(function(x) {
        return x[0];
      });
    }
    function getInnerMostAxes(numAxes, rank) {
      var res = [];
      for (var i = rank - numAxes; i < rank; ++i) {
        res.push(i);
      }
      return res;
    }
    function max_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "max");
      var inputs = { x: $x };
      var attrs = { reductionIndices: axis, keepDims };
      return ENGINE.runKernel(Max, inputs, attrs);
    }
    var max = /* @__PURE__ */ op({ max_ });
    function min_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "min");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Min, inputs, attrs);
    }
    var min = /* @__PURE__ */ op({ min_ });
    function pow_(base, exp2) {
      var _a;
      var $base = convertToTensor(base, "base", "pow");
      var $exp = convertToTensor(exp2, "exp", "pow");
      _a = __read(makeTypesMatch($base, $exp), 2), $base = _a[0], $exp = _a[1];
      var inputs = { a: $base, b: $exp };
      return ENGINE.runKernel(Pow, inputs);
    }
    var pow = /* @__PURE__ */ op({ pow_ });
    function scalar(value, dtype) {
      if ((isTypedArray(value) && dtype !== "string" || Array.isArray(value)) && dtype !== "complex64") {
        throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
      }
      if (dtype === "string" && isTypedArray(value) && !(value instanceof Uint8Array)) {
        throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
      }
      var shape = [];
      var inferredShape = [];
      return makeTensor(value, shape, inferredShape, dtype);
    }
    function sqrt_(x) {
      var $x = convertToTensor(x, "x", "sqrt", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sqrt, inputs);
    }
    var sqrt = /* @__PURE__ */ op({ sqrt_ });
    function square_(x) {
      var $x = convertToTensor(x, "x", "square");
      var attrs = {};
      return ENGINE.runKernel("Square", { x: $x }, attrs);
    }
    var square = /* @__PURE__ */ op({ square_ });
    function sum_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "sum");
      if ($x.dtype === "bool") {
        $x = cast($x, "int32");
      }
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Sum, inputs, attrs);
    }
    var sum = /* @__PURE__ */ op({ sum_ });
    function norm_(x, ord, axis, keepDims) {
      if (ord === void 0) {
        ord = "euclidean";
      }
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      x = convertToTensor(x, "x", "norm");
      var norm2 = normImpl(x, ord, axis);
      var keepDimsShape = norm2.shape;
      if (keepDims) {
        var axes = parseAxisParam(axis, x.shape);
        keepDimsShape = expandShapeToKeepDim(norm2.shape, axes);
      }
      return reshape(norm2, keepDimsShape);
    }
    function normImpl(x, p, axis) {
      if (axis === void 0) {
        axis = null;
      }
      if (x.rank === 0) {
        return abs(x);
      }
      if (x.rank !== 1 && axis === null) {
        return normImpl(reshape(x, [-1]), p, axis);
      }
      if (x.rank === 1 || typeof axis === "number" || Array.isArray(axis) && axis.length === 1) {
        if (p === 1) {
          return sum(abs(x), axis);
        }
        if (p === Infinity) {
          return max(abs(x), axis);
        }
        if (p === -Infinity) {
          return min(abs(x), axis);
        }
        if (p === "euclidean" || p === 2) {
          return sqrt(sum(pow(abs(x), scalar(2, "int32")), axis));
        }
        throw new Error("Error in norm: invalid ord value: ".concat(p));
      }
      if (Array.isArray(axis) && axis.length === 2) {
        if (p === 1) {
          return max(sum(abs(x), axis[0]), axis[1] - 1);
        }
        if (p === Infinity) {
          return max(sum(abs(x), axis[1]), axis[0]);
        }
        if (p === -Infinity) {
          return min(sum(abs(x), axis[1]), axis[0]);
        }
        if (p === "fro" || p === "euclidean") {
          return sqrt(sum(square(x), axis));
        }
        throw new Error("Error in norm: invalid ord value: ".concat(p));
      }
      throw new Error("Error in norm: invalid axis: ".concat(axis));
    }
    var norm = /* @__PURE__ */ op({ norm_ });
    function euclideanNorm_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      return norm(x, "euclidean", axis, keepDims);
    }
    var euclideanNorm = /* @__PURE__ */ op({ euclideanNorm_ });
    function exp_(x) {
      var $x = convertToTensor(x, "x", "exp");
      var inputs = { x: $x };
      return ENGINE.runKernel(Exp, inputs);
    }
    var exp = /* @__PURE__ */ op({ exp_ });
    function expandDims_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "expandDims", "string_or_numeric");
      assert(axis <= $x.rank, function() {
        return "Axis must be <= rank of the tensor";
      });
      var inputs = { input: $x };
      var attrs = { dim: axis };
      return ENGINE.runKernel(ExpandDims, inputs, attrs);
    }
    var expandDims = /* @__PURE__ */ op({ expandDims_ });
    function expm1_(x) {
      var $x = convertToTensor(x, "x", "expm1");
      var inputs = { x: $x };
      return ENGINE.runKernel(Expm1, inputs);
    }
    var expm1 = /* @__PURE__ */ op({ expm1_ });
    function tile_(x, reps) {
      var $x = convertToTensor(x, "x", "tile", "string_or_numeric");
      assert($x.rank === reps.length, function() {
        return "Error in transpose: rank of input ".concat($x.rank, " ") + "must match length of reps ".concat(reps, ".");
      });
      var inputs = { x: $x };
      var attrs = { reps };
      return ENGINE.runKernel(Tile, inputs, attrs);
    }
    var tile = /* @__PURE__ */ op({ tile_ });
    function eye_(numRows, numColumns, batchShape, dtype) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      if (numColumns == null) {
        numColumns = numRows;
      }
      var buff = buffer([numRows, numColumns], dtype);
      var n = numRows <= numColumns ? numRows : numColumns;
      for (var i = 0; i < n; ++i) {
        buff.set(1, i, i);
      }
      var out = reshape(buff.toTensor(), [numRows, numColumns]);
      if (batchShape == null) {
        return out;
      } else {
        if (batchShape.length === 1) {
          return tile(expandDims(out, 0), [batchShape[0], 1, 1]);
        } else if (batchShape.length === 2) {
          return tile(expandDims(expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);
        } else if (batchShape.length === 3) {
          return tile(expandDims(expandDims(expandDims(out, 0), 0), 0), [
            batchShape[0],
            batchShape[1],
            batchShape[2],
            1,
            1
          ]);
        } else {
          throw new Error("eye() currently supports only 1D and 2D " + // tslint:disable-next-line:no-any
          "batchShapes, but received ".concat(batchShape.length, "D."));
        }
      }
    }
    var eye = /* @__PURE__ */ op({ eye_ });
    function floor_(x) {
      var $x = convertToTensor(x, "x", "floor", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Floor, inputs);
    }
    var floor = /* @__PURE__ */ op({ floor_ });
    function gather_(x, indices, axis, batchDims) {
      if (axis === void 0) {
        axis = 0;
      }
      if (batchDims === void 0) {
        batchDims = 0;
      }
      var $x = convertToTensor(x, "x", "gather");
      var $indices = convertToTensor(indices, "indices", "gather", "int32");
      var inputs = { x: $x, indices: $indices };
      var attrs = { axis, batchDims };
      return ENGINE.runKernel(GatherV2, inputs, attrs);
    }
    var gather = /* @__PURE__ */ op({ gather_ });
    function greater_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "greater", "string_or_numeric");
      var $b = convertToTensor(b, "b", "greater", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Greater, inputs);
    }
    var greater = /* @__PURE__ */ op({ greater_ });
    function greaterEqual_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "greaterEqual", "string_or_numeric");
      var $b = convertToTensor(b, "b", "greaterEqual", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(GreaterEqual, inputs);
    }
    var greaterEqual = /* @__PURE__ */ op({ greaterEqual_ });
    function imag_(input) {
      var $input = convertToTensor(input, "input", "imag");
      var inputs = { input: $input };
      return ENGINE.runKernel(Imag, inputs);
    }
    var imag = /* @__PURE__ */ op({ imag_ });
    function isFinite_(x) {
      var $x = convertToTensor(x, "x", "isFinite");
      var inputs = { x: $x };
      return ENGINE.runKernel(IsFinite, inputs);
    }
    var isFinite$1 = /* @__PURE__ */ op({ isFinite_ });
    function isInf_(x) {
      var $x = convertToTensor(x, "x", "isInf");
      var inputs = { x: $x };
      return ENGINE.runKernel(IsInf, inputs);
    }
    var isInf = /* @__PURE__ */ op({ isInf_ });
    function isNaN_(x) {
      var $x = convertToTensor(x, "x", "isNaN");
      var inputs = { x: $x };
      return ENGINE.runKernel(IsNan, inputs);
    }
    var isNaN$1 = /* @__PURE__ */ op({ isNaN_ });
    function leakyRelu_(x, alpha) {
      if (alpha === void 0) {
        alpha = 0.2;
      }
      var $x = convertToTensor(x, "x", "leakyRelu");
      var inputs = { x: $x };
      var attrs = { alpha };
      return ENGINE.runKernel(LeakyRelu, inputs, attrs);
    }
    var leakyRelu = /* @__PURE__ */ op({ leakyRelu_ });
    function less_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "less", "string_or_numeric");
      var $b = convertToTensor(b, "b", "less", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Less, inputs);
    }
    var less = /* @__PURE__ */ op({ less_ });
    function lessEqual_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "lessEqual", "string_or_numeric");
      var $b = convertToTensor(b, "b", "lessEqual", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(LessEqual, inputs);
    }
    var lessEqual = /* @__PURE__ */ op({ lessEqual_ });
    function linspace(start, stop, num) {
      if (num <= 0) {
        throw new Error("The number of values should be positive.");
      }
      var attrs = { start, stop, num };
      return ENGINE.runKernel(LinSpace, {}, attrs);
    }
    function localResponseNormalization_(x, depthRadius, bias, alpha, beta) {
      if (depthRadius === void 0) {
        depthRadius = 5;
      }
      if (bias === void 0) {
        bias = 1;
      }
      if (alpha === void 0) {
        alpha = 1;
      }
      if (beta === void 0) {
        beta = 0.5;
      }
      var $x = convertToTensor(x, "x", "localResponseNormalization");
      assert($x.rank === 4 || $x.rank === 3, function() {
        return "Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ".concat($x.rank, ".");
      });
      assert(isInt(depthRadius), function() {
        return "Error in localResponseNormalization: depthRadius must be an " + "integer but got depthRadius ".concat(depthRadius, ".");
      });
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      var inputs = { x: x4D };
      var attrs = { depthRadius, bias, alpha, beta };
      var res = ENGINE.runKernel(LRN, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      } else {
        return res;
      }
    }
    var localResponseNormalization = /* @__PURE__ */ op({ localResponseNormalization_ });
    function log_(x) {
      var $x = convertToTensor(x, "x", "log", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Log, inputs);
    }
    var log = /* @__PURE__ */ op({ log_ });
    function log1p_(x) {
      var $x = convertToTensor(x, "x", "log1p");
      var inputs = { x: $x };
      return ENGINE.runKernel(Log1p, inputs);
    }
    var log1p = /* @__PURE__ */ op({ log1p_ });
    function grad(f) {
      assert(isFunction(f), function() {
        return "The f passed in grad(f) must be a function";
      });
      return function(x, dy) {
        var $x = convertToTensor(x, "x", "tf.grad", "string_or_numeric");
        var $dy = dy != null ? convertToTensor(dy, "dy", "tf.grad") : null;
        return ENGINE.tidy(function() {
          var _a = ENGINE.gradients(function() {
            return f($x);
          }, [$x], $dy), value = _a.value, grads2 = _a.grads;
          if ($dy != null) {
            assertShapesMatch(value.shape, $dy.shape, "The shape of dy passed in grad(f)(x, dy) must match the shape returned by f(x)");
          }
          checkGrads(grads2);
          return grads2[0];
        });
      };
    }
    function grads(f) {
      assert(isFunction(f), function() {
        return "The f passed in grads(f) must be a function";
      });
      return function(args, dy) {
        assert(Array.isArray(args), function() {
          return "The args passed in grads(f)(args) must be an array of `Tensor`s or `TensorLike`s";
        });
        var $args = convertToTensorArray(args, "args", "tf.grads", "string_or_numeric");
        var $dy = dy != null ? convertToTensor(dy, "dy", "tf.grads") : null;
        return ENGINE.tidy(function() {
          var _a = ENGINE.gradients(function() {
            return f.apply(void 0, __spreadArray([], __read($args), false));
          }, $args, $dy), value = _a.value, grads2 = _a.grads;
          if ($dy != null) {
            assertShapesMatch(value.shape, $dy.shape, "The shape of dy passed in grads(f)([x1,...], dy) must match the shape returned by f([x1,...])");
          }
          checkGrads(grads2);
          return grads2;
        });
      };
    }
    function valueAndGrad(f) {
      assert(isFunction(f), function() {
        return "The f passed in valueAndGrad(f) must be a function";
      });
      return function(x, dy) {
        assert(x instanceof Tensor, function() {
          return "The x passed in valueAndGrad(f)(x) must be a tensor";
        });
        assert(dy == null || dy instanceof Tensor, function() {
          return "The dy passed in valueAndGrad(f)(x, dy) must be a tensor";
        });
        var _a = ENGINE.gradients(function() {
          return f(x);
        }, [x], dy), grads2 = _a.grads, value = _a.value;
        checkGrads(grads2);
        return { grad: grads2[0], value };
      };
    }
    function valueAndGrads(f) {
      assert(isFunction(f), function() {
        return "The f passed in valueAndGrads(f) must be a function";
      });
      return function(args, dy) {
        assert(Array.isArray(args) && args.every(function(arg) {
          return arg instanceof Tensor;
        }), function() {
          return "The args passed in valueAndGrads(f)(args) must be array of tensors";
        });
        assert(dy == null || dy instanceof Tensor, function() {
          return "The dy passed in valueAndGrads(f)(args, dy) must be a tensor";
        });
        var res = ENGINE.gradients(function() {
          return f.apply(void 0, __spreadArray([], __read(args), false));
        }, args, dy);
        if (dy != null) {
          assertShapesMatch(res.value.shape, dy.shape, "The shape of dy passed in valueAndGrads(f)([x1,...], dy) must match the shape returned by f([x1,...])");
        }
        checkGrads(res.grads);
        return res;
      };
    }
    function variableGrads(f, varList) {
      assert(isFunction(f), function() {
        return "The f passed in variableGrads(f) must be a function";
      });
      assert(varList == null || Array.isArray(varList) && varList.every(function(v) {
        return v instanceof Variable;
      }), function() {
        return "The varList passed in variableGrads(f, varList) must be an array of variables";
      });
      var specifiedVarList = varList != null;
      if (!specifiedVarList) {
        varList = [];
        for (var varName in ENGINE.registeredVariables) {
          varList.push(ENGINE.registeredVariables[varName]);
        }
      }
      var specifiedNonTrainable = specifiedVarList ? varList.filter(function(variable2) {
        return !variable2.trainable;
      }) : null;
      var originalVarCount = varList.length;
      varList = varList.filter(function(variable2) {
        return variable2.trainable;
      });
      assert(varList.length > 0, function() {
        return "variableGrads() expects at least one of the input variables to " + "be trainable, but none of the ".concat(originalVarCount, " variables is ") + "trainable.";
      });
      var allowNoGradients = true;
      var _a = ENGINE.gradients(f, varList, null, allowNoGradients), value = _a.value, grads2 = _a.grads;
      assert(grads2.some(function(g) {
        return g != null;
      }), function() {
        return "Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().";
      });
      assert(value.rank === 0, function() {
        return "The f passed in variableGrads(f) must return a scalar, but it " + "returned a rank-".concat(value.rank, " tensor");
      });
      var namedGrads = {};
      varList.forEach(function(v, i) {
        if (grads2[i] != null) {
          namedGrads[v.name] = grads2[i];
        }
      });
      if (specifiedNonTrainable != null) {
        specifiedNonTrainable.forEach(function(v) {
          return namedGrads[v.name] = null;
        });
      }
      return { value, grads: namedGrads };
    }
    function customGrad(f) {
      return ENGINE.customGrad(f);
    }
    function checkGrads(grads2) {
      var numNullGradients = grads2.filter(function(g) {
        return g == null;
      }).length;
      if (numNullGradients > 0) {
        throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that\n    the f you passed encloses all operations that lead from x to y.");
      }
    }
    function neg_(x) {
      var $x = convertToTensor(x, "x", "neg");
      var inputs = { x: $x };
      return ENGINE.runKernel(Neg, inputs);
    }
    var neg = /* @__PURE__ */ op({ neg_ });
    function softplus_(x) {
      var $x = convertToTensor(x, "x", "softplus");
      var inputs = { x: $x };
      return ENGINE.runKernel(Softplus, inputs);
    }
    var softplus = /* @__PURE__ */ op({ softplus_ });
    function logSigmoid_(x) {
      var $x = convertToTensor(x, "x", "logSigmoid");
      var customOp = customGrad(function(x2) {
        var value = neg(softplus(neg(x2)));
        var gradFunc = function(dy) {
          var derX = mul(dy, sigmoid(neg(x2)));
          return derX;
        };
        return { value, gradFunc };
      });
      return customOp($x);
    }
    var logSigmoid = /* @__PURE__ */ op({ logSigmoid_ });
    function sub_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "sub");
      var $b = convertToTensor(b, "b", "sub");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Sub, inputs);
    }
    var sub = /* @__PURE__ */ op({ sub_ });
    function logSoftmax_(logits, axis) {
      if (axis === void 0) {
        axis = -1;
      }
      var $logits = convertToTensor(logits, "logits", "logSoftmax");
      if (axis === -1) {
        axis = $logits.rank - 1;
      }
      if (axis !== $logits.rank - 1) {
        throw Error("Log Softmax along a non-last dimension is not yet supported. " + "Logits was rank ".concat($logits.rank, " and axis was ").concat(axis));
      }
      var customOp = customGrad(function(logits2, save) {
        var keepDims = true;
        var xMax = max(logits2, axis, true);
        var shifted = sub(logits2, xMax);
        var value = sub(cast(shifted, "float32"), log(sum(exp(shifted), axis, keepDims)));
        save([value]);
        var gradFunc = function(dy, saved) {
          var _a = __read(saved, 1), value2 = _a[0];
          var keepDims2 = true;
          var softmax2 = exp(value2);
          return sub(dy, mul(sum(dy, axis, keepDims2), softmax2));
        };
        return { value, gradFunc };
      });
      return customOp($logits);
    }
    var logSoftmax = /* @__PURE__ */ op({ logSoftmax_ });
    function logSumExp_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "logSumExp");
      var axes = parseAxisParam(axis, $x.shape);
      var xMax = max(
        $x,
        axes,
        true
        /* keepDims */
      );
      var a = sub($x, xMax);
      var b = exp(a);
      var c = sum(b, axes);
      var d = log(c);
      var res = add(reshape(xMax, d.shape), d);
      if (keepDims) {
        var newShape = expandShapeToKeepDim(res.shape, axes);
        return reshape(res, newShape);
      }
      return res;
    }
    var logSumExp = /* @__PURE__ */ op({ logSumExp_ });
    function logicalAnd_(a, b) {
      var $a = convertToTensor(a, "a", "logicalAnd", "bool");
      var $b = convertToTensor(b, "b", "logicalAnd", "bool");
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(LogicalAnd, inputs);
    }
    var logicalAnd = /* @__PURE__ */ op({ logicalAnd_ });
    function logicalNot_(x) {
      var $x = convertToTensor(x, "x", "logicalNot", "bool");
      var inputs = { x: $x };
      return ENGINE.runKernel(LogicalNot, inputs);
    }
    var logicalNot = /* @__PURE__ */ op({ logicalNot_ });
    function logicalOr_(a, b) {
      var $a = convertToTensor(a, "a", "logicalOr", "bool");
      var $b = convertToTensor(b, "b", "logicalOr", "bool");
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(LogicalOr, inputs);
    }
    var logicalOr = /* @__PURE__ */ op({ logicalOr_ });
    function logicalXor_(a, b) {
      var $a = convertToTensor(a, "a", "logicalXor", "bool");
      var $b = convertToTensor(b, "b", "logicalXor", "bool");
      assertAndGetBroadcastShape($a.shape, $b.shape);
      return logicalAnd(logicalOr(a, b), logicalNot(logicalAnd(a, b)));
    }
    var logicalXor = /* @__PURE__ */ op({ logicalXor_ });
    var INT32_MAX = 2147483648;
    function searchSorted_(sortedSequence, values, side) {
      if (side === void 0) {
        side = "left";
      }
      var $sortedSequence = convertToTensor(sortedSequence, "sortedSequence", "searchSorted");
      var $values = convertToTensor(values, "values", "searchSorted");
      var sequenceSize = $sortedSequence.shape[$sortedSequence.shape.length - 1];
      var valuesSize = $values.shape[$values.shape.length - 1];
      var $sortedSequence2D = reshape($sortedSequence, [-1, sequenceSize]);
      var $values2D = reshape($values, [-1, valuesSize]);
      if ($sortedSequence2D.rank < 2) {
        throw new Error("Sorted input argument must be at least 2-dimensional");
      }
      if ($sortedSequence2D.shape[0] !== $values2D.shape[0]) {
        throw new Error("Leading dimension of 'sortedSequence' and 'values' must match.");
      }
      if (sizeFromShape($values2D.shape) >= INT32_MAX) {
        throw new Error("values tensor size must less than ".concat(INT32_MAX));
      }
      if ($sortedSequence2D.shape[1] >= INT32_MAX) {
        throw new Error("trailing dim_size must less than ".concat(INT32_MAX, " for int32 output type, was ").concat($sortedSequence2D.shape[1]));
      }
      var inputs = {
        sortedSequence: $sortedSequence2D,
        values: $values2D
      };
      var attrs = { side };
      return ENGINE.runKernel(SearchSorted, inputs, attrs);
    }
    var searchSorted = /* @__PURE__ */ op({ searchSorted_ });
    function lowerBound(sortedSequence, values) {
      return searchSorted(sortedSequence, values, "left");
    }
    function maxPool_(x, filterSize, strides, pad2, dimRoundingMode) {
      var $x = convertToTensor(x, "x", "maxPool");
      var dilations = 1;
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in maxPool: input must be rank 4 but got rank ".concat(x4D.rank, ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in maxPool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      checkPadOnDimRoundingMode("maxPool", pad2, dimRoundingMode);
      var inputs = { x: x4D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
      var res = ENGINE.runKernel(MaxPool, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var maxPool = /* @__PURE__ */ op({ maxPool_ });
    function maxPool3d_(x, filterSize, strides, pad2, dimRoundingMode, dataFormat) {
      if (filterSize === void 0) {
        filterSize = [1, 1, 1];
      }
      if (dataFormat === void 0) {
        dataFormat = "NDHWC";
      }
      var $x = convertToTensor(x, "x", "maxPool3d");
      var x5D = $x;
      var reshapedTo5D = false;
      if ($x.rank === 4) {
        reshapedTo5D = true;
        x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
      }
      assert(x5D.rank === 5, function() {
        return "Error in maxPool3d: x must be rank 5 but got rank ".concat(x5D.rank, ".");
      });
      assert(dataFormat === "NDHWC", function() {
        return "Error in maxPool3d: Only NDHWC is currently supported, " + "but got dataFormat of ".concat(dataFormat);
      });
      checkPadOnDimRoundingMode("maxPool3d", pad2, dimRoundingMode);
      var inputs = { x: x5D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat };
      var res = ENGINE.runKernel(MaxPool3D, inputs, attrs);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var maxPool3d = /* @__PURE__ */ op({ maxPool3d_ });
    function maxPoolWithArgmax_(x, filterSize, strides, pad2, includeBatchInIndex) {
      if (includeBatchInIndex === void 0) {
        includeBatchInIndex = false;
      }
      var $x = convertToTensor(x, "x", "maxPoolWithArgmax");
      var inputs = { x: $x };
      var attrs = { filterSize, strides, pad: pad2, includeBatchInIndex };
      var result = ENGINE.runKernel(MaxPoolWithArgmax, inputs, attrs);
      return { result: result[0], indexes: result[1] };
    }
    var maxPoolWithArgmax = /* @__PURE__ */ op({ maxPoolWithArgmax_ });
    function maximum_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "maximum");
      var $b = convertToTensor(b, "b", "maximum");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      if ($a.dtype === "bool") {
        $a = cast($a, "int32");
        $b = cast($b, "int32");
      }
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Maximum, inputs);
    }
    var maximum = /* @__PURE__ */ op({ maximum_ });
    function mean_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "mean");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Mean, inputs, attrs);
    }
    var mean = /* @__PURE__ */ op({ mean_ });
    function zeros(shape, dtype) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype === "complex64") {
        var real2 = zeros(shape, "float32");
        var imag2 = zeros(shape, "float32");
        return complex(real2, imag2);
      }
      var values = makeZerosTypedArray(sizeFromShape(shape), dtype);
      return ENGINE.makeTensor(values, shape, dtype);
    }
    function ones(shape, dtype) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype === "complex64") {
        var real2 = ones(shape, "float32");
        var imag2 = zeros(shape, "float32");
        return complex(real2, imag2);
      }
      var values = makeOnesTypedArray(sizeFromShape(shape), dtype);
      return ENGINE.makeTensor(values, shape, dtype);
    }
    function meshgrid(x, y, _a) {
      var _b = _a === void 0 ? {} : _a, _c = _b.indexing, indexing = _c === void 0 ? "xy" : _c;
      if (indexing !== "xy" && indexing !== "ij") {
        throw new TypeError("".concat(indexing, " is not a valid third argument to meshgrid"));
      }
      if (x === void 0) {
        return [];
      }
      var $x = convertToTensor(x, "x", "meshgrid", x instanceof Tensor ? x.dtype : "float32");
      if (y === void 0) {
        return [$x];
      }
      var $y = convertToTensor(y, "y", "meshgrid", y instanceof Tensor ? y.dtype : "float32");
      var w = sizeFromShape($x.shape);
      var h = sizeFromShape($y.shape);
      if (indexing === "xy") {
        $x = reshape($x, [1, -1]);
        $y = reshape($y, [-1, 1]);
        return [
          matMul$1(ones([h, 1], $x.dtype), $x),
          matMul$1($y, ones([1, w], $y.dtype))
        ];
      }
      $x = reshape($x, [-1, 1]);
      $y = reshape($y, [1, -1]);
      return [
        matMul$1($x, ones([1, h], $x.dtype)),
        matMul$1(ones([w, 1], $y.dtype), $y)
      ];
    }
    function minimum_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "minimum");
      var $b = convertToTensor(b, "b", "minimum");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      if ($a.dtype === "bool") {
        $a = cast($a, "int32");
        $b = cast($b, "int32");
      }
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Minimum, inputs);
    }
    var minimum = /* @__PURE__ */ op({ minimum_ });
    function mirrorPad_(x, paddings, mode) {
      assert(mode === "reflect" || mode === "symmetric", function() {
        return "Invalid mode. Mode must be either reflect or symmetric. " + "Got ".concat(mode, ".");
      });
      var $x = convertToTensor(x, "x", "mirrorPad");
      if ($x.rank === 0) {
        throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
      }
      assert(paddings.length === $x.rank, function() {
        return "Padding doesn't match input. Must be ".concat($x.rank, ". ") + "Got ".concat(paddings.length, ".");
      });
      var shapeOffset = mode === "reflect" ? 1 : 0;
      var _loop_1 = function(i2) {
        assert(paddings[i2].length === 2, function() {
          return "Invalid number of paddings. Must be length of 2 each.";
        });
        assert(paddings[i2][0] >= 0 && paddings[i2][0] <= $x.shape[i2] - shapeOffset && paddings[i2][1] >= 0 && paddings[i2][1] <= $x.shape[i2] - shapeOffset, function() {
          return "Padding in dimension ".concat(i2, " cannot be greater than or equal ") + "to ".concat($x.shape[i2] - shapeOffset, " or less than 0 for input of ") + "shape ".concat($x.shape);
        });
      };
      for (var i = 0; i < $x.rank; i++) {
        _loop_1(i);
      }
      var attrs = { paddings, mode };
      var inputs = { x: $x };
      return ENGINE.runKernel(MirrorPad, inputs, attrs);
    }
    var mirrorPad = /* @__PURE__ */ op({ mirrorPad_ });
    function mod_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "mod");
      var $b = convertToTensor(b, "b", "mod");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Mod, inputs);
    }
    var mod = /* @__PURE__ */ op({ mod_ });
    function moments_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      x = convertToTensor(x, "x", "moments");
      var axes = parseAxisParam(axis, x.shape);
      var xMean = mean(x, axes, keepDims);
      var keepDimsShape = xMean.shape;
      if (!keepDims) {
        keepDimsShape = expandShapeToKeepDim(xMean.shape, axes);
      }
      var devSquared = square(sub(cast(x, "float32"), reshape(xMean, keepDimsShape)));
      var variance = mean(devSquared, axes, keepDims);
      return { mean: xMean, variance };
    }
    var moments = /* @__PURE__ */ op({ moments_ });
    function multiRNNCell_(lstmCells, data, c, h) {
      var $data = convertToTensor(data, "data", "multiRNNCell");
      var $c = convertToTensorArray(c, "c", "multiRNNCell");
      var $h = convertToTensorArray(h, "h", "multiRNNCell");
      var input = $data;
      var newStates = [];
      for (var i = 0; i < lstmCells.length; i++) {
        var output = lstmCells[i](input, $c[i], $h[i]);
        newStates.push(output[0]);
        newStates.push(output[1]);
        input = output[1];
      }
      var newC = [];
      var newH = [];
      for (var i = 0; i < newStates.length; i += 2) {
        newC.push(newStates[i]);
        newH.push(newStates[i + 1]);
      }
      return [newC, newH];
    }
    var multiRNNCell = /* @__PURE__ */ op({ multiRNNCell_ });
    function multinomial_(logits, numSamples, seed, normalized) {
      if (normalized === void 0) {
        normalized = false;
      }
      var $logits = convertToTensor(logits, "logits", "multinomial");
      var numOutcomes = $logits.size;
      var origRank = $logits.rank;
      if (numOutcomes < 2) {
        throw new Error("Error in multinomial: you need at least 2 outcomes, but got " + "".concat(numOutcomes, "."));
      }
      if (origRank > 2) {
        throw new Error("Rank of probabilities must be 1 or 2, but is ".concat(origRank));
      }
      seed = seed || Math.random();
      var logits2D = origRank === 1 ? reshape($logits, [1, -1]) : $logits;
      var inputs = { logits: logits2D };
      var attrs = { numSamples, seed, normalized };
      var res = ENGINE.runKernel(Multinomial, inputs, attrs);
      return origRank === 1 ? reshape(res, [res.size]) : res;
    }
    var multinomial = /* @__PURE__ */ op({ multinomial_ });
    function notEqual_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "notEqual", "string_or_numeric");
      var $b = convertToTensor(b, "b", "notEqual", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(NotEqual, inputs);
    }
    var notEqual = /* @__PURE__ */ op({ notEqual_ });
    function oneHot_(indices, depth, onValue, offValue, dtype) {
      if (onValue === void 0) {
        onValue = 1;
      }
      if (offValue === void 0) {
        offValue = 0;
      }
      if (dtype === void 0) {
        dtype = "int32";
      }
      if (depth < 2) {
        throw new Error("Error in oneHot: depth must be >=2, but it is ".concat(depth));
      }
      var $indices = convertToTensor(indices, "indices", "oneHot", "int32");
      var inputs = { indices: $indices };
      var attrs = { dtype, depth, onValue, offValue };
      return ENGINE.runKernel(OneHot, inputs, attrs);
    }
    var oneHot = /* @__PURE__ */ op({ oneHot_ });
    function onesLike_(x) {
      var $x = convertToTensor(x, "x", "onesLike");
      var inputs = { x: $x };
      return ENGINE.runKernel(OnesLike, inputs);
    }
    var onesLike = /* @__PURE__ */ op({ onesLike_ });
    function outerProduct_(v1, v2) {
      var $v1 = convertToTensor(v1, "v1", "outerProduct");
      var $v2 = convertToTensor(v2, "v2", "outerProduct");
      assert($v1.rank === 1 && $v2.rank === 1, function() {
        return "Error in outerProduct: inputs must be rank 1, but got ranks " + "".concat($v1.rank, " and ").concat($v2.rank, ".");
      });
      var v12D = reshape($v1, [-1, 1]);
      var v22D = reshape($v2, [1, -1]);
      return matMul$1(v12D, v22D);
    }
    var outerProduct = /* @__PURE__ */ op({ outerProduct_ });
    function pad_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      var $x = convertToTensor(x, "x", "pad");
      if ($x.rank === 0) {
        throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
      }
      var attrs = { paddings, constantValue };
      var inputs = { x: $x };
      return ENGINE.runKernel(PadV2, inputs, attrs);
    }
    var pad = /* @__PURE__ */ op({ pad_ });
    function pad1d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 2, function() {
        return "Invalid number of paddings. Must be length of 2.";
      });
      return pad(x, [paddings], constantValue);
    }
    var pad1d = /* @__PURE__ */ op({ pad1d_ });
    function pad2d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 2 && paddings[0].length === 2 && paddings[1].length === 2, function() {
        return "Invalid number of paddings. Must be length of 2 each.";
      });
      return pad(x, paddings, constantValue);
    }
    var pad2d = /* @__PURE__ */ op({ pad2d_ });
    function pad3d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 3 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2, function() {
        return "Invalid number of paddings. Must be length of 2 each.";
      });
      return pad(x, paddings, constantValue);
    }
    var pad3d = /* @__PURE__ */ op({ pad3d_ });
    function pad4d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 4 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2 && paddings[3].length === 2, function() {
        return "Invalid number of paddings. Must be length of 2 each.";
      });
      return pad(x, paddings, constantValue);
    }
    var pad4d = /* @__PURE__ */ op({ pad4d_ });
    function spaceToBatchND_(x, blockShape, paddings) {
      var $x = convertToTensor(x, "x", "spaceToBatchND");
      assert($x.rank >= 1 + blockShape.length, function() {
        return "input rank ".concat($x.rank, " should be > than [blockShape] ").concat(blockShape.length);
      });
      assert(paddings.length === blockShape.length, function() {
        return "paddings.shape[0] ".concat(paddings.length, " must be equal to [blockShape] ").concat(blockShape.length);
      });
      assert($x.shape.reduce(function(a, b, i) {
        if (i > 0 && i <= blockShape.length) {
          return a && (b + paddings[i - 1][0] + paddings[i - 1][1]) % blockShape[i - 1] === 0;
        }
        return a;
      }, true), function() {
        return "input spatial dimensions ".concat($x.shape.slice(1), " with paddings ").concat(paddings.toString(), " must be divisible by blockShapes ").concat(blockShape.toString());
      });
      var inputs = { x: $x };
      var attrs = { blockShape, paddings };
      return ENGINE.runKernel(SpaceToBatchND, inputs, attrs);
    }
    var spaceToBatchND = /* @__PURE__ */ op({ spaceToBatchND_ });
    function pool_(input, windowShape, poolingType, pad2, dilations, strides, dimRoundingMode) {
      if (dilations == null) {
        dilations = [1, 1];
      }
      if (strides == null) {
        strides = 1;
      }
      if (pad2 === 0) {
        pad2 = "valid";
      }
      var $x = convertToTensor(input, "x", "maxPool");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in pool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var convInfo = computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad2);
      var dilation = [convInfo.dilationHeight, convInfo.dilationWidth];
      var basePadding;
      if (pad2 === "same") {
        basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);
      } else {
        basePadding = [[0, 0], [0, 0]];
      }
      var isDilationOne = dilation[0] === 1 && dilation[1] === 1;
      var _a = __read(requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding), 2), adjustedPadding = _a[0], adjustedCrops = _a[1];
      var convertedPad = isDilationOne ? pad2 : "valid";
      var convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);
      var forwardOp = poolingType === "avg" ? function() {
        return avgPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode);
      } : function() {
        return maxPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode);
      };
      var y = forwardOp();
      var res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    function requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {
      var padStart = basePadding.map(function(b) {
        return b[0];
      });
      var origPadEnd = basePadding.map(function(b) {
        return b[1];
      });
      var fullInputShape = inputShape.concat(padStart, origPadEnd);
      var padEndExtra = blockShape.map(function(b, i) {
        return (b - fullInputShape[i] % b) % b;
      });
      var padEnd = origPadEnd.map(function(s, i) {
        return s + padEndExtra[i];
      });
      var paddings = blockShape.map(function(_, i) {
        return [padStart[i], padEnd[i]];
      });
      var crops = blockShape.map(function(_, i) {
        return [0, padEndExtra[i]];
      });
      return [paddings, crops];
    }
    function withSpaceToBatchBasePaddings(filterShape, dilation) {
      var dilatedFilterShape = filterShape.map(function(s, i) {
        return s + (s - 1) * (dilation[i] - 1);
      });
      var padExtraShape = dilatedFilterShape.map(function(s) {
        return s - 1;
      });
      var padExtraStart = padExtraShape.map(function(s) {
        return Math.floor(s / 2);
      });
      var padExtraEnd = padExtraShape.map(function(s, i) {
        return s - padExtraStart[i];
      });
      return padExtraShape.map(function(_, i) {
        return [padExtraStart[i], padExtraEnd[i]];
      });
    }
    var pool = /* @__PURE__ */ op({ pool_ });
    function prelu_(x, alpha) {
      var $x = convertToTensor(x, "x", "prelu");
      var $alpha = convertToTensor(alpha, "alpha", "prelu");
      var inputs = { x: $x, alpha: $alpha };
      return ENGINE.runKernel(Prelu, inputs);
    }
    var prelu = /* @__PURE__ */ op({ prelu_ });
    function prod_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "prod");
      if ($x.dtype === "bool") {
        $x = cast($x, "int32");
      }
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Prod, inputs, attrs);
    }
    var prod = /* @__PURE__ */ op({ prod_ });
    function raggedGather_(paramsNestedSplits, paramsDenseValues, indices, outputRaggedRank) {
      var $paramsNestedSplits = paramsNestedSplits.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "raggedGather", "int32");
      });
      var $paramsDenseValues = convertToTensor(paramsDenseValues, "paramsDenseValues", "raggedGather");
      var $indices = convertToTensor(indices, "indices", "raggedGather", "int32");
      var inputs = {
        paramsNestedSplits: $paramsNestedSplits,
        paramsDenseValues: $paramsDenseValues,
        indices: $indices
      };
      var attrs = { outputRaggedRank };
      var result = ENGINE.runKernel(RaggedGather, inputs, attrs);
      return {
        outputNestedSplits: result.slice(0, result.length - 1),
        outputDenseValues: result[result.length - 1]
      };
    }
    var raggedGather = /* @__PURE__ */ op({ raggedGather_ });
    function raggedRange_(starts, limits, deltas) {
      var $starts = convertToTensor(starts, "starts", "raggedRange");
      var $limits = convertToTensor(limits, "limits", "raggedRange", $starts.dtype);
      var $deltas = convertToTensor(deltas, "deltas", "raggedRange", $starts.dtype);
      var inputs = {
        starts: $starts,
        limits: $limits,
        deltas: $deltas
      };
      var result = ENGINE.runKernel(RaggedRange, inputs);
      return {
        rtNestedSplits: result[0],
        rtDenseValues: result[1]
      };
    }
    var raggedRange = /* @__PURE__ */ op({ raggedRange_ });
    function raggedTensorToTensor_(shape, values, defaultValue, rowPartitionTensors, rowPartitionTypes) {
      var $shape = convertToTensor(shape, "shape", "raggedTensorToTensor", "int32");
      var $values = convertToTensor(values, "values", "raggedTensorToTensor");
      var $defaultValue = convertToTensor(defaultValue, "defaultValue", "raggedTensorToTensor", $values.dtype);
      var $rowPartitionTensors = rowPartitionTensors.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "raggedTensorToTensor", "int32");
      });
      var inputs = {
        shape: $shape,
        values: $values,
        defaultValue: $defaultValue,
        rowPartitionTensors: $rowPartitionTensors
      };
      var attrs = { rowPartitionTypes };
      return ENGINE.runKernel(RaggedTensorToTensor, inputs, attrs);
    }
    var raggedTensorToTensor = /* @__PURE__ */ op({ raggedTensorToTensor_ });
    function rand_(shape, randFunction, dtype) {
      assertNonNegativeIntegerDimensions(shape);
      var size = sizeFromShape(shape);
      var values = null;
      if (dtype == null || dtype === "float32") {
        values = new Float32Array(size);
      } else if (dtype === "int32") {
        values = new Int32Array(size);
      } else if (dtype === "bool") {
        values = new Uint8Array(size);
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
      for (var i = 0; i < size; i++) {
        values[i] = randFunction();
      }
      return ENGINE.makeTensor(values, shape, dtype);
    }
    var rand = /* @__PURE__ */ op({ rand_ });
    var alea$1 = { exports: {} };
    (function(module2) {
      (function(global2, module3, define2) {
        function Alea(seed) {
          var me = this, mash = Mash();
          me.next = function() {
            var t = 2091639 * me.s0 + me.c * 23283064365386963e-26;
            me.s0 = me.s1;
            me.s1 = me.s2;
            return me.s2 = t - (me.c = t | 0);
          };
          me.c = 1;
          me.s0 = mash(" ");
          me.s1 = mash(" ");
          me.s2 = mash(" ");
          me.s0 -= mash(seed);
          if (me.s0 < 0) {
            me.s0 += 1;
          }
          me.s1 -= mash(seed);
          if (me.s1 < 0) {
            me.s1 += 1;
          }
          me.s2 -= mash(seed);
          if (me.s2 < 0) {
            me.s2 += 1;
          }
          mash = null;
        }
        function copy(f, t) {
          t.c = f.c;
          t.s0 = f.s0;
          t.s1 = f.s1;
          t.s2 = f.s2;
          return t;
        }
        function impl(seed, opts) {
          var xg = new Alea(seed), state = opts && opts.state, prng = xg.next;
          prng.int32 = function() {
            return xg.next() * 4294967296 | 0;
          };
          prng.double = function() {
            return prng() + (prng() * 2097152 | 0) * 11102230246251565e-32;
          };
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        function Mash() {
          var n = 4022871197;
          var mash = function(data) {
            data = String(data);
            for (var i = 0; i < data.length; i++) {
              n += data.charCodeAt(i);
              var h = 0.02519603282416938 * n;
              n = h >>> 0;
              h -= n;
              h *= n;
              n = h >>> 0;
              h -= n;
              n += h * 4294967296;
            }
            return (n >>> 0) * 23283064365386963e-26;
          };
          return mash;
        }
        if (module3 && module3.exports) {
          module3.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.alea = impl;
        }
      })(
        commonjsGlobal,
        module2,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(alea$1);
    var aleaExports = alea$1.exports;
    var xor128$1 = { exports: {} };
    (function(module2) {
      (function(global2, module3, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.next = function() {
            var t = me.x ^ me.x << 11;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            return me.w ^= me.w >>> 19 ^ t ^ t >>> 8;
          };
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 64; k++) {
            me.x ^= strseed.charCodeAt(k) | 0;
            me.next();
          }
        }
        function copy(f, t) {
          t.x = f.x;
          t.y = f.y;
          t.z = f.z;
          t.w = f.w;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module3 && module3.exports) {
          module3.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xor128 = impl;
        }
      })(
        commonjsGlobal,
        module2,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xor128$1);
    var xor128Exports = xor128$1.exports;
    var xorwow$1 = { exports: {} };
    (function(module2) {
      (function(global2, module3, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var t = me.x ^ me.x >>> 2;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            me.w = me.v;
            return (me.d = me.d + 362437 | 0) + (me.v = me.v ^ me.v << 4 ^ (t ^ t << 1)) | 0;
          };
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.v = 0;
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 64; k++) {
            me.x ^= strseed.charCodeAt(k) | 0;
            if (k == strseed.length) {
              me.d = me.x << 10 ^ me.x >>> 4;
            }
            me.next();
          }
        }
        function copy(f, t) {
          t.x = f.x;
          t.y = f.y;
          t.z = f.z;
          t.w = f.w;
          t.v = f.v;
          t.d = f.d;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module3 && module3.exports) {
          module3.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xorwow = impl;
        }
      })(
        commonjsGlobal,
        module2,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xorwow$1);
    var xorwowExports = xorwow$1.exports;
    var xorshift7$1 = { exports: {} };
    (function(module2) {
      (function(global2, module3, define2) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var X = me.x, i = me.i, t, v;
            t = X[i];
            t ^= t >>> 7;
            v = t ^ t << 24;
            t = X[i + 1 & 7];
            v ^= t ^ t >>> 10;
            t = X[i + 3 & 7];
            v ^= t ^ t >>> 3;
            t = X[i + 4 & 7];
            v ^= t ^ t << 7;
            t = X[i + 7 & 7];
            t = t ^ t << 13;
            v ^= t ^ t << 9;
            X[i] = v;
            me.i = i + 1 & 7;
            return v;
          };
          function init(me2, seed2) {
            var j, X = [];
            if (seed2 === (seed2 | 0)) {
              X[0] = seed2;
            } else {
              seed2 = "" + seed2;
              for (j = 0; j < seed2.length; ++j) {
                X[j & 7] = X[j & 7] << 15 ^ seed2.charCodeAt(j) + X[j + 1 & 7] << 13;
              }
            }
            while (X.length < 8)
              X.push(0);
            for (j = 0; j < 8 && X[j] === 0; ++j)
              ;
            if (j == 8)
              X[7] = -1;
            else
              X[j];
            me2.x = X;
            me2.i = 0;
            for (j = 256; j > 0; --j) {
              me2.next();
            }
          }
          init(me, seed);
        }
        function copy(f, t) {
          t.x = f.x.slice();
          t.i = f.i;
          return t;
        }
        function impl(seed, opts) {
          if (seed == null)
            seed = +/* @__PURE__ */ new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.x)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module3 && module3.exports) {
          module3.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xorshift7 = impl;
        }
      })(
        commonjsGlobal,
        module2,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xorshift7$1);
    var xorshift7Exports = xorshift7$1.exports;
    var xor4096$1 = { exports: {} };
    (function(module2) {
      (function(global2, module3, define2) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var w = me.w, X = me.X, i = me.i, t, v;
            me.w = w = w + 1640531527 | 0;
            v = X[i + 34 & 127];
            t = X[i = i + 1 & 127];
            v ^= v << 13;
            t ^= t << 17;
            v ^= v >>> 15;
            t ^= t >>> 12;
            v = X[i] = v ^ t;
            me.i = i;
            return v + (w ^ w >>> 16) | 0;
          };
          function init(me2, seed2) {
            var t, v, i, j, w, X = [], limit = 128;
            if (seed2 === (seed2 | 0)) {
              v = seed2;
              seed2 = null;
            } else {
              seed2 = seed2 + "\0";
              v = 0;
              limit = Math.max(limit, seed2.length);
            }
            for (i = 0, j = -32; j < limit; ++j) {
              if (seed2)
                v ^= seed2.charCodeAt((j + 32) % seed2.length);
              if (j === 0)
                w = v;
              v ^= v << 10;
              v ^= v >>> 15;
              v ^= v << 4;
              v ^= v >>> 13;
              if (j >= 0) {
                w = w + 1640531527 | 0;
                t = X[j & 127] ^= v + w;
                i = 0 == t ? i + 1 : 0;
              }
            }
            if (i >= 128) {
              X[(seed2 && seed2.length || 0) & 127] = -1;
            }
            i = 127;
            for (j = 4 * 128; j > 0; --j) {
              v = X[i + 34 & 127];
              t = X[i = i + 1 & 127];
              v ^= v << 13;
              t ^= t << 17;
              v ^= v >>> 15;
              t ^= t >>> 12;
              X[i] = v ^ t;
            }
            me2.w = w;
            me2.X = X;
            me2.i = i;
          }
          init(me, seed);
        }
        function copy(f, t) {
          t.i = f.i;
          t.w = f.w;
          t.X = f.X.slice();
          return t;
        }
        function impl(seed, opts) {
          if (seed == null)
            seed = +/* @__PURE__ */ new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.X)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module3 && module3.exports) {
          module3.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xor4096 = impl;
        }
      })(
        commonjsGlobal,
        // window object or global
        module2,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xor4096$1);
    var xor4096Exports = xor4096$1.exports;
    var tychei$1 = { exports: {} };
    (function(module2) {
      (function(global2, module3, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var b = me.b, c = me.c, d = me.d, a = me.a;
            b = b << 25 ^ b >>> 7 ^ c;
            c = c - d | 0;
            d = d << 24 ^ d >>> 8 ^ a;
            a = a - b | 0;
            me.b = b = b << 20 ^ b >>> 12 ^ c;
            me.c = c = c - d | 0;
            me.d = d << 16 ^ c >>> 16 ^ a;
            return me.a = a - b | 0;
          };
          me.a = 0;
          me.b = 0;
          me.c = 2654435769 | 0;
          me.d = 1367130551;
          if (seed === Math.floor(seed)) {
            me.a = seed / 4294967296 | 0;
            me.b = seed | 0;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 20; k++) {
            me.b ^= strseed.charCodeAt(k) | 0;
            me.next();
          }
        }
        function copy(f, t) {
          t.a = f.a;
          t.b = f.b;
          t.c = f.c;
          t.d = f.d;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module3 && module3.exports) {
          module3.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.tychei = impl;
        }
      })(
        commonjsGlobal,
        module2,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(tychei$1);
    var tycheiExports = tychei$1.exports;
    var seedrandom$1 = { exports: {} };
    (function(module2) {
      (function(global2, pool2, math2) {
        var width = 256, chunks = 6, digits = 52, rngname = "random", startdenom = math2.pow(width, chunks), significance = math2.pow(2, digits), overflow = significance * 2, mask = width - 1, nodecrypto;
        function seedrandom2(seed, options, callback) {
          var key = [];
          options = options == true ? { entropy: true } : options || {};
          var shortseed = mixkey(flatten2(options.entropy ? [seed, tostring(pool2)] : seed == null ? autoseed() : seed, 3), key);
          var arc4 = new ARC4(key);
          var prng = function() {
            var n = arc4.g(chunks), d = startdenom, x = 0;
            while (n < significance) {
              n = (n + x) * width;
              d *= width;
              x = arc4.g(1);
            }
            while (n >= overflow) {
              n /= 2;
              d /= 2;
              x >>>= 1;
            }
            return (n + x) / d;
          };
          prng.int32 = function() {
            return arc4.g(4) | 0;
          };
          prng.quick = function() {
            return arc4.g(4) / 4294967296;
          };
          prng.double = prng;
          mixkey(tostring(arc4.S), pool2);
          return (options.pass || callback || function(prng2, seed2, is_math_call, state) {
            if (state) {
              if (state.S) {
                copy(state, arc4);
              }
              prng2.state = function() {
                return copy(arc4, {});
              };
            }
            if (is_math_call) {
              math2[rngname] = prng2;
              return seed2;
            } else
              return prng2;
          })(prng, shortseed, "global" in options ? options.global : this == math2, options.state);
        }
        function ARC4(key) {
          var t, keylen = key.length, me = this, i = 0, j = me.i = me.j = 0, s = me.S = [];
          if (!keylen) {
            key = [keylen++];
          }
          while (i < width) {
            s[i] = i++;
          }
          for (i = 0; i < width; i++) {
            s[i] = s[j = mask & j + key[i % keylen] + (t = s[i])];
            s[j] = t;
          }
          (me.g = function(count) {
            var t2, r = 0, i2 = me.i, j2 = me.j, s2 = me.S;
            while (count--) {
              t2 = s2[i2 = mask & i2 + 1];
              r = r * width + s2[mask & (s2[i2] = s2[j2 = mask & j2 + t2]) + (s2[j2] = t2)];
            }
            me.i = i2;
            me.j = j2;
            return r;
          })(width);
        }
        function copy(f, t) {
          t.i = f.i;
          t.j = f.j;
          t.S = f.S.slice();
          return t;
        }
        function flatten2(obj, depth) {
          var result = [], typ = typeof obj, prop;
          if (depth && typ == "object") {
            for (prop in obj) {
              try {
                result.push(flatten2(obj[prop], depth - 1));
              } catch (e) {
              }
            }
          }
          return result.length ? result : typ == "string" ? obj : obj + "\0";
        }
        function mixkey(seed, key) {
          var stringseed = seed + "", smear, j = 0;
          while (j < stringseed.length) {
            key[mask & j] = mask & (smear ^= key[mask & j] * 19) + stringseed.charCodeAt(j++);
          }
          return tostring(key);
        }
        function autoseed() {
          try {
            var out;
            if (nodecrypto && (out = nodecrypto.randomBytes)) {
              out = out(width);
            } else {
              out = new Uint8Array(width);
              (global2.crypto || global2.msCrypto).getRandomValues(out);
            }
            return tostring(out);
          } catch (e) {
            var browser2 = global2.navigator, plugins = browser2 && browser2.plugins;
            return [+/* @__PURE__ */ new Date(), global2, plugins, global2.screen, tostring(pool2)];
          }
        }
        function tostring(a) {
          return String.fromCharCode.apply(0, a);
        }
        mixkey(math2.random(), pool2);
        if (module2.exports) {
          module2.exports = seedrandom2;
          try {
            nodecrypto = require_crypto();
          } catch (ex) {
          }
        } else {
          math2["seed" + rngname] = seedrandom2;
        }
      })(
        // global: `self` in browsers (including strict mode and web workers),
        // otherwise `this` in Node and other environments
        typeof self !== "undefined" ? self : commonjsGlobal,
        [],
        // pool: entropy pool starts empty
        Math
        // math: package containing random, pow, and seedrandom
      );
    })(seedrandom$1);
    var seedrandomExports = seedrandom$1.exports;
    var alea = aleaExports;
    var xor128 = xor128Exports;
    var xorwow = xorwowExports;
    var xorshift7 = xorshift7Exports;
    var xor4096 = xor4096Exports;
    var tychei = tycheiExports;
    var sr = seedrandomExports;
    sr.alea = alea;
    sr.xor128 = xor128;
    sr.xorwow = xorwow;
    sr.xorshift7 = xorshift7;
    sr.xor4096 = xor4096;
    sr.tychei = tychei;
    var seedrandom = sr;
    var TEST_EPSILON_FLOAT32 = 1e-3;
    var TEST_EPSILON_FLOAT16 = 0.1;
    function expectArraysClose(actual, expected, epsilon) {
      if (epsilon == null) {
        epsilon = testEpsilon();
      }
      return expectArraysPredicate(actual, expected, function(a, b) {
        return areClose(a, b, epsilon);
      });
    }
    function testEpsilon() {
      return ENGINE.backend.floatPrecision() === 32 ? TEST_EPSILON_FLOAT32 : TEST_EPSILON_FLOAT16;
    }
    function expectArraysPredicate(actual, expected, predicate) {
      var checkClassType = true;
      if (isTypedArray(actual) || isTypedArray(expected)) {
        checkClassType = false;
      }
      if (isTypedArray(actual) && isTypedArray(expected)) {
        checkClassType = true;
      }
      if (checkClassType) {
        var aType = actual.constructor.name;
        var bType = expected.constructor.name;
        if (aType !== bType) {
          throw new Error("Arrays are of different type. Actual: ".concat(aType, ". ") + "Expected: ".concat(bType));
        }
      }
      if (Array.isArray(actual) && Array.isArray(expected)) {
        var actualShape = inferShape(actual);
        var expectedShape = inferShape(expected);
        if (!arraysEqual(actualShape, expectedShape)) {
          throw new Error("Arrays have different shapes. " + "Actual: [".concat(actualShape, "]. Expected: [").concat(expectedShape, "]"));
        }
      }
      var actualFlat = isTypedArray(actual) ? actual : flatten(actual);
      var expectedFlat = isTypedArray(expected) ? expected : flatten(expected);
      if (actualFlat.length !== expectedFlat.length) {
        throw new Error("Arrays have different lengths actual: ".concat(actualFlat.length, " vs ") + "expected: ".concat(expectedFlat.length, ".\n") + "Actual:   ".concat(actualFlat, ".\n") + "Expected: ".concat(expectedFlat, "."));
      }
      for (var i = 0; i < expectedFlat.length; ++i) {
        var a = actualFlat[i];
        var e = expectedFlat[i];
        if (!predicate(a, e)) {
          throw new Error("Arrays differ: actual[".concat(i, "] = ").concat(a, ", expected[").concat(i, "] = ").concat(e, ".\n") + "Actual:   ".concat(actualFlat, ".\n") + "Expected: ".concat(expectedFlat, "."));
        }
      }
      if (typeof expect !== "undefined") {
        expect().nothing();
      }
    }
    function expectPromiseToFail(fn, done) {
      fn().then(function() {
        return done.fail();
      }, function() {
        return done();
      });
      if (typeof expect !== "undefined") {
        expect().nothing();
      }
    }
    function expectArraysEqual(actual, expected) {
      var exp2 = typeof expected === "string" || typeof expected === "number" || typeof expected === "boolean" ? [expected] : expected;
      if (isString(actual) || isString(actual[0]) || isString(expected) || isString(expected[0])) {
        return expectArraysPredicate(actual, exp2, function(a, b) {
          return a == b;
        });
      }
      return expectArraysPredicate(actual, expected, function(a, b) {
        return areClose(a, b, 0);
      });
    }
    function expectNumbersClose(a, e, epsilon) {
      if (epsilon == null) {
        epsilon = testEpsilon();
      }
      if (!areClose(a, e, epsilon)) {
        throw new Error("Numbers differ: actual === ".concat(a, ", expected === ").concat(e));
      }
      if (typeof expect !== "undefined") {
        expect().nothing();
      }
    }
    function areClose(a, e, epsilon) {
      if (!isFinite(a) && !isFinite(e)) {
        return true;
      }
      if (isNaN(a) || isNaN(e) || Math.abs(a - e) > epsilon) {
        return false;
      }
      return true;
    }
    function expectValuesInRange(actual, low, high) {
      for (var i = 0; i < actual.length; i++) {
        if (actual[i] < low || actual[i] > high) {
          throw new Error("Value out of range:".concat(actual[i], " low: ").concat(low, ", high: ").concat(high));
        }
      }
    }
    function expectArrayBuffersEqual(actual, expected) {
      var actualArray = new Float32Array(actual);
      var expectedArray = new Float32Array(expected);
      if (actualArray.length !== expectedArray.length) {
        throw new Error("Expected ArrayBuffer to be of length " + "".concat(expectedArray.length, ", but it was ").concat(actualArray.length));
      }
      for (var i = 0; i < expectedArray.length; i++) {
        if (actualArray[i] !== expectedArray[i]) {
          throw new Error("Expected ArrayBuffer value at ".concat(i, " to be ") + "".concat(expectedArray[i], " but got ").concat(actualArray[i], " instead"));
        }
      }
    }
    function encodeStrings(a) {
      for (var i = 0; i < a.length; i++) {
        var val = a[i];
        if (Array.isArray(val)) {
          encodeStrings(val);
        } else {
          a[i] = encodeString(val);
        }
      }
      return a;
    }
    function createVideoElement(source) {
      var video = document.createElement("video");
      if ("playsInline" in video) {
        video.playsInline = true;
      }
      video.muted = true;
      video.loop = true;
      video.style.position = "fixed";
      video.style.left = "0px";
      video.style.top = "0px";
      video.preload = "auto";
      video.appendChild(source);
      return new Promise(function(resolve) {
        video.addEventListener("loadeddata", function(_) {
          return resolve(video);
        });
        video.load();
      });
    }
    function play(video) {
      return __awaiter(this, void 0, void 0, function() {
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              return [4, video.play()];
            case 1:
              _a.sent();
              if (!("requestVideoFrameCallback" in video))
                return [3, 3];
              return [4, new Promise(function(resolve) {
                video.requestVideoFrameCallback(resolve);
              })];
            case 2:
              _a.sent();
              _a.label = 3;
            case 3:
              return [
                2
                /*return*/
              ];
          }
        });
      });
    }
    var test_util = {
      __proto__: null,
      TEST_EPSILON_FLOAT16,
      createVideoElement,
      encodeStrings,
      expectArrayBuffersEqual,
      expectArraysClose,
      expectArraysEqual,
      expectNumbersClose,
      expectPromiseToFail,
      expectValuesInRange,
      play,
      testEpsilon
    };
    var MPRandGauss = (
      /** @class */
      function() {
        function MPRandGauss2(mean2, stdDeviation, dtype, truncated, seed) {
          this.mean = mean2;
          this.stdDev = stdDeviation;
          this.dtype = dtype;
          this.nextVal = NaN;
          this.truncated = truncated;
          if (this.truncated) {
            this.upper = this.mean + this.stdDev * 2;
            this.lower = this.mean - this.stdDev * 2;
          }
          var seedValue = seed ? seed : Math.random();
          this.random = seedrandom.alea(seedValue.toString());
        }
        MPRandGauss2.prototype.nextValue = function() {
          if (!isNaN(this.nextVal)) {
            var value = this.nextVal;
            this.nextVal = NaN;
            return value;
          }
          var resultX, resultY;
          var isValid = false;
          while (!isValid) {
            var v1 = void 0, v2 = void 0, s = void 0;
            do {
              v1 = 2 * this.random() - 1;
              v2 = 2 * this.random() - 1;
              s = v1 * v1 + v2 * v2;
            } while (s >= 1 || s === 0);
            var mul2 = Math.sqrt(-2 * Math.log(s) / s);
            resultX = this.mean + this.stdDev * v1 * mul2;
            resultY = this.mean + this.stdDev * v2 * mul2;
            if (!this.truncated || this.isValidTruncated(resultX)) {
              isValid = true;
            }
          }
          if (!this.truncated || this.isValidTruncated(resultY)) {
            this.nextVal = this.convertValue(resultY);
          }
          return this.convertValue(resultX);
        };
        MPRandGauss2.prototype.convertValue = function(value) {
          if (this.dtype == null || this.dtype === "float32") {
            return value;
          }
          return Math.round(value);
        };
        MPRandGauss2.prototype.isValidTruncated = function(value) {
          return value <= this.upper && value >= this.lower;
        };
        return MPRandGauss2;
      }()
    );
    var RandGamma = (
      /** @class */
      function() {
        function RandGamma2(alpha, beta, dtype, seed) {
          this.alpha = alpha;
          this.beta = 1 / beta;
          this.dtype = dtype;
          var seedValue = seed ? seed : Math.random();
          this.randu = seedrandom.alea(seedValue.toString());
          this.randn = new MPRandGauss(0, 1, dtype, false, this.randu());
          if (alpha < 1) {
            this.d = alpha + 2 / 3;
          } else {
            this.d = alpha - 1 / 3;
          }
          this.c = 1 / Math.sqrt(9 * this.d);
        }
        RandGamma2.prototype.nextValue = function() {
          var x2, v0, v1, x, u, v;
          while (true) {
            do {
              x = this.randn.nextValue();
              v = 1 + this.c * x;
            } while (v <= 0);
            v *= v * v;
            x2 = x * x;
            v0 = 1 - 0.331 * x2 * x2;
            v1 = 0.5 * x2 + this.d * (1 - v + Math.log(v));
            u = this.randu();
            if (u < v0 || Math.log(u) < v1) {
              break;
            }
          }
          v = 1 / this.beta * this.d * v;
          if (this.alpha < 1) {
            v *= Math.pow(this.randu(), 1 / this.alpha);
          }
          return this.convertValue(v);
        };
        RandGamma2.prototype.convertValue = function(value) {
          if (this.dtype === "float32") {
            return value;
          }
          return Math.round(value);
        };
        return RandGamma2;
      }()
    );
    var UniformRandom = (
      /** @class */
      function() {
        function UniformRandom2(min2, max2, dtype, seed) {
          if (min2 === void 0) {
            min2 = 0;
          }
          if (max2 === void 0) {
            max2 = 1;
          }
          var _this = this;
          this.canReturnFloat = function() {
            return _this.dtype == null || _this.dtype === "float32";
          };
          this.min = min2;
          this.range = max2 - min2;
          this.dtype = dtype;
          if (seed == null) {
            seed = Math.random();
          }
          if (typeof seed === "number") {
            seed = seed.toString();
          }
          if (!this.canReturnFloat() && this.range <= 1) {
            throw new Error("The difference between ".concat(min2, " - ").concat(max2, " <= 1 and dtype is not float"));
          }
          this.random = seedrandom.alea(seed);
        }
        UniformRandom2.prototype.convertValue = function(value) {
          if (this.canReturnFloat()) {
            return value;
          }
          return Math.round(value);
        };
        UniformRandom2.prototype.nextValue = function() {
          return this.convertValue(this.min + this.range * this.random());
        };
        return UniformRandom2;
      }()
    );
    function randomGamma_(shape, alpha, beta, dtype, seed) {
      if (beta === void 0) {
        beta = 1;
      }
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      if (beta == null) {
        beta = 1;
      }
      if (dtype == null) {
        dtype = "float32";
      }
      if (dtype !== "float32" && dtype !== "int32") {
        throw new Error("Unsupported data type ".concat(dtype));
      }
      var rgamma = new RandGamma(alpha, beta, dtype, seed);
      var res = buffer(shape, dtype);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = rgamma.nextValue();
      }
      return res.toTensor();
    }
    var randomGamma = /* @__PURE__ */ op({ randomGamma_ });
    function randomNormal_(shape, mean2, stdDev, dtype, seed) {
      if (mean2 === void 0) {
        mean2 = 0;
      }
      if (stdDev === void 0) {
        stdDev = 1;
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype != null && dtype === "bool") {
        throw new Error("Unsupported data type ".concat(dtype));
      }
      var randGauss = new MPRandGauss(mean2, stdDev, dtype, false, seed);
      var res = buffer(shape, dtype);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = randGauss.nextValue();
      }
      return res.toTensor();
    }
    var randomNormal = /* @__PURE__ */ op({ randomNormal_ });
    function randomStandardNormal_(shape, dtype, seed) {
      if (dtype != null && dtype === "bool") {
        throw new Error("Unsupported data type ".concat(dtype));
      }
      return randomNormal(shape, 0, 1, dtype, seed);
    }
    var randomStandardNormal = /* @__PURE__ */ op({ randomStandardNormal_ });
    function randomUniform_(shape, minval, maxval, dtype, seed) {
      if (minval === void 0) {
        minval = 0;
      }
      if (maxval === void 0) {
        maxval = 1;
      }
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      var res = buffer(shape, dtype);
      var random = new UniformRandom(minval, maxval, null, seed);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = random.nextValue();
      }
      return res.toTensor();
    }
    var randomUniform = /* @__PURE__ */ op({ randomUniform_ });
    function randomUniformInt_(shape, minval, maxval, seed) {
      return randomUniform(shape, minval, maxval, "int32", seed);
    }
    var randomUniformInt = /* @__PURE__ */ op({ randomUniformInt_ });
    function range(start, stop, step2, dtype) {
      if (step2 === void 0) {
        step2 = 1;
      }
      if (dtype === void 0) {
        dtype = "float32";
      }
      if (step2 === 0) {
        throw new Error("Cannot have a step of zero");
      }
      var attrs = { start, stop, step: step2, dtype };
      return ENGINE.runKernel(Range, {}, attrs);
    }
    function real_(input) {
      var $input = convertToTensor(input, "input", "real");
      var inputs = { input: $input };
      return ENGINE.runKernel(Real, inputs);
    }
    var real = /* @__PURE__ */ op({ real_ });
    function reciprocal_(x) {
      var $x = convertToTensor(x, "x", "reciprocal");
      var inputs = { x: $x };
      return ENGINE.runKernel(Reciprocal, inputs);
    }
    var reciprocal = /* @__PURE__ */ op({ reciprocal_ });
    function relu_(x) {
      var $x = convertToTensor(x, "x", "relu");
      var inputs = { x: $x };
      return ENGINE.runKernel(Relu, inputs);
    }
    var relu = /* @__PURE__ */ op({ relu_ });
    function relu6_(x) {
      var $x = convertToTensor(x, "x", "relu6");
      var inputs = { x: $x };
      return ENGINE.runKernel(Relu6, inputs);
    }
    var relu6 = /* @__PURE__ */ op({ relu6_ });
    function reverse_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      var inputs = { x: $x };
      var attrs = { dims: axis };
      return ENGINE.runKernel(Reverse, inputs, attrs);
    }
    var reverse = /* @__PURE__ */ op({ reverse_ });
    function reverse1d_(x) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 1, function() {
        return "Error in reverse1D: x must be rank 1 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, 0);
    }
    var reverse1d = /* @__PURE__ */ op({ reverse1d_ });
    function reverse2d_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 2, function() {
        return "Error in reverse2D: x must be rank 2 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, axis);
    }
    var reverse2d = /* @__PURE__ */ op({ reverse2d_ });
    function reverse3d_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 3, function() {
        return "Error in reverse3D: x must be rank 3 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, axis);
    }
    var reverse3d = /* @__PURE__ */ op({ reverse3d_ });
    function reverse4d_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 4, function() {
        return "Error in reverse4D: x must be rank 4 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, axis);
    }
    var reverse4d = /* @__PURE__ */ op({ reverse4d_ });
    function round_(x) {
      var $x = convertToTensor(x, "x", "round");
      var inputs = { x: $x };
      return ENGINE.runKernel(Round, inputs);
    }
    var round = /* @__PURE__ */ op({ round_ });
    function rsqrt_(x) {
      var $x = convertToTensor(x, "x", "rsqrt", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Rsqrt, inputs);
    }
    var rsqrt = /* @__PURE__ */ op({ rsqrt_ });
    function selu_(x) {
      var $x = convertToTensor(x, "x", "selu");
      var inputs = { x: $x };
      return ENGINE.runKernel(Selu, inputs);
    }
    var selu = /* @__PURE__ */ op({ selu_ });
    function separableConv2d_(x, depthwiseFilter, pointwiseFilter, strides, pad2, dilation, dataFormat) {
      if (dilation === void 0) {
        dilation = [1, 1];
      }
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var $x = convertToTensor(x, "x", "separableConv2d");
      var $depthwiseFilter = convertToTensor(depthwiseFilter, "depthwiseFilter", "separableConv2d");
      var $pointwiseFilter = convertToTensor(pointwiseFilter, "pointwiseFilter", "separableConv2d");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      if (dataFormat === "NCHW") {
        throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
      }
      assert(x4D.rank === 4, function() {
        return "Error in separableConv2d: input must be rank 4, but got " + "rank ".concat(x4D.rank, ".");
      });
      assert($depthwiseFilter.rank === 4, function() {
        return "Error in separableConv2d: depthwise filter must be rank 4, but " + "got rank ".concat($depthwiseFilter.rank, ".");
      });
      assert($pointwiseFilter.rank === 4, function() {
        return "Error in separableConv2d: pointwise filter must be rank 4, but " + "got rank ".concat($depthwiseFilter.rank, ".");
      });
      assert($pointwiseFilter.shape[0] === 1, function() {
        return "Error in separableConv2d: the first dimension of pointwise filter " + " must be 1, but got ".concat($pointwiseFilter.shape[0], ".");
      });
      assert($pointwiseFilter.shape[1] === 1, function() {
        return "Error in separableConv2d: the second dimension of pointwise " + "filter must be 1, but got ".concat($pointwiseFilter.shape[1], ".");
      });
      var inChannels = $depthwiseFilter.shape[2];
      var channelMultiplier = $depthwiseFilter.shape[3];
      assert($pointwiseFilter.shape[2] === inChannels * channelMultiplier, function() {
        return "Error in separableConv2d: the third dimension of pointwise filter " + "must be ".concat(inChannels * channelMultiplier, ", ") + "but got ".concat($pointwiseFilter.shape[2], ".");
      });
      var depthwise = depthwiseConv2d$1(x4D, $depthwiseFilter, strides, pad2, dataFormat, dilation);
      var pointwiseStride = 1;
      var res = conv2d$1(depthwise, $pointwiseFilter, pointwiseStride, "valid", dataFormat);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var separableConv2d = /* @__PURE__ */ op({ separableConv2d_ });
    function setdiff1dAsync_(x, y) {
      return __awaiter(this, void 0, void 0, function() {
        var $x, $y, xVals, yVals, ySet, outputSize, i, buffer2, indices, i, p;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $x = convertToTensor(x, "x", "setdiff1d");
              $y = convertToTensor(y, "y", "setdiff1d");
              assert($x.dtype === $y.dtype, function() {
                return "x and y should have the same dtype, but got x (".concat($x.dtype, ") and y (").concat($y.dtype, ").");
              });
              assert($x.rank === 1, function() {
                return "x should be 1D tensor, but got x (".concat($x.shape, ").");
              });
              assert($y.rank === 1, function() {
                return "y should be 1D tensor, but got y (".concat($y.shape, ").");
              });
              return [4, $x.data()];
            case 1:
              xVals = _a.sent();
              return [4, $y.data()];
            case 2:
              yVals = _a.sent();
              ySet = new Set(yVals);
              outputSize = 0;
              for (i = 0; i < xVals.length; i++) {
                if (!ySet.has(xVals[i])) {
                  outputSize++;
                }
              }
              buffer2 = new TensorBuffer([outputSize], $x.dtype);
              indices = new TensorBuffer([outputSize], "int32");
              for (i = 0, p = 0; i < xVals.length; i++) {
                if (!ySet.has(xVals[i])) {
                  buffer2.values[p] = xVals[i];
                  indices.values[p] = i;
                  p++;
                }
              }
              return [2, [buffer2.toTensor(), indices.toTensor()]];
          }
        });
      });
    }
    var setdiff1dAsync = setdiff1dAsync_;
    function sign_(x) {
      var $x = convertToTensor(x, "x", "sign");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sign, inputs);
    }
    var sign = /* @__PURE__ */ op({ sign_ });
    function sin_(x) {
      var $x = convertToTensor(x, "x", "sin", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sin, inputs);
    }
    var sin = /* @__PURE__ */ op({ sin_ });
    function sinh_(x) {
      var $x = convertToTensor(x, "x", "sinh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sinh, inputs);
    }
    var sinh = /* @__PURE__ */ op({ sinh_ });
    function slice1d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice1d");
      assert($x.rank === 1, function() {
        return "slice1d expects a rank-1 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, [begin], [size]);
    }
    var slice1d = /* @__PURE__ */ op({ slice1d_ });
    function slice2d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice2d");
      assert($x.rank === 2, function() {
        return "slice2d expects a rank-2 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, begin, size);
    }
    var slice2d = /* @__PURE__ */ op({ slice2d_ });
    function slice3d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice3d");
      assert($x.rank === 3, function() {
        return "slice3d expects a rank-3 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, begin, size);
    }
    var slice3d = /* @__PURE__ */ op({ slice3d_ });
    function slice4d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice4d");
      assert($x.rank === 4, function() {
        return "slice4d expects a rank-4 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, begin, size);
    }
    var slice4d = /* @__PURE__ */ op({ slice4d_ });
    function softmax_(logits, dim) {
      if (dim === void 0) {
        dim = -1;
      }
      var $logits = convertToTensor(logits, "logits", "softmax", "float32");
      if (dim === -1) {
        dim = $logits.rank - 1;
      }
      if (dim !== $logits.rank - 1) {
        throw Error("Softmax along a non-last dimension is not yet supported. " + "Logits was rank ".concat($logits.rank, " and dim was ").concat(dim));
      }
      var inputs = { logits: $logits };
      var attrs = { dim };
      return ENGINE.runKernel(Softmax, inputs, attrs);
    }
    var softmax = /* @__PURE__ */ op({ softmax_ });
    function fft_(input) {
      assert(input.dtype === "complex64", function() {
        return "The dtype for tf.spectral.fft() must be complex64 " + "but got ".concat(input.dtype, ".");
      });
      var inputs = { input };
      return ENGINE.runKernel(FFT, inputs);
    }
    var fft = /* @__PURE__ */ op({ fft_ });
    function ifft_(input) {
      assert(input.dtype === "complex64", function() {
        return "The dtype for tf.spectral.ifft() must be complex64 " + "but got ".concat(input.dtype, ".");
      });
      var inputs = { input };
      return ENGINE.runKernel(IFFT, inputs);
    }
    var ifft = /* @__PURE__ */ op({ ifft_ });
    function irfft_(input) {
      var innerDimensionSize = input.shape[input.shape.length - 1];
      var batch = input.size / innerDimensionSize;
      var ret;
      if (innerDimensionSize <= 2) {
        var complexInput = reshape(input, [batch, innerDimensionSize]);
        ret = ifft(complexInput);
      } else {
        var outputShape = [batch, 2 * (innerDimensionSize - 1)];
        var realInput = reshape(real(input), [batch, innerDimensionSize]);
        var imagInput = reshape(imag(input), [batch, innerDimensionSize]);
        var realConjugate = reverse(slice(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);
        var imagConjugate = mul(reverse(slice(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1), scalar(-1));
        var r = concat([realInput, realConjugate], 1);
        var i = concat([imagInput, imagConjugate], 1);
        var complexInput = reshape(complex(r, i), [outputShape[0], outputShape[1]]);
        ret = ifft(complexInput);
      }
      ret = real(ret);
      if (input.rank === 3 && input.shape[0] !== 0) {
        var temp = ret;
        var batch_1 = input.shape[0];
        ret = reshape(ret, [batch_1, ret.shape[0] / batch_1, ret.shape[1]]);
        temp.dispose();
      }
      return ret;
    }
    var irfft = /* @__PURE__ */ op({ irfft_ });
    function split_(x, numOrSizeSplits, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "split");
      var inputs = { x: $x };
      var attr = { numOrSizeSplits, axis };
      return ENGINE.runKernel(SplitV, inputs, attr);
    }
    var split = /* @__PURE__ */ op({ split_ });
    function rfft_(input, fftLength) {
      assert(input.dtype === "float32", function() {
        return "The dtype for rfft() must be real value but got ".concat(input.dtype);
      });
      var innerDimensionSize = input.shape[input.shape.length - 1];
      var batch = input.size / innerDimensionSize;
      var adjustedInput;
      if (fftLength != null && fftLength < innerDimensionSize) {
        var begin = input.shape.map(function(v) {
          return 0;
        });
        var size = input.shape.map(function(v) {
          return v;
        });
        size[input.shape.length - 1] = fftLength;
        adjustedInput = slice(input, begin, size);
        innerDimensionSize = fftLength;
      } else if (fftLength != null && fftLength > innerDimensionSize) {
        var zerosShape = input.shape.map(function(v) {
          return v;
        });
        zerosShape[input.shape.length - 1] = fftLength - innerDimensionSize;
        adjustedInput = concat([input, zeros(zerosShape)], input.shape.length - 1);
        innerDimensionSize = fftLength;
      } else {
        adjustedInput = input;
      }
      var zerosInput = zerosLike(adjustedInput);
      var complexInput = reshape(complex(adjustedInput, zerosInput), [batch, innerDimensionSize]);
      var ret = fft(complexInput);
      var half = Math.floor(innerDimensionSize / 2) + 1;
      var realValues = real(ret);
      var imagValues = imag(ret);
      var realComplexConjugate = split(realValues, [half, innerDimensionSize - half], realValues.shape.length - 1);
      var imagComplexConjugate = split(imagValues, [half, innerDimensionSize - half], imagValues.shape.length - 1);
      var outputShape = adjustedInput.shape.slice();
      outputShape[adjustedInput.shape.length - 1] = half;
      return reshape(complex(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);
    }
    var rfft = /* @__PURE__ */ op({ rfft_ });
    function squaredDifference_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "squaredDifference");
      var $b = convertToTensor(b, "b", "squaredDifference");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      var attrs = {};
      return ENGINE.runKernel(SquaredDifference, inputs, attrs);
    }
    var squaredDifference = /* @__PURE__ */ op({ squaredDifference_ });
    function squeeze_(x, axis) {
      var $x = convertToTensor(x, "x", "squeeze", "string_or_numeric");
      return reshape($x, squeezeShape($x.shape, axis).newShape);
    }
    var squeeze = /* @__PURE__ */ op({ squeeze_ });
    function stack_(tensors, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $tensors = convertToTensorArray(tensors, "tensors", "stack", "string_or_numeric");
      assert($tensors.length >= 1, function() {
        return "Pass at least one tensor to tf.stack";
      });
      if ($tensors.length > 0) {
        assert(axis <= $tensors[0].rank, function() {
          return "Axis must be <= rank of the tensor";
        });
      }
      var inputs = $tensors;
      var attrs = { axis };
      return ENGINE.runKernel(Pack, inputs, attrs);
    }
    var stack = /* @__PURE__ */ op({ stack_ });
    function step_(x, alpha) {
      if (alpha === void 0) {
        alpha = 0;
      }
      var $x = convertToTensor(x, "x", "step");
      var inputs = { x: $x };
      var attrs = { alpha };
      return ENGINE.runKernel(Step, inputs, attrs);
    }
    var step = /* @__PURE__ */ op({ step_ });
    function stridedSlice_(x, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
      if (beginMask === void 0) {
        beginMask = 0;
      }
      if (endMask === void 0) {
        endMask = 0;
      }
      if (ellipsisMask === void 0) {
        ellipsisMask = 0;
      }
      if (newAxisMask === void 0) {
        newAxisMask = 0;
      }
      if (shrinkAxisMask === void 0) {
        shrinkAxisMask = 0;
      }
      var $x = convertToTensor(x, "x", "stridedSlice", "string_or_numeric");
      var inputs = { x: $x };
      var attrs = {
        begin,
        end,
        strides,
        beginMask,
        endMask,
        ellipsisMask,
        newAxisMask,
        shrinkAxisMask
      };
      return ENGINE.runKernel(StridedSlice, inputs, attrs);
    }
    var stridedSlice = /* @__PURE__ */ op({ stridedSlice_ });
    function tan_(x) {
      var $x = convertToTensor(x, "x", "tan", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Tan, inputs);
    }
    var tan = /* @__PURE__ */ op({ tan_ });
    function tensor1d(values, dtype) {
      assertNonNull(values);
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 1) {
        throw new Error("tensor1d() requires values to be a flat/TypedArray");
      }
      var shape = null;
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor2d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 2) {
        throw new Error("tensor2d() requires shape to have two numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 2 && inferredShape.length !== 1) {
        throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor3d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 3) {
        throw new Error("tensor3d() requires shape to have three numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 3 && inferredShape.length !== 1) {
        throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor4d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 4) {
        throw new Error("tensor4d() requires shape to have four numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 4 && inferredShape.length !== 1) {
        throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor5d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 5) {
        throw new Error("tensor5d() requires shape to have five numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 5 && inferredShape.length !== 1) {
        throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor6d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 6) {
        throw new Error("tensor6d() requires shape to have six numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 6 && inferredShape.length !== 1) {
        throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");
      }
      shape = shape || inferredShape;
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function validateUpdateShape(shape, indices, updates) {
      var sliceDim = indices.rank > 1 ? indices.shape[indices.rank - 1] : 1;
      var batchDim = indices.rank > 1 ? indices.rank - 1 : 1;
      var shapeError = "Must have updates.shape = indices.shape[:batchDim] + " + "shape[sliceDim:], got updates.shape: ".concat(updates.shape) + ", indices.shape: ".concat(indices.shape, ", shape: ").concat(shape) + ", sliceDim: ".concat(sliceDim, ", and batchDim: ").concat(batchDim, ".");
      if (updates.rank < batchDim) {
        throw new Error(shapeError + " update.rank < ".concat(batchDim, ". "));
      }
      if (shape.length < sliceDim + (updates.rank - batchDim)) {
        throw new Error(shapeError + " Output shape length < ".concat(sliceDim + (updates.rank - batchDim)));
      }
      if (updates.rank !== batchDim + shape.length - sliceDim) {
        throw new Error(shapeError + " update.rank != ".concat(batchDim + shape.length - sliceDim));
      }
      for (var d = 0; d < batchDim; ++d) {
        if (updates.shape[d] !== indices.shape[d]) {
          throw new Error(shapeError + " updates.shape[".concat(d, "] (").concat(updates.shape[d], ") != indices.shape[").concat(d, "] (").concat(indices.shape[d], ")."));
        }
      }
      for (var d = 0; d < updates.rank - batchDim; ++d) {
        if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {
          throw new Error(shapeError + " updates.shape[".concat(d + batchDim, "] (").concat(updates.shape[d + batchDim], ") != shape[").concat(d + batchDim, "] (").concat(shape[d + batchDim], ")"));
        }
      }
    }
    function validateInput$1(updates, indices, shape) {
      if (indices.rank < 1) {
        throw new Error("tf.scatterND() expects the indices to be rank 1 or higher," + " but the rank was ".concat(indices.rank, "."));
      }
      if (updates.rank < 1) {
        throw new Error("tf.scatterND() expects the updates to be rank 1 or higher," + " but the rank was ".concat(updates.rank, "."));
      }
      if (indices.dtype !== "int32") {
        throw new Error("The dtype of 'indices' should be int32, but got dtype: ".concat(indices.dtype));
      }
      if (shape.length < 1) {
        throw new Error("Output rank must be greater or equal to 1, but got shape: ".concat(shape));
      }
      if (shape.length === 0) {
        if (indices.size === 0) {
          throw new Error("Indices specified for empty output. indices shape: ".concat(indices.shape));
        }
        if (updates.size === 0) {
          throw new Error("Updates specified for empty output. updates shape: ".concat(updates.shape));
        }
      }
      validateUpdateShape(shape, indices, updates);
    }
    function calculateShapes(updates, indices, shape) {
      var indicesRank = indices.shape.length;
      var sliceRank = indicesRank > 1 ? indices.shape[indicesRank - 1] : 1;
      var totalNd = shape.length;
      var sliceSize = 1;
      for (var i = sliceRank; i < totalNd; ++i) {
        sliceSize *= shape[i];
      }
      var safeSliceDim = sliceRank < 1 ? 1 : sliceRank;
      var numUpdates = sizeFromShape(indices.shape) / safeSliceDim;
      var strides = __spreadArray(__spreadArray([], __read(computeStrides(shape.slice(0, sliceRank))), false), [1], false);
      var outputSize = sizeFromShape(shape);
      return { sliceRank, numUpdates, sliceSize, strides, outputSize };
    }
    var scatter_nd_util = {
      __proto__: null,
      calculateShapes,
      validateInput: validateInput$1,
      validateUpdateShape
    };
    function tensorScatterUpdate_(tensor2, indices, updates) {
      var $tensor = convertToTensor(tensor2, "tensor", "tensorScatterupdate");
      var $indices = convertToTensor(indices, "indices", "tensorScatterupdate", "int32");
      var $updates = convertToTensor(updates, "updates", "tensorScatterupdate");
      validateInput$1($updates, $indices, $tensor.shape);
      if ($tensor.dtype !== $updates.dtype) {
        throw new Error("tensor and updates must have the same dtype, instead they are ".concat($tensor.dtype, " and ").concat($updates.dtype, "."));
      }
      var inputs = {
        tensor: $tensor,
        indices: $indices,
        updates: $updates
      };
      var attrs = {};
      return ENGINE.runKernel(TensorScatterUpdate, inputs, attrs);
    }
    var tensorScatterUpdate = op({ tensorScatterUpdate_ });
    function topk_(x, k, sorted) {
      if (k === void 0) {
        k = 1;
      }
      if (sorted === void 0) {
        sorted = true;
      }
      var $x = convertToTensor(x, "x", "topk");
      if ($x.rank === 0) {
        throw new Error("topk() expects the input to be of rank 1 or higher");
      }
      var lastDim = $x.shape[$x.shape.length - 1];
      if (k < 0) {
        throw new Error("'k' passed to topk() must be >= 0 but got ".concat(k));
      }
      if (k > lastDim) {
        throw new Error("'k' passed to topk() must be <= the last dimension (".concat(lastDim, ") ") + "but got ".concat(k));
      }
      var inputs = { x: $x };
      var attrs = { k, sorted };
      var _a = __read(ENGINE.runKernel(TopK, inputs, attrs), 2), values = _a[0], indices = _a[1];
      return { values, indices };
    }
    var topk = /* @__PURE__ */ op({ topk_ });
    function truncatedNormal_(shape, mean2, stdDev, dtype, seed) {
      if (mean2 === void 0) {
        mean2 = 0;
      }
      if (stdDev === void 0) {
        stdDev = 1;
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype != null && dtype === "bool") {
        throw new Error("Unsupported data type $ { dtype }");
      }
      var randGauss = new MPRandGauss(mean2, stdDev, dtype, true, seed);
      var res = buffer(shape, dtype);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = randGauss.nextValue();
      }
      return res.toTensor();
    }
    var truncatedNormal = /* @__PURE__ */ op({ truncatedNormal_ });
    function unique_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "unique", "string_or_numeric");
      assert($x.rank > 0, function() {
        return "The input tensor must be at least 1D";
      });
      var inputs = { x: $x };
      var attrs = { axis };
      var _a = __read(ENGINE.runKernel(Unique, inputs, attrs), 2), values = _a[0], indices = _a[1];
      return { values, indices };
    }
    var unique = /* @__PURE__ */ op({ unique_ });
    function unsortedSegmentSum_(x, segmentIds, numSegments) {
      var $x = convertToTensor(x, "x", "unsortedSegmentSum");
      var $segmentIds = convertToTensor(segmentIds, "segmentIds", "unsortedSegmentSum", "int32");
      assert(isInt(numSegments), function() {
        return "numSegments must be of dtype int";
      });
      var inputs = { x: $x, segmentIds: $segmentIds };
      var attrs = { numSegments };
      return ENGINE.runKernel(UnsortedSegmentSum, inputs, attrs);
    }
    var unsortedSegmentSum = /* @__PURE__ */ op({ unsortedSegmentSum_ });
    function unstack_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "unstack", "string_or_numeric");
      assert(axis >= -$x.shape.length && axis < $x.shape.length, function() {
        return "Axis = ".concat(axis, " is not in [-").concat($x.shape.length, ", ").concat($x.shape.length, ")");
      });
      var inputs = { value: $x };
      var attrs = { axis };
      return ENGINE.runKernel(Unpack, inputs, attrs);
    }
    var unstack = /* @__PURE__ */ op({ unstack_ });
    function upperBound(sortedSequence, values) {
      return searchSorted(sortedSequence, values, "right");
    }
    function variable(initialValue, trainable, name, dtype) {
      if (trainable === void 0) {
        trainable = true;
      }
      return ENGINE.makeVariable(initialValue, trainable, name, dtype);
    }
    function whereImpl(condShape, condVals) {
      var indices = [];
      for (var i = 0; i < condVals.length; i++) {
        if (condVals[i]) {
          indices.push(i);
        }
      }
      var inBuffer = buffer(condShape, "int32");
      var out = buffer([indices.length, condShape.length], "int32");
      for (var i = 0; i < indices.length; i++) {
        var loc = inBuffer.indexToLoc(indices[i]);
        var offset = i * condShape.length;
        out.values.set(loc, offset);
      }
      return out.toTensor();
    }
    function whereAsync_(condition) {
      return __awaiter(this, void 0, void 0, function() {
        var $condition, vals, res;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $condition = convertToTensor(condition, "condition", "whereAsync", "bool");
              return [4, $condition.data()];
            case 1:
              vals = _a.sent();
              res = whereImpl($condition.shape, vals);
              if (condition !== $condition) {
                $condition.dispose();
              }
              return [2, res];
          }
        });
      });
    }
    var whereAsync = whereAsync_;
    function booleanMaskAsync_(tensor2, mask, axis) {
      return __awaiter(this, void 0, void 0, function() {
        var $tensor, $mask, axisFrom, maskDim, tensorShape, leadingSize, i, targetTensorShape, reshapedTensor, reshapedMask, positivePositions, indices, res;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $tensor = convertToTensor(tensor2, "tensor", "boolMask");
              $mask = convertToTensor(mask, "mask", "boolMask", "bool");
              axisFrom = axis == null ? 0 : axis;
              maskDim = $mask.rank;
              tensorShape = $tensor.shape;
              assert(maskDim > 0, function() {
                return "mask cannot be scalar";
              });
              assertShapesMatch(tensorShape.slice(axisFrom, axisFrom + maskDim), $mask.shape, "mask's shape must match the first K dimensions of tensor's shape,");
              leadingSize = 1;
              for (i = axisFrom; i < axisFrom + maskDim; i++) {
                leadingSize *= tensorShape[i];
              }
              targetTensorShape = tensorShape.slice(0, axisFrom).concat([leadingSize], tensorShape.slice(axisFrom + maskDim));
              reshapedTensor = reshape($tensor, targetTensorShape);
              reshapedMask = reshape($mask, [-1]);
              return [4, whereAsync(reshapedMask)];
            case 1:
              positivePositions = _a.sent();
              indices = squeeze(positivePositions, [1]);
              res = gather(reshapedTensor, indices, axisFrom);
              if (tensor2 !== $tensor) {
                $tensor.dispose();
              }
              if (mask !== $mask) {
                $mask.dispose();
              }
              indices.dispose();
              reshapedTensor.dispose();
              reshapedMask.dispose();
              positivePositions.dispose();
              return [2, res];
          }
        });
      });
    }
    var booleanMaskAsync = booleanMaskAsync_;
    function transpose_(x, perm, conjugate) {
      var $x = convertToTensor(x, "x", "transpose");
      if (perm == null) {
        perm = $x.shape.map(function(s, i) {
          return i;
        }).reverse();
      }
      assert($x.rank === perm.length, function() {
        return "Error in transpose: rank of input ".concat($x.rank, " ") + "must match length of perm ".concat(perm, ".");
      });
      perm.forEach(function(axis) {
        assert(axis >= 0 && axis < $x.rank, function() {
          return "All entries in 'perm' must be between 0 and ".concat($x.rank - 1) + " but got ".concat(perm);
        });
      });
      if ($x.rank <= 1) {
        return $x.clone();
      }
      var inputs = { x: $x };
      var attrs = { perm };
      if ($x.dtype === "complex64") {
        return tidy(function() {
          var $real = real($x);
          var $imag = imag($x);
          $real = ENGINE.runKernel(Transpose, { x: $real }, attrs);
          $imag = ENGINE.runKernel(Transpose, { x: $imag }, attrs);
          if (conjugate) {
            $imag = neg($imag);
          }
          return complex($real, $imag);
        });
      }
      return ENGINE.runKernel(Transpose, inputs, attrs);
    }
    var transpose = /* @__PURE__ */ op({ transpose_ });
    function movingAverage_(v, x, decay, step2, zeroDebias) {
      if (zeroDebias === void 0) {
        zeroDebias = true;
      }
      var $v = convertToTensor(v, "v", "movingAverage");
      var $x = convertToTensor(x, "x", "movingAverage");
      var $decay = convertToTensor(decay, "decay", "movingAverage");
      assertTypesMatch($v, $x);
      assert(arraysEqual($v.shape, $x.shape), function() {
        return "Shape mismatch in v and x";
      });
      var one = scalar(1);
      var oneMinusDecay = sub(one, $decay);
      var update = mul(sub($x, $v), oneMinusDecay);
      if (zeroDebias) {
        assert(step2 != null, function() {
          return "When using zeroDebias: true, step is required.";
        });
        var $step = convertToTensor(step2, "step", "movingAverage");
        update = div(update, sub(one, pow($decay, $step)));
      }
      return add($v, update);
    }
    var movingAverage = /* @__PURE__ */ op({ movingAverage_ });
    function scatterND_(indices, updates, shape) {
      assertNonNegativeIntegerDimensions(shape);
      var $indices = convertToTensor(indices, "indices", "scatterND", "int32");
      var $updates = convertToTensor(updates, "updates", "scatterND");
      validateInput$1($updates, $indices, shape);
      var inputs = { indices: $indices, updates: $updates };
      var attrs = { shape };
      return ENGINE.runKernel(ScatterNd, inputs, attrs);
    }
    var scatterND = /* @__PURE__ */ op({ scatterND_ });
    function validateInput(sparseIndices, sparseValues, outputShape, defaultValues) {
      if (sparseIndices.dtype !== "int32") {
        throw new Error("tf.sparseToDense() expects the indices to be int32 type," + " but the dtype was ".concat(sparseIndices.dtype, "."));
      }
      if (sparseIndices.rank > 2) {
        throw new Error("sparseIndices should be a scalar, vector, or matrix," + " but got shape ".concat(sparseIndices.shape, "."));
      }
      var numElems = sparseIndices.rank > 0 ? sparseIndices.shape[0] : 1;
      var numDims = sparseIndices.rank > 1 ? sparseIndices.shape[1] : 1;
      if (outputShape.length !== numDims) {
        throw new Error("outputShape has incorrect number of elements:," + " ".concat(outputShape.length, ", should be: ").concat(numDims, "."));
      }
      var numValues = sparseValues.size;
      if (!(sparseValues.rank === 0 || sparseValues.rank === 1 && numValues === numElems)) {
        throw new Error("sparseValues has incorrect shape " + "".concat(sparseValues.shape, ", should be [] or [").concat(numElems, "]"));
      }
      if (sparseValues.dtype !== defaultValues.dtype) {
        throw new Error("sparseValues.dtype must match defaultValues.dtype");
      }
    }
    function sparseToDense_(sparseIndices, sparseValues, outputShape, defaultValue) {
      if (defaultValue === void 0) {
        defaultValue = 0;
      }
      assertNonNegativeIntegerDimensions(outputShape);
      var $sparseIndices = convertToTensor(sparseIndices, "sparseIndices", "sparseToDense", "int32");
      var $sparseValues = convertToTensor(sparseValues, "sparseValues", "sparseToDense", "string_or_numeric");
      var $defaultValue = convertToTensor(defaultValue, "defaultValue", "sparseToDense", $sparseValues.dtype);
      validateInput($sparseIndices, $sparseValues, outputShape, $defaultValue);
      var inputs = {
        sparseIndices: $sparseIndices,
        sparseValues: $sparseValues,
        defaultValue: $defaultValue
      };
      var attrs = { outputShape };
      return ENGINE.runKernel(SparseToDense, inputs, attrs);
    }
    var sparseToDense = /* @__PURE__ */ op({ sparseToDense_ });
    function gatherND_(x, indices) {
      var $indices = convertToTensor(indices, "indices", "gatherND", "int32");
      var $x = convertToTensor(x, "x", "gatherND", "string_or_numeric");
      var inputs = { params: $x, indices: $indices };
      return ENGINE.runKernel(GatherNd, inputs);
    }
    var gatherND = /* @__PURE__ */ op({ gatherND_ });
    function getNoiseShape(x, noiseShape) {
      if (noiseShape == null) {
        return x.shape.slice();
      }
      if (arraysEqual(x.shape, noiseShape)) {
        return noiseShape;
      }
      if (x.shape.length === noiseShape.length) {
        var newDimension = [];
        for (var i = 0; i < x.shape.length; i++) {
          if (noiseShape[i] == null && x.shape[i] != null) {
            newDimension.push(x.shape[i]);
          } else {
            newDimension.push(noiseShape[i]);
          }
        }
        return newDimension;
      }
      return noiseShape;
    }
    function dropout_(x, rate, noiseShape, seed) {
      var $x = convertToTensor(x, "x", "dropout");
      assert($x.dtype === "float32", function() {
        return "x has to be a floating point tensor since it's going to be " + "scaled, but got a ".concat($x.dtype, " tensor instead.");
      });
      assert(rate >= 0 && rate < 1, function() {
        return "rate must be a float in the range [0, 1), but got ".concat(rate, ".");
      });
      if (rate === 0) {
        return x instanceof Tensor ? $x.clone() : $x;
      }
      var $noiseShape = getNoiseShape($x, noiseShape);
      var keepProb = 1 - rate;
      var multiplier = div(floor(add(randomUniform($noiseShape, 0, 1, "float32", seed), keepProb)), keepProb);
      return mul($x, multiplier);
    }
    var dropout = /* @__PURE__ */ op({ dropout_ });
    function enclosingPowerOfTwo(value) {
      return Math.floor(Math.pow(2, Math.ceil(Math.log(value) / Math.log(2))));
    }
    function cosineWindow(windowLength, a, b) {
      var even = 1 - windowLength % 2;
      var newValues = new Float32Array(windowLength);
      for (var i = 0; i < windowLength; ++i) {
        var cosArg = 2 * Math.PI * i / (windowLength + even - 1);
        newValues[i] = a - b * Math.cos(cosArg);
      }
      return tensor1d(newValues, "float32");
    }
    function inTopKAsync_(predictions, targets, k) {
      if (k === void 0) {
        k = 1;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $predictions, $targets, lastDim, predictionsVals, targetsVals, _a, batch, size, precision, b, offset, vals, valAndInd, i, i;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              $predictions = convertToTensor(predictions, "predictions", "inTopK");
              $targets = convertToTensor(targets, "targets", "inTopK");
              assert($predictions.rank > 1, function() {
                return "inTopK() expects the predictions to be of rank 2 or higher, " + "but got ".concat($predictions.rank);
              });
              assert($predictions.rank - 1 === $targets.rank, function() {
                return "predictions rank should be 1 larger than targets rank, but got predictions rank " + "".concat($predictions.rank, " and targets rank ").concat($targets.rank);
              });
              assertShapesMatch($predictions.shape.slice(0, $predictions.shape.length - 1), $targets.shape, "predictions's shape should be align with the targets' shape, except the last dimension.");
              lastDim = $predictions.shape[$predictions.shape.length - 1];
              assert(k > 0 && k <= lastDim, function() {
                return "'k' passed to inTopK() must be > 0 && <= the predictions last " + "dimension (".concat(lastDim, "), but got ").concat(k);
              });
              return [4, $predictions.data()];
            case 1:
              predictionsVals = _b.sent();
              return [4, $targets.data()];
            case 2:
              targetsVals = _b.sent();
              _a = __read([predictionsVals.length / lastDim, lastDim], 2), batch = _a[0], size = _a[1];
              precision = getTypedArrayFromDType("bool", batch);
              for (b = 0; b < batch; b++) {
                offset = b * size;
                vals = predictionsVals.subarray(offset, offset + size);
                valAndInd = [];
                for (i = 0; i < vals.length; i++) {
                  valAndInd.push({ value: vals[i], index: i });
                }
                valAndInd.sort(function(a, b2) {
                  return b2.value - a.value;
                });
                precision[b] = 0;
                for (i = 0; i < k; i++) {
                  if (valAndInd[i].index === targetsVals[b]) {
                    precision[b] = 1;
                    break;
                  }
                }
              }
              if (predictions !== $predictions) {
                $predictions.dispose();
              }
              if (targets !== $targets) {
                $targets.dispose();
              }
              return [2, tensor(precision, $targets.shape, "bool")];
          }
        });
      });
    }
    var inTopKAsync = inTopKAsync_;
    function conv2DBackpropFilter_(x, dy, filterShape, strides, pad2, dataFormat, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var x4D = x;
      if (x.rank === 3) {
        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
      }
      var dy4D = dy;
      if (dy4D.rank === 3) {
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in conv2dDerFilter: input must be rank 4, but got shape " + "".concat(x4D.shape, ".");
      });
      assert(dy4D.rank === 4, function() {
        return "Error in conv2dDerFilter: dy must be rank 4, but got shape " + "".concat(dy4D.shape, ".");
      });
      assert(filterShape.length === 4, function() {
        return "Error in conv2dDerFilter: filterShape must be length 4, but got " + "".concat(filterShape, ".");
      });
      var inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      var outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
      assert(inDepth === filterShape[2], function() {
        return "Error in conv2dDerFilter: depth of input ".concat(inDepth, ") must ") + "match input depth in filter (".concat(filterShape[2], ".");
      });
      assert(outDepth === filterShape[3], function() {
        return "Error in conv2dDerFilter: depth of dy (".concat(outDepth, ") must ") + "match output depth for filter (".concat(filterShape[3], ").");
      });
      checkPadOnDimRoundingMode("conv2dDerFilter", pad2, dimRoundingMode);
      var inputs = { x: x4D, dy: dy4D };
      var attrs = { strides, pad: pad2, dataFormat, dimRoundingMode, filterShape };
      return ENGINE.runKernel(Conv2DBackpropFilter, inputs, attrs);
    }
    var conv2DBackpropFilter = /* @__PURE__ */ op({ conv2DBackpropFilter_ });
    function getFusedDyActivation(dy, y, activation) {
      if (activation == null || activation === "linear") {
        return dy;
      }
      if (activation === "relu") {
        return mul(dy, step(y));
      }
      throw new Error("Cannot compute gradient for fused activation ".concat(activation, "."));
    }
    function getFusedBiasGradient(bias, dyActivation) {
      var res = dyActivation;
      var reduceAxes = getReductionAxes(bias.shape, dyActivation.shape);
      if (reduceAxes.length > 0) {
        res = sum(res, reduceAxes);
      }
      return reshape(res, bias.shape);
    }
    function applyActivation(x, activation, preluActivationWeights, leakyreluAlpha) {
      if (activation === "linear") {
        return x;
      } else if (activation === "relu") {
        return relu(x);
      } else if (activation === "elu") {
        return elu(x);
      } else if (activation === "relu6") {
        return relu6(x);
      } else if (activation === "prelu") {
        return prelu(x, preluActivationWeights);
      } else if (activation === "leakyrelu") {
        return leakyRelu(x, leakyreluAlpha);
      } else if (activation === "sigmoid") {
        return sigmoid(x);
      }
      throw new Error("Unknown fused activation ".concat(activation, "."));
    }
    var shouldFuse = function(gradientDepth, activation) {
      var gradientMode = gradientDepth > 0;
      return !gradientMode || activation === "linear";
    };
    function fusedConv2d_(_a) {
      var _b;
      var x = _a.x, filter = _a.filter, strides = _a.strides, pad2 = _a.pad, _c = _a.dataFormat, dataFormat = _c === void 0 ? "NHWC" : _c, _d = _a.dilations, dilations = _d === void 0 ? [1, 1] : _d, dimRoundingMode = _a.dimRoundingMode, bias = _a.bias, _e = _a.activation, activation = _e === void 0 ? "linear" : _e, preluActivationWeights = _a.preluActivationWeights, leakyreluAlpha = _a.leakyreluAlpha;
      activation = activation || "linear";
      if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
        assert(dataFormat === "NHWC", function() {
          return "Error in fused conv2d: got dataFormat of ".concat(dataFormat, " but ") + "only NHWC is currently supported for the case of gradient depth is 0 and the activation is not linear.";
        });
        var result = conv2d$1(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
        if (bias != null) {
          result = add(result, bias);
        }
        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
      }
      var $x = convertToTensor(x, "x", "conv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "conv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in fused conv2d: input must be rank 4, but got rank " + "".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in fused conv2d: filter must be rank 4, but got rank " + "".concat($filter.rank, ".");
      });
      checkPadOnDimRoundingMode("fused conv2d", pad2, dimRoundingMode);
      var inputChannels = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      assert($filter.shape[2] === inputChannels, function() {
        return "Error in conv2d: depth of input (".concat(inputChannels, ") must match ") + "input depth for filter ".concat($filter.shape[2], ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in conv2D: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var convInfo = computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad2, dimRoundingMode);
      var $bias;
      if (bias != null) {
        $bias = convertToTensor(bias, "bias", "fused conv2d");
        _b = __read(makeTypesMatch($bias, $x), 1), $bias = _b[0];
        if (dataFormat === "NHWC") {
          assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
        } else {
          assert($bias.shape.length <= 1, function() {
            return "Error in fused conv2d: only supports scalar or 1-D Tensor bias for NCHW format but got the bias of " + "rank-".concat($bias.shape.length, ".");
          });
          assert($bias.shape.length === 0 || $bias.shape[0] === convInfo.outChannels || $bias.shape[0] === 1, function() {
            return "Error in fused conv2d: bias shape (".concat($bias.shape, ") is not ") + "compatible with the number of output channels " + "(".concat(convInfo.outChannels, ")");
          });
        }
      }
      var $preluActivationWeights;
      if (preluActivationWeights != null) {
        var alphaShape_1 = preluActivationWeights.shape;
        assert(alphaShape_1.length <= 1 || alphaShape_1.length === 3, function() {
          return "Error in fused conv2d: only supports scalar, 1-D Tensor or 3-D Tensor PReLU activation weights but got a tensor of " + "rank-".concat(alphaShape_1.length, ".");
        });
        if (alphaShape_1.length === 1) {
          assert(alphaShape_1[0] === 1 || alphaShape_1[0] === convInfo.outChannels, function() {
            return "Error in fused conv2d: PReLU activation weights " + "(".concat(alphaShape_1, ") is not compatible with the number of output ") + "channels (".concat(convInfo.outChannels, ").");
          });
        } else if (alphaShape_1.length === 3) {
          try {
            assertAndGetBroadcastShape(alphaShape_1, convInfo.outShape);
          } catch (e) {
            var errMsg = "Error in fused conv2d: PReLU activation weights (".concat(alphaShape_1, ") ") + "is not compatible with the output shape of the conv2d " + "(".concat(convInfo.outShape, ").");
            throw Error(errMsg);
          }
        }
        $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused conv2d");
      }
      var grad2 = function(dy, saved) {
        assert(dataFormat === "NHWC", function() {
          return "Error in gradient of fused conv2D: got dataFormat of ".concat(dataFormat, " but only NHWC is currently supported.");
        });
        var _a2 = __read(saved, 4), $filter2 = _a2[0], x4D2 = _a2[1], y = _a2[2], $bias2 = _a2[3];
        var dyActivation = getFusedDyActivation(dy, y, activation);
        assert(tupleValuesAreOne(dilations), function() {
          return "Error in gradient of fused conv2D: dilation rates greater than 1 " + "are not yet supported in gradients. Got dilations '".concat(dilations, "'");
        });
        var xDer = conv2DBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2);
        var filterDer = conv2DBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2);
        var der = [xDer, filterDer];
        if ($bias2 != null) {
          var biasDer = getFusedBiasGradient($bias2, dyActivation);
          der.push(biasDer);
        }
        return der;
      };
      var inputs = {
        x: x4D,
        filter: $filter,
        bias: $bias,
        preluActivationWeights: $preluActivationWeights
      };
      var attrs = {
        strides,
        pad: pad2,
        dataFormat,
        dilations,
        dimRoundingMode,
        activation,
        leakyreluAlpha
      };
      if (bias == null) {
        var customOp = customGrad(function(x4D2, filter2, save) {
          var res = (
            // tslint:disable-next-line: no-unnecessary-type-assertion
            ENGINE.runKernel(FusedConv2D, inputs, attrs)
          );
          save([filter2, x4D2, res]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad2 };
        });
        return customOp(x4D, $filter);
      } else {
        var customOpWithBias = customGrad(function(x4D2, filter2, bias2, save) {
          var res = ENGINE.runKernel(FusedConv2D, inputs, attrs);
          save([filter2, x4D2, res, bias2]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad2 };
        });
        return customOpWithBias(x4D, $filter, $bias);
      }
    }
    var conv2d = /* @__PURE__ */ op({ fusedConv2d_ });
    function depthwiseConv2dNativeBackpropFilter_(x, dy, filterShape, strides, pad2, dilations, dimRoundingMode) {
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var x4D = x;
      if (x.rank === 3) {
        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
      }
      var dy4D = dy;
      if (dy4D.rank === 3) {
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
      }
      var inputs = { x: x4D, dy: dy4D };
      var attrs = { strides, pad: pad2, dimRoundingMode, dilations, filterShape };
      return ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter, inputs, attrs);
    }
    var depthwiseConv2dNativeBackpropFilter = op({ depthwiseConv2dNativeBackpropFilter_ });
    function depthwiseConv2dNativeBackpropInput_(xShape, dy, filter, strides, pad2, dilations, dimRoundingMode) {
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var dy4D = dy;
      var reshapedTo4D = false;
      if (dy.rank === 3) {
        reshapedTo4D = true;
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
      }
      var inputs = { dy: dy4D, filter };
      var attrs = { strides, pad: pad2, dimRoundingMode, dilations, inputShape: xShape };
      var res = (
        // tslint:disable-next-line: no-unnecessary-type-assertion
        ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput, inputs, attrs)
      );
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var depthwiseConv2dNativeBackpropInput = op({ depthwiseConv2dNativeBackpropInput_ });
    function fusedDepthwiseConv2d_(_a) {
      var _b;
      var x = _a.x, filter = _a.filter, strides = _a.strides, pad2 = _a.pad, _c = _a.dataFormat, dataFormat = _c === void 0 ? "NHWC" : _c, _d = _a.dilations, dilations = _d === void 0 ? [1, 1] : _d, dimRoundingMode = _a.dimRoundingMode, bias = _a.bias, _e = _a.activation, activation = _e === void 0 ? "linear" : _e, preluActivationWeights = _a.preluActivationWeights, leakyreluAlpha = _a.leakyreluAlpha;
      if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
        var result = depthwiseConv2d$1(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
        if (bias != null) {
          result = add(result, bias);
        }
        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
      }
      var $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in fused depthwiseConv2d: input must be rank 4, but got " + "rank ".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in fused depthwiseConv2d: filter must be rank 4, " + "but got rank ".concat($filter.rank, ".");
      });
      assert(x4D.shape[3] === $filter.shape[2], function() {
        return "Error in fused depthwiseConv2d: number of input channels " + "(".concat(x4D.shape[3], ") must match the inChannels dimension in ") + "filter ".concat($filter.shape[2], ".");
      });
      if (dilations == null) {
        dilations = [1, 1];
      }
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in fused depthwiseConv2d: Either strides or dilations must " + "be 1. Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      checkPadOnDimRoundingMode("fused depthwiseConv2d", pad2, dimRoundingMode);
      var convInfo = computeConv2DInfo(
        x4D.shape,
        $filter.shape,
        strides,
        dilations,
        pad2,
        dimRoundingMode,
        true
        /* depthwise */
      );
      var $bias;
      if (bias != null) {
        $bias = convertToTensor(bias, "bias", "fused conv2d");
        _b = __read(makeTypesMatch($bias, $x), 1), $bias = _b[0];
        assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
      }
      var $preluActivationWeights;
      if (preluActivationWeights != null) {
        $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused depthwiseConv2d");
      }
      var grad2 = function(dy, saved) {
        assert(tupleValuesAreOne(dilations), function() {
          return "Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations " + "'".concat(dilations, "'");
        });
        var _a2 = __read(saved, 4), $filter2 = _a2[0], x4D2 = _a2[1], y = _a2[2], bias2 = _a2[3];
        var dyActivation = getFusedDyActivation(dy, y, activation);
        var xDer = depthwiseConv2dNativeBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2, dilations, dimRoundingMode);
        var filterDer = depthwiseConv2dNativeBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2, dilations, dimRoundingMode);
        if (bias2 != null) {
          var biasDer = getFusedBiasGradient($bias, dyActivation);
          return [xDer, filterDer, biasDer];
        }
        return [xDer, filterDer];
      };
      var inputs = {
        x: x4D,
        filter: $filter,
        bias: $bias,
        preluActivationWeights: $preluActivationWeights
      };
      var attrs = {
        strides,
        pad: pad2,
        dataFormat,
        dilations,
        dimRoundingMode,
        activation,
        leakyreluAlpha
      };
      if (bias == null) {
        var customOp = customGrad(function(x4D2, filter2, save) {
          var res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
          save([filter2, x4D2, res]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad2 };
        });
        return customOp(x4D, $filter);
      } else {
        var customOpWithBias = customGrad(function(x4D2, filter2, bias2, save) {
          var res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
          save([filter2, x4D2, res, bias2]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad2 };
        });
        return customOpWithBias(x4D, $filter, $bias);
      }
    }
    var depthwiseConv2d = /* @__PURE__ */ op({ fusedDepthwiseConv2d_ });
    function fusedMatMul_(_a) {
      var _b, _c;
      var a = _a.a, b = _a.b, _d = _a.transposeA, transposeA = _d === void 0 ? false : _d, _e = _a.transposeB, transposeB = _e === void 0 ? false : _e, bias = _a.bias, _f = _a.activation, activation = _f === void 0 ? "linear" : _f, preluActivationWeights = _a.preluActivationWeights, _g = _a.leakyreluAlpha, leakyreluAlpha = _g === void 0 ? 0.2 : _g;
      if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
        var result = matMul$1(a, b, transposeA, transposeB);
        if (bias != null) {
          result = add(result, bias);
        }
        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
      }
      var $a = convertToTensor(a, "a", "fused matMul");
      var $b = convertToTensor(b, "b", "fused matMul");
      _b = __read(makeTypesMatch($a, $b), 2), $a = _b[0], $b = _b[1];
      var innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];
      var innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];
      var outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];
      var outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];
      var outerDimsA = $a.shape.slice(0, -2);
      var outerDimsB = $b.shape.slice(0, -2);
      var batchDimA = sizeFromShape(outerDimsA);
      var batchDimB = sizeFromShape(outerDimsB);
      assert(innerShapeA === innerShapeB, function() {
        return "Error in fused matMul: inner shapes (".concat(innerShapeA, ") and (") + "".concat(innerShapeB, ") of Tensors with shapes ").concat($a.shape, " and ") + "".concat($b.shape, " and transposeA=").concat(transposeA) + " and transposeB=".concat(transposeB, " must match.");
      });
      var outShapeOuterDims = assertAndGetBroadcastShape($a.shape.slice(0, -2), $b.shape.slice(0, -2));
      var outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
      var a3D = transposeA ? reshape($a, [batchDimA, innerShapeA, outerShapeA]) : reshape($a, [batchDimA, outerShapeA, innerShapeA]);
      var b3D = transposeB ? reshape($b, [batchDimB, outerShapeB, innerShapeB]) : reshape($b, [batchDimB, innerShapeB, outerShapeB]);
      var $bias;
      if (bias != null) {
        $bias = convertToTensor(bias, "bias", "fused matMul");
        _c = __read(makeTypesMatch($bias, $a), 1), $bias = _c[0];
        assertAndGetBroadcastShape(outShape, $bias.shape);
      }
      var $preluActivationWeights;
      if (preluActivationWeights != null) {
        $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused matMul");
      }
      var grad2 = function(dy, saved) {
        var _a2 = __read(saved, 4), a3D2 = _a2[0], b3D2 = _a2[1], y = _a2[2], $bias2 = _a2[3];
        var dyActivation = getFusedDyActivation(reshape(dy, y.shape), y, activation);
        var aDer;
        var bDer;
        if (!transposeA && !transposeB) {
          aDer = matMul$1(dyActivation, b3D2, false, true);
          bDer = matMul$1(a3D2, dyActivation, true, false);
        } else if (!transposeA && transposeB) {
          aDer = matMul$1(dyActivation, b3D2, false, false);
          bDer = matMul$1(dyActivation, a3D2, true, false);
        } else if (transposeA && !transposeB) {
          aDer = matMul$1(b3D2, dyActivation, false, true);
          bDer = matMul$1(a3D2, dyActivation, false, false);
        } else {
          aDer = matMul$1(b3D2, dyActivation, true, true);
          bDer = matMul$1(dyActivation, a3D2, true, true);
        }
        if (bias != null) {
          var biasDer = getFusedBiasGradient($bias2, dyActivation);
          return [aDer, bDer, biasDer];
        } else {
          return [aDer, bDer];
        }
      };
      var inputs = {
        a: a3D,
        b: b3D,
        bias: $bias,
        preluActivationWeights: $preluActivationWeights
      };
      var attrs = { transposeA, transposeB, activation, leakyreluAlpha };
      if (bias == null) {
        var customOp = customGrad(function(a3D2, b3D2, save) {
          var res = (
            // tslint:disable-next-line: no-unnecessary-type-assertion
            ENGINE.runKernel(_FusedMatMul, inputs, attrs)
          );
          save([a3D2, b3D2, res]);
          return { value: reshape(res, outShape), gradFunc: grad2 };
        });
        return customOp(a3D, b3D);
      } else {
        var customOpWithBias = customGrad(function(a3D2, b3D2, $bias2, save) {
          var res = (
            // tslint:disable-next-line: no-unnecessary-type-assertion
            ENGINE.runKernel(_FusedMatMul, inputs, attrs)
          );
          save([a3D2, b3D2, res, $bias2]);
          return { value: reshape(res, outShape), gradFunc: grad2 };
        });
        return customOpWithBias(a3D, b3D, $bias);
      }
    }
    var matMul = /* @__PURE__ */ op({ fusedMatMul_ });
    var fused_ops = {
      __proto__: null,
      conv2d,
      depthwiseConv2d,
      matMul
    };
    function hammingWindow_(windowLength) {
      return cosineWindow(windowLength, 0.54, 0.46);
    }
    var hammingWindow = /* @__PURE__ */ op({ hammingWindow_ });
    function hannWindow_(windowLength) {
      return cosineWindow(windowLength, 0.5, 0.5);
    }
    var hannWindow = /* @__PURE__ */ op({ hannWindow_ });
    function frame_(signal2, frameLength, frameStep, padEnd, padValue) {
      if (padEnd === void 0) {
        padEnd = false;
      }
      if (padValue === void 0) {
        padValue = 0;
      }
      var start = 0;
      var output = [];
      while (start + frameLength <= signal2.size) {
        output.push(slice(signal2, start, frameLength));
        start += frameStep;
      }
      if (padEnd) {
        while (start < signal2.size) {
          var padLen = start + frameLength - signal2.size;
          var pad2 = concat([
            slice(signal2, start, frameLength - padLen),
            fill([padLen], padValue)
          ]);
          output.push(pad2);
          start += frameStep;
        }
      }
      if (output.length === 0) {
        return tensor2d([], [0, frameLength]);
      }
      return reshape(concat(output), [output.length, frameLength]);
    }
    var frame = /* @__PURE__ */ op({ frame_ });
    function stft_(signal2, frameLength, frameStep, fftLength, windowFn) {
      if (windowFn === void 0) {
        windowFn = hannWindow;
      }
      if (fftLength == null) {
        fftLength = enclosingPowerOfTwo(frameLength);
      }
      var framedSignal = frame(signal2, frameLength, frameStep);
      var windowedSignal = mul(framedSignal, windowFn(frameLength));
      return rfft(windowedSignal, fftLength);
    }
    var stft = /* @__PURE__ */ op({ stft_ });
    function cropAndResize_(image2, boxes, boxInd, cropSize, method, extrapolationValue) {
      if (method === void 0) {
        method = "bilinear";
      }
      if (extrapolationValue === void 0) {
        extrapolationValue = 0;
      }
      var $image = convertToTensor(image2, "image", "cropAndResize");
      var $boxes = convertToTensor(boxes, "boxes", "cropAndResize", "float32");
      var $boxInd = convertToTensor(boxInd, "boxInd", "cropAndResize", "int32");
      var numBoxes = $boxes.shape[0];
      assert($image.rank === 4, function() {
        return "Error in cropAndResize: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      assert($boxes.rank === 2 && $boxes.shape[1] === 4, function() {
        return "Error in cropAndResize: boxes must be have size [".concat(numBoxes, ",4] ") + "but had shape ".concat($boxes.shape, ".");
      });
      assert($boxInd.rank === 1 && $boxInd.shape[0] === numBoxes, function() {
        return "Error in cropAndResize: boxInd must be have size [".concat(numBoxes, "] ") + "but had shape ".concat($boxes.shape, ".");
      });
      assert(cropSize.length === 2, function() {
        return "Error in cropAndResize: cropSize must be of length 2, but got " + "length ".concat(cropSize.length, ".");
      });
      assert(cropSize[0] >= 1 && cropSize[1] >= 1, function() {
        return "cropSize must be atleast [1,1], but was ".concat(cropSize);
      });
      assert(method === "bilinear" || method === "nearest", function() {
        return "method must be bilinear or nearest, but was ".concat(method);
      });
      var inputs = { image: $image, boxes: $boxes, boxInd: $boxInd };
      var attrs = { method, extrapolationValue, cropSize };
      var res = ENGINE.runKernel(CropAndResize, inputs, attrs);
      return res;
    }
    var cropAndResize = /* @__PURE__ */ op({ cropAndResize_ });
    function flipLeftRight_(image2) {
      var $image = convertToTensor(image2, "image", "flipLeftRight", "float32");
      assert($image.rank === 4, function() {
        return "Error in flipLeftRight: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      var inputs = { image: $image };
      var res = ENGINE.runKernel(FlipLeftRight, inputs, {});
      return res;
    }
    var flipLeftRight = /* @__PURE__ */ op({ flipLeftRight_ });
    function grayscaleToRGB_(image2) {
      var $image = convertToTensor(image2, "image", "grayscaleToRGB");
      var lastDimsIdx = $image.rank - 1;
      var lastDims = $image.shape[lastDimsIdx];
      assert($image.rank >= 2, function() {
        return "Error in grayscaleToRGB: images must be at least rank 2, " + "but got rank ".concat($image.rank, ".");
      });
      assert(lastDims === 1, function() {
        return "Error in grayscaleToRGB: last dimension of a grayscale image " + "should be size 1, but got size ".concat(lastDims, ".");
      });
      var reps = new Array($image.rank);
      reps.fill(1, 0, lastDimsIdx);
      reps[lastDimsIdx] = 3;
      return tile($image, reps);
    }
    var grayscaleToRGB = /* @__PURE__ */ op({ grayscaleToRGB_ });
    function rgbToGrayscale_(image2) {
      var $image = convertToTensor(image2, "image", "RGBToGrayscale");
      var lastDimsIdx = $image.rank - 1;
      var lastDims = $image.shape[lastDimsIdx];
      assert($image.rank >= 2, function() {
        return "Error in RGBToGrayscale: images must be at least rank 2, " + "but got rank ".concat($image.rank, ".");
      });
      assert(lastDims === 3, function() {
        return "Error in RGBToGrayscale: last dimension of an RGB image " + "should be size 3, but got size ".concat(lastDims, ".");
      });
      var origDtype = $image.dtype;
      var fltImage = cast($image, "float32");
      var rgbWeights = tensor1d([0.2989, 0.587, 0.114]);
      var grayFloat;
      switch ($image.rank) {
        case 2:
          grayFloat = einsum("ij,j->i", fltImage, rgbWeights);
          break;
        case 3:
          grayFloat = einsum("ijk,k->ij", fltImage, rgbWeights);
          break;
        case 4:
          grayFloat = einsum("ijkl,l->ijk", fltImage, rgbWeights);
          break;
        case 5:
          grayFloat = einsum("ijklm,m->ijkl", fltImage, rgbWeights);
          break;
        case 6:
          grayFloat = einsum("ijklmn,n->ijklm", fltImage, rgbWeights);
          break;
        default:
          throw new Error("Not a valid tensor rank.");
      }
      grayFloat = expandDims(grayFloat, -1);
      return cast(grayFloat, origDtype);
    }
    var rgbToGrayscale = /* @__PURE__ */ op({ rgbToGrayscale_ });
    function rotateWithOffset_(image2, radians, fillValue, center) {
      if (fillValue === void 0) {
        fillValue = 0;
      }
      if (center === void 0) {
        center = 0.5;
      }
      var $image = convertToTensor(image2, "image", "rotateWithOffset", "float32");
      assert($image.rank === 4, function() {
        return "Error in rotateWithOffset: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      var inputs = { image: $image };
      var attrs = { radians, fillValue, center };
      var res = ENGINE.runKernel(RotateWithOffset, inputs, attrs);
      return res;
    }
    var rotateWithOffset = /* @__PURE__ */ op({ rotateWithOffset_ });
    function nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      if (iouThreshold == null) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold == null) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (softNmsSigma == null) {
        softNmsSigma = 0;
      }
      var numBoxes = boxes.shape[0];
      maxOutputSize = Math.min(maxOutputSize, numBoxes);
      assert(0 <= iouThreshold && iouThreshold <= 1, function() {
        return "iouThreshold must be in [0, 1], but was '".concat(iouThreshold, "'");
      });
      assert(boxes.rank === 2, function() {
        return "boxes must be a 2D tensor, but was of rank '".concat(boxes.rank, "'");
      });
      assert(boxes.shape[1] === 4, function() {
        return "boxes must have 4 columns, but 2nd dimension was ".concat(boxes.shape[1]);
      });
      assert(scores.rank === 1, function() {
        return "scores must be a 1D tensor";
      });
      assert(scores.shape[0] === numBoxes, function() {
        return "scores has incompatible shape with boxes. Expected ".concat(numBoxes, ", ") + "but was ".concat(scores.shape[0]);
      });
      assert(0 <= softNmsSigma && softNmsSigma <= 1, function() {
        return "softNmsSigma must be in [0, 1], but was '".concat(softNmsSigma, "'");
      });
      return { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
    }
    function nonMaxSuppression_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      var $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression", "float32");
      var $scores = convertToTensor(scores, "scores", "nonMaxSuppression", "float32");
      var inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
      maxOutputSize = inputs.maxOutputSize;
      iouThreshold = inputs.iouThreshold;
      scoreThreshold = inputs.scoreThreshold;
      var attrs = { maxOutputSize, iouThreshold, scoreThreshold };
      return ENGINE.runKernel(NonMaxSuppressionV3, { boxes: $boxes, scores: $scores }, attrs);
    }
    var nonMaxSuppression = /* @__PURE__ */ op({ nonMaxSuppression_ });
    function binaryInsert(arr, element, comparator) {
      var index = binarySearch(arr, element, comparator);
      var insertionPoint = index < 0 ? -(index + 1) : index;
      arr.splice(insertionPoint, 0, element);
    }
    function binarySearch(arr, target, comparator) {
      return binarySearch_(arr, target, comparator || defaultComparator);
    }
    function defaultComparator(a, b) {
      return a > b ? 1 : a < b ? -1 : 0;
    }
    function binarySearch_(arr, target, comparator) {
      var left = 0;
      var right = arr.length;
      var middle = 0;
      var found = false;
      while (left < right) {
        middle = left + (right - left >>> 1);
        var compareResult = comparator(target, arr[middle]);
        if (compareResult > 0) {
          left = middle + 1;
        } else {
          right = middle;
          found = !compareResult;
        }
      }
      return found ? left : -left - 1;
    }
    function nonMaxSuppressionV3Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
      return nonMaxSuppressionImpl_(
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        0
        /* softNmsSigma */
      );
    }
    function nonMaxSuppressionV4Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
      return nonMaxSuppressionImpl_(
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        0,
        false,
        padToMaxOutputSize,
        true
        /* returnValidOutputs */
      );
    }
    function nonMaxSuppressionV5Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      return nonMaxSuppressionImpl_(
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        softNmsSigma,
        true
        /* returnScoresTensor */
      );
    }
    function nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor, padToMaxOutputSize, returnValidOutputs) {
      if (returnScoresTensor === void 0) {
        returnScoresTensor = false;
      }
      if (padToMaxOutputSize === void 0) {
        padToMaxOutputSize = false;
      }
      if (returnValidOutputs === void 0) {
        returnValidOutputs = false;
      }
      var candidates = [];
      for (var i = 0; i < scores.length; i++) {
        if (scores[i] > scoreThreshold) {
          candidates.push({ score: scores[i], boxIndex: i, suppressBeginIndex: 0 });
        }
      }
      candidates.sort(ascendingComparator);
      var scale = softNmsSigma > 0 ? -0.5 / softNmsSigma : 0;
      var selectedIndices = [];
      var selectedScores = [];
      while (selectedIndices.length < maxOutputSize && candidates.length > 0) {
        var candidate = candidates.pop();
        var originalScore = candidate.score, boxIndex = candidate.boxIndex, suppressBeginIndex = candidate.suppressBeginIndex;
        if (originalScore < scoreThreshold) {
          break;
        }
        var ignoreCandidate = false;
        for (var j = selectedIndices.length - 1; j >= suppressBeginIndex; --j) {
          var iou = intersectionOverUnion(boxes, boxIndex, selectedIndices[j]);
          if (iou >= iouThreshold) {
            ignoreCandidate = true;
            break;
          }
          candidate.score = candidate.score * suppressWeight(iouThreshold, scale, iou);
          if (candidate.score <= scoreThreshold) {
            break;
          }
        }
        candidate.suppressBeginIndex = selectedIndices.length;
        if (!ignoreCandidate) {
          if (candidate.score === originalScore) {
            selectedIndices.push(boxIndex);
            selectedScores.push(candidate.score);
          } else if (candidate.score > scoreThreshold) {
            binaryInsert(candidates, candidate, ascendingComparator);
          }
        }
      }
      var validOutputs = selectedIndices.length;
      var elemsToPad = maxOutputSize - validOutputs;
      if (padToMaxOutputSize && elemsToPad > 0) {
        selectedIndices.push.apply(selectedIndices, __spreadArray([], __read(new Array(elemsToPad).fill(0)), false));
        selectedScores.push.apply(selectedScores, __spreadArray([], __read(new Array(elemsToPad).fill(0)), false));
      }
      var result = { selectedIndices };
      if (returnScoresTensor) {
        result["selectedScores"] = selectedScores;
      }
      if (returnValidOutputs) {
        result["validOutputs"] = validOutputs;
      }
      return result;
    }
    function intersectionOverUnion(boxes, i, j) {
      var iCoord = boxes.subarray(i * 4, i * 4 + 4);
      var jCoord = boxes.subarray(j * 4, j * 4 + 4);
      var yminI = Math.min(iCoord[0], iCoord[2]);
      var xminI = Math.min(iCoord[1], iCoord[3]);
      var ymaxI = Math.max(iCoord[0], iCoord[2]);
      var xmaxI = Math.max(iCoord[1], iCoord[3]);
      var yminJ = Math.min(jCoord[0], jCoord[2]);
      var xminJ = Math.min(jCoord[1], jCoord[3]);
      var ymaxJ = Math.max(jCoord[0], jCoord[2]);
      var xmaxJ = Math.max(jCoord[1], jCoord[3]);
      var areaI = (ymaxI - yminI) * (xmaxI - xminI);
      var areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);
      if (areaI <= 0 || areaJ <= 0) {
        return 0;
      }
      var intersectionYmin = Math.max(yminI, yminJ);
      var intersectionXmin = Math.max(xminI, xminJ);
      var intersectionYmax = Math.min(ymaxI, ymaxJ);
      var intersectionXmax = Math.min(xmaxI, xmaxJ);
      var intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0) * Math.max(intersectionXmax - intersectionXmin, 0);
      return intersectionArea / (areaI + areaJ - intersectionArea);
    }
    function suppressWeight(iouThreshold, scale, iou) {
      var weight = Math.exp(scale * iou * iou);
      return iou <= iouThreshold ? weight : 0;
    }
    function ascendingComparator(c1, c2) {
      return c1.score - c2.score || c1.score === c2.score && c2.boxIndex - c1.boxIndex;
    }
    function nonMaxSuppressionAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $boxes, $scores, inputs, boxesAndScores, boxesVals, scoresVals, selectedIndices;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
              $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
              inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
              maxOutputSize = inputs.maxOutputSize;
              iouThreshold = inputs.iouThreshold;
              scoreThreshold = inputs.scoreThreshold;
              return [4, Promise.all([$boxes.data(), $scores.data()])];
            case 1:
              boxesAndScores = _a.sent();
              boxesVals = boxesAndScores[0];
              scoresVals = boxesAndScores[1];
              selectedIndices = nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold).selectedIndices;
              if ($boxes !== boxes) {
                $boxes.dispose();
              }
              if ($scores !== scores) {
                $scores.dispose();
              }
              return [2, tensor1d(selectedIndices, "int32")];
          }
        });
      });
    }
    var nonMaxSuppressionAsync = nonMaxSuppressionAsync_;
    function nonMaxSuppressionWithScore_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (softNmsSigma === void 0) {
        softNmsSigma = 0;
      }
      var $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
      var $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
      var params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
      maxOutputSize = params.maxOutputSize;
      iouThreshold = params.iouThreshold;
      scoreThreshold = params.scoreThreshold;
      softNmsSigma = params.softNmsSigma;
      var inputs = { boxes: $boxes, scores: $scores };
      var attrs = { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
      var result = ENGINE.runKernel(NonMaxSuppressionV5, inputs, attrs);
      return { selectedIndices: result[0], selectedScores: result[1] };
    }
    var nonMaxSuppressionWithScore = /* @__PURE__ */ op({ nonMaxSuppressionWithScore_ });
    function nonMaxSuppressionWithScoreAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (softNmsSigma === void 0) {
        softNmsSigma = 0;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $boxes, $scores, params, boxesAndScores, boxesVals, scoresVals, _a, selectedIndices, selectedScores;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
              $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
              params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
              maxOutputSize = params.maxOutputSize;
              iouThreshold = params.iouThreshold;
              scoreThreshold = params.scoreThreshold;
              softNmsSigma = params.softNmsSigma;
              return [4, Promise.all([$boxes.data(), $scores.data()])];
            case 1:
              boxesAndScores = _b.sent();
              boxesVals = boxesAndScores[0];
              scoresVals = boxesAndScores[1];
              _a = nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma), selectedIndices = _a.selectedIndices, selectedScores = _a.selectedScores;
              if ($boxes !== boxes) {
                $boxes.dispose();
              }
              if ($scores !== scores) {
                $scores.dispose();
              }
              return [2, {
                selectedIndices: tensor1d(selectedIndices, "int32"),
                selectedScores: tensor1d(selectedScores)
              }];
          }
        });
      });
    }
    var nonMaxSuppressionWithScoreAsync = nonMaxSuppressionWithScoreAsync_;
    function nonMaxSuppressionPadded_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (padToMaxOutputSize === void 0) {
        padToMaxOutputSize = false;
      }
      var $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
      var $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
      var params = nonMaxSuppSanityCheck(
        $boxes,
        $scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        null
        /* softNmsSigma */
      );
      var $maxOutputSize = params.maxOutputSize;
      var $iouThreshold = params.iouThreshold;
      var $scoreThreshold = params.scoreThreshold;
      var inputs = { boxes: $boxes, scores: $scores };
      var attrs = {
        maxOutputSize: $maxOutputSize,
        iouThreshold: $iouThreshold,
        scoreThreshold: $scoreThreshold,
        padToMaxOutputSize
      };
      var result = ENGINE.runKernel(NonMaxSuppressionV4, inputs, attrs);
      return { selectedIndices: result[0], validOutputs: result[1] };
    }
    var nonMaxSuppressionPadded = /* @__PURE__ */ op({ nonMaxSuppressionPadded_ });
    function nonMaxSuppressionPaddedAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (padToMaxOutputSize === void 0) {
        padToMaxOutputSize = false;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $boxes, $scores, params, $maxOutputSize, $iouThreshold, $scoreThreshold, _a, boxesVals, scoresVals, _b, selectedIndices, validOutputs;
        return __generator(this, function(_c) {
          switch (_c.label) {
            case 0:
              $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
              $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
              params = nonMaxSuppSanityCheck(
                $boxes,
                $scores,
                maxOutputSize,
                iouThreshold,
                scoreThreshold,
                null
                /* softNmsSigma */
              );
              $maxOutputSize = params.maxOutputSize;
              $iouThreshold = params.iouThreshold;
              $scoreThreshold = params.scoreThreshold;
              return [4, Promise.all([$boxes.data(), $scores.data()])];
            case 1:
              _a = __read.apply(void 0, [_c.sent(), 2]), boxesVals = _a[0], scoresVals = _a[1];
              _b = nonMaxSuppressionV4Impl(boxesVals, scoresVals, $maxOutputSize, $iouThreshold, $scoreThreshold, padToMaxOutputSize), selectedIndices = _b.selectedIndices, validOutputs = _b.validOutputs;
              if ($boxes !== boxes) {
                $boxes.dispose();
              }
              if ($scores !== scores) {
                $scores.dispose();
              }
              return [2, {
                selectedIndices: tensor1d(selectedIndices, "int32"),
                validOutputs: scalar(validOutputs, "int32")
              }];
          }
        });
      });
    }
    var nonMaxSuppressionPaddedAsync = nonMaxSuppressionPaddedAsync_;
    function resizeBilinear_(images, size, alignCorners, halfPixelCenters) {
      if (alignCorners === void 0) {
        alignCorners = false;
      }
      if (halfPixelCenters === void 0) {
        halfPixelCenters = false;
      }
      var $images = convertToTensor(images, "images", "resizeBilinear");
      assert($images.rank === 3 || $images.rank === 4, function() {
        return "Error in resizeBilinear: x must be rank 3 or 4, but got " + "rank ".concat($images.rank, ".");
      });
      assert(size.length === 2, function() {
        return "Error in resizeBilinear: new shape must 2D, but got shape " + "".concat(size, ".");
      });
      assert(halfPixelCenters === false || alignCorners === false, function() {
        return "Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.";
      });
      var batchImages = $images;
      var reshapedTo4D = false;
      if ($images.rank === 3) {
        reshapedTo4D = true;
        batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
      }
      __read(size, 0);
      var inputs = { images: batchImages };
      var attrs = { alignCorners, halfPixelCenters, size };
      var res = ENGINE.runKernel(ResizeBilinear, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var resizeBilinear = /* @__PURE__ */ op({ resizeBilinear_ });
    function resizeNearestNeighbor_(images, size, alignCorners, halfPixelCenters) {
      if (alignCorners === void 0) {
        alignCorners = false;
      }
      if (halfPixelCenters === void 0) {
        halfPixelCenters = false;
      }
      var $images = convertToTensor(images, "images", "resizeNearestNeighbor");
      assert($images.rank === 3 || $images.rank === 4, function() {
        return "Error in resizeNearestNeighbor: x must be rank 3 or 4, but got " + "rank ".concat($images.rank, ".");
      });
      assert(size.length === 2, function() {
        return "Error in resizeNearestNeighbor: new shape must 2D, but got shape " + "".concat(size, ".");
      });
      assert($images.dtype === "float32" || $images.dtype === "int32", function() {
        return "`images` must have `int32` or `float32` as dtype";
      });
      assert(halfPixelCenters === false || alignCorners === false, function() {
        return "Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.";
      });
      var batchImages = $images;
      var reshapedTo4D = false;
      if ($images.rank === 3) {
        reshapedTo4D = true;
        batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
      }
      __read(size, 0);
      var inputs = { images: batchImages };
      var attrs = { alignCorners, halfPixelCenters, size };
      var res = ENGINE.runKernel(ResizeNearestNeighbor, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var resizeNearestNeighbor = /* @__PURE__ */ op({ resizeNearestNeighbor_ });
    function threshold_(image2, method, inverted, threshValue) {
      var _a;
      if (method === void 0) {
        method = "binary";
      }
      if (inverted === void 0) {
        inverted = false;
      }
      if (threshValue === void 0) {
        threshValue = 0.5;
      }
      var $image = convertToTensor(image2, "image", "threshold");
      var RED_INTENCITY_COEF = 0.2989;
      var GREEN_INTENCITY_COEF = 0.587;
      var BLUE_INTENCITY_COEF = 0.114;
      var totalPixelsInImage = $image.shape[0] * $image.shape[1];
      var $threshold = mul(tensor1d([threshValue]), 255);
      var r, g, b, grayscale;
      assert($image.rank === 3, function() {
        return "Error in threshold: image must be rank 3," + "but got rank ".concat($image.rank, ".");
      });
      assert($image.shape[2] === 3 || $image.shape[2] === 1, function() {
        return "Error in threshold: image color channel must be equal to 3 or 1" + "but got ".concat($image.shape[2], ".");
      });
      assert($image.dtype === "int32" || $image.dtype === "float32", function() {
        return "Error in dtype: image dtype must be int32 or float32," + "but got dtype ".concat($image.dtype, ".");
      });
      assert(method === "otsu" || method === "binary", function() {
        return "Method must be binary or otsu, but was ".concat(method);
      });
      if ($image.shape[2] === 3) {
        _a = __read(split($image, [1, 1, 1], -1), 3), r = _a[0], g = _a[1], b = _a[2];
        var $r = mul(r, RED_INTENCITY_COEF);
        var $g = mul(g, GREEN_INTENCITY_COEF);
        var $b = mul(b, BLUE_INTENCITY_COEF);
        grayscale = add(add($r, $g), $b);
      } else {
        grayscale = image2;
      }
      if (method === "otsu") {
        var $histogram = bincount(cast(round(grayscale), "int32"), tensor([]), 256);
        $threshold = otsu($histogram, totalPixelsInImage);
      }
      var invCondition = inverted ? lessEqual(grayscale, $threshold) : greater(grayscale, $threshold);
      var result = cast(mul(invCondition, 255), "int32");
      return result;
    }
    function otsu(histogram, total) {
      var bestThresh = tensor1d([-1]);
      var bestInBetVar = tensor1d([0]);
      var cInBetVar = tensor1d([0]);
      var classFirst, classSecond, meanFirst, meanSec, weightForeground, weightBack;
      for (var index = 0; index < histogram.size - 1; index++) {
        classFirst = slice(histogram, 0, index + 1);
        classSecond = slice(histogram, index + 1);
        weightForeground = div(sum(classFirst), total);
        weightBack = div(sum(classSecond), total);
        var meanFirstDivA = sum(mul(classFirst, range(0, classFirst.size)));
        meanFirst = div(meanFirstDivA, sum(classFirst));
        var meanSecFill = fill(classSecond.shape, classFirst.size);
        var meanSecAdd = add(range(0, classSecond.size), meanSecFill);
        var meanSecMul = mul(classSecond, meanSecAdd);
        meanSec = div(sum(meanSecMul), sum(classSecond));
        var cInBetVarSubA = sub(meanFirst, meanSec);
        var cInBetVarSubB = sub(meanFirst, meanSec);
        var cInBetVarMul = mul(weightForeground, weightBack);
        cInBetVar = mul(mul(cInBetVarMul, cInBetVarSubA), cInBetVarSubB);
        var condition = greater(cInBetVar, bestInBetVar);
        bestInBetVar = where(condition, cInBetVar, bestInBetVar);
        bestThresh = where(condition, tensor1d([index]), bestThresh);
      }
      return bestThresh;
    }
    var threshold = /* @__PURE__ */ op({ threshold_ });
    function transform_(image2, transforms, interpolation, fillMode, fillValue, outputShape) {
      if (interpolation === void 0) {
        interpolation = "nearest";
      }
      if (fillMode === void 0) {
        fillMode = "constant";
      }
      if (fillValue === void 0) {
        fillValue = 0;
      }
      var $image = convertToTensor(image2, "image", "transform", "float32");
      var $transforms = convertToTensor(transforms, "transforms", "transform", "float32");
      assert($image.rank === 4, function() {
        return "Error in transform: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      assert($transforms.rank === 2 && ($transforms.shape[0] === $image.shape[0] || $transforms.shape[0] === 1) && $transforms.shape[1] === 8, function() {
        return "Error in transform: Input transform should be batch x 8 or 1 x 8";
      });
      assert(outputShape == null || outputShape.length === 2, function() {
        return "Error in transform: outputShape must be [height, width] or null, " + "but got ".concat(outputShape, ".");
      });
      var inputs = { image: $image, transforms: $transforms };
      var attrs = { interpolation, fillMode, fillValue, outputShape };
      return ENGINE.runKernel(Transform, inputs, attrs);
    }
    var transform = /* @__PURE__ */ op({ transform_ });
    function bandPart_(a, numLower, numUpper) {
      var $a = convertToTensor(a, "a", "bandPart");
      assert($a.rank >= 2, function() {
        return "bandPart(): Rank must be at least 2, got ".concat($a.rank, ".");
      });
      var shape = $a.shape;
      var _a = __read($a.shape.slice(-2), 2), M = _a[0], N = _a[1];
      var $numLower;
      var $numUpper;
      if (typeof numLower === "number") {
        assert(numLower % 1 === 0, function() {
          return "bandPart(): numLower must be an integer, got ".concat(numLower, ".");
        });
        assert(numLower <= M, function() {
          return "bandPart(): numLower (".concat(numLower, ")") + " must not be greater than the number of rows (".concat(M, ").");
        });
        $numLower = convertToTensor(numLower < 0 ? M : numLower, "numLower", "bandPart");
      } else {
        assert(numLower.dtype === "int32", function() {
          return "bandPart(): numLower's dtype must be an int32.";
        });
        $numLower = where(less(numLower, 0), M, minimum(numLower, M));
      }
      if (typeof numUpper === "number") {
        assert(numUpper % 1 === 0, function() {
          return "bandPart(): numUpper must be an integer, got ".concat(numUpper, ".");
        });
        assert(numUpper <= N, function() {
          return "bandPart(): numUpper (".concat(numUpper, ")") + " must not be greater than the number of columns (".concat(N, ").");
        });
        $numUpper = convertToTensor(numUpper < 0 ? N : numUpper, "numUpper", "bandPart");
      } else {
        assert(numUpper.dtype === "int32", function() {
          return "bandPart(): numUpper's dtype must be an int32.";
        });
        $numUpper = where(less(numUpper, 0), N, minimum(numUpper, N));
      }
      var i = reshape(range(0, M, 1, "int32"), [-1, 1]);
      var j = range(0, N, 1, "int32");
      var ij = sub(i, j);
      var inBand = logicalAnd(lessEqual(ij, $numLower), greaterEqual(ij, neg($numUpper)));
      var zero = zeros([M, N], $a.dtype);
      return reshape(stack(unstack(reshape($a, [-1, M, N])).map(function(mat) {
        return where(inBand, mat, zero);
      })), shape);
    }
    var bandPart = /* @__PURE__ */ op({ bandPart_ });
    function gramSchmidt_(xs) {
      var inputIsTensor2D;
      if (Array.isArray(xs)) {
        inputIsTensor2D = false;
        assert(xs != null && xs.length > 0, function() {
          return "Gram-Schmidt process: input must not be null, undefined, or empty";
        });
        var dim_1 = xs[0].shape[0];
        var _loop_1 = function(i2) {
          assert(xs[i2].shape[0] === dim_1, function() {
            return "Gram-Schmidt: Non-unique lengths found in the input vectors: " + "(".concat(xs[i2].shape[0], " vs. ").concat(dim_1, ")");
          });
        };
        for (var i = 1; i < xs.length; ++i) {
          _loop_1(i);
        }
      } else {
        inputIsTensor2D = true;
        xs = split(xs, xs.shape[0], 0).map(function(x) {
          return squeeze(x, [0]);
        });
      }
      assert(xs.length <= xs[0].shape[0], function() {
        return "Gram-Schmidt: Number of vectors (".concat(xs.length, ") exceeds ") + "number of dimensions (".concat(xs[0].shape[0], ").");
      });
      var ys = [];
      var xs1d = xs;
      var _loop_2 = function(i2) {
        ys.push(ENGINE.tidy(function() {
          var x = xs1d[i2];
          if (i2 > 0) {
            for (var j = 0; j < i2; ++j) {
              var proj = mul(sum(mul(ys[j], x)), ys[j]);
              x = sub(x, proj);
            }
          }
          return div(x, norm(x, "euclidean"));
        }));
      };
      for (var i = 0; i < xs.length; ++i) {
        _loop_2(i);
      }
      if (inputIsTensor2D) {
        return stack(ys, 0);
      } else {
        return ys;
      }
    }
    var gramSchmidt = /* @__PURE__ */ op({ gramSchmidt_ });
    function qr_(x, fullMatrices) {
      if (fullMatrices === void 0) {
        fullMatrices = false;
      }
      assert(x.rank >= 2, function() {
        return "qr() requires input tensor to have a rank >= 2, but got rank ".concat(x.rank);
      });
      if (x.rank === 2) {
        return qr2d(x, fullMatrices);
      } else {
        var outerDimsProd = x.shape.slice(0, x.shape.length - 2).reduce(function(value, prev) {
          return value * prev;
        });
        var x2ds = unstack(reshape(x, [
          outerDimsProd,
          x.shape[x.shape.length - 2],
          x.shape[x.shape.length - 1]
        ]), 0);
        var q2ds_1 = [];
        var r2ds_1 = [];
        x2ds.forEach(function(x2d) {
          var _a = __read(qr2d(x2d, fullMatrices), 2), q2d = _a[0], r2d = _a[1];
          q2ds_1.push(q2d);
          r2ds_1.push(r2d);
        });
        var q = reshape(stack(q2ds_1, 0), x.shape);
        var r = reshape(stack(r2ds_1, 0), x.shape);
        return [q, r];
      }
    }
    function qr2d(x, fullMatrices) {
      if (fullMatrices === void 0) {
        fullMatrices = false;
      }
      return ENGINE.tidy(function() {
        assert(x.shape.length === 2, function() {
          return "qr2d() requires a 2D Tensor, but got a ".concat(x.shape.length, "D Tensor.");
        });
        var m = x.shape[0];
        var n = x.shape[1];
        var q = eye(m);
        var r = clone(x);
        var one2D = tensor2d([[1]], [1, 1]);
        var w = clone(one2D);
        var iters = m >= n ? n : m;
        var _loop_1 = function(j2) {
          var _a;
          var rTemp = r;
          var wTemp = w;
          var qTemp = q;
          _a = __read(ENGINE.tidy(function() {
            var rjEnd1 = slice(r, [j2, j2], [m - j2, 1]);
            var normX = norm(rjEnd1);
            var rjj = slice(r, [j2, j2], [1, 1]);
            var s = where(greater(rjj, 0), tensor2d([[-1]]), tensor2d([[1]]));
            var u1 = sub(rjj, mul(s, normX));
            var wPre = div(rjEnd1, u1);
            if (wPre.shape[0] === 1) {
              w = clone(one2D);
            } else {
              w = concat([
                one2D,
                slice(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]])
              ], 0);
            }
            var tau = neg(div(matMul$1(s, u1), normX));
            var rjEndAll = slice(r, [j2, 0], [m - j2, n]);
            var tauTimesW = mul(tau, w);
            var wT = transpose(w);
            if (j2 === 0) {
              r = sub(rjEndAll, matMul$1(tauTimesW, matMul$1(wT, rjEndAll)));
            } else {
              var rTimesTau = sub(rjEndAll, matMul$1(tauTimesW, matMul$1(wT, rjEndAll)));
              r = concat([slice(r, [0, 0], [j2, n]), rTimesTau], 0);
            }
            var tawTimesWT = transpose(tauTimesW);
            var qAllJEnd = slice(q, [0, j2], [m, q.shape[1] - j2]);
            if (j2 === 0) {
              q = sub(qAllJEnd, matMul$1(matMul$1(qAllJEnd, w), tawTimesWT));
            } else {
              var qTimesTau = sub(qAllJEnd, matMul$1(matMul$1(qAllJEnd, w), tawTimesWT));
              q = concat([slice(q, [0, 0], [m, j2]), qTimesTau], 1);
            }
            return [w, r, q];
          }), 3), w = _a[0], r = _a[1], q = _a[2];
          dispose([rTemp, wTemp, qTemp]);
        };
        for (var j = 0; j < iters; ++j) {
          _loop_1(j);
        }
        if (!fullMatrices && m > n) {
          q = slice(q, [0, 0], [m, n]);
          r = slice(r, [0, 0], [n, n]);
        }
        return [q, r];
      });
    }
    var qr = /* @__PURE__ */ op({ qr_ });
    exports.Reduction = void 0;
    (function(Reduction) {
      Reduction[Reduction["NONE"] = 0] = "NONE";
      Reduction[Reduction["MEAN"] = 1] = "MEAN";
      Reduction[Reduction["SUM"] = 2] = "SUM";
      Reduction[Reduction["SUM_BY_NONZERO_WEIGHTS"] = 3] = "SUM_BY_NONZERO_WEIGHTS";
    })(exports.Reduction || (exports.Reduction = {}));
    function computeWeightedLoss_(losses2, weights, reduction) {
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $losses = convertToTensor(losses2, "losses", "computeWeightedLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "computeWeightedLoss");
      }
      var weightedLoss = $weights == null ? $losses : mul($losses, $weights);
      if (reduction === exports.Reduction.NONE) {
        return weightedLoss;
      }
      if (reduction === exports.Reduction.SUM) {
        return sum(weightedLoss);
      }
      if (reduction === exports.Reduction.MEAN) {
        if ($weights == null) {
          return mean(weightedLoss);
        } else {
          var broadcastFactor = $losses.size / $weights.size;
          var result = div(sum(weightedLoss), sum($weights));
          return broadcastFactor > 1 ? div(result, scalar(broadcastFactor)) : result;
        }
      }
      if (reduction === exports.Reduction.SUM_BY_NONZERO_WEIGHTS) {
        if ($weights == null) {
          return div(sum(weightedLoss), scalar($losses.size));
        } else {
          var broadcastedWeights = mul($weights, ones($losses.shape));
          var numNonZeros = cast(sum(notEqual(broadcastedWeights, scalar(0))), "float32");
          return div(sum(weightedLoss), numNonZeros);
        }
      }
      throw Error("Unknown reduction: ".concat(reduction));
    }
    var computeWeightedLoss = /* @__PURE__ */ op({ computeWeightedLoss_ });
    function absoluteDifference_(labels, predictions, weights, reduction) {
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "absoluteDifference");
      var $predictions = convertToTensor(predictions, "predictions", "absoluteDifference");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "absoluteDifference");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in absoluteDifference: ");
      var losses2 = abs(sub($labels, $predictions));
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var absoluteDifference = /* @__PURE__ */ op({ absoluteDifference_ });
    function cosineDistance_(labels, predictions, axis, weights, reduction) {
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "cosineDistance");
      var $predictions = convertToTensor(predictions, "predictions", "cosineDistance");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "cosineDistance");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in cosineDistance: ");
      var one = scalar(1);
      var losses2 = sub(one, sum(mul($labels, $predictions), axis, true));
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var cosineDistance = /* @__PURE__ */ op({ cosineDistance_ });
    function hingeLoss_(labels, predictions, weights, reduction) {
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "hingeLoss");
      var $predictions = convertToTensor(predictions, "predictions", "hingeLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "hingeLoss");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in hingeLoss: ");
      var one = scalar(1);
      $labels = sub(mul(scalar(2), $labels), one);
      var losses2 = relu(sub(one, mul($labels, $predictions)));
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var hingeLoss = /* @__PURE__ */ op({ hingeLoss_ });
    function huberLoss_(labels, predictions, weights, delta, reduction) {
      if (delta === void 0) {
        delta = 1;
      }
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "huberLoss");
      var $predictions = convertToTensor(predictions, "predictions", "huberLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "huberLoss");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in huberLoss: ");
      var deltaScalar = scalar(delta);
      var error = abs(sub($predictions, $labels));
      var quadratic = minimum(error, deltaScalar);
      var linear = sub(error, quadratic);
      var losses2 = add(mul(scalar(0.5), square(quadratic)), mul(deltaScalar, linear));
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var huberLoss = /* @__PURE__ */ op({ huberLoss_ });
    function logLoss_(labels, predictions, weights, epsilon, reduction) {
      if (epsilon === void 0) {
        epsilon = 1e-7;
      }
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "logLoss");
      var $predictions = convertToTensor(predictions, "predictions", "logLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "logLoss");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in logLoss: ");
      var one = scalar(1);
      var epsilonScalar = scalar(epsilon);
      var l1 = neg(mul($labels, log(add($predictions, epsilonScalar))));
      var l2 = mul(sub(one, $labels), log(add(sub(one, $predictions), epsilonScalar)));
      var losses2 = sub(l1, l2);
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var logLoss = /* @__PURE__ */ op({ logLoss_ });
    function meanSquaredError_(labels, predictions, weights, reduction) {
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "meanSquaredError");
      var $predictions = convertToTensor(predictions, "predictions", "meanSquaredError");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "meanSquaredError");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in meanSquaredError: ");
      var losses2 = squaredDifference($labels, $predictions);
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var meanSquaredError = /* @__PURE__ */ op({ meanSquaredError_ });
    function sigmoidCrossEntropyWithLogits_(labels, logits) {
      var $labels = convertToTensor(labels, "labels", "sigmoidCrossEntropyWithLogits");
      var $logits = convertToTensor(logits, "logits", "sigmoidCrossEntropyWithLogits");
      assertShapesMatch($labels.shape, $logits.shape, "Error in sigmoidCrossEntropyWithLogits: ");
      var maxOutput = relu($logits);
      var outputXTarget = mul($logits, $labels);
      var sigmoidOutput = log1p(exp(neg(abs($logits))));
      return add(sub(maxOutput, outputXTarget), sigmoidOutput);
    }
    function sigmoidCrossEntropy_(multiClassLabels, logits, weights, labelSmoothing, reduction) {
      if (labelSmoothing === void 0) {
        labelSmoothing = 0;
      }
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $multiClassLabels = convertToTensor(multiClassLabels, "multiClassLabels", "sigmoidCrossEntropy");
      var $logits = convertToTensor(logits, "logits", "sigmoidCrossEntropy");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "sigmoidCrossEntropy");
      }
      assertShapesMatch($multiClassLabels.shape, $logits.shape, "Error in sigmoidCrossEntropy: ");
      if (labelSmoothing > 0) {
        var labelSmoothingScalar = scalar(labelSmoothing);
        var one = scalar(1);
        var half = scalar(0.5);
        $multiClassLabels = add(mul($multiClassLabels, sub(one, labelSmoothingScalar)), mul(half, labelSmoothingScalar));
      }
      var losses2 = sigmoidCrossEntropyWithLogits_($multiClassLabels, $logits);
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var sigmoidCrossEntropy = /* @__PURE__ */ op({ sigmoidCrossEntropy_ });
    function softmaxCrossEntropyWithLogits_(labels, logits, dim) {
      if (dim === void 0) {
        dim = -1;
      }
      if (dim === -1) {
        dim = logits.rank - 1;
      }
      if (dim !== logits.rank - 1) {
        throw Error("Softmax cross entropy along a non-last dimension is not yet " + "supported. Labels / logits was rank ".concat(logits.rank, " ") + "and dim was ".concat(dim));
      }
      var customOp = customGrad(function(labels2, logits2, save) {
        var keepDims = true;
        var lse = logSumExp(logits2, [dim], keepDims);
        var logResult = sub(cast(logits2, "float32"), lse);
        save([labels2, logResult]);
        var costVector = neg(mul(logResult, labels2));
        var value = sum(costVector, [dim]);
        var gradFunc = function(dy, saved) {
          var _a = __read(saved, 2), labels3 = _a[0], logResult2 = _a[1];
          var dyShape = expandShapeToKeepDim(dy.shape, [dim]);
          return [
            mul(reshape(dy, dyShape), sub(cast(labels3, "float32"), exp(logResult2))),
            mul(reshape(dy, dyShape), sub(exp(logResult2), cast(labels3, "float32")))
          ];
        };
        return { value, gradFunc };
      });
      return customOp(labels, logits);
    }
    function softmaxCrossEntropy_(onehotLabels, logits, weights, labelSmoothing, reduction) {
      if (labelSmoothing === void 0) {
        labelSmoothing = 0;
      }
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $onehotLabels = convertToTensor(onehotLabels, "onehotLabels", "softmaxCrossEntropy");
      var $logits = convertToTensor(logits, "logits", "softmaxCrossEntropy");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "softmaxCrossEntropy");
      }
      assertShapesMatch($onehotLabels.shape, $logits.shape, "Error in softmaxCrossEntropy: ");
      if (labelSmoothing > 0) {
        var labelSmoothingScalar = scalar(labelSmoothing);
        var one = scalar(1);
        var numClasses = scalar($onehotLabels.shape[1]);
        $onehotLabels = add(mul($onehotLabels, sub(one, labelSmoothingScalar)), div(labelSmoothingScalar, numClasses));
      }
      var losses2 = softmaxCrossEntropyWithLogits_($onehotLabels, $logits);
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var softmaxCrossEntropy = /* @__PURE__ */ op({ softmaxCrossEntropy_ });
    function sparseFillEmptyRows_(indices, values, denseShape, defaultValue) {
      var $indices = convertToTensor(indices, "indices", "sparseFillEmptyRows", "int32");
      var $values = convertToTensor(values, "values", "sparseFillEmptyRows");
      var $denseShape = convertToTensor(denseShape, "denseShape", "sparseFillEmptyRows", "int32");
      var $defaultValue = convertToTensor(defaultValue, "defaultValue", "sparseFillEmptyRows", $values.dtype);
      if ($indices.rank !== 2) {
        throw new Error("Indices should be Tensor2D but received shape\n        ".concat($indices.shape));
      }
      if ($values.rank !== 1) {
        throw new Error("Values should be Tensor1D but received shape ".concat($values.shape));
      }
      if ($denseShape.rank !== 1) {
        throw new Error("Dense shape should be Tensor1D but received shape ".concat($denseShape.shape));
      }
      if ($defaultValue.rank !== 0) {
        throw new Error("Default value should be a scalar but received shape ".concat($defaultValue.shape));
      }
      var inputs = {
        indices: $indices,
        values: $values,
        denseShape: $denseShape,
        defaultValue: $defaultValue
      };
      var result = ENGINE.runKernel(SparseFillEmptyRows, inputs);
      return {
        outputIndices: result[0],
        outputValues: result[1],
        emptyRowIndicator: result[2],
        reverseIndexMap: result[3]
      };
    }
    var sparseFillEmptyRows = /* @__PURE__ */ op({ sparseFillEmptyRows_ });
    function sparseReshape_(inputIndices, inputShape, newShape) {
      var $inputIndices = convertToTensor(inputIndices, "inputIndices", "sparseReshape", "int32");
      var $inputShape = convertToTensor(inputShape, "inputShape", "sparseReshape", "int32");
      var $newShape = convertToTensor(newShape, "newShape", "sparseReshape", "int32");
      if ($inputIndices.rank !== 2) {
        throw new Error("Input indices should be Tensor2D but received shape\n        ".concat($inputIndices.shape));
      }
      if ($inputShape.rank !== 1) {
        throw new Error("Input shape should be Tensor1D but received shape ".concat($inputShape.shape));
      }
      if ($newShape.rank !== 1) {
        throw new Error("New shape should be Tensor1D but received shape ".concat($newShape.shape));
      }
      var inputs = {
        inputIndices: $inputIndices,
        inputShape: $inputShape,
        newShape: $newShape
      };
      var result = ENGINE.runKernel(SparseReshape, inputs);
      return { outputIndices: result[0], outputShape: result[1] };
    }
    var sparseReshape = /* @__PURE__ */ op({ sparseReshape_ });
    function sparseSegmentMean_(data, indices, segmentIds) {
      var $data = convertToTensor(data, "data", "sparseSegmentMean");
      var $indices = convertToTensor(indices, "indices", "sparseSegmentMean", "int32");
      var $segmentIds = convertToTensor(segmentIds, "segmentIds", "sparseSegmentMean", "int32");
      if ($data.rank < 1) {
        throw new Error("Data should be at least 1 dimensional but received scalar");
      }
      if ($indices.rank !== 1) {
        throw new Error("Indices should be Tensor1D but received shape\n          ".concat($indices.shape));
      }
      if ($segmentIds.rank !== 1) {
        throw new Error("Segment ids should be Tensor1D but received shape\n          ".concat($segmentIds.shape));
      }
      var inputs = {
        data: $data,
        indices: $indices,
        segmentIds: $segmentIds
      };
      return ENGINE.runKernel(SparseSegmentMean, inputs);
    }
    var sparseSegmentMean = /* @__PURE__ */ op({ sparseSegmentMean_ });
    function sparseSegmentSum_(data, indices, segmentIds) {
      var $data = convertToTensor(data, "data", "sparseSegmentSum");
      var $indices = convertToTensor(indices, "indices", "sparseSegmentSum", "int32");
      var $segmentIds = convertToTensor(segmentIds, "segmentIds", "sparseSegmentSum", "int32");
      if ($data.rank < 1) {
        throw new Error("Data should be at least 1 dimensional but received scalar");
      }
      if ($indices.rank !== 1) {
        throw new Error("Indices should be Tensor1D but received shape\n         ".concat($indices.shape));
      }
      if ($segmentIds.rank !== 1) {
        throw new Error("Segment ids should be Tensor1D but received shape\n         ".concat($segmentIds.shape));
      }
      var inputs = {
        data: $data,
        indices: $indices,
        segmentIds: $segmentIds
      };
      return ENGINE.runKernel(SparseSegmentSum, inputs);
    }
    var sparseSegmentSum = /* @__PURE__ */ op({ sparseSegmentSum_ });
    function stringNGrams_(data, dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences) {
      var $data = convertToTensor(data, "data", "stringNGrams", "string");
      if ($data.dtype !== "string") {
        throw new Error("Data must be of datatype string");
      }
      if ($data.shape.length !== 1) {
        throw new Error("Data must be a vector, saw: ".concat($data.shape));
      }
      var $dataSplits = convertToTensor(dataSplits, "dataSplits", "stringNGrams");
      if ($dataSplits.dtype !== "int32") {
        throw new Error("Data splits must be of datatype int32");
      }
      var attrs = {
        separator,
        nGramWidths,
        leftPad,
        rightPad: rightPad2,
        padWidth,
        preserveShortSequences
      };
      var inputs = { data: $data, dataSplits: $dataSplits };
      var result = ENGINE.runKernel(StringNGrams, inputs, attrs);
      return { nGrams: result[0], nGramsSplits: result[1] };
    }
    var stringNGrams = /* @__PURE__ */ op({ stringNGrams_ });
    function stringSplit_(input, delimiter, skipEmpty) {
      if (skipEmpty === void 0) {
        skipEmpty = true;
      }
      var $input = convertToTensor(input, "input", "stringSplit", "string");
      var $delimiter = convertToTensor(delimiter, "delimiter", "stringSplit", "string");
      if ($input.rank !== 1) {
        throw new Error("Input should be Tensor1D but received shape ".concat($input.shape));
      }
      if ($delimiter.rank !== 0) {
        throw new Error("Delimiter should be a scalar but received shape ".concat($delimiter.shape));
      }
      var attrs = { skipEmpty };
      var inputs = { input: $input, delimiter: $delimiter };
      var result = ENGINE.runKernel(StringSplit, inputs, attrs);
      return { indices: result[0], values: result[1], shape: result[2] };
    }
    var stringSplit = /* @__PURE__ */ op({ stringSplit_ });
    function stringToHashBucketFast_(input, numBuckets) {
      var $input = convertToTensor(input, "input", "stringToHashBucketFast", "string");
      var attrs = { numBuckets };
      if (numBuckets <= 0) {
        throw new Error("Number of buckets must be at least 1");
      }
      var inputs = { input: $input };
      return ENGINE.runKernel(StringToHashBucketFast, inputs, attrs);
    }
    var stringToHashBucketFast = /* @__PURE__ */ op({ stringToHashBucketFast_ });
    function staticRegexReplace_(input, pattern, rewrite, replaceGlobal) {
      if (replaceGlobal === void 0) {
        replaceGlobal = true;
      }
      var $input = convertToTensor(input, "input", "staticRegexReplace", "string");
      var attrs = { pattern, rewrite, replaceGlobal };
      return ENGINE.runKernel(StaticRegexReplace, { x: $input }, attrs);
    }
    var staticRegexReplace = /* @__PURE__ */ op({ staticRegexReplace_ });
    var spectral = {
      fft,
      ifft,
      rfft,
      irfft
    };
    var signal = {
      hammingWindow,
      hannWindow,
      frame,
      stft
    };
    var image = {
      flipLeftRight,
      grayscaleToRGB,
      resizeNearestNeighbor,
      resizeBilinear,
      rgbToGrayscale,
      rotateWithOffset,
      cropAndResize,
      nonMaxSuppression,
      nonMaxSuppressionAsync,
      nonMaxSuppressionWithScore,
      nonMaxSuppressionWithScoreAsync,
      nonMaxSuppressionPadded,
      nonMaxSuppressionPaddedAsync,
      threshold,
      transform
    };
    var linalg = {
      bandPart,
      gramSchmidt,
      qr
    };
    var losses = {
      absoluteDifference,
      computeWeightedLoss,
      cosineDistance,
      hingeLoss,
      huberLoss,
      logLoss,
      meanSquaredError,
      sigmoidCrossEntropy,
      softmaxCrossEntropy
    };
    var sparse = {
      sparseFillEmptyRows,
      sparseReshape,
      sparseSegmentMean,
      sparseSegmentSum
    };
    var string = {
      stringNGrams,
      stringSplit,
      stringToHashBucketFast,
      staticRegexReplace
    };
    var GLOBAL_CUSTOM_OBJECT = /* @__PURE__ */ new Map();
    var GLOBAL_CUSTOM_NAMES = /* @__PURE__ */ new Map();
    var Serializable = (
      /** @class */
      function() {
        function Serializable2() {
        }
        Serializable2.prototype.getClassName = function() {
          return this.constructor.className;
        };
        Serializable2.fromConfig = function(cls, config) {
          return new cls(config);
        };
        return Serializable2;
      }()
    );
    var SerializationMap = (
      /** @class */
      function() {
        function SerializationMap2() {
          this.classNameMap = {};
        }
        SerializationMap2.getMap = function() {
          if (SerializationMap2.instance == null) {
            SerializationMap2.instance = new SerializationMap2();
          }
          return SerializationMap2.instance;
        };
        SerializationMap2.register = function(cls) {
          SerializationMap2.getMap().classNameMap[cls.className] = [cls, cls.fromConfig];
        };
        return SerializationMap2;
      }()
    );
    function registerClass(cls, pkg, name) {
      assert(cls.className != null, function() {
        return "Class being registered does not have the static className property defined.";
      });
      assert(typeof cls.className === "string", function() {
        return "className is required to be a string, but got type " + typeof cls.className;
      });
      assert(cls.className.length > 0, function() {
        return "Class being registered has an empty-string as its className, which is disallowed.";
      });
      if (typeof pkg === "undefined") {
        pkg = "Custom";
      }
      if (typeof name === "undefined") {
        name = cls.className;
      }
      var className = name;
      var registerName = pkg + ">" + className;
      SerializationMap.register(cls);
      GLOBAL_CUSTOM_OBJECT.set(registerName, cls);
      GLOBAL_CUSTOM_NAMES.set(cls, registerName);
      return cls;
    }
    function getRegisteredName(cls) {
      if (GLOBAL_CUSTOM_NAMES.has(cls)) {
        return GLOBAL_CUSTOM_NAMES.get(cls);
      } else {
        return cls.className;
      }
    }
    var serialization = {
      __proto__: null,
      Serializable,
      SerializationMap,
      getRegisteredName,
      registerClass
    };
    var Optimizer = (
      /** @class */
      function(_super) {
        __extends(Optimizer2, _super);
        function Optimizer2() {
          return _super !== null && _super.apply(this, arguments) || this;
        }
        Optimizer2.prototype.minimize = function(f, returnCost, varList) {
          if (returnCost === void 0) {
            returnCost = false;
          }
          var _a = this.computeGradients(f, varList), value = _a.value, grads2 = _a.grads;
          if (varList != null) {
            var gradArray = varList.map(function(v) {
              return { name: v.name, tensor: grads2[v.name] };
            });
            this.applyGradients(gradArray);
          } else {
            this.applyGradients(grads2);
          }
          dispose(grads2);
          if (returnCost) {
            return value;
          } else {
            value.dispose();
            return null;
          }
        };
        Object.defineProperty(Optimizer2.prototype, "iterations", {
          /**
           * The number of iterations that this optimizer instance has been invoked for.
           */
          get: function() {
            if (this.iterations_ == null) {
              this.iterations_ = 0;
            }
            return this.iterations_;
          },
          enumerable: false,
          configurable: true
        });
        Optimizer2.prototype.incrementIterations = function() {
          this.iterations_ = this.iterations + 1;
        };
        Optimizer2.prototype.computeGradients = function(f, varList) {
          return variableGrads(f, varList);
        };
        Optimizer2.prototype.dispose = function() {
          if (this.iterations_ != null) {
            dispose(this.iterations_);
          }
        };
        Optimizer2.prototype.saveIterations = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              if (this.iterations_ == null) {
                this.iterations_ = 0;
              }
              return [2, {
                name: "iter",
                // TODO(cais): Use 'int64' type when available.
                tensor: scalar(this.iterations_, "int32")
              }];
            });
          });
        };
        Optimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              throw new Error("getWeights() is not implemented for this optimizer yet.");
            });
          });
        };
        Optimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              throw new Error("setWeights() is not implemented for this optimizer class " + "".concat(this.getClassName()));
            });
          });
        };
        Optimizer2.prototype.extractIterations = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            var _a;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  _a = this;
                  return [4, weightValues[0].tensor.data()];
                case 1:
                  _a.iterations_ = _b.sent()[0];
                  return [2, weightValues.slice(1)];
              }
            });
          });
        };
        return Optimizer2;
      }(Serializable)
    );
    Object.defineProperty(Optimizer, Symbol.hasInstance, {
      value: function(instance) {
        return instance.minimize != null && instance.computeGradients != null && instance.applyGradients != null;
      }
    });
    var AdadeltaOptimizer = (
      /** @class */
      function(_super) {
        __extends(AdadeltaOptimizer2, _super);
        function AdadeltaOptimizer2(learningRate, rho, epsilon) {
          if (epsilon === void 0) {
            epsilon = null;
          }
          var _this = _super.call(this) || this;
          _this.learningRate = learningRate;
          _this.rho = rho;
          _this.epsilon = epsilon;
          _this.accumulatedGrads = [];
          _this.accumulatedUpdates = [];
          if (epsilon == null) {
            _this.epsilon = ENGINE.backend.epsilon();
          }
          return _this;
        }
        Object.defineProperty(AdadeltaOptimizer2, "className", {
          /** @nocollapse */
          get: function() {
            return "Adadelta";
          },
          enumerable: false,
          configurable: true
        });
        AdadeltaOptimizer2.prototype.applyGradients = function(variableGradients) {
          var _this = this;
          var variableNames = Array.isArray(variableGradients) ? variableGradients.map(function(item) {
            return item.name;
          }) : Object.keys(variableGradients);
          variableNames.forEach(function(name, i) {
            var value = ENGINE.registeredVariables[name];
            var trainable = false;
            if (_this.accumulatedGrads[i] == null) {
              _this.accumulatedGrads[i] = {
                originalName: "".concat(name, "/accum_grad"),
                variable: tidy(function() {
                  return zerosLike(value).variable(trainable);
                })
              };
            }
            if (_this.accumulatedUpdates[i] == null) {
              _this.accumulatedUpdates[i] = {
                originalName: "".concat(name, "/accum_var"),
                variable: tidy(function() {
                  return zerosLike(value).variable(trainable);
                })
              };
            }
            var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            var accumulatedGrad = _this.accumulatedGrads[i].variable;
            var accumulatedUpdate = _this.accumulatedUpdates[i].variable;
            tidy(function() {
              var newAccumulatedGrad = add(mul(accumulatedGrad, _this.rho), mul(square(gradient), 1 - _this.rho));
              var updates = mul(div(sqrt(add(accumulatedUpdate, _this.epsilon)), sqrt(add(accumulatedGrad, _this.epsilon))), gradient);
              var newAccumulatedUpdate = add(mul(accumulatedUpdate, _this.rho), mul(square(updates), 1 - _this.rho));
              accumulatedGrad.assign(newAccumulatedGrad);
              accumulatedUpdate.assign(newAccumulatedUpdate);
              var newValue = add(mul(updates, -_this.learningRate), value);
              value.assign(newValue);
            });
          });
          this.incrementIterations();
        };
        AdadeltaOptimizer2.prototype.dispose = function() {
          if (this.accumulatedUpdates != null) {
            dispose(this.accumulatedGrads.map(function(v) {
              return v.variable;
            }));
            dispose(this.accumulatedUpdates.map(function(v) {
              return v.variable;
            }));
          }
        };
        AdadeltaOptimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            var variables;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  variables = __spreadArray(__spreadArray([], __read(this.accumulatedGrads), false), __read(this.accumulatedUpdates), false);
                  return [4, this.saveIterations()];
                case 1:
                  return [2, [_a.sent()].concat(variables.map(function(v) {
                    return { name: v.originalName, tensor: v.variable };
                  }))];
              }
            });
          });
        };
        AdadeltaOptimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            var variableCount, trainable;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.extractIterations(weightValues)];
                case 1:
                  weightValues = _a.sent();
                  variableCount = weightValues.length / 2;
                  trainable = false;
                  this.accumulatedGrads = weightValues.slice(0, variableCount).map(function(v) {
                    return {
                      originalName: v.name,
                      variable: v.tensor.variable(trainable)
                    };
                  });
                  this.accumulatedUpdates = weightValues.slice(variableCount, variableCount * 2).map(function(v) {
                    return {
                      originalName: v.name,
                      variable: v.tensor.variable(trainable)
                    };
                  });
                  return [
                    2
                    /*return*/
                  ];
              }
            });
          });
        };
        AdadeltaOptimizer2.prototype.getConfig = function() {
          return {
            "learningRate": this.learningRate,
            "rho": this.rho,
            "epsilon": this.epsilon
          };
        };
        AdadeltaOptimizer2.fromConfig = function(cls, config) {
          return new cls(config["learningRate"], config["rho"], config["epsilon"]);
        };
        return AdadeltaOptimizer2;
      }(Optimizer)
    );
    var AdagradOptimizer = (
      /** @class */
      function(_super) {
        __extends(AdagradOptimizer2, _super);
        function AdagradOptimizer2(learningRate, initialAccumulatorValue) {
          if (initialAccumulatorValue === void 0) {
            initialAccumulatorValue = 0.1;
          }
          var _this = _super.call(this) || this;
          _this.learningRate = learningRate;
          _this.initialAccumulatorValue = initialAccumulatorValue;
          _this.accumulatedGrads = [];
          return _this;
        }
        Object.defineProperty(AdagradOptimizer2, "className", {
          /** @nocollapse */
          get: function() {
            return "Adagrad";
          },
          enumerable: false,
          configurable: true
        });
        AdagradOptimizer2.prototype.applyGradients = function(variableGradients) {
          var _this = this;
          var variableNames = Array.isArray(variableGradients) ? variableGradients.map(function(item) {
            return item.name;
          }) : Object.keys(variableGradients);
          variableNames.forEach(function(name, i) {
            var value = ENGINE.registeredVariables[name];
            if (_this.accumulatedGrads[i] == null) {
              var trainable_1 = false;
              _this.accumulatedGrads[i] = {
                originalName: "".concat(name, "/accumulator"),
                variable: tidy(function() {
                  return fill(value.shape, _this.initialAccumulatorValue).variable(trainable_1);
                })
              };
            }
            var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            var accumulatedGrad = _this.accumulatedGrads[i].variable;
            tidy(function() {
              var newAccumulatedGrad = add(accumulatedGrad, square(gradient));
              accumulatedGrad.assign(newAccumulatedGrad);
              var newValue = add(mul(div(gradient, sqrt(add(newAccumulatedGrad, ENGINE.backend.epsilon()))), -_this.learningRate), value);
              value.assign(newValue);
            });
          });
          this.incrementIterations();
        };
        AdagradOptimizer2.prototype.dispose = function() {
          if (this.accumulatedGrads != null) {
            dispose(this.accumulatedGrads.map(function(v) {
              return v.variable;
            }));
          }
        };
        AdagradOptimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.saveIterations()];
                case 1:
                  return [2, [_a.sent()].concat(this.accumulatedGrads.map(function(v) {
                    return { name: v.originalName, tensor: v.variable };
                  }))];
              }
            });
          });
        };
        AdagradOptimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            var trainable;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.extractIterations(weightValues)];
                case 1:
                  weightValues = _a.sent();
                  trainable = false;
                  this.accumulatedGrads = weightValues.map(function(v) {
                    return { originalName: v.name, variable: v.tensor.variable(trainable) };
                  });
                  return [
                    2
                    /*return*/
                  ];
              }
            });
          });
        };
        AdagradOptimizer2.prototype.getConfig = function() {
          return {
            "learningRate": this.learningRate,
            "initialAccumulatorValue": this.initialAccumulatorValue
          };
        };
        AdagradOptimizer2.fromConfig = function(cls, config) {
          return new cls(config["learningRate"], config["initialAccumulatorValue"]);
        };
        return AdagradOptimizer2;
      }(Optimizer)
    );
    var AdamOptimizer = (
      /** @class */
      function(_super) {
        __extends(AdamOptimizer2, _super);
        function AdamOptimizer2(learningRate, beta1, beta2, epsilon) {
          if (epsilon === void 0) {
            epsilon = null;
          }
          var _this = _super.call(this) || this;
          _this.learningRate = learningRate;
          _this.beta1 = beta1;
          _this.beta2 = beta2;
          _this.epsilon = epsilon;
          _this.accumulatedFirstMoment = [];
          _this.accumulatedSecondMoment = [];
          tidy(function() {
            _this.accBeta1 = scalar(beta1).variable();
            _this.accBeta2 = scalar(beta2).variable();
          });
          if (epsilon == null) {
            _this.epsilon = ENGINE.backend.epsilon();
          }
          return _this;
        }
        Object.defineProperty(AdamOptimizer2, "className", {
          /** @nocollapse */
          get: function() {
            return "Adam";
          },
          enumerable: false,
          configurable: true
        });
        AdamOptimizer2.prototype.applyGradients = function(variableGradients) {
          var _this = this;
          var varNames = Array.isArray(variableGradients) ? variableGradients.map(function(v) {
            return v.name;
          }) : Object.keys(variableGradients);
          tidy(function() {
            var oneMinusAccBeta1 = sub(1, _this.accBeta1);
            var oneMinusAccBeta2 = sub(1, _this.accBeta2);
            varNames.forEach(function(name, i) {
              var value = ENGINE.registeredVariables[name];
              var trainable = false;
              if (_this.accumulatedFirstMoment[i] == null) {
                _this.accumulatedFirstMoment[i] = {
                  originalName: "".concat(name, "/m"),
                  variable: tidy(function() {
                    return zerosLike(value).variable(trainable);
                  })
                };
              }
              if (_this.accumulatedSecondMoment[i] == null) {
                _this.accumulatedSecondMoment[i] = {
                  originalName: "".concat(name, "/v"),
                  variable: tidy(function() {
                    return zerosLike(value).variable(trainable);
                  })
                };
              }
              var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
              if (gradient == null) {
                return;
              }
              var firstMoment = _this.accumulatedFirstMoment[i].variable;
              var secondMoment = _this.accumulatedSecondMoment[i].variable;
              var newFirstMoment = add(mul(firstMoment, _this.beta1), mul(gradient, 1 - _this.beta1));
              var newSecondMoment = add(mul(secondMoment, _this.beta2), mul(square(gradient), 1 - _this.beta2));
              var biasCorrectedFirstMoment = div(newFirstMoment, oneMinusAccBeta1);
              var biasCorrectedSecondMoment = div(newSecondMoment, oneMinusAccBeta2);
              firstMoment.assign(newFirstMoment);
              secondMoment.assign(newSecondMoment);
              var newValue = add(mul(div(biasCorrectedFirstMoment, add(sqrt(biasCorrectedSecondMoment), _this.epsilon)), -_this.learningRate), value);
              value.assign(newValue);
            });
            _this.accBeta1.assign(mul(_this.accBeta1, _this.beta1));
            _this.accBeta2.assign(mul(_this.accBeta2, _this.beta2));
          });
          this.incrementIterations();
        };
        AdamOptimizer2.prototype.dispose = function() {
          this.accBeta1.dispose();
          this.accBeta2.dispose();
          if (this.accumulatedFirstMoment != null) {
            dispose(this.accumulatedFirstMoment.map(function(v) {
              return v.variable;
            }));
          }
          if (this.accumulatedSecondMoment != null) {
            dispose(this.accumulatedSecondMoment.map(function(v) {
              return v.variable;
            }));
          }
        };
        AdamOptimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            var variables;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  variables = __spreadArray(__spreadArray([], __read(this.accumulatedFirstMoment), false), __read(this.accumulatedSecondMoment), false);
                  return [4, this.saveIterations()];
                case 1:
                  return [2, [_a.sent()].concat(variables.map(function(v) {
                    return { name: v.originalName, tensor: v.variable };
                  }))];
              }
            });
          });
        };
        AdamOptimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            var variableCount, trainable;
            var _this = this;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.extractIterations(weightValues)];
                case 1:
                  weightValues = _a.sent();
                  tidy(function() {
                    _this.accBeta1.assign(pow(_this.beta1, _this.iterations_ + 1));
                    _this.accBeta2.assign(pow(_this.beta2, _this.iterations_ + 1));
                  });
                  variableCount = weightValues.length / 2;
                  trainable = false;
                  this.accumulatedFirstMoment = weightValues.slice(0, variableCount).map(function(v) {
                    return {
                      originalName: v.name,
                      variable: v.tensor.variable(trainable)
                    };
                  });
                  this.accumulatedSecondMoment = weightValues.slice(variableCount, variableCount * 2).map(function(v) {
                    return {
                      originalName: v.name,
                      variable: v.tensor.variable(trainable)
                    };
                  });
                  return [
                    2
                    /*return*/
                  ];
              }
            });
          });
        };
        AdamOptimizer2.prototype.getConfig = function() {
          return {
            "learningRate": this.learningRate,
            "beta1": this.beta1,
            "beta2": this.beta2,
            "epsilon": this.epsilon
          };
        };
        AdamOptimizer2.fromConfig = function(cls, config) {
          return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"]);
        };
        return AdamOptimizer2;
      }(Optimizer)
    );
    var AdamaxOptimizer = (
      /** @class */
      function(_super) {
        __extends(AdamaxOptimizer2, _super);
        function AdamaxOptimizer2(learningRate, beta1, beta2, epsilon, decay) {
          if (epsilon === void 0) {
            epsilon = null;
          }
          if (decay === void 0) {
            decay = 0;
          }
          var _this = _super.call(this) || this;
          _this.learningRate = learningRate;
          _this.beta1 = beta1;
          _this.beta2 = beta2;
          _this.epsilon = epsilon;
          _this.decay = decay;
          _this.accumulatedFirstMoment = [];
          _this.accumulatedWeightedInfNorm = [];
          tidy(function() {
            _this.iteration = scalar(0).variable();
            _this.accBeta1 = scalar(beta1).variable();
          });
          if (epsilon == null) {
            _this.epsilon = ENGINE.backend.epsilon();
          }
          return _this;
        }
        Object.defineProperty(AdamaxOptimizer2, "className", {
          /** @nocollapse */
          get: function() {
            return "Adamax";
          },
          enumerable: false,
          configurable: true
        });
        AdamaxOptimizer2.prototype.applyGradients = function(variableGradients) {
          var _this = this;
          var variableNames = Array.isArray(variableGradients) ? variableGradients.map(function(item) {
            return item.name;
          }) : Object.keys(variableGradients);
          tidy(function() {
            var oneMinusAccBeta1 = sub(1, _this.accBeta1);
            var lr = div(-_this.learningRate, add(mul(_this.iteration, _this.decay), 1));
            variableNames.forEach(function(name, i) {
              var value = ENGINE.registeredVariables[name];
              var trainable = false;
              if (_this.accumulatedFirstMoment[i] == null) {
                _this.accumulatedFirstMoment[i] = {
                  originalName: "".concat(name, "/m"),
                  variable: zerosLike(value).variable(trainable)
                };
              }
              if (_this.accumulatedWeightedInfNorm[i] == null) {
                _this.accumulatedWeightedInfNorm[i] = {
                  originalName: "".concat(name, "/v"),
                  variable: zerosLike(value).variable(trainable)
                };
              }
              var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
              if (gradient == null) {
                return;
              }
              var firstMoment = _this.accumulatedFirstMoment[i].variable;
              var weightedInfNorm = _this.accumulatedWeightedInfNorm[i].variable;
              var newFirstMoment = add(mul(firstMoment, _this.beta1), mul(gradient, 1 - _this.beta1));
              var ut0 = mul(weightedInfNorm, _this.beta2);
              var ut1 = abs(gradient);
              var newWeightedInfNorm = maximum(ut0, ut1);
              firstMoment.assign(newFirstMoment);
              weightedInfNorm.assign(newWeightedInfNorm);
              var newValue = add(mul(div(lr, oneMinusAccBeta1), div(newFirstMoment, add(newWeightedInfNorm, _this.epsilon))), value);
              value.assign(newValue);
            });
            _this.iteration.assign(add(_this.iteration, 1));
            _this.accBeta1.assign(mul(_this.accBeta1, _this.beta1));
          });
          this.incrementIterations();
        };
        AdamaxOptimizer2.prototype.dispose = function() {
          this.accBeta1.dispose();
          this.iteration.dispose();
          if (this.accumulatedFirstMoment != null) {
            dispose(this.accumulatedFirstMoment.map(function(v) {
              return v.variable;
            }));
          }
          if (this.accumulatedWeightedInfNorm != null) {
            dispose(this.accumulatedWeightedInfNorm.map(function(v) {
              return v.variable;
            }));
          }
        };
        AdamaxOptimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              throw new Error("getWeights() is not implemented for Adamax yet.");
            });
          });
        };
        AdamaxOptimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              throw new Error("setWeights() is not implemented for Adamax yet.");
            });
          });
        };
        AdamaxOptimizer2.prototype.getConfig = function() {
          return {
            "learningRate": this.learningRate,
            "beta1": this.beta1,
            "beta2": this.beta2,
            "epsilon": this.epsilon,
            "decay": this.decay
          };
        };
        AdamaxOptimizer2.fromConfig = function(cls, config) {
          return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"], config["decay"]);
        };
        return AdamaxOptimizer2;
      }(Optimizer)
    );
    var SGDOptimizer = (
      /** @class */
      function(_super) {
        __extends(SGDOptimizer2, _super);
        function SGDOptimizer2(learningRate) {
          var _this = _super.call(this) || this;
          _this.learningRate = learningRate;
          _this.setLearningRate(learningRate);
          return _this;
        }
        Object.defineProperty(SGDOptimizer2, "className", {
          /** @nocollapse */
          get: function() {
            return "SGD";
          },
          enumerable: false,
          configurable: true
        });
        SGDOptimizer2.prototype.applyGradients = function(variableGradients) {
          var _this = this;
          var varNames = Array.isArray(variableGradients) ? variableGradients.map(function(v) {
            return v.name;
          }) : Object.keys(variableGradients);
          varNames.forEach(function(name, i) {
            var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            var value = ENGINE.registeredVariables[name];
            tidy(function() {
              var newValue = add(mul(_this.c, gradient), value);
              value.assign(newValue);
            });
          });
          this.incrementIterations();
        };
        SGDOptimizer2.prototype.setLearningRate = function(learningRate) {
          this.learningRate = learningRate;
          if (this.c != null) {
            this.c.dispose();
          }
          this.c = keep(scalar(-learningRate));
        };
        SGDOptimizer2.prototype.dispose = function() {
          this.c.dispose();
        };
        SGDOptimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.saveIterations()];
                case 1:
                  return [2, [_a.sent()]];
              }
            });
          });
        };
        SGDOptimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.extractIterations(weightValues)];
                case 1:
                  weightValues = _a.sent();
                  if (weightValues.length !== 0) {
                    throw new Error("SGD optimizer does not have settable weights.");
                  }
                  return [
                    2
                    /*return*/
                  ];
              }
            });
          });
        };
        SGDOptimizer2.prototype.getConfig = function() {
          return { "learningRate": this.learningRate };
        };
        SGDOptimizer2.fromConfig = function(cls, config) {
          return new cls(config["learningRate"]);
        };
        return SGDOptimizer2;
      }(Optimizer)
    );
    var MomentumOptimizer = (
      /** @class */
      function(_super) {
        __extends(MomentumOptimizer2, _super);
        function MomentumOptimizer2(learningRate, momentum, useNesterov) {
          if (useNesterov === void 0) {
            useNesterov = false;
          }
          var _this = _super.call(this, learningRate) || this;
          _this.learningRate = learningRate;
          _this.momentum = momentum;
          _this.useNesterov = useNesterov;
          _this.accumulations = [];
          _this.m = scalar(_this.momentum);
          return _this;
        }
        Object.defineProperty(MomentumOptimizer2, "className", {
          /** @nocollapse */
          // Name matters for Python compatibility.
          get: function() {
            return "Momentum";
          },
          enumerable: false,
          configurable: true
        });
        MomentumOptimizer2.prototype.applyGradients = function(variableGradients) {
          var _this = this;
          var variableNames = Array.isArray(variableGradients) ? variableGradients.map(function(item) {
            return item.name;
          }) : Object.keys(variableGradients);
          variableNames.forEach(function(name, i) {
            var value = ENGINE.registeredVariables[name];
            if (_this.accumulations[i] == null) {
              var trainable_1 = false;
              _this.accumulations[i] = {
                originalName: "".concat(name, "/momentum"),
                variable: tidy(function() {
                  return zerosLike(value).variable(trainable_1);
                })
              };
            }
            var accumulation = _this.accumulations[i].variable;
            var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            tidy(function() {
              var newValue;
              var newAccumulation = add(mul(_this.m, accumulation), gradient);
              if (_this.useNesterov) {
                newValue = add(mul(_this.c, add(gradient, mul(newAccumulation, _this.m))), value);
              } else {
                newValue = add(mul(_this.c, newAccumulation), value);
              }
              accumulation.assign(newAccumulation);
              value.assign(newValue);
            });
          });
          this.incrementIterations();
        };
        MomentumOptimizer2.prototype.dispose = function() {
          this.m.dispose();
          if (this.accumulations != null) {
            dispose(this.accumulations.map(function(v) {
              return v.variable;
            }));
          }
        };
        MomentumOptimizer2.prototype.setMomentum = function(momentum) {
          this.momentum = momentum;
        };
        MomentumOptimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.saveIterations()];
                case 1:
                  return [2, [_a.sent()].concat(this.accumulations.map(function(v) {
                    return { name: v.originalName, tensor: v.variable };
                  }))];
              }
            });
          });
        };
        MomentumOptimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            var trainable;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.extractIterations(weightValues)];
                case 1:
                  weightValues = _a.sent();
                  trainable = false;
                  this.accumulations = weightValues.map(function(v) {
                    return { originalName: v.name, variable: v.tensor.variable(trainable) };
                  });
                  return [
                    2
                    /*return*/
                  ];
              }
            });
          });
        };
        MomentumOptimizer2.prototype.getConfig = function() {
          return {
            "learningRate": this.learningRate,
            "momentum": this.momentum,
            "useNesterov": this.useNesterov
          };
        };
        MomentumOptimizer2.fromConfig = function(cls, config) {
          return new cls(config["learningRate"], config["momentum"], config["useNesterov"]);
        };
        return MomentumOptimizer2;
      }(SGDOptimizer)
    );
    var RMSPropOptimizer = (
      /** @class */
      function(_super) {
        __extends(RMSPropOptimizer2, _super);
        function RMSPropOptimizer2(learningRate, decay, momentum, epsilon, centered) {
          if (decay === void 0) {
            decay = 0.9;
          }
          if (momentum === void 0) {
            momentum = 0;
          }
          if (epsilon === void 0) {
            epsilon = null;
          }
          if (centered === void 0) {
            centered = false;
          }
          var _this = _super.call(this) || this;
          _this.learningRate = learningRate;
          _this.decay = decay;
          _this.momentum = momentum;
          _this.epsilon = epsilon;
          _this.accumulatedMeanSquares = [];
          _this.accumulatedMoments = [];
          _this.accumulatedMeanGrads = [];
          _this.centered = centered;
          if (epsilon == null) {
            _this.epsilon = ENGINE.backend.epsilon();
          }
          if (learningRate == null) {
            throw new Error("learningRate for RMSPropOptimizer must be defined.");
          }
          return _this;
        }
        Object.defineProperty(RMSPropOptimizer2, "className", {
          /** @nocollapse */
          get: function() {
            return "RMSProp";
          },
          enumerable: false,
          configurable: true
        });
        RMSPropOptimizer2.prototype.applyGradients = function(variableGradients) {
          var _this = this;
          var variableNames = Array.isArray(variableGradients) ? variableGradients.map(function(item) {
            return item.name;
          }) : Object.keys(variableGradients);
          variableNames.forEach(function(name, i) {
            var value = ENGINE.registeredVariables[name];
            var trainable = false;
            if (_this.accumulatedMeanSquares[i] == null) {
              _this.accumulatedMeanSquares[i] = {
                originalName: "".concat(name, "/rms"),
                variable: tidy(function() {
                  return zerosLike(value).variable(trainable);
                })
              };
            }
            if (_this.accumulatedMoments[i] == null) {
              _this.accumulatedMoments[i] = {
                originalName: "".concat(name, "/momentum"),
                variable: tidy(function() {
                  return zerosLike(value).variable(trainable);
                })
              };
            }
            if (_this.accumulatedMeanGrads[i] == null && _this.centered) {
              _this.accumulatedMeanGrads[i] = {
                originalName: "".concat(name, "/mg"),
                variable: tidy(function() {
                  return zerosLike(value).variable(trainable);
                })
              };
            }
            var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            var accumulatedMeanSquare = _this.accumulatedMeanSquares[i].variable;
            var accumulatedMoments = _this.accumulatedMoments[i].variable;
            tidy(function() {
              var newAccumulatedMeanSquare = add(mul(accumulatedMeanSquare, _this.decay), mul(square(gradient), 1 - _this.decay));
              if (_this.centered) {
                var accumulatedMeanGrad = _this.accumulatedMeanGrads[i].variable;
                var newAccumulatedMeanGrad = add(mul(accumulatedMeanGrad, _this.decay), mul(gradient, 1 - _this.decay));
                var gradContribution = div(mul(gradient, _this.learningRate), sqrt(sub(newAccumulatedMeanSquare, add(square(newAccumulatedMeanGrad), _this.epsilon))));
                var newAccumulatedMoments = add(mul(accumulatedMoments, _this.momentum), gradContribution);
                accumulatedMeanSquare.assign(newAccumulatedMeanSquare);
                accumulatedMeanGrad.assign(newAccumulatedMeanGrad);
                accumulatedMoments.assign(newAccumulatedMoments);
                var newValue = sub(value, newAccumulatedMoments);
                value.assign(newValue);
              } else {
                var newAccumulatedMeanSquare_1 = add(mul(accumulatedMeanSquare, _this.decay), mul(square(gradient), 1 - _this.decay));
                var newAccumulatedMoments = add(mul(accumulatedMoments, _this.momentum), div(mul(gradient, _this.learningRate), sqrt(add(newAccumulatedMeanSquare_1, _this.epsilon))));
                accumulatedMeanSquare.assign(newAccumulatedMeanSquare_1);
                accumulatedMoments.assign(newAccumulatedMoments);
                var newValue = sub(value, newAccumulatedMoments);
                value.assign(newValue);
              }
            });
          });
          this.incrementIterations();
        };
        RMSPropOptimizer2.prototype.dispose = function() {
          if (this.accumulatedMeanSquares != null) {
            dispose(this.accumulatedMeanSquares.map(function(v) {
              return v.variable;
            }));
          }
          if (this.accumulatedMeanGrads != null && this.centered) {
            dispose(this.accumulatedMeanGrads.map(function(v) {
              return v.variable;
            }));
          }
          if (this.accumulatedMoments != null) {
            dispose(this.accumulatedMoments.map(function(v) {
              return v.variable;
            }));
          }
        };
        RMSPropOptimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            var variables;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  variables = __spreadArray(__spreadArray([], __read(this.accumulatedMeanSquares), false), __read(this.accumulatedMoments), false);
                  if (this.centered) {
                    variables.push.apply(variables, __spreadArray([], __read(this.accumulatedMeanGrads), false));
                  }
                  return [4, this.saveIterations()];
                case 1:
                  return [2, [_a.sent()].concat(variables.map(function(v) {
                    return { name: v.originalName, tensor: v.variable };
                  }))];
              }
            });
          });
        };
        RMSPropOptimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            var variableCount, trainable;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.extractIterations(weightValues)];
                case 1:
                  weightValues = _a.sent();
                  variableCount = this.centered ? weightValues.length / 3 : weightValues.length / 2;
                  trainable = false;
                  this.accumulatedMeanSquares = weightValues.slice(0, variableCount).map(function(v) {
                    return {
                      originalName: v.name,
                      variable: v.tensor.variable(trainable)
                    };
                  });
                  this.accumulatedMoments = weightValues.slice(variableCount, variableCount * 2).map(function(v) {
                    return {
                      originalName: v.name,
                      variable: v.tensor.variable(trainable)
                    };
                  });
                  if (this.centered) {
                    this.accumulatedMeanGrads = weightValues.slice(variableCount * 2, variableCount * 3).map(function(v) {
                      return {
                        originalName: v.name,
                        variable: v.tensor.variable(trainable)
                      };
                    });
                  }
                  return [
                    2
                    /*return*/
                  ];
              }
            });
          });
        };
        RMSPropOptimizer2.prototype.getConfig = function() {
          return {
            "learningRate": this.learningRate,
            "decay": this.decay,
            "momentum": this.momentum,
            "epsilon": this.epsilon,
            "centered": this.centered
          };
        };
        RMSPropOptimizer2.fromConfig = function(cls, config) {
          return new cls(config["learningRate"], config["decay"], config["momentum"], config["epsilon"], config["centered"]);
        };
        return RMSPropOptimizer2;
      }(Optimizer)
    );
    var OPTIMIZERS = [
      AdadeltaOptimizer,
      AdagradOptimizer,
      AdamOptimizer,
      AdamaxOptimizer,
      MomentumOptimizer,
      RMSPropOptimizer,
      SGDOptimizer
    ];
    function registerOptimizers() {
      var e_1, _a;
      try {
        for (var OPTIMIZERS_1 = __values(OPTIMIZERS), OPTIMIZERS_1_1 = OPTIMIZERS_1.next(); !OPTIMIZERS_1_1.done; OPTIMIZERS_1_1 = OPTIMIZERS_1.next()) {
          var optimizer = OPTIMIZERS_1_1.value;
          registerClass(optimizer);
        }
      } catch (e_1_1) {
        e_1 = { error: e_1_1 };
      } finally {
        try {
          if (OPTIMIZERS_1_1 && !OPTIMIZERS_1_1.done && (_a = OPTIMIZERS_1.return))
            _a.call(OPTIMIZERS_1);
        } finally {
          if (e_1)
            throw e_1.error;
        }
      }
    }
    var DEFAULT_FILE_NAME_PREFIX = "model";
    var DEFAULT_JSON_EXTENSION_NAME = ".json";
    var DEFAULT_WEIGHT_DATA_EXTENSION_NAME = ".weights.bin";
    function defer(f) {
      return new Promise(function(resolve) {
        return setTimeout(resolve);
      }).then(f);
    }
    var BrowserDownloads = (
      /** @class */
      function() {
        function BrowserDownloads2(fileNamePrefix) {
          if (!env().getBool("IS_BROWSER")) {
            throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");
          }
          if (fileNamePrefix.startsWith(BrowserDownloads2.URL_SCHEME)) {
            fileNamePrefix = fileNamePrefix.slice(BrowserDownloads2.URL_SCHEME.length);
          }
          if (fileNamePrefix == null || fileNamePrefix.length === 0) {
            fileNamePrefix = DEFAULT_FILE_NAME_PREFIX;
          }
          this.modelJsonFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME;
          this.weightDataFileName = fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;
        }
        BrowserDownloads2.prototype.save = function(modelArtifacts) {
          return __awaiter(this, void 0, void 0, function() {
            var weightBuffer, weightsURL, weightsManifest, modelJSON, modelJsonURL, jsonAnchor_1, weightDataAnchor_1;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  if (typeof document === "undefined") {
                    throw new Error("Browser downloads are not supported in this environment since `document` is not present");
                  }
                  weightBuffer = CompositeArrayBuffer.join(modelArtifacts.weightData);
                  weightsURL = window.URL.createObjectURL(new Blob([weightBuffer], { type: "application/octet-stream" }));
                  if (!(modelArtifacts.modelTopology instanceof ArrayBuffer))
                    return [3, 1];
                  throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");
                case 1:
                  weightsManifest = [{
                    paths: ["./" + this.weightDataFileName],
                    weights: modelArtifacts.weightSpecs
                  }];
                  modelJSON = getModelJSONForModelArtifacts(modelArtifacts, weightsManifest);
                  modelJsonURL = window.URL.createObjectURL(new Blob([JSON.stringify(modelJSON)], { type: "application/json" }));
                  jsonAnchor_1 = this.modelJsonAnchor == null ? document.createElement("a") : this.modelJsonAnchor;
                  jsonAnchor_1.download = this.modelJsonFileName;
                  jsonAnchor_1.href = modelJsonURL;
                  return [4, defer(function() {
                    return jsonAnchor_1.dispatchEvent(new MouseEvent("click"));
                  })];
                case 2:
                  _a.sent();
                  if (!(modelArtifacts.weightData != null))
                    return [3, 4];
                  weightDataAnchor_1 = this.weightDataAnchor == null ? document.createElement("a") : this.weightDataAnchor;
                  weightDataAnchor_1.download = this.weightDataFileName;
                  weightDataAnchor_1.href = weightsURL;
                  return [4, defer(function() {
                    return weightDataAnchor_1.dispatchEvent(new MouseEvent("click"));
                  })];
                case 3:
                  _a.sent();
                  _a.label = 4;
                case 4:
                  return [2, { modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts) }];
              }
            });
          });
        };
        return BrowserDownloads2;
      }()
    );
    BrowserDownloads.URL_SCHEME = "downloads://";
    var BrowserFiles = (
      /** @class */
      function() {
        function BrowserFiles2(files) {
          if (files == null || files.length < 1) {
            throw new Error("When calling browserFiles, at least 1 file is required, " + "but received ".concat(files));
          }
          this.jsonFile = files[0];
          this.weightsFiles = files.slice(1);
        }
        BrowserFiles2.prototype.load = function() {
          return __awaiter(this, void 0, void 0, function() {
            var _this = this;
            return __generator(this, function(_a) {
              return [2, new Promise(function(resolve, reject) {
                var jsonReader = new FileReader();
                jsonReader.onload = function(event) {
                  var modelJSON = JSON.parse(event.target.result);
                  var modelTopology = modelJSON.modelTopology;
                  if (modelTopology == null) {
                    reject(new Error("modelTopology field is missing from file ".concat(_this.jsonFile.name)));
                    return;
                  }
                  var weightsManifest = modelJSON.weightsManifest;
                  if (weightsManifest == null) {
                    reject(new Error("weightManifest field is missing from file ".concat(_this.jsonFile.name)));
                    return;
                  }
                  if (_this.weightsFiles.length === 0) {
                    resolve({ modelTopology });
                    return;
                  }
                  var modelArtifactsPromise = getModelArtifactsForJSON(modelJSON, function(weightsManifest2) {
                    return _this.loadWeights(weightsManifest2);
                  });
                  resolve(modelArtifactsPromise);
                };
                jsonReader.onerror = function(error) {
                  return reject("Failed to read model topology and weights manifest JSON " + "from file '".concat(_this.jsonFile.name, "'. BrowserFiles supports loading ") + "Keras-style tf.Model artifacts only.");
                };
                jsonReader.readAsText(_this.jsonFile);
              })];
            });
          });
        };
        BrowserFiles2.prototype.loadWeights = function(weightsManifest) {
          var e_1, _a;
          var _this = this;
          var weightSpecs = [];
          var paths = [];
          try {
            for (var weightsManifest_1 = __values(weightsManifest), weightsManifest_1_1 = weightsManifest_1.next(); !weightsManifest_1_1.done; weightsManifest_1_1 = weightsManifest_1.next()) {
              var entry = weightsManifest_1_1.value;
              weightSpecs.push.apply(weightSpecs, __spreadArray([], __read(entry.weights), false));
              paths.push.apply(paths, __spreadArray([], __read(entry.paths), false));
            }
          } catch (e_1_1) {
            e_1 = { error: e_1_1 };
          } finally {
            try {
              if (weightsManifest_1_1 && !weightsManifest_1_1.done && (_a = weightsManifest_1.return))
                _a.call(weightsManifest_1);
            } finally {
              if (e_1)
                throw e_1.error;
            }
          }
          var pathToFile = this.checkManifestAndWeightFiles(weightsManifest);
          var promises = paths.map(function(path) {
            return _this.loadWeightsFile(path, pathToFile[path]);
          });
          return Promise.all(promises).then(function(buffers) {
            return [weightSpecs, buffers];
          });
        };
        BrowserFiles2.prototype.loadWeightsFile = function(path, file) {
          return new Promise(function(resolve, reject) {
            var weightFileReader = new FileReader();
            weightFileReader.onload = function(event) {
              var weightData = event.target.result;
              resolve(weightData);
            };
            weightFileReader.onerror = function(error) {
              return reject("Failed to weights data from file of path '".concat(path, "'."));
            };
            weightFileReader.readAsArrayBuffer(file);
          });
        };
        BrowserFiles2.prototype.checkManifestAndWeightFiles = function(manifest) {
          var e_2, _a;
          var _this = this;
          var basenames = [];
          var fileNames = this.weightsFiles.map(function(file) {
            return basename(file.name);
          });
          var pathToFile = {};
          try {
            for (var manifest_1 = __values(manifest), manifest_1_1 = manifest_1.next(); !manifest_1_1.done; manifest_1_1 = manifest_1.next()) {
              var group = manifest_1_1.value;
              group.paths.forEach(function(path) {
                var pathBasename = basename(path);
                if (basenames.indexOf(pathBasename) !== -1) {
                  throw new Error("Duplicate file basename found in weights manifest: " + "'".concat(pathBasename, "'"));
                }
                basenames.push(pathBasename);
                if (fileNames.indexOf(pathBasename) === -1) {
                  throw new Error("Weight file with basename '".concat(pathBasename, "' is not provided."));
                } else {
                  pathToFile[path] = _this.weightsFiles[fileNames.indexOf(pathBasename)];
                }
              });
            }
          } catch (e_2_1) {
            e_2 = { error: e_2_1 };
          } finally {
            try {
              if (manifest_1_1 && !manifest_1_1.done && (_a = manifest_1.return))
                _a.call(manifest_1);
            } finally {
              if (e_2)
                throw e_2.error;
            }
          }
          if (basenames.length !== this.weightsFiles.length) {
            throw new Error("Mismatch in the number of files in weights manifest " + "(".concat(basenames.length, ") and the number of weight files provided ") + "(".concat(this.weightsFiles.length, ")."));
          }
          return pathToFile;
        };
        return BrowserFiles2;
      }()
    );
    var browserDownloadsRouter = function(url) {
      if (!env().getBool("IS_BROWSER")) {
        return null;
      } else {
        if (!Array.isArray(url) && url.startsWith(BrowserDownloads.URL_SCHEME)) {
          return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length));
        } else {
          return null;
        }
      }
    };
    IORouterRegistry.registerSaveRouter(browserDownloadsRouter);
    function browserDownloads(fileNamePrefix) {
      if (fileNamePrefix === void 0) {
        fileNamePrefix = "model";
      }
      return new BrowserDownloads(fileNamePrefix);
    }
    function browserFiles(files) {
      return new BrowserFiles(files);
    }
    function monitorPromisesProgress(promises, onProgress, startFraction, endFraction) {
      checkPromises(promises);
      startFraction = startFraction == null ? 0 : startFraction;
      endFraction = endFraction == null ? 1 : endFraction;
      checkFraction(startFraction, endFraction);
      var resolvedPromise = 0;
      var registerMonitor = function(promise) {
        promise.then(function(value) {
          var fraction = startFraction + ++resolvedPromise / promises.length * (endFraction - startFraction);
          onProgress(fraction);
          return value;
        });
        return promise;
      };
      function checkPromises(promises2) {
        assert(promises2 != null && Array.isArray(promises2) && promises2.length > 0, function() {
          return "promises must be a none empty array";
        });
      }
      function checkFraction(startFraction2, endFraction2) {
        assert(startFraction2 >= 0 && startFraction2 <= 1, function() {
          return "Progress fraction must be in range [0, 1], but " + "got startFraction ".concat(startFraction2);
        });
        assert(endFraction2 >= 0 && endFraction2 <= 1, function() {
          return "Progress fraction must be in range [0, 1], but " + "got endFraction ".concat(endFraction2);
        });
        assert(endFraction2 >= startFraction2, function() {
          return "startFraction must be no more than endFraction, but " + "got startFraction ".concat(startFraction2, " and endFraction ") + "".concat(endFraction2);
        });
      }
      return Promise.all(promises.map(registerMonitor));
    }
    function loadWeightsAsArrayBuffer(fetchURLs, loadOptions) {
      return __awaiter(this, void 0, void 0, function() {
        var fetchFunc, requests, fetchStartFraction, fetchEndFraction, responses, _b, bufferPromises, bufferStartFraction, bufferEndFraction, buffers, _c;
        return __generator(this, function(_d) {
          switch (_d.label) {
            case 0:
              if (loadOptions == null) {
                loadOptions = {};
              }
              fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch : loadOptions.fetchFunc;
              requests = fetchURLs.map(function(fetchURL) {
                return fetchFunc(fetchURL, loadOptions.requestInit, { isBinary: true });
              });
              fetchStartFraction = 0;
              fetchEndFraction = 0.5;
              if (!(loadOptions.onProgress == null))
                return [3, 2];
              return [4, Promise.all(requests)];
            case 1:
              _b = _d.sent();
              return [3, 4];
            case 2:
              return [4, monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction)];
            case 3:
              _b = _d.sent();
              _d.label = 4;
            case 4:
              responses = _b;
              bufferPromises = responses.map(function(response) {
                return response.arrayBuffer();
              });
              bufferStartFraction = 0.5;
              bufferEndFraction = 1;
              if (!(loadOptions.onProgress == null))
                return [3, 6];
              return [4, Promise.all(bufferPromises)];
            case 5:
              _c = _d.sent();
              return [3, 8];
            case 6:
              return [4, monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction)];
            case 7:
              _c = _d.sent();
              _d.label = 8;
            case 8:
              buffers = _c;
              return [2, buffers];
          }
        });
      });
    }
    function streamWeights(fetchURLs, loadOptions) {
      var _this = this;
      var _a;
      var fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch : loadOptions.fetchFunc;
      var fetchIndex = 0;
      var chunkReader;
      (_a = loadOptions.onProgress) === null || _a === void 0 ? void 0 : _a.call(loadOptions, 0);
      return new ReadableStream({
        pull: function(controller) {
          return __awaiter(_this, void 0, void 0, function() {
            var _a2, body, _b, done, value;
            return __generator(this, function(_c) {
              switch (_c.label) {
                case 0:
                  if (!(fetchIndex < fetchURLs.length))
                    return [3, 4];
                  if (!!chunkReader)
                    return [3, 2];
                  return [4, fetchFunc(fetchURLs[fetchIndex], loadOptions.requestInit, { isBinary: true })];
                case 1:
                  body = _c.sent().body;
                  chunkReader = body.getReader();
                  _c.label = 2;
                case 2:
                  return [4, chunkReader.read()];
                case 3:
                  _b = _c.sent(), done = _b.done, value = _b.value;
                  if (done) {
                    fetchIndex++;
                    chunkReader = void 0;
                    (_a2 = loadOptions.onProgress) === null || _a2 === void 0 ? void 0 : _a2.call(loadOptions, fetchIndex / fetchURLs.length);
                    return [3, 0];
                  }
                  controller.enqueue(value);
                  return [
                    2
                    /*return*/
                  ];
                case 4:
                  controller.close();
                  return [
                    2
                    /*return*/
                  ];
              }
            });
          });
        }
      });
    }
    function loadWeights(manifest, filePathPrefix, weightNames, requestInit) {
      if (filePathPrefix === void 0) {
        filePathPrefix = "";
      }
      return __awaiter(this, void 0, void 0, function() {
        var fetchWeights, loadWeights2;
        return __generator(this, function(_b) {
          fetchWeights = function(fetchUrls) {
            return loadWeightsAsArrayBuffer(fetchUrls, { requestInit });
          };
          loadWeights2 = weightsLoaderFactory(fetchWeights);
          return [2, loadWeights2(manifest, filePathPrefix, weightNames)];
        });
      });
    }
    function weightsLoaderFactory(fetchWeightsFunction) {
      var _this = this;
      return function(manifest, filePathPrefix, weightNames) {
        if (filePathPrefix === void 0) {
          filePathPrefix = "";
        }
        return __awaiter(_this, void 0, void 0, function() {
          var groupIndicesToFetchMap, groupWeightsToFetch, weightsFound, allManifestWeightNames, weightsNotFound, groupIndicesToFetch, fetchUrls, buffers, weightsTensorMap, bufferIndexOffset;
          return __generator(this, function(_b) {
            switch (_b.label) {
              case 0:
                groupIndicesToFetchMap = manifest.map(function() {
                  return false;
                });
                groupWeightsToFetch = {};
                weightsFound = weightNames != null ? weightNames.map(function() {
                  return false;
                }) : [];
                allManifestWeightNames = [];
                manifest.forEach(function(manifestGroupConfig, groupIndex) {
                  var groupOffset = 0;
                  manifestGroupConfig.weights.forEach(function(weightsEntry) {
                    var rawDtype = "quantization" in weightsEntry ? weightsEntry.quantization.dtype : weightsEntry.dtype;
                    var weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] * sizeFromShape(weightsEntry.shape);
                    var enqueueWeightsForFetchingFn = function() {
                      groupIndicesToFetchMap[groupIndex] = true;
                      if (groupWeightsToFetch[groupIndex] == null) {
                        groupWeightsToFetch[groupIndex] = [];
                      }
                      groupWeightsToFetch[groupIndex].push({
                        manifestEntry: weightsEntry,
                        groupOffset,
                        sizeBytes: weightsBytes
                      });
                    };
                    if (weightNames != null) {
                      weightNames.forEach(function(weightName, weightIndex) {
                        if (weightName === weightsEntry.name) {
                          enqueueWeightsForFetchingFn();
                          weightsFound[weightIndex] = true;
                        }
                      });
                    } else {
                      enqueueWeightsForFetchingFn();
                    }
                    allManifestWeightNames.push(weightsEntry.name);
                    groupOffset += weightsBytes;
                  });
                });
                if (!weightsFound.every(function(found) {
                  return found;
                })) {
                  weightsNotFound = weightNames.filter(function(_, i) {
                    return !weightsFound[i];
                  });
                  throw new Error("Could not find weights in manifest with names: " + "".concat(weightsNotFound.join(", "), ". \n") + "Manifest JSON has weights with names: " + "".concat(allManifestWeightNames.join(", "), "."));
                }
                groupIndicesToFetch = groupIndicesToFetchMap.reduce(function(accumulator, shouldFetch, i) {
                  if (shouldFetch) {
                    accumulator.push(i);
                  }
                  return accumulator;
                }, []);
                fetchUrls = [];
                groupIndicesToFetch.forEach(function(i) {
                  manifest[i].paths.forEach(function(filepath) {
                    var fetchUrl = filePathPrefix + (!filePathPrefix.endsWith("/") ? "/" : "") + filepath;
                    fetchUrls.push(fetchUrl);
                  });
                });
                return [4, fetchWeightsFunction(fetchUrls)];
              case 1:
                buffers = _b.sent();
                weightsTensorMap = {};
                bufferIndexOffset = 0;
                groupIndicesToFetch.forEach(function(i) {
                  var numBuffers = manifest[i].paths.length;
                  var weightsBuffer = new CompositeArrayBuffer(buffers.slice(bufferIndexOffset, bufferIndexOffset + numBuffers));
                  var weightsEntries = groupWeightsToFetch[i];
                  weightsEntries.forEach(function(weightsEntry) {
                    var byteBuffer = weightsBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);
                    var nameToTensorMap = decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);
                    for (var name in nameToTensorMap) {
                      weightsTensorMap[name] = nameToTensorMap[name];
                    }
                  });
                  bufferIndexOffset += numBuffers;
                });
                return [2, weightsTensorMap];
            }
          });
        });
      };
    }
    var OCTET_STREAM_MIME_TYPE = "application/octet-stream";
    var JSON_TYPE = "application/json";
    var HTTPRequest = (
      /** @class */
      function() {
        function HTTPRequest2(path, loadOptions) {
          this.DEFAULT_METHOD = "POST";
          if (loadOptions == null) {
            loadOptions = {};
          }
          this.weightPathPrefix = loadOptions.weightPathPrefix;
          this.weightUrlConverter = loadOptions.weightUrlConverter;
          if (loadOptions.fetchFunc != null) {
            assert(typeof loadOptions.fetchFunc === "function", function() {
              return "Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)";
            });
            this.fetch = loadOptions.fetchFunc;
          } else {
            this.fetch = env().platform.fetch;
          }
          assert(path != null && path.length > 0, function() {
            return "URL path for http must not be null, undefined or empty.";
          });
          if (Array.isArray(path)) {
            assert(path.length === 2, function() {
              return "URL paths for http must have a length of 2, " + "(actual length is ".concat(path.length, ").");
            });
          }
          this.path = path;
          if (loadOptions.requestInit != null && loadOptions.requestInit.body != null) {
            throw new Error("requestInit is expected to have no pre-existing body, but has one.");
          }
          this.requestInit = loadOptions.requestInit || {};
          this.loadOptions = loadOptions;
        }
        HTTPRequest2.prototype.save = function(modelArtifacts) {
          return __awaiter(this, void 0, void 0, function() {
            var init, weightsManifest, modelTopologyAndWeightManifest, weightBuffer, response;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
                    throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");
                  }
                  init = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);
                  init.body = new FormData();
                  weightsManifest = [{
                    paths: ["./model.weights.bin"],
                    weights: modelArtifacts.weightSpecs
                  }];
                  modelTopologyAndWeightManifest = getModelJSONForModelArtifacts(modelArtifacts, weightsManifest);
                  init.body.append("model.json", new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: JSON_TYPE }), "model.json");
                  if (modelArtifacts.weightData != null) {
                    weightBuffer = CompositeArrayBuffer.join(modelArtifacts.weightData);
                    init.body.append("model.weights.bin", new Blob([weightBuffer], { type: OCTET_STREAM_MIME_TYPE }), "model.weights.bin");
                  }
                  return [4, this.fetch(this.path, init)];
                case 1:
                  response = _a.sent();
                  if (response.ok) {
                    return [2, {
                      modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts),
                      responses: [response]
                    }];
                  } else {
                    throw new Error("BrowserHTTPRequest.save() failed due to HTTP response status " + "".concat(response.status, "."));
                  }
              }
            });
          });
        };
        HTTPRequest2.prototype.loadModelJSON = function() {
          return __awaiter(this, void 0, void 0, function() {
            var modelConfigRequest, modelJSON, message, modelTopology, weightsManifest;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.fetch(this.path, this.requestInit)];
                case 1:
                  modelConfigRequest = _a.sent();
                  if (!modelConfigRequest.ok) {
                    throw new Error("Request to ".concat(this.path, " failed with status code ") + "".concat(modelConfigRequest.status, ". Please verify this URL points to ") + "the model JSON of the model to load.");
                  }
                  _a.label = 2;
                case 2:
                  _a.trys.push([2, 4, , 5]);
                  return [4, modelConfigRequest.json()];
                case 3:
                  modelJSON = _a.sent();
                  return [3, 5];
                case 4:
                  _a.sent();
                  message = "Failed to parse model JSON of response from ".concat(this.path, ".");
                  if (this.path.endsWith(".pb")) {
                    message += " Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.";
                  } else {
                    message += " Please make sure the server is serving valid JSON for this request.";
                  }
                  throw new Error(message);
                case 5:
                  modelTopology = modelJSON.modelTopology;
                  weightsManifest = modelJSON.weightsManifest;
                  if (modelTopology == null && weightsManifest == null) {
                    throw new Error("The JSON from HTTP path ".concat(this.path, " contains neither model ") + "topology or manifest for weights.");
                  }
                  return [2, modelJSON];
              }
            });
          });
        };
        HTTPRequest2.prototype.load = function() {
          return __awaiter(this, void 0, void 0, function() {
            var modelJSON;
            var _this = this;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  if (this.loadOptions.streamWeights) {
                    return [2, this.loadStream()];
                  }
                  return [4, this.loadModelJSON()];
                case 1:
                  modelJSON = _a.sent();
                  return [2, getModelArtifactsForJSON(modelJSON, function(weightsManifest) {
                    return _this.loadWeights(weightsManifest);
                  })];
              }
            });
          });
        };
        HTTPRequest2.prototype.loadStream = function() {
          return __awaiter(this, void 0, void 0, function() {
            var modelJSON, fetchURLs, weightSpecs, stream;
            var _this = this;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.loadModelJSON()];
                case 1:
                  modelJSON = _a.sent();
                  return [4, this.getWeightUrls(modelJSON.weightsManifest)];
                case 2:
                  fetchURLs = _a.sent();
                  weightSpecs = getWeightSpecs(modelJSON.weightsManifest);
                  stream = function() {
                    return streamWeights(fetchURLs, _this.loadOptions);
                  };
                  return [2, Object.assign(Object.assign({}, modelJSON), { weightSpecs, getWeightStream: stream })];
              }
            });
          });
        };
        HTTPRequest2.prototype.getWeightUrls = function(weightsManifest) {
          return __awaiter(this, void 0, void 0, function() {
            var weightPath, _a, prefix, suffix, pathPrefix, fetchURLs, urlPromises, weightsManifest_1, weightsManifest_1_1, weightsGroup, _b, _c, path, _d, _e, _f, _g;
            var e_2, _h, e_3, _j;
            return __generator(this, function(_k) {
              switch (_k.label) {
                case 0:
                  weightPath = Array.isArray(this.path) ? this.path[1] : this.path;
                  _a = __read(parseUrl(weightPath), 2), prefix = _a[0], suffix = _a[1];
                  pathPrefix = this.weightPathPrefix || prefix;
                  fetchURLs = [];
                  urlPromises = [];
                  try {
                    for (weightsManifest_1 = __values(weightsManifest), weightsManifest_1_1 = weightsManifest_1.next(); !weightsManifest_1_1.done; weightsManifest_1_1 = weightsManifest_1.next()) {
                      weightsGroup = weightsManifest_1_1.value;
                      try {
                        for (_b = (e_3 = void 0, __values(weightsGroup.paths)), _c = _b.next(); !_c.done; _c = _b.next()) {
                          path = _c.value;
                          if (this.weightUrlConverter != null) {
                            urlPromises.push(this.weightUrlConverter(path));
                          } else {
                            fetchURLs.push(pathPrefix + path + suffix);
                          }
                        }
                      } catch (e_3_1) {
                        e_3 = { error: e_3_1 };
                      } finally {
                        try {
                          if (_c && !_c.done && (_j = _b.return))
                            _j.call(_b);
                        } finally {
                          if (e_3)
                            throw e_3.error;
                        }
                      }
                    }
                  } catch (e_2_1) {
                    e_2 = { error: e_2_1 };
                  } finally {
                    try {
                      if (weightsManifest_1_1 && !weightsManifest_1_1.done && (_h = weightsManifest_1.return))
                        _h.call(weightsManifest_1);
                    } finally {
                      if (e_2)
                        throw e_2.error;
                    }
                  }
                  if (!this.weightUrlConverter)
                    return [3, 2];
                  _e = (_d = fetchURLs.push).apply;
                  _f = [fetchURLs];
                  _g = [[]];
                  return [4, Promise.all(urlPromises)];
                case 1:
                  _e.apply(_d, _f.concat([__spreadArray.apply(void 0, _g.concat([__read.apply(void 0, [_k.sent()]), false]))]));
                  _k.label = 2;
                case 2:
                  return [2, fetchURLs];
              }
            });
          });
        };
        HTTPRequest2.prototype.loadWeights = function(weightsManifest) {
          return __awaiter(this, void 0, void 0, function() {
            var fetchURLs, weightSpecs, buffers;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.getWeightUrls(weightsManifest)];
                case 1:
                  fetchURLs = _a.sent();
                  weightSpecs = getWeightSpecs(weightsManifest);
                  return [4, loadWeightsAsArrayBuffer(fetchURLs, this.loadOptions)];
                case 2:
                  buffers = _a.sent();
                  return [2, [weightSpecs, buffers]];
              }
            });
          });
        };
        return HTTPRequest2;
      }()
    );
    HTTPRequest.URL_SCHEME_REGEX = /^https?:\/\//;
    function parseUrl(url) {
      var lastSlash = url.lastIndexOf("/");
      var lastSearchParam = url.lastIndexOf("?");
      var prefix = url.substring(0, lastSlash);
      var suffix = lastSearchParam > lastSlash ? url.substring(lastSearchParam) : "";
      return [prefix + "/", suffix];
    }
    function isHTTPScheme(url) {
      return url.match(HTTPRequest.URL_SCHEME_REGEX) != null;
    }
    var httpRouter = function(url, loadOptions) {
      if (typeof fetch === "undefined" && (loadOptions == null || loadOptions.fetchFunc == null)) {
        return null;
      } else {
        var isHTTP = true;
        if (Array.isArray(url)) {
          isHTTP = url.every(function(urlItem) {
            return isHTTPScheme(urlItem);
          });
        } else {
          isHTTP = isHTTPScheme(url);
        }
        if (isHTTP) {
          return http(url, loadOptions);
        }
      }
      return null;
    };
    IORouterRegistry.registerSaveRouter(httpRouter);
    IORouterRegistry.registerLoadRouter(httpRouter);
    function http(path, loadOptions) {
      return new HTTPRequest(path, loadOptions);
    }
    function browserHTTPRequest(path, loadOptions) {
      return http(path, loadOptions);
    }
    var PassthroughLoader = (
      /** @class */
      function() {
        function PassthroughLoader2(modelArtifacts) {
          this.modelArtifacts = modelArtifacts;
        }
        PassthroughLoader2.prototype.load = function() {
          return this.modelArtifacts;
        };
        return PassthroughLoader2;
      }()
    );
    var PassthroughSaver = (
      /** @class */
      function() {
        function PassthroughSaver2(saveHandler) {
          this.saveHandler = saveHandler;
        }
        PassthroughSaver2.prototype.save = function(modelArtifacts) {
          return this.saveHandler(modelArtifacts);
        };
        return PassthroughSaver2;
      }()
    );
    var PassthroughAsync = (
      /** @class */
      function() {
        function PassthroughAsync2(handler) {
          if (handler.load) {
            this.load = function() {
              return Promise.resolve(handler.load());
            };
          }
          if (handler.save) {
            this.save = function(modelArtifacts) {
              return Promise.resolve(handler.save(modelArtifacts));
            };
          }
        }
        return PassthroughAsync2;
      }()
    );
    function fromMemory(modelArtifacts, weightSpecs, weightData, trainingConfig) {
      var args = arguments;
      return new PassthroughAsync(fromMemorySync.apply(void 0, __spreadArray([], __read(args), false)));
    }
    function fromMemorySync(modelArtifacts, weightSpecs, weightData, trainingConfig) {
      if (arguments.length === 1) {
        var isModelArtifacts = modelArtifacts.modelTopology != null || modelArtifacts.weightSpecs != null;
        if (isModelArtifacts) {
          return new PassthroughLoader(modelArtifacts);
        } else {
          console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
          return new PassthroughLoader({ modelTopology: modelArtifacts });
        }
      } else {
        console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
        return new PassthroughLoader({
          modelTopology: modelArtifacts,
          weightSpecs,
          weightData,
          trainingConfig
        });
      }
    }
    function withSaveHandler(saveHandler) {
      return new PassthroughSaver(saveHandler);
    }
    function withSaveHandlerSync(saveHandler) {
      return new PassthroughSaver(saveHandler);
    }
    var io = {
      __proto__: null,
      CompositeArrayBuffer,
      browserFiles,
      browserHTTPRequest,
      concatenateArrayBuffers,
      copyModel,
      decodeWeights,
      decodeWeightsStream,
      encodeWeights,
      fromMemory,
      fromMemorySync,
      getLoadHandlers,
      getModelArtifactsForJSON,
      getModelArtifactsForJSONSync,
      getModelArtifactsInfoForJSON,
      getSaveHandlers,
      getWeightSpecs,
      http,
      isHTTPScheme,
      listModels,
      loadWeights,
      moveModel,
      registerLoadRouter,
      registerSaveRouter,
      removeModel,
      weightsLoaderFactory,
      withSaveHandler,
      withSaveHandlerSync
    };
    function confusionMatrix_(labels, predictions, numClasses) {
      var $labels = convertToTensor(labels, "labels", "confusionMatrix");
      var $predictions = convertToTensor(predictions, "predictions", "confusionMatrix");
      assert(numClasses == null || numClasses > 0 && Number.isInteger(numClasses), function() {
        return "If provided, numClasses must be a positive integer, " + "but got ".concat(numClasses);
      });
      assert($labels.rank === 1, function() {
        return "Expected the rank of labels to be 1, but got ".concat($labels.rank);
      });
      assert($predictions.rank === 1, function() {
        return "Expected the rank of predictions to be 1, " + "but got ".concat($predictions.rank);
      });
      assert($labels.shape[0] === $predictions.shape[0], function() {
        return "Mismatch in the number of examples: " + "".concat($labels.shape[0], " vs. ").concat($predictions.shape[0], ". ") + "Labels and predictions should have the same number of elements.";
      });
      assert(numClasses > 0 && Number.isInteger(numClasses), function() {
        return "numClasses is required to be a positive integer, but got " + "".concat(numClasses);
      });
      var oneHotLabels = oneHot(cast($labels, "int32"), numClasses);
      var oneHotPredictions = oneHot(cast($predictions, "int32"), numClasses);
      var oneHotLabelsT = transpose(oneHotLabels);
      var product = matMul$1(oneHotLabelsT, oneHotPredictions);
      return cast(product, "int32");
    }
    var confusionMatrix = /* @__PURE__ */ op({ confusionMatrix_ });
    var math = {
      __proto__: null,
      confusionMatrix
    };
    var fromPixels2DContext;
    var hasToPixelsWarned = false;
    function fromPixels_(pixels, numChannels) {
      if (numChannels === void 0) {
        numChannels = 3;
      }
      if (numChannels > 4) {
        throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");
      }
      if (pixels == null) {
        throw new Error("pixels passed to tf.browser.fromPixels() can not be null");
      }
      var isPixelData2 = false;
      var isImageData = false;
      var isVideo = false;
      var isImage = false;
      var isCanvasLike = false;
      var isImageBitmap = false;
      if (pixels.data instanceof Uint8Array) {
        isPixelData2 = true;
      } else if (typeof ImageData !== "undefined" && pixels instanceof ImageData) {
        isImageData = true;
      } else if (typeof HTMLVideoElement !== "undefined" && pixels instanceof HTMLVideoElement) {
        isVideo = true;
      } else if (typeof HTMLImageElement !== "undefined" && pixels instanceof HTMLImageElement) {
        isImage = true;
      } else if (pixels.getContext != null) {
        isCanvasLike = true;
      } else if (typeof ImageBitmap !== "undefined" && pixels instanceof ImageBitmap) {
        isImageBitmap = true;
      } else {
        throw new Error("pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, " + "but was ".concat(pixels.constructor.name));
      }
      var kernel = getKernel(FromPixels, ENGINE.backendName);
      if (kernel != null) {
        var inputs = { pixels };
        var attrs = { numChannels };
        return ENGINE.runKernel(FromPixels, inputs, attrs);
      }
      var _a = __read(isVideo ? [
        pixels.videoWidth,
        pixels.videoHeight
      ] : [pixels.width, pixels.height], 2), width = _a[0], height = _a[1];
      var vals;
      if (isCanvasLike) {
        vals = // tslint:disable-next-line:no-any
        pixels.getContext("2d").getImageData(0, 0, width, height).data;
      } else if (isImageData || isPixelData2) {
        vals = pixels.data;
      } else if (isImage || isVideo || isImageBitmap) {
        if (fromPixels2DContext == null) {
          if (typeof document === "undefined") {
            if (typeof OffscreenCanvas !== "undefined" && typeof OffscreenCanvasRenderingContext2D !== "undefined") {
              fromPixels2DContext = new OffscreenCanvas(1, 1).getContext("2d");
            } else {
              throw new Error("Cannot parse input in current context. Reason: OffscreenCanvas Context2D rendering is not supported.");
            }
          } else {
            fromPixels2DContext = document.createElement("canvas").getContext("2d", { willReadFrequently: true });
          }
        }
        fromPixels2DContext.canvas.width = width;
        fromPixels2DContext.canvas.height = height;
        fromPixels2DContext.drawImage(pixels, 0, 0, width, height);
        vals = fromPixels2DContext.getImageData(0, 0, width, height).data;
      }
      var values;
      if (numChannels === 4) {
        values = new Int32Array(vals);
      } else {
        var numPixels = width * height;
        values = new Int32Array(numPixels * numChannels);
        for (var i = 0; i < numPixels; i++) {
          for (var channel = 0; channel < numChannels; ++channel) {
            values[i * numChannels + channel] = vals[i * 4 + channel];
          }
        }
      }
      var outShape = [height, width, numChannels];
      return tensor3d(values, outShape, "int32");
    }
    function isPixelData(pixels) {
      return pixels != null && pixels.data instanceof Uint8Array;
    }
    function isImageBitmapFullySupported() {
      return typeof window !== "undefined" && typeof ImageBitmap !== "undefined" && window.hasOwnProperty("createImageBitmap");
    }
    function isNonEmptyPixels(pixels) {
      return pixels != null && pixels.width !== 0 && pixels.height !== 0;
    }
    function canWrapPixelsToImageBitmap(pixels) {
      return isImageBitmapFullySupported() && !(pixels instanceof ImageBitmap) && isNonEmptyPixels(pixels) && !isPixelData(pixels);
    }
    function fromPixelsAsync(pixels, numChannels) {
      if (numChannels === void 0) {
        numChannels = 3;
      }
      return __awaiter(this, void 0, void 0, function() {
        var inputs, imageBitmap;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              inputs = null;
              if (!(env().getBool("WRAP_TO_IMAGEBITMAP") && canWrapPixelsToImageBitmap(pixels)))
                return [3, 5];
              imageBitmap = void 0;
              _a.label = 1;
            case 1:
              _a.trys.push([1, 3, , 4]);
              return [4, createImageBitmap(pixels, { premultiplyAlpha: "none" })];
            case 2:
              imageBitmap = _a.sent();
              return [3, 4];
            case 3:
              _a.sent();
              imageBitmap = null;
              return [3, 4];
            case 4:
              if (imageBitmap != null && imageBitmap.width === pixels.width && imageBitmap.height === pixels.height) {
                inputs = imageBitmap;
              } else {
                inputs = pixels;
              }
              return [3, 6];
            case 5:
              inputs = pixels;
              _a.label = 6;
            case 6:
              return [2, fromPixels_(inputs, numChannels)];
          }
        });
      });
    }
    function validateImgTensor(img) {
      if (img.rank !== 2 && img.rank !== 3) {
        throw new Error("toPixels only supports rank 2 or 3 tensors, got rank ".concat(img.rank, "."));
      }
      var depth = img.rank === 2 ? 1 : img.shape[2];
      if (depth > 4 || depth === 2) {
        throw new Error("toPixels only supports depth of size " + "1, 3 or 4 but got ".concat(depth));
      }
      if (img.dtype !== "float32" && img.dtype !== "int32") {
        throw new Error("Unsupported type for toPixels: ".concat(img.dtype, ".") + " Please use float32 or int32 tensors.");
      }
    }
    function validateImageOptions(imageOptions) {
      var alpha = (imageOptions === null || imageOptions === void 0 ? void 0 : imageOptions.alpha) || 1;
      if (alpha > 1 || alpha < 0) {
        throw new Error("Alpha value ".concat(alpha, " is suppoed to be in range [0 - 1]."));
      }
    }
    function toPixels(img, canvas) {
      return __awaiter(this, void 0, void 0, function() {
        var $img, originalImgTensor, _a, height, width, depth, data, multiplier, bytes, i, rgba, d, value, j, kernel, ctx, imageData;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              $img = convertToTensor(img, "img", "toPixels");
              if (!(img instanceof Tensor)) {
                originalImgTensor = $img;
                $img = cast(originalImgTensor, "int32");
                originalImgTensor.dispose();
              }
              validateImgTensor($img);
              _a = __read($img.shape.slice(0, 2), 2), height = _a[0], width = _a[1];
              depth = $img.rank === 2 ? 1 : $img.shape[2];
              return [4, $img.data()];
            case 1:
              data = _b.sent();
              multiplier = $img.dtype === "float32" ? 255 : 1;
              bytes = new Uint8ClampedArray(width * height * 4);
              for (i = 0; i < height * width; ++i) {
                rgba = [0, 0, 0, 255];
                for (d = 0; d < depth; d++) {
                  value = data[i * depth + d];
                  if ($img.dtype === "float32") {
                    if (value < 0 || value > 1) {
                      throw new Error("Tensor values for a float32 Tensor must be in the " + "range [0 - 1] but encountered ".concat(value, "."));
                    }
                  } else if ($img.dtype === "int32") {
                    if (value < 0 || value > 255) {
                      throw new Error("Tensor values for a int32 Tensor must be in the " + "range [0 - 255] but encountered ".concat(value, "."));
                    }
                  }
                  if (depth === 1) {
                    rgba[0] = value * multiplier;
                    rgba[1] = value * multiplier;
                    rgba[2] = value * multiplier;
                  } else {
                    rgba[d] = value * multiplier;
                  }
                }
                j = i * 4;
                bytes[j + 0] = Math.round(rgba[0]);
                bytes[j + 1] = Math.round(rgba[1]);
                bytes[j + 2] = Math.round(rgba[2]);
                bytes[j + 3] = Math.round(rgba[3]);
              }
              if (canvas != null) {
                if (!hasToPixelsWarned) {
                  kernel = getKernel(Draw, ENGINE.backendName);
                  if (kernel != null) {
                    console.warn("tf.browser.toPixels is not efficient to draw tensor on canvas. Please try tf.browser.draw instead.");
                    hasToPixelsWarned = true;
                  }
                }
                canvas.width = width;
                canvas.height = height;
                ctx = canvas.getContext("2d");
                imageData = new ImageData(bytes, width, height);
                ctx.putImageData(imageData, 0, 0);
              }
              if ($img !== img) {
                $img.dispose();
              }
              return [2, bytes];
          }
        });
      });
    }
    function draw(image2, canvas, options) {
      var $img = convertToTensor(image2, "img", "draw");
      if (!(image2 instanceof Tensor)) {
        var originalImgTensor = $img;
        $img = cast(originalImgTensor, "int32");
        originalImgTensor.dispose();
      }
      validateImgTensor($img);
      validateImageOptions(options === null || options === void 0 ? void 0 : options.imageOptions);
      var inputs = { image: $img };
      var attrs = { canvas, options };
      ENGINE.runKernel(Draw, inputs, attrs);
    }
    var fromPixels = /* @__PURE__ */ op({ fromPixels_ });
    var browser = {
      __proto__: null,
      draw,
      fromPixels,
      fromPixelsAsync,
      toPixels
    };
    function prepareAndValidate(tensor2, indices) {
      var tensorRank = tensor2.shape.length;
      var indicesRank = indices.shape.length;
      if (tensorRank < 1) {
        throw new Error("tf.gatherND() expects the input to be rank 1 or higher," + " but the rank was ".concat(tensorRank, "."));
      }
      if (indicesRank < 1) {
        throw new Error("tf.gatherND() expects the indices to be rank 1 or higher," + " but the rank was ".concat(indicesRank, "."));
      }
      if (indices.dtype !== "int32") {
        throw new Error("tf.gatherND() expects the indices to be int32 type," + " but the dtype was ".concat(indices.dtype, "."));
      }
      if (indices.shape[indicesRank - 1] > tensorRank) {
        throw new Error("index innermost dimension length must be <= tensor rank; saw: " + "".concat(indices.shape[indicesRank - 1], " vs. ").concat(tensorRank));
      }
      if (sizeFromShape(tensor2.shape) === 0) {
        throw new Error("Requested more than 0 entries, but input is empty." + " Input shape: ".concat(tensor2.shape, "."));
      }
      var indicesShape = indices.shape;
      var sliceRank = indicesShape[indicesShape.length - 1];
      var nResult = 1;
      for (var i = 0; i < indicesShape.length - 1; ++i) {
        nResult *= indicesShape[i];
      }
      var inputShape = tensor2.shape;
      var resultShape = indicesShape.slice();
      resultShape.pop();
      var sliceSize = 1;
      for (var i = sliceRank; i < tensorRank; ++i) {
        sliceSize *= inputShape[i];
        resultShape.push(inputShape[i]);
      }
      var strides = __spreadArray(__spreadArray([], __read(computeStrides(tensor2.shape).map(function(stride) {
        return stride / sliceSize;
      })), false), [1], false).slice(0, sliceRank);
      return [resultShape, nResult, sliceSize, strides];
    }
    var gather_nd_util = {
      __proto__: null,
      prepareAndValidate
    };
    var NEW_AXIS = -2;
    var SHRINK_AXIS = -1;
    function assertParamsValid(input, begin, size) {
      var inputRank = input.shape.length;
      assert(inputRank === begin.length, function() {
        return "Error in slice".concat(inputRank, "D: Length of begin ").concat(begin, " must ") + "match the rank of the array (".concat(inputRank, ").");
      });
      assert(inputRank === size.length, function() {
        return "Error in slice".concat(inputRank, "D: Length of size ").concat(size, " must ") + "match the rank of the array (".concat(inputRank, ").");
      });
      var _loop_1 = function(i2) {
        assert(begin[i2] + size[i2] <= input.shape[i2], function() {
          return "Error in slice".concat(inputRank, "D: begin[").concat(i2, "] + size[").concat(i2, "] ") + "(".concat(begin[i2] + size[i2], ") would overflow input.shape[").concat(i2, "] (").concat(input.shape[i2], ")");
        });
      };
      for (var i = 0; i < inputRank; ++i) {
        _loop_1(i);
      }
    }
    function maskToAxes(mask) {
      var axes = [];
      var axis = 0;
      while (mask > 0) {
        if (mask & 1) {
          axes.push(axis);
        }
        mask /= 2;
        axis++;
      }
      return axes;
    }
    function computeOutShape$2(begin, end, strides) {
      var size = [];
      for (var axis = 0; axis < begin.length; axis++) {
        size[axis] = Math.ceil((end[axis] - begin[axis]) / strides[axis]);
      }
      return size;
    }
    function stridesWithElidedDims(strides, ellipsisInsertionIndex, numElidedAxes, inputShape) {
      var newStrides = __spreadArray([], __read(strides), false);
      for (var i = newStrides.length; i < inputShape.length; i++) {
        newStrides.push(1);
      }
      for (var i = 0; i < numElidedAxes; i++) {
        if (i === 0) {
          newStrides[ellipsisInsertionIndex] = 1;
        } else {
          newStrides.splice(
            ellipsisInsertionIndex,
            0,
            1
            /* element to add */
          );
          newStrides.pop();
        }
      }
      return newStrides;
    }
    function unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, normalizedAxis) {
      if (normalizedAxis <= ellipsisInsertionIndex) {
        return normalizedAxis;
      }
      return normalizedAxis - (numElidedAxes - 1);
    }
    function getElidedAxes(numElidedAxes, ellipsisInsertionIndex) {
      var elidedAxes = [];
      for (var i = 0; i < numElidedAxes; i++) {
        elidedAxes.push(ellipsisInsertionIndex + i);
      }
      return elidedAxes;
    }
    function getNormalizedAxes(inputShape, ellipsisAxes, numInterpolatedAxes, begin, end, strides, beginMask, endMask, ellipsisMask) {
      var inputRank = inputShape.length;
      var normalizedBegin = new Array(inputRank), normalizedEnd = new Array(inputRank), normalizedStrides = new Array(inputRank);
      if (ellipsisAxes.length && numInterpolatedAxes > 0) {
        var fullIndex = ellipsisAxes[0];
        var numElidedAxes = numInterpolatedAxes + 1;
        normalizedBegin = startIndicesWithElidedDims(beginMask, fullIndex, numElidedAxes, begin, inputShape);
        normalizedEnd = stopIndicesWithElidedDims(endMask, fullIndex, numElidedAxes, end, inputShape);
        normalizedStrides = stridesWithElidedDims(strides, fullIndex, numElidedAxes, inputShape);
      } else {
        for (var axis = 0; axis < inputRank; axis++) {
          normalizedBegin[axis] = startForAxis(beginMask, begin, strides, inputShape, axis, ellipsisMask);
          normalizedEnd[axis] = stopForAxis(endMask, end, strides, inputShape, axis, ellipsisMask);
          normalizedStrides[axis] = stridesForAxis(strides, axis, ellipsisMask);
        }
      }
      return {
        begin: normalizedBegin,
        end: normalizedEnd,
        strides: normalizedStrides
      };
    }
    function startIndicesWithElidedDims(beginMask, ellipsisInsertionIndex, numElidedAxes, originalBegin, inputShape) {
      var newIndices = __spreadArray([], __read(inputShape), false);
      var elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);
      for (var axis = 0; axis < newIndices.length; axis++) {
        if (elidedAxes.indexOf(axis) > -1) {
          newIndices[axis] = 0;
        } else {
          var originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);
          var originalValue = originalBegin[originalAxis];
          if (beginMask & 1 << originalAxis) {
            originalValue = 0;
          }
          newIndices[axis] = originalValue;
        }
      }
      return newIndices;
    }
    function stopIndicesWithElidedDims(endMask, ellipsisInsertionIndex, numElidedAxes, originalEnd, inputShape) {
      var newIndices = __spreadArray([], __read(inputShape), false);
      var elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);
      for (var axis = 0; axis < newIndices.length; axis++) {
        if (elidedAxes.indexOf(axis) > -1) {
          newIndices[axis] = Number.MAX_SAFE_INTEGER;
        } else {
          var originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);
          var originalValue = originalEnd[originalAxis];
          if (endMask & 1 << originalAxis) {
            originalValue = Number.MAX_SAFE_INTEGER;
          }
          newIndices[axis] = originalValue;
        }
      }
      for (var i = 0; i < newIndices.length; i++) {
        var axisSize = inputShape[i];
        if (newIndices[i] < 0) {
          newIndices[i] += axisSize;
        }
        newIndices[i] = clamp(0, newIndices[i], inputShape[i]);
      }
      return newIndices;
    }
    function stridesForAxis(strides, axis, ellipsisMask) {
      var stride = strides[axis];
      if (ellipsisMask & 1 << axis || stride == null) {
        stride = 1;
      }
      return stride;
    }
    function startForAxis(beginMask, startIndices, strides, inputShape, axis, ellipsisMask) {
      var start = startIndices[axis];
      var stride = strides[axis] || 1;
      if (beginMask & 1 << axis || ellipsisMask & 1 << axis || start == null) {
        if (stride > 0) {
          start = Number.MIN_SAFE_INTEGER;
        } else {
          start = Number.MAX_SAFE_INTEGER;
        }
      }
      var axisSize = inputShape[axis];
      if (start < 0) {
        start += axisSize;
      }
      start = clamp(0, start, axisSize - 1);
      return start;
    }
    function stopForAxis(endMask, stopIndices, strides, inputShape, axis, ellipsisMask) {
      var stop = stopIndices[axis];
      var stride = strides[axis] || 1;
      if (endMask & 1 << axis || ellipsisMask & 1 << axis || stop == null) {
        if (stride > 0) {
          stop = Number.MAX_SAFE_INTEGER;
        } else {
          stop = Number.MIN_SAFE_INTEGER;
        }
      }
      var axisSize = inputShape[axis];
      if (stop < 0) {
        stop += axisSize;
      }
      if (stride > 0) {
        stop = clamp(0, stop, axisSize);
      } else {
        stop = clamp(-1, stop, axisSize - 1);
      }
      return stop;
    }
    function isSliceContinous(shape, begin, size) {
      var firstNonOneAxis = size.length;
      for (var i = 0; i < size.length; i++) {
        if (size[i] > 1) {
          firstNonOneAxis = i;
          break;
        }
      }
      for (var i = firstNonOneAxis + 1; i < size.length; i++) {
        if (begin[i] > 0 || size[i] !== shape[i]) {
          return false;
        }
      }
      return true;
    }
    function computeFlatOffset(begin, strides) {
      var flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;
      for (var i = 0; i < begin.length - 1; i++) {
        flatOffset += begin[i] * strides[i];
      }
      return flatOffset;
    }
    function parseSliceParams(x, begin, size) {
      var begin_;
      var xRank = x.shape.length;
      if (typeof begin === "number") {
        begin_ = __spreadArray([begin], __read(new Array(xRank - 1).fill(0)), false);
      } else if (begin.length < xRank) {
        begin_ = begin.concat(new Array(xRank - begin.length).fill(0));
      } else {
        begin_ = begin.slice();
      }
      begin_.forEach(function(d) {
        assert(d !== -1, function() {
          return "slice() does not support negative begin indexing.";
        });
      });
      var size_;
      if (size == null) {
        size_ = new Array(xRank).fill(-1);
      } else if (typeof size === "number") {
        size_ = __spreadArray([size], __read(new Array(xRank - 1).fill(-1)), false);
      } else if (size.length < xRank) {
        size_ = size.concat(new Array(xRank - size.length).fill(-1));
      } else {
        size_ = size;
      }
      size_ = size_.map(function(d, i) {
        if (d >= 0) {
          return d;
        } else {
          assert(d === -1, function() {
            return "Negative size values should be exactly -1 but got " + "".concat(d, " for the slice() size at index ").concat(i, ".");
          });
          return x.shape[i] - begin_[i];
        }
      });
      return [begin_, size_];
    }
    function sliceInfo(xShape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
      var stridesNonNull;
      if (strides == null) {
        stridesNonNull = new Array(begin.length);
        stridesNonNull.fill(1);
      } else {
        stridesNonNull = strides;
      }
      if (ellipsisMask != null && (ellipsisMask & ellipsisMask - 1) !== 0) {
        throw new Error("Multiple ellipses in slice is not allowed.");
      }
      var ellipsisSeen = false;
      var sparseSpec = {
        dims: stridesNonNull.length,
        numAddAxisAfterEllipsis: 0,
        begin: begin.slice(),
        end: end.slice(),
        strides: stridesNonNull.slice(),
        beginMask,
        endMask,
        ellipsisMask,
        newAxisMask,
        shrinkAxisMask
      };
      for (var i = 0; i < sparseSpec.dims; i++) {
        if (ellipsisSeen && (1 << i & newAxisMask) !== 0) {
          sparseSpec.numAddAxisAfterEllipsis++;
        }
        if (1 << i & ellipsisMask) {
          ellipsisSeen = true;
        }
      }
      if (!ellipsisSeen) {
        sparseSpec.ellipsisMask |= 1 << sparseSpec.dims;
        sparseSpec.dims++;
      }
      var denseSpec = {
        dims: xShape.length,
        beginMask: 0,
        endMask: 0,
        beginValid: false,
        endValid: false
      };
      buildDenseSpec(sparseSpec, denseSpec);
      var isIdentity = true;
      var sliceDim0 = true;
      var isSimpleSlice = true;
      var processingShape = [];
      var finalShape = [];
      for (var i = 0; i < xShape.length; ++i) {
        if (denseSpec.strides[i] === 0) {
          throw Error("strides[".concat(i, "] must be non-zero"));
        }
        var shrinkI = !!(denseSpec.shrinkAxisMask & 1 << i);
        var dimI = xShape[i];
        if (dimI === -1) {
          processingShape.push(shrinkI ? 1 : -1);
          continue;
        }
        var masks = [denseSpec.beginMask & 1 << i, denseSpec.endMask & 1 << i];
        var validRange = [
          denseSpec.strides[i] > 0 ? 0 : -1,
          denseSpec.strides[i] > 0 ? dimI : dimI - 1
        ];
        if (shrinkI && denseSpec.strides[i] <= 0) {
          throw Error("only stride 1 allowed on non-range indexing.");
        }
        isSimpleSlice = isSimpleSlice && denseSpec.strides[i] === 1;
        var beginAndEndMasked = !!(denseSpec.beginMask & 1 << i && denseSpec.endMask & 1 << i);
        if (denseSpec.beginValid && denseSpec.endValid) {
          if (shrinkI) {
            var xFwd = denseSpec.begin[i] < 0 ? dimI + denseSpec.begin[i] : denseSpec.begin[i];
            denseSpec.begin[i] = xFwd;
            denseSpec.end[i] = denseSpec.begin[i] + 1;
            if (xFwd < 0 || xFwd >= dimI) {
              throw Error("slice index ".concat(denseSpec.begin[i], " of dimension ").concat(i, " out of bounds."));
            }
          } else {
            denseSpec.begin[i] = canonical(denseSpec.begin[i], 0, denseSpec.strides[i], dimI, masks, validRange);
            denseSpec.end[i] = canonical(denseSpec.end[i], 1, denseSpec.strides[i], dimI, masks, validRange);
          }
          var takeAllInDimension = denseSpec.strides[i] === 1 && denseSpec.begin[i] === 0 && denseSpec.end[i] === dimI;
          isIdentity = isIdentity && takeAllInDimension;
          sliceDim0 = sliceDim0 && (i === 0 && denseSpec.strides[i] === 1 || takeAllInDimension);
        } else {
          isIdentity = isIdentity && (denseSpec.strides[i] === 1 && beginAndEndMasked);
          sliceDim0 = sliceDim0 && (i === 0 && denseSpec.strides[i] === 1 || beginAndEndMasked);
        }
        var intervalLength = void 0;
        var knownInterval = false;
        if (denseSpec.beginValid && denseSpec.endValid) {
          intervalLength = denseSpec.end[i] - denseSpec.begin[i];
          knownInterval = true;
        } else if (shrinkI) {
          intervalLength = 1;
          knownInterval = true;
        } else if (beginAndEndMasked) {
          if (dimI >= 0) {
            if (denseSpec.strides[i] < 0) {
              intervalLength = -dimI;
            } else {
              intervalLength = dimI;
            }
            knownInterval = true;
          }
        }
        if (knownInterval) {
          var sizeI = void 0;
          if (intervalLength === 0 || intervalLength < 0 !== denseSpec.strides[i] < 0) {
            sizeI = 0;
          } else {
            sizeI = Math.trunc(intervalLength / denseSpec.strides[i]) + (intervalLength % denseSpec.strides[i] !== 0 ? 1 : 0);
          }
          processingShape.push(sizeI);
        } else {
          processingShape.push(-1);
        }
      }
      for (var denseDim = 0; denseDim < denseSpec.finalShapeGatherIndices.length; ++denseDim) {
        var gatherIndex = denseSpec.finalShapeGatherIndices[denseDim];
        if (gatherIndex >= 0) {
          finalShape.push(processingShape[gatherIndex]);
        } else if (gatherIndex === NEW_AXIS) {
          finalShape.push(1);
        }
      }
      var finalShapeSparse = finalShape.filter(function(dim, i2) {
        return denseSpec.finalShapeGatherIndices[i2] !== NEW_AXIS;
      });
      return {
        finalShapeSparse,
        finalShape,
        isIdentity,
        sliceDim0,
        isSimpleSlice,
        begin: denseSpec.begin,
        end: denseSpec.end,
        strides: denseSpec.strides
      };
    }
    function buildDenseSpec(sparse2, dense) {
      dense.beginMask = 0;
      dense.endMask = 0;
      dense.shrinkAxisMask = 0;
      var fullIndex = 0;
      dense.beginValid = sparse2.begin != null;
      dense.endValid = sparse2.end != null;
      dense.begin = new Array(dense.dims);
      dense.end = new Array(dense.dims);
      dense.strides = new Array(dense.dims);
      dense.finalShapeGatherIndices = [];
      dense.finalShapeGatherIndicesSparse = [];
      dense.inputShapeGatherIndicesSparse = new Array(dense.dims);
      for (var i = 0; i < sparse2.dims; i++) {
        if (1 << i & sparse2.ellipsisMask) {
          var nextIndex = Math.min(dense.dims - (sparse2.dims - i) + 1 + sparse2.numAddAxisAfterEllipsis, dense.dims);
          for (; fullIndex < nextIndex; fullIndex++) {
            dense.begin[fullIndex] = 0;
            dense.end[fullIndex] = 0;
            dense.strides[fullIndex] = 1;
            dense.beginMask |= 1 << fullIndex;
            dense.endMask |= 1 << fullIndex;
            dense.finalShapeGatherIndices.push(fullIndex);
            dense.finalShapeGatherIndicesSparse.push(-1);
            dense.inputShapeGatherIndicesSparse[fullIndex] = i;
          }
        } else if (1 << i & sparse2.newAxisMask) {
          dense.finalShapeGatherIndices.push(NEW_AXIS);
          dense.finalShapeGatherIndicesSparse.push(-1);
        } else {
          if (fullIndex === dense.begin.length) {
            throw Error("Index out of range using input dim ".concat(fullIndex, "; input ") + "has only ".concat(dense.dims, " dims, ").concat(dense.begin.length, "."));
          }
          if (sparse2.begin != null) {
            dense.begin[fullIndex] = sparse2.begin[i];
          }
          if (sparse2.end != null) {
            dense.end[fullIndex] = sparse2.end[i];
          }
          dense.strides[fullIndex] = sparse2.strides[i];
          if (sparse2.beginMask & 1 << i) {
            dense.beginMask |= 1 << fullIndex;
          }
          if (sparse2.endMask & 1 << i) {
            dense.endMask |= 1 << fullIndex;
          }
          if (sparse2.shrinkAxisMask & 1 << i) {
            dense.finalShapeGatherIndices.push(SHRINK_AXIS);
            dense.finalShapeGatherIndicesSparse.push(-1);
            dense.shrinkAxisMask |= 1 << fullIndex;
          } else {
            dense.finalShapeGatherIndices.push(fullIndex);
            dense.finalShapeGatherIndicesSparse.push(i);
          }
          dense.inputShapeGatherIndicesSparse[fullIndex] = i;
          fullIndex++;
        }
      }
    }
    function canonical(x, c, strideI, dimI, masks, validRange) {
      if (masks[c]) {
        return strideI > 0 ? validRange[c] : validRange[c + 1 & 1];
      } else {
        var xFwd = x < 0 ? dimI + x : x;
        return xFwd < validRange[0] ? validRange[0] : xFwd > validRange[1] ? validRange[1] : xFwd;
      }
    }
    var slice_util = {
      __proto__: null,
      assertParamsValid,
      computeFlatOffset,
      computeOutShape: computeOutShape$2,
      getNormalizedAxes,
      isSliceContinous,
      maskToAxes,
      parseSliceParams,
      sliceInfo,
      startForAxis,
      startIndicesWithElidedDims,
      stopForAxis,
      stopIndicesWithElidedDims,
      stridesForAxis,
      stridesWithElidedDims
    };
    var version = "4.15.0";
    var OptimizerConstructors = (
      /** @class */
      function() {
        function OptimizerConstructors2() {
        }
        OptimizerConstructors2.sgd = function(learningRate) {
          return new SGDOptimizer(learningRate);
        };
        OptimizerConstructors2.momentum = function(learningRate, momentum, useNesterov) {
          if (useNesterov === void 0) {
            useNesterov = false;
          }
          return new MomentumOptimizer(learningRate, momentum, useNesterov);
        };
        OptimizerConstructors2.rmsprop = function(learningRate, decay, momentum, epsilon, centered) {
          if (decay === void 0) {
            decay = 0.9;
          }
          if (momentum === void 0) {
            momentum = 0;
          }
          if (epsilon === void 0) {
            epsilon = null;
          }
          if (centered === void 0) {
            centered = false;
          }
          return new RMSPropOptimizer(learningRate, decay, momentum, epsilon, centered);
        };
        OptimizerConstructors2.adam = function(learningRate, beta1, beta2, epsilon) {
          if (learningRate === void 0) {
            learningRate = 1e-3;
          }
          if (beta1 === void 0) {
            beta1 = 0.9;
          }
          if (beta2 === void 0) {
            beta2 = 0.999;
          }
          if (epsilon === void 0) {
            epsilon = null;
          }
          return new AdamOptimizer(learningRate, beta1, beta2, epsilon);
        };
        OptimizerConstructors2.adadelta = function(learningRate, rho, epsilon) {
          if (learningRate === void 0) {
            learningRate = 1e-3;
          }
          if (rho === void 0) {
            rho = 0.95;
          }
          if (epsilon === void 0) {
            epsilon = null;
          }
          return new AdadeltaOptimizer(learningRate, rho, epsilon);
        };
        OptimizerConstructors2.adamax = function(learningRate, beta1, beta2, epsilon, decay) {
          if (learningRate === void 0) {
            learningRate = 2e-3;
          }
          if (beta1 === void 0) {
            beta1 = 0.9;
          }
          if (beta2 === void 0) {
            beta2 = 0.999;
          }
          if (epsilon === void 0) {
            epsilon = null;
          }
          if (decay === void 0) {
            decay = 0;
          }
          return new AdamaxOptimizer(learningRate, beta1, beta2, epsilon, decay);
        };
        OptimizerConstructors2.adagrad = function(learningRate, initialAccumulatorValue) {
          if (initialAccumulatorValue === void 0) {
            initialAccumulatorValue = 0.1;
          }
          return new AdagradOptimizer(learningRate, initialAccumulatorValue);
        };
        return OptimizerConstructors2;
      }()
    );
    var train = OptimizerConstructors;
    var delayCallback = function() {
      if (typeof requestAnimationFrame !== "undefined") {
        return requestAnimationFrame;
      } else if (typeof setImmediate !== "undefined") {
        return setImmediate;
      }
      return function(f) {
        return f();
      };
    }();
    function nextFrame() {
      return new Promise(function(resolve) {
        return delayCallback(function() {
          return resolve();
        });
      });
    }
    function assertParamsConsistent(shapes, axis) {
      var rank = shapes[0].length;
      shapes.forEach(function(shape, i) {
        assert(shape.length === rank, function() {
          return "Error in concat".concat(rank, "D: rank of tensors[").concat(i, "] must be the same ") + "as the rank of the rest (".concat(rank, ")");
        });
      });
      assert(axis >= 0 && axis < rank, function() {
        return "Error in concat".concat(rank, "D: axis must be between 0 and ").concat(rank - 1, ".");
      });
      var firstShape = shapes[0];
      shapes.forEach(function(shape, i) {
        for (var r = 0; r < rank; r++) {
          assert(r === axis || shape[r] === firstShape[r], function() {
            return "Error in concat".concat(rank, "D: Shape of tensors[").concat(i, "] (").concat(shape, ") ") + "does not match the shape of the rest (".concat(firstShape, ") ") + "along the non-concatenated axis ".concat(i, ".");
          });
        }
      });
    }
    function computeOutShape$1(shapes, axis) {
      var outputShape = shapes[0].slice();
      for (var i = 1; i < shapes.length; i++) {
        outputShape[axis] += shapes[i][axis];
      }
      return outputShape;
    }
    var RowPartitionType;
    (function(RowPartitionType2) {
      RowPartitionType2[RowPartitionType2["FIRST_DIM_SIZE"] = 0] = "FIRST_DIM_SIZE";
      RowPartitionType2[RowPartitionType2["VALUE_ROWIDS"] = 1] = "VALUE_ROWIDS";
      RowPartitionType2[RowPartitionType2["ROW_LENGTHS"] = 2] = "ROW_LENGTHS";
      RowPartitionType2[RowPartitionType2["ROW_SPLITS"] = 3] = "ROW_SPLITS";
      RowPartitionType2[RowPartitionType2["ROW_LIMITS"] = 4] = "ROW_LIMITS";
      RowPartitionType2[RowPartitionType2["ROW_STARTS"] = 5] = "ROW_STARTS";
    })(RowPartitionType || (RowPartitionType = {}));
    function combineRaggedTensorToTensorShapes(raggedRank, shape, valueShape) {
      var outputShape = new Array();
      if (valueShape == null && shape == null) {
        return outputShape;
      }
      if (shape == null) {
        while (outputShape.length < raggedRank + valueShape.length) {
          outputShape.push(-1);
        }
      } else {
        outputShape = shape.slice();
      }
      if (valueShape == null) {
        return outputShape;
      }
      if (raggedRank + valueShape.length !== outputShape.length) {
        throw new Error("rt input.shape and shape=".concat(shape, " are incompatible: rt input.rank = ").concat(raggedRank + valueShape.length, ", but shape.rank = ").concat(outputShape.length));
      }
      for (var i = 1; i < valueShape.length; ++i) {
        var valueDim = valueShape[i];
        var outputShapeDimIndex = outputShape[outputShape.length - valueShape.length + i];
        var outputShapeDim = outputShape[outputShapeDimIndex];
        if (valueDim >= 0) {
          if (outputShapeDim >= 0) {
            if (outputShapeDim !== valueDim) {
              throw new Error("rt input.shape and shape=".concat(shape, " are incompatible: rt input.shape[").concat(i + raggedRank, "] = ").concat(valueDim, " but shape[").concat(i + raggedRank, "] = ").concat(outputShapeDim));
            }
          } else {
            outputShape[outputShapeDimIndex] = valueDim;
          }
        }
      }
      return outputShape;
    }
    function getRowPartitionTypesHelper(rowPartitionTypeStrings) {
      var e_1, _a;
      var stringToType = {
        "FIRST_DIM_SIZE": RowPartitionType.FIRST_DIM_SIZE,
        "VALUE_ROWIDS": RowPartitionType.VALUE_ROWIDS,
        "ROW_LENGTHS": RowPartitionType.ROW_LENGTHS,
        "ROW_SPLITS": RowPartitionType.ROW_SPLITS,
        "ROW_LIMITS": RowPartitionType.ROW_LIMITS,
        "ROW_STARTS": RowPartitionType.ROW_STARTS
      };
      var result = [];
      try {
        for (var rowPartitionTypeStrings_1 = __values(rowPartitionTypeStrings), rowPartitionTypeStrings_1_1 = rowPartitionTypeStrings_1.next(); !rowPartitionTypeStrings_1_1.done; rowPartitionTypeStrings_1_1 = rowPartitionTypeStrings_1.next()) {
          var typeStr = rowPartitionTypeStrings_1_1.value;
          if (typeStr in stringToType) {
            result.push(stringToType[typeStr]);
          } else {
            break;
          }
        }
      } catch (e_1_1) {
        e_1 = { error: e_1_1 };
      } finally {
        try {
          if (rowPartitionTypeStrings_1_1 && !rowPartitionTypeStrings_1_1.done && (_a = rowPartitionTypeStrings_1.return))
            _a.call(rowPartitionTypeStrings_1);
        } finally {
          if (e_1)
            throw e_1.error;
        }
      }
      return result;
    }
    function getRaggedRank(rowPartitionTypes) {
      if (rowPartitionTypes.length === 0) {
        return 0;
      }
      if (rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {
        return rowPartitionTypes.length - 1;
      }
      return rowPartitionTypes.length;
    }
    function validateDefaultValueShape(defaultValueShape, valueShape) {
      if (defaultValueShape == null || valueShape == null) {
        return;
      }
      var defaultNDims = defaultValueShape.length;
      var valuesNDims = valueShape.length;
      if (defaultNDims >= valuesNDims) {
        throw new Error("defaultValue.shape=".concat(defaultValueShape, " and ragged tensor flatValues.shape=").concat(valueShape, ", are incompatible: defaultValue.rank = ").concat(defaultNDims, " must be less than ragged tensor input flatValues.rank = ").concat(valuesNDims, ")"));
      }
      for (var i = 0; i < Math.min(defaultNDims, valuesNDims - 1); ++i) {
        var defaultDim = defaultValueShape[i];
        var valueDim = valueShape[i + 1];
        if (defaultDim >= 0 && valueDim >= 0 && defaultDim !== 1 && defaultDim !== valueDim) {
          throw new Error("defaultValue.shape=".concat(defaultValueShape, ", and ragged tensor input flatValues.shape=").concat(valueShape, " are incompatible: defaultValue.shape[").concat(i - defaultValueShape.length, "] = ").concat(defaultDim, " but ragged tensor input.flatValues.shape[").concat(i - defaultValueShape.length, "] = ").concat(valueDim));
        }
      }
    }
    var PARALLELIZE_THRESHOLD = 30;
    function computeOptimalWindowSize(inSize) {
      if (inSize <= PARALLELIZE_THRESHOLD) {
        return inSize;
      }
      return nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));
    }
    function getImageCenter(center, imageHeight, imageWidth) {
      var centerX = imageWidth * (typeof center === "number" ? center : center[0]);
      var centerY = imageHeight * (typeof center === "number" ? center : center[1]);
      return [centerX, centerY];
    }
    function getReshaped(inputShape, blockShape, prod2, batchToSpace) {
      if (batchToSpace === void 0) {
        batchToSpace = true;
      }
      var reshaped = [];
      if (batchToSpace) {
        reshaped = reshaped.concat(blockShape.slice(0));
        reshaped.push(inputShape[0] / prod2);
        reshaped = reshaped.concat(inputShape.slice(1));
      } else {
        reshaped = reshaped.concat(inputShape[0]);
        var spatialLength = blockShape.length;
        for (var i = 0; i < spatialLength; ++i) {
          reshaped = reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);
        }
        reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));
      }
      return reshaped;
    }
    function getPermuted(reshapedRank, blockShapeRank, batchToSpace) {
      if (batchToSpace === void 0) {
        batchToSpace = true;
      }
      var permuted = [];
      if (batchToSpace) {
        permuted.push(blockShapeRank);
        for (var i = blockShapeRank + 1; i < reshapedRank; ++i) {
          if (i <= 2 * blockShapeRank) {
            permuted.push(i);
            permuted.push(i - (blockShapeRank + 1));
          } else {
            permuted.push(i);
          }
        }
      } else {
        var permutedBeforeBatch = [];
        var permutedAfterBatch = [];
        for (var i = 1; i < reshapedRank; ++i) {
          if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {
            permutedAfterBatch.push(i);
          } else {
            permutedBeforeBatch.push(i);
          }
        }
        permuted.push.apply(permuted, __spreadArray([], __read(permutedBeforeBatch), false));
        permuted.push(0);
        permuted.push.apply(permuted, __spreadArray([], __read(permutedAfterBatch), false));
      }
      return permuted;
    }
    function getReshapedPermuted(inputShape, blockShape, prod2, batchToSpace) {
      if (batchToSpace === void 0) {
        batchToSpace = true;
      }
      var reshapedPermuted = [];
      if (batchToSpace) {
        reshapedPermuted.push(inputShape[0] / prod2);
      } else {
        reshapedPermuted.push(inputShape[0] * prod2);
      }
      for (var i = 1; i < inputShape.length; ++i) {
        if (i <= blockShape.length) {
          if (batchToSpace) {
            reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);
          } else {
            reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);
          }
        } else {
          reshapedPermuted.push(inputShape[i]);
        }
      }
      return reshapedPermuted;
    }
    function getSliceBeginCoords(crops, blockShape) {
      var sliceBeginCoords = [0];
      for (var i = 0; i < blockShape; ++i) {
        sliceBeginCoords.push(crops[i][0]);
      }
      return sliceBeginCoords;
    }
    function getSliceSize(uncroppedShape, crops, blockShape) {
      var sliceSize = uncroppedShape.slice(0, 1);
      for (var i = 0; i < blockShape; ++i) {
        sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);
      }
      return sliceSize;
    }
    var SELU_SCALEALPHA = 1.7580993408473768;
    var SELU_SCALE = 1.0507009873554805;
    var ERF_P = 0.3275911;
    var ERF_A1 = 0.254829592;
    var ERF_A2 = -0.284496736;
    var ERF_A3 = 1.421413741;
    var ERF_A4 = -1.453152027;
    var ERF_A5 = 1.061405429;
    function mergeRealAndImagArrays(real2, imag2) {
      if (real2.length !== imag2.length) {
        throw new Error("Cannot merge real and imag arrays of different lengths. real:" + "".concat(real2.length, ", imag: ").concat(imag2.length, "."));
      }
      var result = new Float32Array(real2.length * 2);
      for (var i = 0; i < result.length; i += 2) {
        result[i] = real2[i / 2];
        result[i + 1] = imag2[i / 2];
      }
      return result;
    }
    function splitRealAndImagArrays(complex2) {
      var real2 = new Float32Array(complex2.length / 2);
      var imag2 = new Float32Array(complex2.length / 2);
      for (var i = 0; i < complex2.length; i += 2) {
        real2[i / 2] = complex2[i];
        imag2[i / 2] = complex2[i + 1];
      }
      return { real: real2, imag: imag2 };
    }
    function complexWithEvenIndex(complex2) {
      var len = Math.ceil(complex2.length / 4);
      var real2 = new Float32Array(len);
      var imag2 = new Float32Array(len);
      for (var i = 0; i < complex2.length; i += 4) {
        real2[Math.floor(i / 4)] = complex2[i];
        imag2[Math.floor(i / 4)] = complex2[i + 1];
      }
      return { real: real2, imag: imag2 };
    }
    function complexWithOddIndex(complex2) {
      var len = Math.floor(complex2.length / 4);
      var real2 = new Float32Array(len);
      var imag2 = new Float32Array(len);
      for (var i = 2; i < complex2.length; i += 4) {
        real2[Math.floor(i / 4)] = complex2[i];
        imag2[Math.floor(i / 4)] = complex2[i + 1];
      }
      return { real: real2, imag: imag2 };
    }
    function getComplexWithIndex(complex2, index) {
      var real2 = complex2[index * 2];
      var imag2 = complex2[index * 2 + 1];
      return { real: real2, imag: imag2 };
    }
    function assignToTypedArray(data, real2, imag2, index) {
      data[index * 2] = real2;
      data[index * 2 + 1] = imag2;
    }
    function exponents(n, inverse) {
      var real2 = new Float32Array(n / 2);
      var imag2 = new Float32Array(n / 2);
      for (var i = 0; i < Math.ceil(n / 2); i++) {
        var x = (inverse ? 2 : -2) * Math.PI * (i / n);
        real2[i] = Math.cos(x);
        imag2[i] = Math.sin(x);
      }
      return { real: real2, imag: imag2 };
    }
    function exponent(k, n, inverse) {
      var x = (inverse ? 2 : -2) * Math.PI * (k / n);
      var real2 = Math.cos(x);
      var imag2 = Math.sin(x);
      return { real: real2, imag: imag2 };
    }
    var ARROW = "->";
    var ARROW_REGEX = /->/g;
    var COMMA = ",";
    var ELLIPSIS = "...";
    function decodeEinsumEquation(equation, numTensors) {
      equation = equation.replace(/\s/g, "");
      var numArrows = (equation.length - equation.replace(ARROW_REGEX, "").length) / ARROW.length;
      if (numArrows < 1) {
        throw new Error("Equations without an arrow are not supported.");
      } else if (numArrows > 1) {
        throw new Error('Equation must contain exactly one arrow ("'.concat(ARROW, '").'));
      }
      var _a = __read(equation.split(ARROW), 2), inputString = _a[0], outputString = _a[1];
      assert(inputString.indexOf(ELLIPSIS) === -1, function() {
        return 'The ellipsis notation ("'.concat(ELLIPSIS, '") is not supported yet.');
      });
      var inputTerms = inputString.split(COMMA);
      var numInputs = inputTerms.length;
      if (numTensors !== numInputs) {
        throw new Error("Expected ".concat(numInputs, " input tensors, received ").concat(numTensors));
      }
      if (numInputs > 2) {
        throw new Error("Support for more than 2 input tensors is not implemented yet.");
      }
      var allDims = [];
      var _loop_1 = function(i2) {
        var dimName2 = outputString[i2];
        if (!inputTerms.some(function(inputTerm) {
          return inputTerm.indexOf(dimName2) !== -1;
        })) {
          throw new Error("Output subscripts contain the label ".concat(dimName2, " ") + "not present in the input subscripts.");
        }
        if (allDims.indexOf(dimName2) === -1) {
          allDims.push(dimName2);
        }
      };
      for (var i = 0; i < outputString.length; ++i) {
        _loop_1(i);
      }
      for (var i = 0; i < inputString.length; ++i) {
        var dimName = inputString[i];
        if (allDims.indexOf(dimName) === -1 && dimName !== COMMA) {
          allDims.push(dimName);
        }
      }
      var idDims = new Array(inputTerms.length);
      for (var i = 0; i < numInputs; ++i) {
        if (new Set(inputTerms[i].split("")).size !== inputTerms[i].length) {
          throw new Error("Found duplicate axes in input component ".concat(inputTerms[i], ". ") + "Support for duplicate axes in input is not implemented yet.");
        }
        idDims[i] = [];
        for (var j = 0; j < inputTerms[i].length; ++j) {
          idDims[i].push(allDims.indexOf(inputTerms[i][j]));
        }
      }
      var numDims = allDims.length;
      var numOutDims = outputString.length;
      var summedDims = [];
      for (var i = numOutDims; i < numDims; ++i) {
        summedDims.push(i);
      }
      return { allDims, summedDims, idDims };
    }
    function getEinsumPermutation(nDims, idDims) {
      var permutationIndices = new Array(nDims);
      permutationIndices.fill(-1);
      for (var i = 0; i < idDims.length; ++i) {
        permutationIndices[idDims[i]] = i;
      }
      var expandDims2 = [];
      for (var i = 0; i < nDims; ++i) {
        if (permutationIndices[i] === -1) {
          expandDims2.push(i);
        }
      }
      permutationIndices = permutationIndices.filter(function(d) {
        return d !== -1;
      });
      return { permutationIndices, expandDims: expandDims2 };
    }
    function checkEinsumDimSizes(nDims, idDims, tensors) {
      var dimSizes = new Array(nDims);
      var _loop_2 = function(i2) {
        var shape = tensors[i2].shape;
        var _loop_3 = function(j2) {
          if (dimSizes[idDims[i2][j2]] === void 0) {
            dimSizes[idDims[i2][j2]] = shape[j2];
          } else {
            assert(dimSizes[idDims[i2][j2]] === shape[j2], function() {
              return "Expected dimension ".concat(dimSizes[idDims[i2][j2]], " at axis ").concat(j2, " ") + "of input shaped ".concat(JSON.stringify(shape), ", ") + "but got dimension ".concat(shape[j2]);
            });
          }
        };
        for (var j = 0; j < idDims[i2].length; ++j) {
          _loop_3(j);
        }
      };
      for (var i = 0; i < tensors.length; ++i) {
        _loop_2(i);
      }
    }
    function getEinsumComputePath(summedDims, idDims) {
      var e_1, _a;
      var path = summedDims;
      var steps = [];
      var nSteps = 0;
      if (summedDims.length === 0) {
        path.push(-1);
      }
      nSteps = summedDims.length + 1;
      for (var i = 0; i < nSteps; ++i) {
        steps.push([]);
      }
      var computedTermIndices = [];
      for (var i = 0; i < path.length; ++i) {
        var summedDim = path[i];
        var termIndices = findTermsWithDim(idDims, summedDim);
        try {
          for (var termIndices_1 = (e_1 = void 0, __values(termIndices)), termIndices_1_1 = termIndices_1.next(); !termIndices_1_1.done; termIndices_1_1 = termIndices_1.next()) {
            var termIndex = termIndices_1_1.value;
            if (computedTermIndices.indexOf(termIndex) === -1) {
              steps[i].push(termIndex);
              computedTermIndices.push(termIndex);
            }
          }
        } catch (e_1_1) {
          e_1 = { error: e_1_1 };
        } finally {
          try {
            if (termIndices_1_1 && !termIndices_1_1.done && (_a = termIndices_1.return))
              _a.call(termIndices_1);
          } finally {
            if (e_1)
              throw e_1.error;
          }
        }
      }
      return { path, steps };
    }
    function isIdentityPermutation(perm) {
      return perm.every(function(dim, index) {
        return dim === index;
      });
    }
    function findTermsWithDim(idDims, dim) {
      var termIndices = [];
      for (var i = 0; i < idDims.length; ++i) {
        if (idDims[i].length === 0 || idDims[i].indexOf(dim) !== -1 || dim === -1) {
          termIndices.push(i);
        }
      }
      return termIndices;
    }
    function prepareSplitSize(x, numOrSizeSplits, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var splitSizes = [];
      if (typeof numOrSizeSplits === "number") {
        assert(x.shape[axis] % numOrSizeSplits === 0, function() {
          return "Number of splits must evenly divide the axis.";
        });
        splitSizes = new Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);
      } else {
        var numOfNegs = numOrSizeSplits.reduce(function(count, value) {
          if (value === -1) {
            count += 1;
          }
          return count;
        }, 0);
        assert(numOfNegs <= 1, function() {
          return "There should be only one negative value in split array.";
        });
        var negIndex = numOrSizeSplits.indexOf(-1);
        if (negIndex !== -1) {
          var total = numOrSizeSplits.reduce(function(a, b) {
            return b > 0 ? a + b : a;
          });
          numOrSizeSplits[negIndex] = x.shape[axis] - total;
        }
        assert(x.shape[axis] === numOrSizeSplits.reduce(function(a, b) {
          return a + b;
        }), function() {
          return "The sum of sizes must match the size of the axis dimension.";
        });
        splitSizes = numOrSizeSplits;
      }
      return splitSizes;
    }
    function getSparseFillEmptyRowsIndicesDenseShapeMismatch(indicesLength) {
      return "Received SparseTensor with denseShape[0] = 0 but\n  indices.shape[0] = ".concat(indicesLength);
    }
    function getSparseFillEmptyRowsNegativeIndexErrorMessage(index, value) {
      return "indices(".concat(index, ", 0) is invalid: ").concat(value, " < 0");
    }
    function getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(index, value, limit) {
      return "indices(".concat(index, ", 0) is invalid: ").concat(value, " >= ").concat(limit);
    }
    function getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(dim1, dim2) {
      return "only one output dimension may be -1, not both ".concat(dim1, " and ").concat(dim2);
    }
    function getSparseReshapeNegativeOutputDimErrorMessage(dim, value) {
      return "size ".concat(dim, " must be non-negative, not ").concat(value);
    }
    function getSparseReshapeEmptyTensorZeroOutputDimErrorMessage() {
      return "reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero";
    }
    function getSparseReshapeInputOutputMultipleErrorMessage(inputShape, outputShape) {
      var inputSize = sizeFromShape(inputShape);
      var outputSize = sizeFromShape(outputShape);
      return "Input to reshape is a SparseTensor with ".concat(inputSize, "\n  dense values, but the requested shape requires a multiple of ").concat(outputSize, ". inputShape=").concat(inputShape, " outputShape= ").concat(outputShape);
    }
    function getSparseReshapeInputOutputMismatchErrorMessage(inputShape, outputShape) {
      var inputSize = sizeFromShape(inputShape);
      var outputSize = sizeFromShape(outputShape);
      return "Input to reshape is a tensor with ".concat(inputSize, " dense values, but the requested shape has ").concat(outputSize, ". inputShape=").concat(inputShape, " outputShape=").concat(outputShape);
    }
    function getSparseSegmentReductionNegativeSegmentIdsErrorMessage() {
      return "segment ids must be >= 0";
    }
    function getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage() {
      return "segment ids are not increasing";
    }
    function getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(segmentId, outputRows) {
      return "Segment id ".concat(segmentId, " out of range [0, ").concat(outputRows, "), possibly because segmentIds input is not sorted.");
    }
    function getSparseSegmentReductionIndicesOutOfRangeErrorMessage(index, indexValue, inputRows) {
      return "Bad: indices[".concat(index, "] == ").concat(indexValue, " out of range [0, ").concat(inputRows, ")");
    }
    function segOpComputeOptimalWindowSize(inSize, numSegments) {
      var done = false;
      var res;
      if (inSize <= PARALLELIZE_THRESHOLD) {
        res = inSize;
        done = true;
      } else {
        res = nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));
      }
      while (!done) {
        if (res > numSegments || res === inSize) {
          done = true;
        } else {
          res = nearestDivisor(inSize, res + 1);
        }
      }
      return res;
    }
    function computeOutShape(aShape, axis, numSegments) {
      var outShape = [];
      var rank = aShape.length;
      for (var dim = 0; dim < rank; dim++) {
        if (dim !== axis) {
          outShape.push(aShape[dim]);
        } else {
          outShape.push(numSegments);
        }
      }
      return outShape;
    }
    function collectGatherOpShapeInfo(x, indices, axis, batchDims) {
      var indicesRank = indices.shape.length;
      var xRank = x.shape.length;
      if (batchDims !== 0) {
        if (batchDims < -indicesRank || batchDims > indicesRank) {
          throw new Error("Expect batchDims in the range of [-".concat(indicesRank, ", ").concat(indicesRank, "], but got ").concat(batchDims));
        }
      }
      if (batchDims < 0) {
        batchDims += indicesRank;
      }
      if (batchDims > xRank) {
        throw new Error("batchDims (".concat(batchDims, ") must be less than rank(x) (\n    ").concat(xRank, ")."));
      }
      if (axis < batchDims) {
        throw new Error("batchDims (".concat(batchDims, ") must be less than or equal to axis (").concat(axis, ")."));
      }
      for (var i = 0; i < batchDims; ++i) {
        if (x.shape[i] !== indices.shape[i]) {
          throw new Error("x.shape[".concat(i, "]: ").concat(x.shape[i], " should be equal to indices.shape[").concat(i, "]: ").concat(indices.shape[i], "."));
        }
      }
      var dimSize = x.shape[axis];
      var outputShape = [];
      var batchSize = 1;
      var outerSize = 1;
      var sliceSize = 1;
      for (var i = 0; i < batchDims; ++i) {
        outputShape.push(x.shape[i]);
        batchSize *= x.shape[i];
      }
      for (var i = batchDims; i < axis; i++) {
        outputShape.push(x.shape[i]);
        outerSize *= x.shape[i];
      }
      for (var i = batchDims; i < indicesRank; i++) {
        outputShape.push(indices.shape[i]);
      }
      for (var i = axis + 1; i < xRank; i++) {
        outputShape.push(x.shape[i]);
        sliceSize *= x.shape[i];
      }
      return { batchSize, sliceSize, outerSize, dimSize, outputShape };
    }
    var segment_util = {
      __proto__: null,
      collectGatherOpShapeInfo,
      computeOutShape,
      segOpComputeOptimalWindowSize
    };
    function fromUint8ToStringArray(vals) {
      try {
        return vals.map(function(val) {
          return decodeString(val);
        });
      } catch (err) {
        throw new Error("Failed to decode encoded string bytes into utf-8, error: ".concat(err));
      }
    }
    function fromStringArrayToUint8(strings) {
      return strings.map(function(s) {
        return encodeString(s);
      });
    }
    var backend_util = {
      __proto__: null,
      ERF_A1,
      ERF_A2,
      ERF_A3,
      ERF_A4,
      ERF_A5,
      ERF_P,
      PARALLELIZE_THRESHOLD,
      get RowPartitionType() {
        return RowPartitionType;
      },
      SELU_SCALE,
      SELU_SCALEALPHA,
      applyActivation,
      assertAndGetBroadcastShape,
      assertAxesAreInnerMostDims,
      assertParamsConsistent,
      assignToTypedArray,
      axesAreInnerMostDims,
      calculateShapes,
      checkEinsumDimSizes,
      checkPadOnDimRoundingMode,
      combineLocations,
      combineRaggedTensorToTensorShapes,
      complexWithEvenIndex,
      complexWithOddIndex,
      computeConv2DInfo,
      computeConv3DInfo,
      computeDefaultPad,
      computeDilation2DInfo,
      computeOptimalWindowSize,
      computeOutAndReduceShapes,
      computeOutShape: computeOutShape$1,
      computePool2DInfo,
      computePool3DInfo,
      convertConv2DDataFormat,
      decodeEinsumEquation,
      eitherStridesOrDilationsAreOne,
      expandShapeToKeepDim,
      exponent,
      exponents,
      fromStringArrayToUint8,
      fromUint8ToStringArray,
      getAxesPermutation,
      getBroadcastDims,
      getComplexWithIndex,
      getEinsumComputePath,
      getEinsumPermutation,
      getFusedBiasGradient,
      getFusedDyActivation,
      getImageCenter,
      getInnerMostAxes,
      getPermuted,
      getRaggedRank,
      getReductionAxes,
      getReshaped,
      getReshapedPermuted,
      getRowPartitionTypesHelper,
      getSliceBeginCoords,
      getSliceSize,
      getSparseFillEmptyRowsIndicesDenseShapeMismatch,
      getSparseFillEmptyRowsNegativeIndexErrorMessage,
      getSparseFillEmptyRowsOutOfRangeIndexErrorMessage,
      getSparseReshapeEmptyTensorZeroOutputDimErrorMessage,
      getSparseReshapeInputOutputMismatchErrorMessage,
      getSparseReshapeInputOutputMultipleErrorMessage,
      getSparseReshapeMultipleNegativeOneOutputDimErrorMessage,
      getSparseReshapeNegativeOutputDimErrorMessage,
      getSparseSegmentReductionIndicesOutOfRangeErrorMessage,
      getSparseSegmentReductionNegativeSegmentIdsErrorMessage,
      getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage,
      getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage,
      getUndoAxesPermutation,
      isIdentityPermutation,
      log: log$1,
      mergeRealAndImagArrays,
      prepareAndValidate,
      prepareSplitSize,
      segment_util,
      shouldFuse,
      slice_util,
      splitRealAndImagArrays,
      stridesOrDilationsArePositive,
      tupleValuesAreOne,
      upcastType,
      validateDefaultValueShape,
      validateInput: validateInput$1,
      validateUpdateShape,
      warn
    };
    var kernel_impls = {
      __proto__: null,
      nonMaxSuppressionV3Impl,
      nonMaxSuppressionV4Impl,
      nonMaxSuppressionV5Impl,
      whereImpl
    };
    registerOptimizers();
    exports.Abs = Abs;
    exports.Acos = Acos;
    exports.Acosh = Acosh;
    exports.AdadeltaOptimizer = AdadeltaOptimizer;
    exports.AdagradOptimizer = AdagradOptimizer;
    exports.AdamOptimizer = AdamOptimizer;
    exports.AdamaxOptimizer = AdamaxOptimizer;
    exports.Add = Add;
    exports.AddN = AddN;
    exports.All = All;
    exports.Any = Any;
    exports.ArgMax = ArgMax;
    exports.ArgMin = ArgMin;
    exports.Asin = Asin;
    exports.Asinh = Asinh;
    exports.Atan = Atan;
    exports.Atan2 = Atan2;
    exports.Atanh = Atanh;
    exports.AvgPool = AvgPool;
    exports.AvgPool3D = AvgPool3D;
    exports.AvgPool3DGrad = AvgPool3DGrad;
    exports.AvgPoolGrad = AvgPoolGrad;
    exports.BatchMatMul = BatchMatMul;
    exports.BatchToSpaceND = BatchToSpaceND;
    exports.Bincount = Bincount;
    exports.BitwiseAnd = BitwiseAnd;
    exports.BroadcastArgs = BroadcastArgs;
    exports.BroadcastTo = BroadcastTo;
    exports.Cast = Cast;
    exports.Ceil = Ceil;
    exports.ClipByValue = ClipByValue;
    exports.Complex = Complex;
    exports.ComplexAbs = ComplexAbs;
    exports.Concat = Concat;
    exports.Conv2D = Conv2D;
    exports.Conv2DBackpropFilter = Conv2DBackpropFilter;
    exports.Conv2DBackpropInput = Conv2DBackpropInput;
    exports.Conv3D = Conv3D;
    exports.Conv3DBackpropFilterV2 = Conv3DBackpropFilterV2;
    exports.Conv3DBackpropInputV2 = Conv3DBackpropInputV2;
    exports.Cos = Cos;
    exports.Cosh = Cosh;
    exports.CropAndResize = CropAndResize;
    exports.Cumprod = Cumprod;
    exports.Cumsum = Cumsum;
    exports.DataStorage = DataStorage;
    exports.DenseBincount = DenseBincount;
    exports.DepthToSpace = DepthToSpace;
    exports.DepthwiseConv2dNative = DepthwiseConv2dNative;
    exports.DepthwiseConv2dNativeBackpropFilter = DepthwiseConv2dNativeBackpropFilter;
    exports.DepthwiseConv2dNativeBackpropInput = DepthwiseConv2dNativeBackpropInput;
    exports.Diag = Diag;
    exports.Dilation2D = Dilation2D;
    exports.Dilation2DBackpropFilter = Dilation2DBackpropFilter;
    exports.Dilation2DBackpropInput = Dilation2DBackpropInput;
    exports.Draw = Draw;
    exports.Einsum = Einsum;
    exports.Elu = Elu;
    exports.EluGrad = EluGrad;
    exports.Environment = Environment;
    exports.Equal = Equal;
    exports.Erf = Erf;
    exports.Exp = Exp;
    exports.ExpandDims = ExpandDims;
    exports.Expm1 = Expm1;
    exports.FFT = FFT;
    exports.Fill = Fill;
    exports.FlipLeftRight = FlipLeftRight;
    exports.Floor = Floor;
    exports.FloorDiv = FloorDiv;
    exports.FromPixels = FromPixels;
    exports.FusedBatchNorm = FusedBatchNorm;
    exports.FusedConv2D = FusedConv2D;
    exports.FusedDepthwiseConv2D = FusedDepthwiseConv2D;
    exports.GatherNd = GatherNd;
    exports.GatherV2 = GatherV2;
    exports.Greater = Greater;
    exports.GreaterEqual = GreaterEqual;
    exports.IFFT = IFFT;
    exports.Identity = Identity;
    exports.Imag = Imag;
    exports.IsFinite = IsFinite;
    exports.IsInf = IsInf;
    exports.IsNan = IsNan;
    exports.KernelBackend = KernelBackend;
    exports.LRN = LRN;
    exports.LRNGrad = LRNGrad;
    exports.LeakyRelu = LeakyRelu;
    exports.Less = Less;
    exports.LessEqual = LessEqual;
    exports.LinSpace = LinSpace;
    exports.Log = Log;
    exports.Log1p = Log1p;
    exports.LogSoftmax = LogSoftmax;
    exports.LogicalAnd = LogicalAnd;
    exports.LogicalNot = LogicalNot;
    exports.LogicalOr = LogicalOr;
    exports.LogicalXor = LogicalXor;
    exports.LowerBound = LowerBound;
    exports.MatrixBandPart = MatrixBandPart;
    exports.Max = Max;
    exports.MaxPool = MaxPool;
    exports.MaxPool3D = MaxPool3D;
    exports.MaxPool3DGrad = MaxPool3DGrad;
    exports.MaxPoolGrad = MaxPoolGrad;
    exports.MaxPoolWithArgmax = MaxPoolWithArgmax;
    exports.Maximum = Maximum;
    exports.Mean = Mean;
    exports.Min = Min;
    exports.Minimum = Minimum;
    exports.MirrorPad = MirrorPad;
    exports.Mod = Mod;
    exports.MomentumOptimizer = MomentumOptimizer;
    exports.Multinomial = Multinomial;
    exports.Multiply = Multiply;
    exports.Neg = Neg;
    exports.NonMaxSuppressionV3 = NonMaxSuppressionV3;
    exports.NonMaxSuppressionV4 = NonMaxSuppressionV4;
    exports.NonMaxSuppressionV5 = NonMaxSuppressionV5;
    exports.NotEqual = NotEqual;
    exports.OP_SCOPE_SUFFIX = OP_SCOPE_SUFFIX;
    exports.OneHot = OneHot;
    exports.OnesLike = OnesLike;
    exports.Optimizer = Optimizer;
    exports.OptimizerConstructors = OptimizerConstructors;
    exports.Pack = Pack;
    exports.PadV2 = PadV2;
    exports.Pool = Pool;
    exports.Pow = Pow;
    exports.Prelu = Prelu;
    exports.Prod = Prod;
    exports.RMSPropOptimizer = RMSPropOptimizer;
    exports.RaggedGather = RaggedGather;
    exports.RaggedRange = RaggedRange;
    exports.RaggedTensorToTensor = RaggedTensorToTensor;
    exports.Range = Range;
    exports.Real = Real;
    exports.RealDiv = RealDiv;
    exports.Reciprocal = Reciprocal;
    exports.Relu = Relu;
    exports.Relu6 = Relu6;
    exports.Reshape = Reshape;
    exports.ResizeBilinear = ResizeBilinear;
    exports.ResizeBilinearGrad = ResizeBilinearGrad;
    exports.ResizeNearestNeighbor = ResizeNearestNeighbor;
    exports.ResizeNearestNeighborGrad = ResizeNearestNeighborGrad;
    exports.Reverse = Reverse;
    exports.RotateWithOffset = RotateWithOffset;
    exports.Round = Round;
    exports.Rsqrt = Rsqrt;
    exports.SGDOptimizer = SGDOptimizer;
    exports.ScatterNd = ScatterNd;
    exports.SearchSorted = SearchSorted;
    exports.Select = Select;
    exports.Selu = Selu;
    exports.Sigmoid = Sigmoid;
    exports.Sign = Sign;
    exports.Sin = Sin;
    exports.Sinh = Sinh;
    exports.Slice = Slice;
    exports.Softmax = Softmax;
    exports.Softplus = Softplus;
    exports.SpaceToBatchND = SpaceToBatchND;
    exports.SparseFillEmptyRows = SparseFillEmptyRows;
    exports.SparseReshape = SparseReshape;
    exports.SparseSegmentMean = SparseSegmentMean;
    exports.SparseSegmentSum = SparseSegmentSum;
    exports.SparseToDense = SparseToDense;
    exports.SplitV = SplitV;
    exports.Sqrt = Sqrt;
    exports.Square = Square;
    exports.SquaredDifference = SquaredDifference;
    exports.StaticRegexReplace = StaticRegexReplace;
    exports.Step = Step;
    exports.StridedSlice = StridedSlice;
    exports.StringNGrams = StringNGrams;
    exports.StringSplit = StringSplit;
    exports.StringToHashBucketFast = StringToHashBucketFast;
    exports.Sub = Sub;
    exports.Sum = Sum;
    exports.Tan = Tan;
    exports.Tanh = Tanh;
    exports.Tensor = Tensor;
    exports.TensorBuffer = TensorBuffer;
    exports.TensorScatterUpdate = TensorScatterUpdate;
    exports.Tile = Tile;
    exports.TopK = TopK;
    exports.Transform = Transform;
    exports.Transpose = Transpose;
    exports.Unique = Unique;
    exports.Unpack = Unpack;
    exports.UnsortedSegmentSum = UnsortedSegmentSum;
    exports.UpperBound = UpperBound;
    exports.Variable = Variable;
    exports.ZerosLike = ZerosLike;
    exports._FusedMatMul = _FusedMatMul;
    exports.abs = abs;
    exports.acos = acos;
    exports.acosh = acosh;
    exports.add = add;
    exports.addN = addN;
    exports.all = all;
    exports.any = any;
    exports.argMax = argMax;
    exports.argMin = argMin;
    exports.asin = asin;
    exports.asinh = asinh;
    exports.atan = atan;
    exports.atan2 = atan2;
    exports.atanh = atanh;
    exports.avgPool = avgPool;
    exports.avgPool3d = avgPool3d;
    exports.backend = backend;
    exports.backend_util = backend_util;
    exports.basicLSTMCell = basicLSTMCell;
    exports.batchNorm = batchNorm;
    exports.batchNorm2d = batchNorm2d;
    exports.batchNorm3d = batchNorm3d;
    exports.batchNorm4d = batchNorm4d;
    exports.batchToSpaceND = batchToSpaceND;
    exports.bincount = bincount;
    exports.bitwiseAnd = bitwiseAnd;
    exports.booleanMaskAsync = booleanMaskAsync;
    exports.broadcastArgs = broadcastArgs;
    exports.broadcastTo = broadcastTo;
    exports.broadcast_util = broadcast_util;
    exports.browser = browser;
    exports.buffer = buffer;
    exports.cast = cast;
    exports.ceil = ceil;
    exports.clipByValue = clipByValue;
    exports.clone = clone;
    exports.complex = complex;
    exports.concat = concat;
    exports.concat1d = concat1d;
    exports.concat2d = concat2d;
    exports.concat3d = concat3d;
    exports.concat4d = concat4d;
    exports.conv1d = conv1d;
    exports.conv2d = conv2d$1;
    exports.conv2dTranspose = conv2dTranspose;
    exports.conv3d = conv3d;
    exports.conv3dTranspose = conv3dTranspose;
    exports.copyRegisteredKernels = copyRegisteredKernels;
    exports.cos = cos;
    exports.cosh = cosh;
    exports.cosineWindow = cosineWindow;
    exports.cumprod = cumprod;
    exports.cumsum = cumsum;
    exports.customGrad = customGrad;
    exports.denseBincount = denseBincount;
    exports.deprecationWarn = deprecationWarn;
    exports.depthToSpace = depthToSpace;
    exports.depthwiseConv2d = depthwiseConv2d$1;
    exports.device_util = device_util;
    exports.diag = diag;
    exports.dilation2d = dilation2d;
    exports.disableDeprecationWarnings = disableDeprecationWarnings;
    exports.dispose = dispose;
    exports.disposeVariables = disposeVariables;
    exports.div = div;
    exports.divNoNan = divNoNan;
    exports.dot = dot;
    exports.dropout = dropout;
    exports.einsum = einsum;
    exports.elu = elu;
    exports.enableDebugMode = enableDebugMode;
    exports.enableProdMode = enableProdMode;
    exports.enclosingPowerOfTwo = enclosingPowerOfTwo;
    exports.engine = engine;
    exports.ensureShape = ensureShape;
    exports.env = env;
    exports.equal = equal;
    exports.erf = erf;
    exports.euclideanNorm = euclideanNorm;
    exports.exp = exp;
    exports.expandDims = expandDims;
    exports.expm1 = expm1;
    exports.eye = eye;
    exports.fft = fft;
    exports.fill = fill;
    exports.findBackend = findBackend;
    exports.findBackendFactory = findBackendFactory;
    exports.floor = floor;
    exports.floorDiv = floorDiv;
    exports.fused = fused_ops;
    exports.gather = gather;
    exports.gatherND = gatherND;
    exports.gather_util = gather_nd_util;
    exports.getBackend = getBackend;
    exports.getGradient = getGradient;
    exports.getKernel = getKernel;
    exports.getKernelsForBackend = getKernelsForBackend;
    exports.grad = grad;
    exports.grads = grads;
    exports.greater = greater;
    exports.greaterEqual = greaterEqual;
    exports.ifft = ifft;
    exports.imag = imag;
    exports.image = image;
    exports.inTopKAsync = inTopKAsync;
    exports.io = io;
    exports.irfft = irfft;
    exports.isFinite = isFinite$1;
    exports.isInf = isInf;
    exports.isNaN = isNaN$1;
    exports.keep = keep;
    exports.kernel_impls = kernel_impls;
    exports.leakyRelu = leakyRelu;
    exports.less = less;
    exports.lessEqual = lessEqual;
    exports.linalg = linalg;
    exports.linspace = linspace;
    exports.localResponseNormalization = localResponseNormalization;
    exports.log = log;
    exports.log1p = log1p;
    exports.logSigmoid = logSigmoid;
    exports.logSoftmax = logSoftmax;
    exports.logSumExp = logSumExp;
    exports.logicalAnd = logicalAnd;
    exports.logicalNot = logicalNot;
    exports.logicalOr = logicalOr;
    exports.logicalXor = logicalXor;
    exports.losses = losses;
    exports.lowerBound = lowerBound;
    exports.matMul = matMul$1;
    exports.math = math;
    exports.max = max;
    exports.maxPool = maxPool;
    exports.maxPool3d = maxPool3d;
    exports.maxPoolWithArgmax = maxPoolWithArgmax;
    exports.maximum = maximum;
    exports.mean = mean;
    exports.memory = memory;
    exports.meshgrid = meshgrid;
    exports.min = min;
    exports.minimum = minimum;
    exports.mirrorPad = mirrorPad;
    exports.mod = mod;
    exports.moments = moments;
    exports.movingAverage = movingAverage;
    exports.mul = mul;
    exports.multiRNNCell = multiRNNCell;
    exports.multinomial = multinomial;
    exports.neg = neg;
    exports.nextFrame = nextFrame;
    exports.norm = norm;
    exports.notEqual = notEqual;
    exports.oneHot = oneHot;
    exports.ones = ones;
    exports.onesLike = onesLike;
    exports.op = op;
    exports.outerProduct = outerProduct;
    exports.pad = pad;
    exports.pad1d = pad1d;
    exports.pad2d = pad2d;
    exports.pad3d = pad3d;
    exports.pad4d = pad4d;
    exports.pool = pool;
    exports.pow = pow;
    exports.prelu = prelu;
    exports.print = print;
    exports.prod = prod;
    exports.profile = profile;
    exports.raggedGather = raggedGather;
    exports.raggedRange = raggedRange;
    exports.raggedTensorToTensor = raggedTensorToTensor;
    exports.rand = rand;
    exports.randomGamma = randomGamma;
    exports.randomNormal = randomNormal;
    exports.randomStandardNormal = randomStandardNormal;
    exports.randomUniform = randomUniform;
    exports.randomUniformInt = randomUniformInt;
    exports.range = range;
    exports.ready = ready;
    exports.real = real;
    exports.reciprocal = reciprocal;
    exports.registerBackend = registerBackend;
    exports.registerGradient = registerGradient;
    exports.registerKernel = registerKernel;
    exports.relu = relu;
    exports.relu6 = relu6;
    exports.removeBackend = removeBackend;
    exports.reshape = reshape;
    exports.reverse = reverse;
    exports.reverse1d = reverse1d;
    exports.reverse2d = reverse2d;
    exports.reverse3d = reverse3d;
    exports.reverse4d = reverse4d;
    exports.rfft = rfft;
    exports.round = round;
    exports.rsqrt = rsqrt;
    exports.scalar = scalar;
    exports.scatterND = scatterND;
    exports.scatter_util = scatter_nd_util;
    exports.searchSorted = searchSorted;
    exports.selu = selu;
    exports.separableConv2d = separableConv2d;
    exports.serialization = serialization;
    exports.setBackend = setBackend;
    exports.setPlatform = setPlatform;
    exports.setdiff1dAsync = setdiff1dAsync;
    exports.sigmoid = sigmoid;
    exports.sign = sign;
    exports.signal = signal;
    exports.sin = sin;
    exports.sinh = sinh;
    exports.slice = slice;
    exports.slice1d = slice1d;
    exports.slice2d = slice2d;
    exports.slice3d = slice3d;
    exports.slice4d = slice4d;
    exports.slice_util = slice_util;
    exports.softmax = softmax;
    exports.softplus = softplus;
    exports.spaceToBatchND = spaceToBatchND;
    exports.sparse = sparse;
    exports.sparseToDense = sparseToDense;
    exports.spectral = spectral;
    exports.split = split;
    exports.sqrt = sqrt;
    exports.square = square;
    exports.squaredDifference = squaredDifference;
    exports.squeeze = squeeze;
    exports.stack = stack;
    exports.step = step;
    exports.stridedSlice = stridedSlice;
    exports.string = string;
    exports.sub = sub;
    exports.sum = sum;
    exports.sumOutType = sumOutType;
    exports.tan = tan;
    exports.tanh = tanh;
    exports.tensor = tensor;
    exports.tensor1d = tensor1d;
    exports.tensor2d = tensor2d;
    exports.tensor3d = tensor3d;
    exports.tensor4d = tensor4d;
    exports.tensor5d = tensor5d;
    exports.tensor6d = tensor6d;
    exports.tensorScatterUpdate = tensorScatterUpdate;
    exports.tensor_util = tensor_util;
    exports.test_util = test_util;
    exports.tidy = tidy;
    exports.tile = tile;
    exports.time = time;
    exports.topk = topk;
    exports.train = train;
    exports.transpose = transpose;
    exports.truncatedNormal = truncatedNormal;
    exports.unique = unique;
    exports.unregisterGradient = unregisterGradient;
    exports.unregisterKernel = unregisterKernel;
    exports.unsortedSegmentSum = unsortedSegmentSum;
    exports.unstack = unstack;
    exports.upcastType = upcastType;
    exports.upperBound = upperBound;
    exports.util = util;
    exports.valueAndGrad = valueAndGrad;
    exports.valueAndGrads = valueAndGrads;
    exports.variable = variable;
    exports.variableGrads = variableGrads;
    exports.version_core = version;
    exports.where = where;
    exports.whereAsync = whereAsync;
    exports.zeros = zeros;
    exports.zerosLike = zerosLike;
  }
});

// node_modules/seedrandom/lib/alea.js
var require_alea = __commonJS({
  "node_modules/seedrandom/lib/alea.js"(exports, module) {
    (function(global2, module2, define2) {
      function Alea(seed) {
        var me = this, mash = Mash();
        me.next = function() {
          var t = 2091639 * me.s0 + me.c * 23283064365386963e-26;
          me.s0 = me.s1;
          me.s1 = me.s2;
          return me.s2 = t - (me.c = t | 0);
        };
        me.c = 1;
        me.s0 = mash(" ");
        me.s1 = mash(" ");
        me.s2 = mash(" ");
        me.s0 -= mash(seed);
        if (me.s0 < 0) {
          me.s0 += 1;
        }
        me.s1 -= mash(seed);
        if (me.s1 < 0) {
          me.s1 += 1;
        }
        me.s2 -= mash(seed);
        if (me.s2 < 0) {
          me.s2 += 1;
        }
        mash = null;
      }
      function copy(f, t) {
        t.c = f.c;
        t.s0 = f.s0;
        t.s1 = f.s1;
        t.s2 = f.s2;
        return t;
      }
      function impl(seed, opts) {
        var xg = new Alea(seed), state = opts && opts.state, prng = xg.next;
        prng.int32 = function() {
          return xg.next() * 4294967296 | 0;
        };
        prng.double = function() {
          return prng() + (prng() * 2097152 | 0) * 11102230246251565e-32;
        };
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      function Mash() {
        var n = 4022871197;
        var mash = function(data) {
          data = String(data);
          for (var i = 0; i < data.length; i++) {
            n += data.charCodeAt(i);
            var h = 0.02519603282416938 * n;
            n = h >>> 0;
            h -= n;
            h *= n;
            n = h >>> 0;
            h -= n;
            n += h * 4294967296;
          }
          return (n >>> 0) * 23283064365386963e-26;
        };
        return mash;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.alea = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});

// node_modules/seedrandom/lib/xor128.js
var require_xor128 = __commonJS({
  "node_modules/seedrandom/lib/xor128.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.x = 0;
        me.y = 0;
        me.z = 0;
        me.w = 0;
        me.next = function() {
          var t = me.x ^ me.x << 11;
          me.x = me.y;
          me.y = me.z;
          me.z = me.w;
          return me.w ^= me.w >>> 19 ^ t ^ t >>> 8;
        };
        if (seed === (seed | 0)) {
          me.x = seed;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 64; k++) {
          me.x ^= strseed.charCodeAt(k) | 0;
          me.next();
        }
      }
      function copy(f, t) {
        t.x = f.x;
        t.y = f.y;
        t.z = f.z;
        t.w = f.w;
        return t;
      }
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xor128 = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});

// node_modules/seedrandom/lib/xorwow.js
var require_xorwow = __commonJS({
  "node_modules/seedrandom/lib/xorwow.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.next = function() {
          var t = me.x ^ me.x >>> 2;
          me.x = me.y;
          me.y = me.z;
          me.z = me.w;
          me.w = me.v;
          return (me.d = me.d + 362437 | 0) + (me.v = me.v ^ me.v << 4 ^ (t ^ t << 1)) | 0;
        };
        me.x = 0;
        me.y = 0;
        me.z = 0;
        me.w = 0;
        me.v = 0;
        if (seed === (seed | 0)) {
          me.x = seed;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 64; k++) {
          me.x ^= strseed.charCodeAt(k) | 0;
          if (k == strseed.length) {
            me.d = me.x << 10 ^ me.x >>> 4;
          }
          me.next();
        }
      }
      function copy(f, t) {
        t.x = f.x;
        t.y = f.y;
        t.z = f.z;
        t.w = f.w;
        t.v = f.v;
        t.d = f.d;
        return t;
      }
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xorwow = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});

// node_modules/seedrandom/lib/xorshift7.js
var require_xorshift7 = __commonJS({
  "node_modules/seedrandom/lib/xorshift7.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this;
        me.next = function() {
          var X = me.x, i = me.i, t, v, w;
          t = X[i];
          t ^= t >>> 7;
          v = t ^ t << 24;
          t = X[i + 1 & 7];
          v ^= t ^ t >>> 10;
          t = X[i + 3 & 7];
          v ^= t ^ t >>> 3;
          t = X[i + 4 & 7];
          v ^= t ^ t << 7;
          t = X[i + 7 & 7];
          t = t ^ t << 13;
          v ^= t ^ t << 9;
          X[i] = v;
          me.i = i + 1 & 7;
          return v;
        };
        function init(me2, seed2) {
          var j, w, X = [];
          if (seed2 === (seed2 | 0)) {
            w = X[0] = seed2;
          } else {
            seed2 = "" + seed2;
            for (j = 0; j < seed2.length; ++j) {
              X[j & 7] = X[j & 7] << 15 ^ seed2.charCodeAt(j) + X[j + 1 & 7] << 13;
            }
          }
          while (X.length < 8)
            X.push(0);
          for (j = 0; j < 8 && X[j] === 0; ++j)
            ;
          if (j == 8)
            w = X[7] = -1;
          else
            w = X[j];
          me2.x = X;
          me2.i = 0;
          for (j = 256; j > 0; --j) {
            me2.next();
          }
        }
        init(me, seed);
      }
      function copy(f, t) {
        t.x = f.x.slice();
        t.i = f.i;
        return t;
      }
      function impl(seed, opts) {
        if (seed == null)
          seed = +/* @__PURE__ */ new Date();
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (state.x)
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xorshift7 = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});

// node_modules/seedrandom/lib/xor4096.js
var require_xor4096 = __commonJS({
  "node_modules/seedrandom/lib/xor4096.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this;
        me.next = function() {
          var w = me.w, X = me.X, i = me.i, t, v;
          me.w = w = w + 1640531527 | 0;
          v = X[i + 34 & 127];
          t = X[i = i + 1 & 127];
          v ^= v << 13;
          t ^= t << 17;
          v ^= v >>> 15;
          t ^= t >>> 12;
          v = X[i] = v ^ t;
          me.i = i;
          return v + (w ^ w >>> 16) | 0;
        };
        function init(me2, seed2) {
          var t, v, i, j, w, X = [], limit = 128;
          if (seed2 === (seed2 | 0)) {
            v = seed2;
            seed2 = null;
          } else {
            seed2 = seed2 + "\0";
            v = 0;
            limit = Math.max(limit, seed2.length);
          }
          for (i = 0, j = -32; j < limit; ++j) {
            if (seed2)
              v ^= seed2.charCodeAt((j + 32) % seed2.length);
            if (j === 0)
              w = v;
            v ^= v << 10;
            v ^= v >>> 15;
            v ^= v << 4;
            v ^= v >>> 13;
            if (j >= 0) {
              w = w + 1640531527 | 0;
              t = X[j & 127] ^= v + w;
              i = 0 == t ? i + 1 : 0;
            }
          }
          if (i >= 128) {
            X[(seed2 && seed2.length || 0) & 127] = -1;
          }
          i = 127;
          for (j = 4 * 128; j > 0; --j) {
            v = X[i + 34 & 127];
            t = X[i = i + 1 & 127];
            v ^= v << 13;
            t ^= t << 17;
            v ^= v >>> 15;
            t ^= t >>> 12;
            X[i] = v ^ t;
          }
          me2.w = w;
          me2.X = X;
          me2.i = i;
        }
        init(me, seed);
      }
      function copy(f, t) {
        t.i = f.i;
        t.w = f.w;
        t.X = f.X.slice();
        return t;
      }
      ;
      function impl(seed, opts) {
        if (seed == null)
          seed = +/* @__PURE__ */ new Date();
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (state.X)
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xor4096 = impl;
      }
    })(
      exports,
      // window object or global
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});

// node_modules/seedrandom/lib/tychei.js
var require_tychei = __commonJS({
  "node_modules/seedrandom/lib/tychei.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.next = function() {
          var b = me.b, c = me.c, d = me.d, a = me.a;
          b = b << 25 ^ b >>> 7 ^ c;
          c = c - d | 0;
          d = d << 24 ^ d >>> 8 ^ a;
          a = a - b | 0;
          me.b = b = b << 20 ^ b >>> 12 ^ c;
          me.c = c = c - d | 0;
          me.d = d << 16 ^ c >>> 16 ^ a;
          return me.a = a - b | 0;
        };
        me.a = 0;
        me.b = 0;
        me.c = 2654435769 | 0;
        me.d = 1367130551;
        if (seed === Math.floor(seed)) {
          me.a = seed / 4294967296 | 0;
          me.b = seed | 0;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 20; k++) {
          me.b ^= strseed.charCodeAt(k) | 0;
          me.next();
        }
      }
      function copy(f, t) {
        t.a = f.a;
        t.b = f.b;
        t.c = f.c;
        t.d = f.d;
        return t;
      }
      ;
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy(state, xg);
          prng.state = function() {
            return copy(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.tychei = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});

// node_modules/seedrandom/seedrandom.js
var require_seedrandom = __commonJS({
  "node_modules/seedrandom/seedrandom.js"(exports, module) {
    (function(global2, pool, math) {
      var width = 256, chunks = 6, digits = 52, rngname = "random", startdenom = math.pow(width, chunks), significance = math.pow(2, digits), overflow = significance * 2, mask = width - 1, nodecrypto;
      function seedrandom(seed, options, callback) {
        var key = [];
        options = options == true ? { entropy: true } : options || {};
        var shortseed = mixkey(flatten(
          options.entropy ? [seed, tostring(pool)] : seed == null ? autoseed() : seed,
          3
        ), key);
        var arc4 = new ARC4(key);
        var prng = function() {
          var n = arc4.g(chunks), d = startdenom, x = 0;
          while (n < significance) {
            n = (n + x) * width;
            d *= width;
            x = arc4.g(1);
          }
          while (n >= overflow) {
            n /= 2;
            d /= 2;
            x >>>= 1;
          }
          return (n + x) / d;
        };
        prng.int32 = function() {
          return arc4.g(4) | 0;
        };
        prng.quick = function() {
          return arc4.g(4) / 4294967296;
        };
        prng.double = prng;
        mixkey(tostring(arc4.S), pool);
        return (options.pass || callback || function(prng2, seed2, is_math_call, state) {
          if (state) {
            if (state.S) {
              copy(state, arc4);
            }
            prng2.state = function() {
              return copy(arc4, {});
            };
          }
          if (is_math_call) {
            math[rngname] = prng2;
            return seed2;
          } else
            return prng2;
        })(
          prng,
          shortseed,
          "global" in options ? options.global : this == math,
          options.state
        );
      }
      function ARC4(key) {
        var t, keylen = key.length, me = this, i = 0, j = me.i = me.j = 0, s = me.S = [];
        if (!keylen) {
          key = [keylen++];
        }
        while (i < width) {
          s[i] = i++;
        }
        for (i = 0; i < width; i++) {
          s[i] = s[j = mask & j + key[i % keylen] + (t = s[i])];
          s[j] = t;
        }
        (me.g = function(count) {
          var t2, r = 0, i2 = me.i, j2 = me.j, s2 = me.S;
          while (count--) {
            t2 = s2[i2 = mask & i2 + 1];
            r = r * width + s2[mask & (s2[i2] = s2[j2 = mask & j2 + t2]) + (s2[j2] = t2)];
          }
          me.i = i2;
          me.j = j2;
          return r;
        })(width);
      }
      function copy(f, t) {
        t.i = f.i;
        t.j = f.j;
        t.S = f.S.slice();
        return t;
      }
      ;
      function flatten(obj, depth) {
        var result = [], typ = typeof obj, prop;
        if (depth && typ == "object") {
          for (prop in obj) {
            try {
              result.push(flatten(obj[prop], depth - 1));
            } catch (e) {
            }
          }
        }
        return result.length ? result : typ == "string" ? obj : obj + "\0";
      }
      function mixkey(seed, key) {
        var stringseed = seed + "", smear, j = 0;
        while (j < stringseed.length) {
          key[mask & j] = mask & (smear ^= key[mask & j] * 19) + stringseed.charCodeAt(j++);
        }
        return tostring(key);
      }
      function autoseed() {
        try {
          var out;
          if (nodecrypto && (out = nodecrypto.randomBytes)) {
            out = out(width);
          } else {
            out = new Uint8Array(width);
            (global2.crypto || global2.msCrypto).getRandomValues(out);
          }
          return tostring(out);
        } catch (e) {
          var browser = global2.navigator, plugins = browser && browser.plugins;
          return [+/* @__PURE__ */ new Date(), global2, plugins, global2.screen, tostring(pool)];
        }
      }
      function tostring(a) {
        return String.fromCharCode.apply(0, a);
      }
      mixkey(math.random(), pool);
      if (typeof module == "object" && module.exports) {
        module.exports = seedrandom;
        try {
          nodecrypto = require_crypto();
        } catch (ex) {
        }
      } else if (typeof define == "function" && define.amd) {
        define(function() {
          return seedrandom;
        });
      } else {
        math["seed" + rngname] = seedrandom;
      }
    })(
      // global: `self` in browsers (including strict mode and web workers),
      // otherwise `this` in Node and other environments
      typeof self !== "undefined" ? self : exports,
      [],
      // pool: entropy pool starts empty
      Math
      // math: package containing random, pow, and seedrandom
    );
  }
});

// node_modules/seedrandom/index.js
var require_seedrandom2 = __commonJS({
  "node_modules/seedrandom/index.js"(exports, module) {
    var alea = require_alea();
    var xor128 = require_xor128();
    var xorwow = require_xorwow();
    var xorshift7 = require_xorshift7();
    var xor4096 = require_xor4096();
    var tychei = require_tychei();
    var sr = require_seedrandom();
    sr.alea = alea;
    sr.xor128 = xor128;
    sr.xorwow = xorwow;
    sr.xorshift7 = xorshift7;
    sr.xor4096 = xor4096;
    sr.tychei = tychei;
    module.exports = sr;
  }
});

// node_modules/@tensorflow/tfjs-backend-cpu/dist/tf-backend-cpu.node.js
var require_tf_backend_cpu_node = __commonJS({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/tf-backend-cpu.node.js"(exports) {
    "use strict";
    var tfjsCore = require_tf_core_node();
    var seedrandom = require_seedrandom2();
    function _interopNamespaceDefault(e) {
      var n = /* @__PURE__ */ Object.create(null);
      if (e) {
        Object.keys(e).forEach(function(k) {
          if (k !== "default") {
            var d = Object.getOwnPropertyDescriptor(e, k);
            Object.defineProperty(n, k, d.get ? d : {
              enumerable: true,
              get: function() {
                return e[k];
              }
            });
          }
        });
      }
      n.default = e;
      return n;
    }
    var seedrandom__namespace = /* @__PURE__ */ _interopNamespaceDefault(seedrandom);
    var extendStatics = function(d, b) {
      extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(d2, b2) {
        d2.__proto__ = b2;
      } || function(d2, b2) {
        for (var p2 in b2)
          if (Object.prototype.hasOwnProperty.call(b2, p2))
            d2[p2] = b2[p2];
      };
      return extendStatics(d, b);
    };
    function __extends(d, b) {
      if (typeof b !== "function" && b !== null)
        throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
      extendStatics(d, b);
      function __() {
        this.constructor = d;
      }
      d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    }
    function __awaiter(thisArg, _arguments, P, generator) {
      function adopt(value) {
        return value instanceof P ? value : new P(function(resolve) {
          resolve(value);
        });
      }
      return new (P || (P = Promise))(function(resolve, reject) {
        function fulfilled(value) {
          try {
            step2(generator.next(value));
          } catch (e) {
            reject(e);
          }
        }
        function rejected(value) {
          try {
            step2(generator["throw"](value));
          } catch (e) {
            reject(e);
          }
        }
        function step2(result) {
          result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step2((generator = generator.apply(thisArg, _arguments || [])).next());
      });
    }
    function __generator(thisArg, body) {
      var _ = { label: 0, sent: function() {
        if (t[0] & 1)
          throw t[1];
        return t[1];
      }, trys: [], ops: [] }, f, y, t, g;
      return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
      }), g;
      function verb(n) {
        return function(v) {
          return step2([n, v]);
        };
      }
      function step2(op) {
        if (f)
          throw new TypeError("Generator is already executing.");
        while (_)
          try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done)
              return t;
            if (y = 0, t)
              op = [op[0] & 2, t.value];
            switch (op[0]) {
              case 0:
              case 1:
                t = op;
                break;
              case 4:
                _.label++;
                return { value: op[1], done: false };
              case 5:
                _.label++;
                y = op[1];
                op = [0];
                continue;
              case 7:
                op = _.ops.pop();
                _.trys.pop();
                continue;
              default:
                if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {
                  _ = 0;
                  continue;
                }
                if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {
                  _.label = op[1];
                  break;
                }
                if (op[0] === 6 && _.label < t[1]) {
                  _.label = t[1];
                  t = op;
                  break;
                }
                if (t && _.label < t[2]) {
                  _.label = t[2];
                  _.ops.push(op);
                  break;
                }
                if (t[2])
                  _.ops.pop();
                _.trys.pop();
                continue;
            }
            op = body.call(thisArg, _);
          } catch (e) {
            op = [6, e];
            y = 0;
          } finally {
            f = t = 0;
          }
        if (op[0] & 5)
          throw op[1];
        return { value: op[0] ? op[1] : void 0, done: true };
      }
    }
    function __values(o) {
      var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
      if (m)
        return m.call(o);
      if (o && typeof o.length === "number")
        return {
          next: function() {
            if (o && i >= o.length)
              o = void 0;
            return { value: o && o[i++], done: !o };
          }
        };
      throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
    }
    function __read(o, n) {
      var m = typeof Symbol === "function" && o[Symbol.iterator];
      if (!m)
        return o;
      var i = m.call(o), r, ar = [], e;
      try {
        while ((n === void 0 || n-- > 0) && !(r = i.next()).done)
          ar.push(r.value);
      } catch (error) {
        e = { error };
      } finally {
        try {
          if (r && !r.done && (m = i["return"]))
            m.call(i);
        } finally {
          if (e)
            throw e.error;
        }
      }
      return ar;
    }
    function __spreadArray(to, from, pack2) {
      if (pack2 || arguments.length === 2)
        for (var i = 0, l = from.length, ar; i < l; i++) {
          if (ar || !(i in from)) {
            if (!ar)
              ar = Array.prototype.slice.call(from, 0, i);
            ar[i] = from[i];
          }
        }
      return to.concat(ar || Array.prototype.slice.call(from));
    }
    function assertNotComplex(tensor, opName) {
      if (!Array.isArray(tensor)) {
        tensor = [tensor];
      }
      tensor.forEach(function(t) {
        if (t != null) {
          tfjsCore.util.assert(t.dtype !== "complex64", function() {
            return "".concat(opName, " does not support complex64 tensors in the CPU backend.");
          });
        }
      });
    }
    var whereImpl = tfjsCore.kernel_impls.whereImpl;
    var MathBackendCPU = (
      /** @class */
      function(_super) {
        __extends(MathBackendCPU2, _super);
        function MathBackendCPU2() {
          var _this = _super.call(this) || this;
          _this.blockSize = 48;
          _this.firstUse = true;
          _this.data = new tfjsCore.DataStorage(_this, tfjsCore.engine());
          return _this;
        }
        MathBackendCPU2.prototype.nextDataId = function() {
          return MathBackendCPU2.nextDataId++;
        };
        MathBackendCPU2.prototype.write = function(values, shape, dtype) {
          if (this.firstUse) {
            this.firstUse = false;
            if (tfjsCore.env().get("IS_NODE")) {
              tfjsCore.backend_util.warn("\n============================\nHi, looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, visit https://github.com/tensorflow/tfjs-node for more details. \n============================");
            }
          }
          var dataId = { id: this.nextDataId() };
          this.data.set(dataId, { values, dtype, refCount: 1 });
          return dataId;
        };
        MathBackendCPU2.prototype.makeTensorInfo = function(shape, dtype, values) {
          var outId;
          if (dtype === "string" && values != null && values.length > 0 && tfjsCore.util.isString(values[0])) {
            var encodedValues = values.map(function(d) {
              return tfjsCore.util.encodeString(d);
            });
            outId = this.write(encodedValues, shape, dtype);
          } else {
            outId = this.write(values, shape, dtype);
          }
          return { dataId: outId, shape, dtype };
        };
        MathBackendCPU2.prototype.refCount = function(dataId) {
          if (this.data.has(dataId)) {
            var tensorData = this.data.get(dataId);
            return tensorData.refCount;
          }
          return 0;
        };
        MathBackendCPU2.prototype.incRef = function(dataId) {
          var tensorData = this.data.get(dataId);
          tensorData.refCount++;
        };
        MathBackendCPU2.prototype.decRef = function(dataId) {
          if (this.data.has(dataId)) {
            var tensorData = this.data.get(dataId);
            tensorData.refCount--;
          }
        };
        MathBackendCPU2.prototype.move = function(dataId, values, shape, dtype, refCount) {
          this.data.set(dataId, { values, dtype, refCount });
        };
        MathBackendCPU2.prototype.numDataIds = function() {
          return this.data.numDataIds();
        };
        MathBackendCPU2.prototype.read = function(dataId) {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_b) {
              return [2, this.readSync(dataId)];
            });
          });
        };
        MathBackendCPU2.prototype.readSync = function(dataId) {
          var _b = this.data.get(dataId), dtype = _b.dtype, complexTensorInfos = _b.complexTensorInfos;
          if (dtype === "complex64") {
            var realValues = this.readSync(complexTensorInfos.real.dataId);
            var imagValues = this.readSync(complexTensorInfos.imag.dataId);
            return tfjsCore.backend_util.mergeRealAndImagArrays(realValues, imagValues);
          }
          return tfjsCore.util.convertBackendValuesAndArrayBuffer(this.data.get(dataId).values, dtype);
        };
        MathBackendCPU2.prototype.bufferSync = function(t) {
          var data = this.readSync(t.dataId);
          if (t.dtype === "string") {
            try {
              var strings = data.map(function(d) {
                return tfjsCore.util.decodeString(d);
              });
              return tfjsCore.buffer(t.shape, t.dtype, strings);
            } catch (_a2) {
              throw new Error("Failed to decode encoded string bytes into utf-8");
            }
          }
          return tfjsCore.buffer(t.shape, t.dtype, data);
        };
        MathBackendCPU2.prototype.makeOutput = function(values, shape, dtype) {
          return tfjsCore.engine().makeTensorFromTensorInfo(this.makeTensorInfo(shape, dtype, values), this);
        };
        MathBackendCPU2.prototype.disposeData = function(dataId, force) {
          if (force === void 0) {
            force = false;
          }
          if (this.data.has(dataId)) {
            this.data.get(dataId).refCount--;
            if (!force && this.data.get(dataId).refCount > 0) {
              return false;
            }
            var complexTensorInfos = this.data.get(dataId).complexTensorInfos;
            if (complexTensorInfos != null) {
              this.disposeData(complexTensorInfos.real.dataId, true);
              this.disposeData(complexTensorInfos.imag.dataId, true);
            }
            this.data.delete(dataId);
          }
          return true;
        };
        MathBackendCPU2.prototype.disposeIntermediateTensorInfo = function(tensorInfo) {
          this.disposeData(tensorInfo.dataId);
        };
        MathBackendCPU2.prototype.time = function(f) {
          return __awaiter(this, void 0, void 0, function() {
            var start, kernelMs;
            return __generator(this, function(_b) {
              start = tfjsCore.util.now();
              f();
              kernelMs = tfjsCore.util.now() - start;
              return [2, { kernelMs }];
            });
          });
        };
        MathBackendCPU2.prototype.memory = function() {
          return {
            // Unreliable due to automatic gc. The numbers above are cumulative.
            unreliable: true,
            reasons: ["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]
          };
        };
        MathBackendCPU2.prototype.where = function(condition) {
          assertNotComplex([condition], "where");
          var condVals = this.readSync(condition.dataId);
          return whereImpl(condition.shape, condVals);
        };
        MathBackendCPU2.prototype.dispose = function() {
        };
        MathBackendCPU2.prototype.floatPrecision = function() {
          return 32;
        };
        MathBackendCPU2.prototype.epsilon = function() {
          return _super.prototype.epsilon.call(this);
        };
        return MathBackendCPU2;
      }(tfjsCore.KernelBackend)
    );
    MathBackendCPU.nextDataId = 0;
    function simpleAbsImpl(vals) {
      var resultValues = new Float32Array(vals.length);
      for (var i = 0; i < vals.length; ++i) {
        resultValues[i] = Math.abs(vals[i]);
      }
      return resultValues;
    }
    var abs = function(args) {
      var x = args.inputs.x;
      var cpuBackend = args.backend;
      assertNotComplex(x, "abs");
      var resultValues = new Float32Array(tfjsCore.util.sizeFromShape(x.shape));
      var values = cpuBackend.data.get(x.dataId).values;
      resultValues = simpleAbsImpl(values);
      return cpuBackend.makeOutput(resultValues, x.shape, x.dtype);
    };
    var absConfig = {
      kernelName: tfjsCore.Abs,
      backendName: "cpu",
      kernelFunc: abs
    };
    function createSimpleBinaryKernelImpl(op) {
      return function(aShape, bShape, aVals, bVals, dtype) {
        var newShape = tfjsCore.backend_util.assertAndGetBroadcastShape(aShape, bShape);
        var resultRank = newShape.length;
        var resultStrides = tfjsCore.util.computeStrides(newShape);
        var resultSize = tfjsCore.util.sizeFromShape(newShape);
        var result = tfjsCore.util.getTypedArrayFromDType(dtype, resultSize);
        var aRank = aShape.length;
        var bRank = bShape.length;
        var aStrides = tfjsCore.util.computeStrides(aShape);
        var bStrides = tfjsCore.util.computeStrides(bShape);
        var aBroadcastDims = tfjsCore.backend_util.getBroadcastDims(aShape, newShape);
        var bBroadcastDims = tfjsCore.backend_util.getBroadcastDims(bShape, newShape);
        if (aBroadcastDims.length + bBroadcastDims.length === 0) {
          for (var i = 0; i < result.length; ++i) {
            result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);
          }
        } else {
          var _loop_1 = function(i2) {
            var loc = tfjsCore.util.indexToLoc(i2, resultRank, resultStrides);
            var aLoc = loc.slice(-aRank);
            aBroadcastDims.forEach(function(d) {
              return aLoc[d] = 0;
            });
            var aIndex = tfjsCore.util.locToIndex(aLoc, aRank, aStrides);
            var bLoc = loc.slice(-bRank);
            bBroadcastDims.forEach(function(d) {
              return bLoc[d] = 0;
            });
            var bIndex = tfjsCore.util.locToIndex(bLoc, bRank, bStrides);
            result[i2] = op(aVals[aIndex], bVals[bIndex]);
          };
          for (var i = 0; i < result.length; ++i) {
            _loop_1(i);
          }
        }
        return [result, newShape];
      };
    }
    function complex(args) {
      var inputs = args.inputs, backend = args.backend;
      var real2 = inputs.real, imag2 = inputs.imag;
      var realVals = backend.data.get(real2.dataId).values;
      var imagVals = backend.data.get(imag2.dataId).values;
      var complexInfo = backend.makeTensorInfo(real2.shape, "complex64");
      var complex2 = backend.data.get(complexInfo.dataId);
      complex2.complexTensorInfos = {
        real: backend.makeTensorInfo(real2.shape, "float32", realVals),
        imag: backend.makeTensorInfo(imag2.shape, "float32", imagVals)
      };
      return complexInfo;
    }
    var complexConfig = {
      kernelName: tfjsCore.Complex,
      backendName: "cpu",
      kernelFunc: complex
    };
    function zeros(backend, shape, dtype) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      if (dtype === "complex64") {
        var real2 = zeros(backend, shape, "float32");
        var imag2 = zeros(backend, shape, "float32");
        return complex({ inputs: { real: real2, imag: imag2 }, backend });
      }
      var values = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape(shape), dtype);
      return backend.makeTensorInfo(shape, dtype, values);
    }
    function identity(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x;
      backend.incRef(x.dataId);
      return { dataId: x.dataId, shape: x.shape, dtype: x.dtype };
    }
    var identityConfig = {
      kernelName: tfjsCore.Identity,
      backendName: "cpu",
      kernelFunc: identity
    };
    function real(args) {
      var inputs = args.inputs, backend = args.backend;
      var input = inputs.input;
      var real2 = backend.data.get(input.dataId).complexTensorInfos.real;
      var realVal = backend.data.get(real2.dataId).values;
      return backend.makeTensorInfo(real2.shape, real2.dtype, realVal);
    }
    var realConfig = {
      kernelName: tfjsCore.Real,
      backendName: "cpu",
      kernelFunc: real
    };
    function castImpl(values, shape, inputType, dtype) {
      if (dtype === "int32") {
        var resultValues = Int32Array.from(values);
        return [shape, "int32", resultValues];
      }
      if (dtype === "bool") {
        var zero = tfjsCore.util.toTypedArray([0], inputType);
        var _a2 = __read(createSimpleBinaryKernelImpl(function(a, b) {
          return a !== b ? 1 : 0;
        })(shape, [], values, zero, "bool"), 2), resultData = _a2[0], resultShape = _a2[1];
        return [resultShape, "bool", resultData];
      }
      throw new Error("Error in Cast: failed to cast ".concat(inputType, " to ").concat(dtype));
    }
    function cast(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var dtype = attrs.dtype;
      if (dtype === "complex64") {
        if (x.dtype === "complex64") {
          return identity({ inputs: { x }, backend });
        }
        var zerosTensorInfo = zeros(backend, x.shape, x.dtype);
        var floatX = cast({ inputs: { x }, backend, attrs: { dtype: "float32" } });
        var result = complex({ inputs: { real: floatX, imag: zerosTensorInfo }, backend });
        backend.disposeIntermediateTensorInfo(zerosTensorInfo);
        backend.disposeIntermediateTensorInfo(floatX);
        return result;
      }
      if (x.dtype === "complex64") {
        var realPart = real({ inputs: { input: x }, backend });
        var result = cast({ inputs: { x: realPart }, backend, attrs: { dtype } });
        backend.disposeIntermediateTensorInfo(realPart);
        return result;
      }
      if (!tfjsCore.util.hasEncodingLoss(x.dtype, dtype)) {
        var result = identity({ inputs: { x }, backend });
        return { dataId: result.dataId, shape: result.shape, dtype };
      }
      var values = backend.data.get(x.dataId).values;
      var _a2 = __read(castImpl(values, x.shape, x.dtype, dtype), 3), resultShape = _a2[0], resultType = _a2[1], resultData = _a2[2];
      return backend.makeTensorInfo(resultShape, resultType, resultData);
    }
    var castConfig = {
      kernelName: tfjsCore.Cast,
      backendName: "cpu",
      kernelFunc: cast
    };
    function binaryKernelFunc(name, simpleImpl, complexImpl, dtype) {
      if (complexImpl == null) {
        return function(_a2) {
          var inputs = _a2.inputs, backend = _a2.backend;
          var a = inputs.a, b = inputs.b;
          var cpuBackend = backend;
          assertNotComplex([a, b], name);
          var aVals = cpuBackend.data.get(a.dataId).values;
          var bVals = cpuBackend.data.get(b.dataId).values;
          var decodedAVals = a.dtype === "string" ? (
            // tslint:disable-next-line: no-any
            tfjsCore.backend_util.fromUint8ToStringArray(aVals)
          ) : aVals;
          var decodedBVals = a.dtype === "string" ? (
            // tslint:disable-next-line: no-any
            tfjsCore.backend_util.fromUint8ToStringArray(bVals)
          ) : bVals;
          var $dtype = dtype || a.dtype;
          var _b = __read(simpleImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype), 2), resultData = _b[0], resultShape = _b[1];
          return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);
        };
      }
      return function(_a2) {
        var inputs = _a2.inputs, backend = _a2.backend;
        var a = inputs.a, b = inputs.b;
        var cpuBackend = backend;
        if (a.dtype === "complex64" || b.dtype === "complex64") {
          var $aComplex = cast({ inputs: { x: a }, backend: cpuBackend, attrs: { dtype: "complex64" } });
          var $aComplexVals = cpuBackend.data.get($aComplex.dataId);
          var aReal = $aComplexVals.complexTensorInfos.real;
          var aImag = $aComplexVals.complexTensorInfos.imag;
          var aRealVals = cpuBackend.data.get(aReal.dataId).values;
          var aImagVals = cpuBackend.data.get(aImag.dataId).values;
          var $bComplex = cast({ inputs: { x: b }, backend: cpuBackend, attrs: { dtype: "complex64" } });
          var $bComplexVals = cpuBackend.data.get($bComplex.dataId);
          var bReal = $bComplexVals.complexTensorInfos.real;
          var bImag = $bComplexVals.complexTensorInfos.imag;
          var bRealVals = cpuBackend.data.get(bReal.dataId).values;
          var bImagVals = cpuBackend.data.get(bImag.dataId).values;
          var _b = __read(complexImpl(a.shape, b.shape, aRealVals, aImagVals, bRealVals, bImagVals), 3), resultRealData = _b[0], resultImagData = _b[1], resultShape = _b[2];
          var resultReal = cpuBackend.makeTensorInfo(resultShape, "float32", resultRealData);
          var resultImag = cpuBackend.makeTensorInfo(resultShape, "float32", resultImagData);
          var result = complex({ inputs: { real: resultReal, imag: resultImag }, backend: cpuBackend });
          cpuBackend.disposeIntermediateTensorInfo($aComplex);
          cpuBackend.disposeIntermediateTensorInfo($bComplex);
          cpuBackend.disposeIntermediateTensorInfo(resultReal);
          cpuBackend.disposeIntermediateTensorInfo(resultImag);
          return result;
        } else {
          var aVals = cpuBackend.data.get(a.dataId).values;
          var bVals = cpuBackend.data.get(b.dataId).values;
          var $dtype = dtype || a.dtype;
          var _c = __read(simpleImpl(a.shape, b.shape, aVals, bVals, $dtype), 2), resultData = _c[0], resultShape = _c[1];
          return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);
        }
      };
    }
    function createComplexBinaryKernelImpl(op) {
      return function(aShape, bShape, aRealVals, aImagVals, bRealVals, bImagVals) {
        var resultShape = tfjsCore.backend_util.assertAndGetBroadcastShape(aShape, bShape);
        var resultSize = tfjsCore.util.sizeFromShape(resultShape);
        var resultRank = resultShape.length;
        var resultStrides = tfjsCore.util.computeStrides(resultShape);
        var resultRealVals = tfjsCore.util.getTypedArrayFromDType("float32", resultSize);
        var resultImagVals = tfjsCore.util.getTypedArrayFromDType("float32", resultSize);
        var aBroadcastDims = tfjsCore.backend_util.getBroadcastDims(aShape, resultShape);
        var bBroadcastDims = tfjsCore.backend_util.getBroadcastDims(bShape, resultShape);
        var aVals = tfjsCore.backend_util.mergeRealAndImagArrays(aRealVals, aImagVals);
        var bVals = tfjsCore.backend_util.mergeRealAndImagArrays(bRealVals, bImagVals);
        var aRank = aShape.length;
        var aStrides = tfjsCore.util.computeStrides(aShape);
        var bRank = bShape.length;
        var bStrides = tfjsCore.util.computeStrides(bShape);
        if (aBroadcastDims.length + bBroadcastDims.length === 0) {
          for (var i = 0; i < resultRealVals.length; i++) {
            var aIdx = i % aVals.length;
            var bIdx = i % bVals.length;
            var result = op(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2], bVals[bIdx * 2 + 1]);
            resultRealVals[i] = result.real;
            resultImagVals[i] = result.imag;
          }
        } else {
          var _loop_1 = function(i2) {
            var loc = tfjsCore.util.indexToLoc(i2, resultRank, resultStrides);
            var aLoc = loc.slice(-aRank);
            aBroadcastDims.forEach(function(d) {
              return aLoc[d] = 0;
            });
            var aIndex = tfjsCore.util.locToIndex(aLoc, aRank, aStrides);
            var bLoc = loc.slice(-bRank);
            bBroadcastDims.forEach(function(d) {
              return bLoc[d] = 0;
            });
            var bIndex = tfjsCore.util.locToIndex(bLoc, bRank, bStrides);
            var opResult = op(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2], bVals[bIndex * 2 + 1]);
            resultRealVals[i2] = opResult.real;
            resultImagVals[i2] = opResult.imag;
          };
          for (var i = 0; i < resultRealVals.length; i++) {
            _loop_1(i);
          }
        }
        return [resultRealVals, resultImagVals, resultShape];
      };
    }
    var addImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a + b;
    });
    var addComplexImpl = createComplexBinaryKernelImpl(function(aReal, aImag, bReal, bImag) {
      return { real: aReal + bReal, imag: aImag + bImag };
    });
    var add = binaryKernelFunc(tfjsCore.Add, addImpl, addComplexImpl);
    var addConfig = {
      kernelName: tfjsCore.Add,
      backendName: "cpu",
      kernelFunc: add
    };
    function bincountImpl(xVals, weightsVals, weightsDtype, weightsShape, size) {
      var weightsSize = tfjsCore.util.sizeFromShape(weightsShape);
      var outVals = tfjsCore.util.makeZerosTypedArray(size, weightsDtype);
      for (var i = 0; i < xVals.length; i++) {
        var value = xVals[i];
        if (value < 0) {
          throw new Error("Input x must be non-negative!");
        }
        if (value >= size) {
          continue;
        }
        if (weightsSize > 0) {
          outVals[value] += weightsVals[i];
        } else {
          outVals[value] += 1;
        }
      }
      return outVals;
    }
    function bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput) {
      if (binaryOutput === void 0) {
        binaryOutput = false;
      }
      var numRows = xBuf.shape[0];
      var numCols = xBuf.shape[1];
      var outBuf = tfjsCore.buffer([numRows, size], weightsBuf.dtype);
      for (var i = 0; i < numRows; i++) {
        for (var j = 0; j < numCols; j++) {
          var value = xBuf.get(i, j);
          if (value < 0) {
            throw new Error("Input x must be non-negative!");
          }
          if (value >= size) {
            continue;
          }
          if (binaryOutput) {
            outBuf.set(1, i, value);
          } else {
            if (weightsBuf.size > 0) {
              outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j), i, value);
            } else {
              outBuf.set(outBuf.get(i, value) + 1, i, value);
            }
          }
        }
      }
      return outBuf;
    }
    var bitwiseAndImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a & b;
    });
    var bitwiseAnd = binaryKernelFunc(tfjsCore.BitwiseAnd, bitwiseAndImpl);
    var bitwiseAndConfig = {
      kernelName: tfjsCore.BitwiseAnd,
      backendName: "cpu",
      kernelFunc: bitwiseAnd
    };
    function createSimpleUnaryImpl(op) {
      return function(values, dtype, attrs) {
        var newValues = tfjsCore.util.getArrayFromDType(dtype, values.length);
        for (var i = 0; i < values.length; ++i) {
          newValues[i] = op(values[i], attrs);
        }
        return newValues;
      };
    }
    function unaryKernelFunc(name, op, dtype) {
      var impl = createSimpleUnaryImpl(op);
      return unaryKernelFuncFromImpl(name, impl, dtype);
    }
    function unaryKernelFuncFromImpl(name, unaryImpl, dtype) {
      return function(_a2) {
        var inputs = _a2.inputs, attrs = _a2.attrs, backend = _a2.backend;
        var x = inputs.x;
        assertNotComplex(x, name);
        var cpuBackend = backend;
        var values = cpuBackend.data.get(x.dataId).values;
        var decoded;
        if (x.dtype === "string") {
          if (!Array.isArray(values)) {
            throw new Error("String tensor's value was not an instance of Array");
          }
          decoded = tfjsCore.backend_util.fromUint8ToStringArray(values);
        } else {
          decoded = values;
        }
        var $dtype = dtype || x.dtype;
        var newValues = unaryImpl(decoded, $dtype, attrs);
        return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);
      };
    }
    var ceilImpl = createSimpleUnaryImpl(function(xi) {
      return Math.ceil(xi);
    });
    var ceil = unaryKernelFuncFromImpl(tfjsCore.Ceil, ceilImpl);
    var ceilConfig = {
      kernelName: tfjsCore.Ceil,
      backendName: "cpu",
      kernelFunc: ceil
    };
    function concatImpl(inputs, outShape, dtype, simplyConcat) {
      var outVals = tfjsCore.util.getArrayFromDType(dtype, tfjsCore.util.sizeFromShape(outShape));
      if (simplyConcat && dtype !== "string") {
        var offset_1 = 0;
        inputs.forEach(function(input) {
          var size = tfjsCore.util.sizeFromShape(input.shape);
          outVals.set(input.vals, offset_1);
          offset_1 += size;
        });
      } else {
        var colOffset_1 = 0;
        inputs.forEach(function(input) {
          var decodedData = dtype === "string" ? tfjsCore.backend_util.fromUint8ToStringArray(input.vals) : input.vals;
          var tIdx = 0;
          for (var row = 0; row < input.shape[0]; ++row) {
            var resIdx = row * outShape[1] + colOffset_1;
            for (var col = 0; col < input.shape[1]; ++col) {
              outVals[resIdx + col] = decodedData[tIdx++];
            }
          }
          colOffset_1 += input.shape[1];
        });
      }
      return outVals;
    }
    var equalImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a === b ? 1 : 0;
    });
    var equal = binaryKernelFunc(tfjsCore.Equal, equalImpl, null, "bool");
    var equalConfig = {
      kernelName: tfjsCore.Equal,
      backendName: "cpu",
      kernelFunc: equal
    };
    var expImpl = createSimpleUnaryImpl(function(xi) {
      return Math.exp(xi);
    });
    var exp = unaryKernelFuncFromImpl(tfjsCore.Exp, expImpl, "float32");
    var expConfig = {
      kernelName: tfjsCore.Exp,
      backendName: "cpu",
      kernelFunc: exp
    };
    var expm1Impl = createSimpleUnaryImpl(function(xi) {
      return Math.expm1(xi);
    });
    var expm1 = unaryKernelFuncFromImpl(tfjsCore.Expm1, expm1Impl);
    var expm1Config = {
      kernelName: tfjsCore.Expm1,
      backendName: "cpu",
      kernelFunc: expm1
    };
    var floorImpl = createSimpleUnaryImpl(function(xi) {
      return Math.floor(xi);
    });
    var floor = unaryKernelFuncFromImpl(tfjsCore.Floor, floorImpl);
    var floorConfig = {
      kernelName: tfjsCore.Floor,
      backendName: "cpu",
      kernelFunc: floor
    };
    var floorDivImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return Math.floor(a / b);
    });
    var floorDiv = binaryKernelFunc(tfjsCore.FloorDiv, floorDivImpl, null, "int32");
    var floorDivConfig = {
      kernelName: tfjsCore.FloorDiv,
      backendName: "cpu",
      kernelFunc: floorDiv
    };
    function gatherNdImpl(indicesData, paramsBuf, dtype, numSlices, sliceRank, sliceSize, strides, paramsShape, paramsSize) {
      var outBuf = tfjsCore.buffer([numSlices, sliceSize], dtype);
      for (var i = 0; i < numSlices; i++) {
        var index = [];
        var flattenIndex = 0;
        for (var j = 0; j < sliceRank; j++) {
          var dim = indicesData[i * sliceRank + j];
          flattenIndex += dim * strides[j];
          index.push(dim);
        }
        if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {
          throw new Error("Invalid indices: ".concat(index, " does not index into ").concat(paramsShape));
        }
        for (var k = 0; k < sliceSize; k++) {
          outBuf.values[i * sliceSize + k] = paramsBuf.get.apply(paramsBuf, __spreadArray([], __read(paramsBuf.indexToLoc(flattenIndex * sliceSize + k)), false));
        }
      }
      return outBuf;
    }
    function gatherV2Impl(xBuf, indicesBuf, flattenOutputShape) {
      var outBuf = tfjsCore.buffer(flattenOutputShape, xBuf.dtype);
      for (var i = 0; i < outBuf.size; ++i) {
        var newLoc = outBuf.indexToLoc(i);
        var originalLoc = newLoc.slice();
        var batchIdx = originalLoc[0];
        var indicesIdx = originalLoc[2];
        var indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);
        originalLoc[2] = indicesBuf.values[indicesIndex];
        var originalIndex = xBuf.locToIndex(originalLoc);
        if (0 <= originalIndex && originalIndex < xBuf.values.length) {
          outBuf.values[i] = xBuf.values[originalIndex];
        }
      }
      return outBuf;
    }
    var greaterImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a > b ? 1 : 0;
    });
    var greater = binaryKernelFunc(tfjsCore.Greater, greaterImpl, null, "bool");
    var greaterConfig = {
      kernelName: tfjsCore.Greater,
      backendName: "cpu",
      kernelFunc: greater
    };
    var greaterEqualImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a >= b ? 1 : 0;
    });
    var greaterEqual = binaryKernelFunc(tfjsCore.GreaterEqual, greaterEqualImpl, null, "bool");
    var greaterEqualConfig = {
      kernelName: tfjsCore.GreaterEqual,
      backendName: "cpu",
      kernelFunc: greaterEqual
    };
    var lessImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a < b ? 1 : 0;
    });
    var less = binaryKernelFunc(tfjsCore.Less, lessImpl, null, "bool");
    var lessConfig = {
      kernelName: tfjsCore.Less,
      backendName: "cpu",
      kernelFunc: less
    };
    var lessEqualImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a <= b ? 1 : 0;
    });
    var lessEqual = binaryKernelFunc(tfjsCore.LessEqual, lessEqualImpl, null, "bool");
    var lessEqualConfig = {
      kernelName: tfjsCore.LessEqual,
      backendName: "cpu",
      kernelFunc: lessEqual
    };
    function linSpaceImpl(start, stop, num) {
      var step2 = (stop - start) / (num - 1);
      var values = tfjsCore.util.makeZerosTypedArray(num, "float32");
      values[0] = start;
      for (var i = 1; i < values.length; i++) {
        values[i] = values[i - 1] + step2;
      }
      return values;
    }
    var logImpl = createSimpleUnaryImpl(function(xi) {
      return Math.log(xi);
    });
    var log = unaryKernelFuncFromImpl(tfjsCore.Log, logImpl);
    var logConfig = {
      kernelName: tfjsCore.Log,
      backendName: "cpu",
      kernelFunc: log
    };
    function maxImpl(aVals, reduceSize, outShape, dtype) {
      var vals = tfjsCore.util.getTypedArrayFromDType(dtype, tfjsCore.util.sizeFromShape(outShape));
      for (var i = 0; i < vals.length; ++i) {
        var offset = i * reduceSize;
        var max2 = aVals[offset];
        for (var j = 0; j < reduceSize; ++j) {
          var value = aVals[offset + j];
          if (Number.isNaN(value) || value > max2) {
            max2 = value;
          }
        }
        vals[i] = max2;
      }
      return vals;
    }
    var maximumImpl = createSimpleBinaryKernelImpl(function(aValue, bValue) {
      return Math.max(aValue, bValue);
    });
    var maximum = binaryKernelFunc(tfjsCore.Maximum, maximumImpl);
    var maximumConfig = {
      kernelName: tfjsCore.Maximum,
      backendName: "cpu",
      kernelFunc: maximum
    };
    var minimumImpl = createSimpleBinaryKernelImpl(function(aValue, bValue) {
      return Math.min(aValue, bValue);
    });
    var minimum = binaryKernelFunc(tfjsCore.Minimum, minimumImpl);
    var minimumConfig = {
      kernelName: tfjsCore.Minimum,
      backendName: "cpu",
      kernelFunc: minimum
    };
    var multiplyImpl = createSimpleBinaryKernelImpl(function(aValue, bValue) {
      return aValue * bValue;
    });
    var multiplyComplexImpl = createComplexBinaryKernelImpl(function(aReal, aImag, bReal, bImag) {
      return {
        real: aReal * bReal - aImag * bImag,
        imag: aReal * bImag + aImag * bReal
      };
    });
    var multiply = binaryKernelFunc(tfjsCore.Multiply, multiplyImpl, multiplyComplexImpl);
    var multiplyConfig = {
      kernelName: tfjsCore.Multiply,
      backendName: "cpu",
      kernelFunc: multiply
    };
    function negImpl(xVals, xShape, xDtype) {
      var minusOne = tfjsCore.util.createScalarValue(-1, xDtype);
      return multiplyImpl([], xShape, minusOne, xVals, xDtype);
    }
    function neg(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x;
      assertNotComplex(x, "neg");
      var xVals = backend.data.get(x.dataId).values;
      var _a2 = __read(negImpl(xVals, x.shape, x.dtype), 2), res = _a2[0], newShape = _a2[1];
      return backend.makeTensorInfo(newShape, x.dtype, res);
    }
    var negConfig = {
      kernelName: tfjsCore.Neg,
      backendName: "cpu",
      kernelFunc: neg
    };
    var notEqualImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a !== b ? 1 : 0;
    });
    var notEqual = binaryKernelFunc(tfjsCore.NotEqual, notEqualImpl, null, "bool");
    var notEqualConfig = {
      kernelName: tfjsCore.NotEqual,
      backendName: "cpu",
      kernelFunc: notEqual
    };
    function transposeImpl(xVals, xShape, dtype, perm, newShape) {
      var xRank = xShape.length;
      var xSize = tfjsCore.util.sizeFromShape(xShape);
      var xStrides = tfjsCore.util.computeStrides(xShape);
      var newStrides = tfjsCore.util.computeStrides(newShape);
      var result = tfjsCore.util.getTypedArrayFromDType(dtype, tfjsCore.util.sizeFromShape(newShape));
      for (var i = 0; i < xSize; ++i) {
        var loc = tfjsCore.util.indexToLoc(i, xRank, xStrides);
        var newLoc = new Array(loc.length);
        for (var i_1 = 0; i_1 < newLoc.length; i_1++) {
          newLoc[i_1] = loc[perm[i_1]];
        }
        var newIndex = tfjsCore.util.locToIndex(newLoc, xRank, newStrides);
        result[newIndex] = xVals[i];
      }
      return result;
    }
    function transpose(args) {
      var inputs = args.inputs, attrs = args.attrs, backend = args.backend;
      var x = inputs.x;
      var perm = attrs.perm;
      assertNotComplex(x, "transpose");
      var xRank = x.shape.length;
      var newShape = new Array(xRank);
      for (var i = 0; i < newShape.length; i++) {
        newShape[i] = x.shape[perm[i]];
      }
      var values = backend.data.get(x.dataId).values;
      var result = transposeImpl(values, x.shape, x.dtype, perm, newShape);
      var dataId = backend.write(result, newShape, x.dtype);
      return { dataId, shape: newShape, dtype: x.dtype };
    }
    var transposeConfig = {
      kernelName: tfjsCore.Transpose,
      backendName: "cpu",
      kernelFunc: transpose
    };
    function prodImpl(xShape, xDtype, xVals, reductionAxes) {
      var _a2 = __read(tfjsCore.backend_util.computeOutAndReduceShapes(xShape, reductionAxes), 2), outShape = _a2[0], reduceShape = _a2[1];
      var outDtype = tfjsCore.upcastType(xDtype, "int32");
      var outVals = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape(outShape), outDtype);
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      for (var i = 0; i < outVals.length; ++i) {
        var offset = i * reduceSize;
        var prod_1 = 1;
        for (var j = 0; j < reduceSize; ++j) {
          prod_1 *= xVals[offset + j];
        }
        outVals[i] = prod_1;
      }
      return { outVals, outShape, outDtype };
    }
    function prod(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      assertNotComplex(x, "prod");
      var xRank = x.shape.length;
      var axes = tfjsCore.util.parseAxisParam(axis, x.shape);
      var permutation = tfjsCore.backend_util.getAxesPermutation(axes, xRank);
      var reductionAxes = axes;
      var permutedX = x;
      var intermediateTensorInfos = [];
      if (permutation != null) {
        permutedX = transpose({ inputs: { x }, backend, attrs: { perm: permutation } });
        intermediateTensorInfos.push(permutedX);
        reductionAxes = tfjsCore.backend_util.getInnerMostAxes(reductionAxes.length, xRank);
      }
      var xVals = backend.data.get(permutedX.dataId).values;
      var _a2 = prodImpl(permutedX.shape, permutedX.dtype, xVals, reductionAxes), outVals = _a2.outVals, outShape = _a2.outShape, outDtype = _a2.outDtype;
      var resultShape = outShape;
      if (keepDims) {
        resultShape = tfjsCore.backend_util.expandShapeToKeepDim(outShape, axes);
      }
      intermediateTensorInfos.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return backend.makeTensorInfo(resultShape, outDtype, outVals);
    }
    var prodConfig = {
      kernelName: tfjsCore.Prod,
      backendName: "cpu",
      kernelFunc: prod
    };
    function validateIndices(indices, indicesShape, numParams) {
      indices.forEach(function(index, i) {
        if (index < 0 || index >= numParams) {
          var locString = tfjsCore.util.indexToLoc(i, indicesShape.length, tfjsCore.util.computeStrides(indicesShape)).join(",");
          throw new Error("indices[".concat(locString, "] = ").concat(index, " is not in [0, ").concat(numParams, ")"));
        }
      });
    }
    function validateSplits(paramsNestedSplits, numParamsDenseValues) {
      for (var dim = 0; dim < paramsNestedSplits.length; ++dim) {
        var splits = paramsNestedSplits[dim];
        var lastSplit = dim === paramsNestedSplits.length - 1 ? numParamsDenseValues : paramsNestedSplits[dim + 1].length;
        if (splits.length === 0) {
          throw new Error("Ragged splits may not be empty");
        }
        if (splits[0] < 0) {
          throw new Error("Ragged splits must be non-negative");
        }
        if (splits[splits.length - 1] > lastSplit) {
          throw new Error("Ragged splits must not point past values");
        }
        for (var i = 1; i < splits.length; ++i) {
          if (splits[i - 1] > splits[i]) {
            throw new Error("Ragged splits must be sorted in ascending order");
          }
        }
      }
    }
    function makeSplits(indices, indicesShape, paramsNestedSplits, numParamsDenseValues) {
      var valueSlices = [];
      var numValues = 0;
      var numSplits = indicesShape.length - 1 + paramsNestedSplits.length;
      var outSplits = new Array(numSplits).fill(null).map(function() {
        return [0];
      });
      validateSplits(paramsNestedSplits, numParamsDenseValues);
      var nrows = 1;
      for (var dim = 0; dim < indicesShape.length - 1; ++dim) {
        nrows *= indicesShape[dim];
        var rowLength = indicesShape[dim + 1];
        for (var i = 1; i < nrows + 1; ++i) {
          outSplits[dim].push(i * rowLength);
        }
      }
      for (var i = 0; i < indices.length; ++i) {
        var start = indices[i];
        var limit = indices[i] + 1;
        for (var dim = 0; dim < paramsNestedSplits.length; ++dim) {
          var splits = paramsNestedSplits[dim];
          var outDim = dim + indicesShape.length - 1;
          if (outDim >= 0) {
            var outSplitsOutDim = outSplits[outDim];
            var delta = outSplitsOutDim[outSplitsOutDim.length - 1] - splits[start];
            for (var j = start; j < limit; ++j) {
              outSplits[outDim].push(splits[j + 1] + delta);
            }
          }
          start = splits[start];
          limit = splits[limit];
        }
        if (limit !== start) {
          valueSlices.push([start, limit]);
          numValues += limit - start;
        }
      }
      return { outSplits, valueSlices, numValues };
    }
    function getSplits(outSplits) {
      var splitsOut = [];
      var _loop_1 = function(i2) {
        var numSplits = outSplits[i2].length;
        var splits = tfjsCore.util.getArrayFromDType("int32", numSplits);
        splitsOut.push(splits);
        outSplits[i2].forEach(function(value, j) {
          return splits[j] = value;
        });
      };
      for (var i = 0; i < outSplits.length; ++i) {
        _loop_1(i);
      }
      return splitsOut;
    }
    function computeFlatOuterDims(orig, numOutDims) {
      var outDims = orig.slice(0, numOutDims);
      while (outDims.length < numOutDims) {
        outDims.push(1);
      }
      for (var inDim = numOutDims; inDim < orig.length; inDim++) {
        outDims[numOutDims - 1] *= orig[inDim];
      }
      return outDims;
    }
    function writeValueSlices(paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize, values, valuesShape) {
      var e_12, _a2;
      var denseM = computeFlatOuterDims(paramsDenseValuesShape, 2)[1];
      var valuesM = computeFlatOuterDims(valuesShape, 2)[1];
      var outPos = 0;
      try {
        for (var valueSlices_1 = __values(valueSlices), valueSlices_1_1 = valueSlices_1.next(); !valueSlices_1_1.done; valueSlices_1_1 = valueSlices_1.next()) {
          var slice2 = valueSlices_1_1.value;
          for (var i = slice2[0]; i < slice2[1]; ++i) {
            for (var j = 0; j < valueSize; ++j) {
              values[outPos * valuesM + j] = paramsDenseValues[i * denseM + j];
            }
            ++outPos;
          }
        }
      } catch (e_1_1) {
        e_12 = { error: e_1_1 };
      } finally {
        try {
          if (valueSlices_1_1 && !valueSlices_1_1.done && (_a2 = valueSlices_1.return))
            _a2.call(valueSlices_1);
        } finally {
          if (e_12)
            throw e_12.error;
        }
      }
    }
    function getValues(paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, valueSlices, numValues) {
      var valuesShape = paramsDenseValuesShape.slice();
      valuesShape[0] = numValues;
      var valuesOut = tfjsCore.util.getArrayFromDType(paramsDenseValuesDType, tfjsCore.util.sizeFromShape(valuesShape));
      var numElements = paramsDenseValues.length;
      var valueSize = numElements === 0 ? 0 : numElements / paramsDenseValuesShape[0];
      writeValueSlices(paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize, valuesOut, valuesShape);
      return [valuesOut, valuesShape];
    }
    function raggedGatherImpl(paramsNestedSplits, paramsNestedSplitsShapes, paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, indices, indicesShape, outputRaggedRank) {
      if (paramsNestedSplits.length === 0) {
        throw new Error("paramsNestedSplits must be non empty");
      }
      if (paramsNestedSplitsShapes[0].length === 0) {
        throw new Error("Split tensors must not be scalars");
      }
      var numParams = paramsNestedSplitsShapes[0][0] - 1;
      validateIndices(indices, indicesShape, numParams);
      if (paramsDenseValuesShape.length === 0) {
        throw new Error("params.rank must be nonzero");
      }
      var numParamsDenseValues = paramsDenseValuesShape[0];
      var _a2 = makeSplits(indices, indicesShape, paramsNestedSplits, numParamsDenseValues), outSplits = _a2.outSplits, valueSlices = _a2.valueSlices, numValues = _a2.numValues;
      var outputNestedSplits = getSplits(outSplits);
      var outputDenseValues = getValues(paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, valueSlices, numValues);
      return [outputNestedSplits, outputDenseValues[0], outputDenseValues[1]];
    }
    var INT32_MAX = 2147483647;
    function raggedRangeImpl(starts, startsShape, startsDType, limits, limitsShape, deltas, deltasShape) {
      if (startsShape.length > 1) {
        throw new Error("starts must be a scalar or vector");
      }
      if (limitsShape.length > 1) {
        throw new Error("limits must be a scalar or vector");
      }
      if (deltasShape.length > 1) {
        throw new Error("deltas must be a scalar or vector");
      }
      var broadcastStarts = startsShape.length === 0;
      var broadcastLimits = limitsShape.length === 0;
      var broadcastDeltas = deltasShape.length === 0;
      var inSizes = [];
      if (!broadcastStarts) {
        inSizes.push(startsShape[0]);
      }
      if (!broadcastLimits) {
        inSizes.push(limitsShape[0]);
      }
      if (!broadcastDeltas) {
        inSizes.push(deltasShape[0]);
      }
      for (var i = 1; i < inSizes.length; ++i) {
        if (inSizes[i] !== inSizes[i - 1]) {
          throw new Error("starts, limits, and deltas must have the same shape");
        }
      }
      var nRows = inSizes.length === 0 ? 1 : inSizes[0];
      var rtNestedSplits = tfjsCore.util.getArrayFromDType("int32", nRows + 1);
      rtNestedSplits[0] = 0;
      for (var row = 0; row < nRows; ++row) {
        var start = broadcastStarts ? starts[0] : starts[row];
        var limit = broadcastLimits ? limits[0] : limits[row];
        var delta = broadcastDeltas ? deltas[0] : deltas[row];
        if (delta === 0) {
          throw new Error("Requires delta != 0");
        }
        var size = (
          // The number of elements in the specified range.
          void 0
        );
        if (delta > 0 && limit < start || delta < 0 && limit > start) {
          size = 0;
        } else {
          size = Math.ceil(Math.abs((limit - start) / delta));
          if (size > INT32_MAX) {
            throw new Error("Requires ((limit - start) / delta) <= ".concat(INT32_MAX));
          }
        }
        rtNestedSplits[row + 1] = rtNestedSplits[row] + size;
      }
      var nVals = rtNestedSplits[nRows];
      var rtDenseValues = tfjsCore.util.getArrayFromDType(startsDType, nVals);
      var valueIndex = 0;
      for (var row = 0; row < nRows; ++row) {
        var rowSize = rtNestedSplits[row + 1] - rtNestedSplits[row];
        var value = broadcastStarts ? starts[0] : starts[row];
        var delta = broadcastDeltas ? deltas[0] : deltas[row];
        for (var i = 0; i < rowSize; ++i) {
          rtDenseValues[valueIndex++] = value;
          value += delta;
        }
      }
      return [rtNestedSplits, rtDenseValues];
    }
    var RowPartitionType = tfjsCore.backend_util.RowPartitionType;
    var RaggedTensorToTensorOp = (
      /** @class */
      function() {
        function RaggedTensorToTensorOp2(shape, shapeShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypeStrings) {
          this.shape = shape;
          this.shapeShape = shapeShape;
          this.values = values;
          this.valuesShape = valuesShape;
          this.valuesDType = valuesDType;
          this.defaultValue = defaultValue;
          this.defaultValueShape = defaultValueShape;
          this.rowPartitionValues = rowPartitionValues;
          this.rowPartitionValuesShapes = rowPartitionValuesShapes;
          this.rowPartitionTypes = tfjsCore.backend_util.getRowPartitionTypesHelper(rowPartitionTypeStrings);
          this.raggedRank = tfjsCore.backend_util.getRaggedRank(this.rowPartitionTypes);
        }
        RaggedTensorToTensorOp2.prototype.getRowPartitionTypeByDimension = function(dimension) {
          if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {
            return this.rowPartitionTypes[dimension + 1];
          } else {
            return this.rowPartitionTypes[dimension];
          }
        };
        RaggedTensorToTensorOp2.prototype.getRowPartitionTensor = function(dimension) {
          if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {
            return this.rowPartitionValues[dimension + 1];
          } else {
            return this.rowPartitionValues[dimension];
          }
        };
        RaggedTensorToTensorOp2.prototype.getMaxWidth = function(dimension) {
          var rowPartitionTensor = this.getRowPartitionTensor(dimension - 1);
          switch (this.getRowPartitionTypeByDimension(dimension - 1)) {
            case RowPartitionType.VALUE_ROWIDS:
              return RaggedTensorToTensorOp2.getMaxWidthValueRowID(rowPartitionTensor);
            case RowPartitionType.ROW_SPLITS:
              return RaggedTensorToTensorOp2.getMaxWidthRowSplit(rowPartitionTensor);
            default:
              throw new Error("Cannot handle partition type ".concat(RowPartitionType[this.getRowPartitionTypeByDimension(dimension - 1)]));
          }
        };
        RaggedTensorToTensorOp2.getMaxWidthRowSplit = function(rowSplit) {
          var tensorLength = rowSplit.length;
          if (tensorLength === 0 || tensorLength === 1) {
            return 0;
          }
          var maxWidth = 0;
          for (var i = 0; i < tensorLength - 1; ++i) {
            var currentWidth = rowSplit[i + 1] - rowSplit[i];
            if (currentWidth > maxWidth) {
              maxWidth = currentWidth;
            }
          }
          return maxWidth;
        };
        RaggedTensorToTensorOp2.getMaxWidthValueRowID = function(valueRowIds) {
          var indexLength = valueRowIds.length;
          if (indexLength === 0) {
            return 0;
          }
          var firstEqualIndex = 0;
          var firstEqualIndexValue = valueRowIds[0];
          var maxWidth = 0;
          for (var i = 1; i < indexLength; ++i) {
            var value = valueRowIds[i];
            if (value !== firstEqualIndexValue) {
              firstEqualIndexValue = value;
              maxWidth = Math.max(i - firstEqualIndex, maxWidth);
              firstEqualIndex = i;
            }
          }
          return Math.max(indexLength - firstEqualIndex, maxWidth);
        };
        RaggedTensorToTensorOp2.prototype.tensorShapeFromTensor = function(t, tShape, isPartial) {
          if (isPartial === void 0) {
            isPartial = true;
          }
          if (tShape.length === 0) {
            if (t[0] === -1) {
              return [];
            }
            throw new Error("The only valid scalar shape tensor is the fully unknown shape specified as -1.");
          }
          return makeShape(t, isPartial);
        };
        RaggedTensorToTensorOp2.prototype.calculateOutputSize = function(firstDim) {
          var valueShape = this.valuesShape;
          var defaultValueShape = this.defaultValueShape;
          tfjsCore.backend_util.validateDefaultValueShape(defaultValueShape, valueShape);
          var shape = this.tensorShapeFromTensor(this.shape, this.shapeShape);
          var outputShape = tfjsCore.backend_util.combineRaggedTensorToTensorShapes(this.raggedRank, shape, valueShape);
          var result = outputShape;
          if (result[0] < 0) {
            result[0] = firstDim;
          }
          for (var i = 1; i <= this.raggedRank; ++i) {
            if (result[i] < 0) {
              result[i] = this.getMaxWidth(i);
            }
          }
          return result;
        };
        RaggedTensorToTensorOp2.prototype.calculateFirstParentOutputIndex = function(firstDimension, outputIndexMultiplier, firstDimensionOutput) {
          var minDimension = Math.min(firstDimension, firstDimensionOutput);
          var result = [];
          var currentOutputIndex = 0;
          for (var i = 0; i < minDimension; ++i, currentOutputIndex += outputIndexMultiplier) {
            result.push(currentOutputIndex);
          }
          for (var i = minDimension; i < firstDimension; ++i) {
            result.push(-1);
          }
          tfjsCore.util.assert(result.length === firstDimension, function() {
            return "Final length of result must be equal to firstDimension.";
          });
          return result;
        };
        RaggedTensorToTensorOp2.prototype.calculateOutputIndexRowSplit = function(rowSplit, parentOutputIndex, outputIndexMultiplier, outputSize) {
          var rowSplitSize = rowSplit.length;
          var result = [];
          for (var i = 0; i < rowSplitSize - 1; ++i) {
            var rowLength = rowSplit[i + 1] - rowSplit[i];
            var realLength = Math.min(outputSize, rowLength);
            var parentOutputIndexCurrent = parentOutputIndex[i];
            if (parentOutputIndexCurrent === -1) {
              realLength = 0;
            }
            for (var j = 0; j < realLength; ++j) {
              result.push(parentOutputIndexCurrent);
              parentOutputIndexCurrent += outputIndexMultiplier;
            }
            for (var j = 0; j < rowLength - realLength; ++j) {
              result.push(-1);
            }
          }
          if (rowSplitSize > 0 && result.length !== rowSplit[rowSplitSize - 1]) {
            throw new Error("Invalid row split size.");
          }
          return result;
        };
        RaggedTensorToTensorOp2.prototype.calculateOutputIndexValueRowID = function(valueRowIds, parentOutputIndex, outputIndexMultiplier, outputSize) {
          var indexSize = valueRowIds.length;
          var result = [];
          if (indexSize === 0) {
            return [];
          }
          var currentOutputColumn = 0;
          var currentValueRowId = valueRowIds[0];
          if (currentValueRowId >= parentOutputIndex.length) {
            throw new Error("Got currentValueRowId=".concat(currentValueRowId, ", which is not less than ").concat(parentOutputIndex.length));
          }
          var currentOutputIndex = parentOutputIndex[currentValueRowId];
          result.push(currentOutputIndex);
          for (var i = 1; i < indexSize; ++i) {
            var nextValueRowId = valueRowIds[i];
            if (nextValueRowId === currentValueRowId) {
              if (currentOutputIndex >= 0) {
                ++currentOutputColumn;
                if (currentOutputColumn < outputSize) {
                  currentOutputIndex += outputIndexMultiplier;
                } else {
                  currentOutputIndex = -1;
                }
              }
            } else {
              currentOutputColumn = 0;
              currentValueRowId = nextValueRowId;
              if (nextValueRowId >= parentOutputIndex.length) {
                throw new Error("Got nextValueRowId=".concat(nextValueRowId, " which is not less than ").concat(parentOutputIndex.length));
              }
              currentOutputIndex = parentOutputIndex[nextValueRowId];
            }
            result.push(currentOutputIndex);
          }
          if (result.length !== valueRowIds.length) {
            throw new Error("Invalid row ids.");
          }
          return result;
        };
        RaggedTensorToTensorOp2.prototype.calculateOutputIndex = function(dimension, parentOutputIndex, outputIndexMultiplier, outputSize) {
          var rowPartitionTensor = this.getRowPartitionTensor(dimension);
          var partitionType = this.getRowPartitionTypeByDimension(dimension);
          switch (partitionType) {
            case RowPartitionType.VALUE_ROWIDS:
              return this.calculateOutputIndexValueRowID(rowPartitionTensor, parentOutputIndex, outputIndexMultiplier, outputSize);
            case RowPartitionType.ROW_SPLITS:
              if (rowPartitionTensor.length - 1 > parentOutputIndex.length) {
                throw new Error("Row partition size is greater than output size: ".concat(rowPartitionTensor.length - 1, " > ").concat(parentOutputIndex.length));
              }
              return this.calculateOutputIndexRowSplit(rowPartitionTensor, parentOutputIndex, outputIndexMultiplier, outputSize);
            default:
              throw new Error("Unsupported partition type: ".concat(RowPartitionType[partitionType]));
          }
        };
        RaggedTensorToTensorOp2.prototype.getFirstDimensionSize = function() {
          var firstPartitionTensor = this.rowPartitionValues[0];
          if (this.rowPartitionTypes.length === 0) {
            throw new Error("No row_partition_types given.");
          }
          var firstPartitionType = this.rowPartitionTypes[0];
          switch (firstPartitionType) {
            case RowPartitionType.FIRST_DIM_SIZE:
              return firstPartitionTensor[0];
            case RowPartitionType.VALUE_ROWIDS:
              throw new Error("Cannot handle VALUE_ROWIDS in first dimension.");
            case RowPartitionType.ROW_SPLITS:
              return this.rowPartitionValuesShapes[0][0] - 1;
            default:
              throw new Error("Cannot handle type ".concat(RowPartitionType[firstPartitionType]));
          }
        };
        RaggedTensorToTensorOp2.prototype.compute = function() {
          var firstPartitionTensor = this.rowPartitionValues[0];
          if (firstPartitionTensor.length <= 0) {
            throw new Error("Invalid first partition input. Tensor requires at least one element.");
          }
          var firstDimension = this.getFirstDimensionSize();
          var outputSize = this.calculateOutputSize(firstDimension);
          var multiplier = new Array(this.raggedRank + 1);
          multiplier[multiplier.length - 1] = 1;
          for (var i = multiplier.length - 2; i >= 0; --i) {
            multiplier[i] = multiplier[i + 1] * outputSize[i + 1];
          }
          var outputShape = makeShape(outputSize, false);
          var outputTensor = tfjsCore.util.getArrayFromDType(this.valuesDType, tfjsCore.util.sizeFromShape(outputShape));
          var fullSize = multiplier[0] * outputSize[0];
          if (fullSize > 0) {
            var outputIndex = this.calculateFirstParentOutputIndex(firstDimension, multiplier[0], outputSize[0]);
            for (var i = 1; i <= this.raggedRank; ++i) {
              var newOutputIndex = this.calculateOutputIndex(i - 1, outputIndex, multiplier[i], outputSize[i]);
              outputIndex = newOutputIndex;
            }
            this.setOutput(this.raggedRank, outputIndex, outputTensor, outputShape);
          }
          return [outputShape, outputTensor];
        };
        RaggedTensorToTensorOp2.prototype.setOutput = function(raggedRank, outputIndex, outputTensor, outputShape) {
          if (outputTensor.length === 0) {
            return;
          }
          var valuesBase = this.values;
          var outputBase = outputTensor;
          var elementShape = outputShape.slice();
          elementShape = elementShape.slice(raggedRank + 1);
          var valueElementSize = tfjsCore.util.sizeFromShape(elementShape);
          var outputIndexSize = outputIndex.length;
          var defaultValue = this.defaultValue;
          if (defaultValue.length !== valueElementSize && defaultValue.length !== 1) {
            var srcShape_1 = this.defaultValueShape;
            tfjsCore.tidy(function() {
              var defaultValueTensor = tfjsCore.reshape(defaultValue, srcShape_1);
              var bCastDefault = tfjsCore.broadcastTo(defaultValueTensor, elementShape);
              defaultValue = bCastDefault.dataSync();
            });
          }
          var srcStart = 0;
          var dstStart = 0;
          var dstEnd = 0;
          for (var srcI = 0; srcI <= outputIndexSize; ++srcI) {
            var dstI = srcI < outputIndexSize ? outputIndex[srcI] : -1;
            if (dstI === dstEnd) {
              ++dstEnd;
              continue;
            }
            if (dstStart < dstEnd) {
              var src = valuesBase.subarray(srcStart * valueElementSize);
              var dst = outputBase.subarray(dstStart * valueElementSize);
              var nVals = (dstEnd - dstStart) * valueElementSize;
              copyArray(dst, src, nVals);
            }
            if (srcI >= outputIndexSize) {
              var outputSize = outputTensor.length;
              dstI = Math.floor(outputSize / valueElementSize);
            }
            if (dstI > dstEnd) {
              if (this.defaultValue.length === 1) {
                outputBase.subarray(dstEnd * valueElementSize, dstI * valueElementSize).fill(this.defaultValue[0]);
                dstEnd = dstI;
              } else {
                while (dstI > dstEnd) {
                  var dst = outputBase.slice(dstEnd * valueElementSize);
                  copyArray(dst, defaultValue, valueElementSize);
                  ++dstEnd;
                }
              }
            }
            if (dstI < 0) {
              srcStart = srcI + 1;
              dstStart = dstEnd;
            } else {
              srcStart = srcI;
              dstStart = dstEnd;
              dstEnd = dstStart + 1;
            }
          }
        };
        return RaggedTensorToTensorOp2;
      }()
    );
    function copyArray(dst, src, size) {
      for (var i = 0; i < size; i++) {
        dst[i] = src[i];
      }
    }
    function makeShape(shape, isPartial) {
      var e_12, _a2;
      var out = [];
      try {
        for (var shape_1 = __values(shape), shape_1_1 = shape_1.next(); !shape_1_1.done; shape_1_1 = shape_1.next()) {
          var dim = shape_1_1.value;
          if (dim < 0) {
            if (!isPartial) {
              throw new Error("Dimension ".concat(dim, " must be >= 0"));
            }
            if (dim < -1) {
              throw new Error("Dimension ".concat(dim, " must be >= -1"));
            }
            dim = -1;
          }
          out.push(dim);
        }
      } catch (e_1_1) {
        e_12 = { error: e_1_1 };
      } finally {
        try {
          if (shape_1_1 && !shape_1_1.done && (_a2 = shape_1.return))
            _a2.call(shape_1);
        } finally {
          if (e_12)
            throw e_12.error;
        }
      }
      return out;
    }
    function raggedTensorToTensorImpl(shape, shapesShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes) {
      return new RaggedTensorToTensorOp(shape, shapesShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes).compute();
    }
    function rangeImpl(start, stop, step2, dtype) {
      var sameStartStop = start === stop;
      var increasingRangeNegativeStep = start < stop && step2 < 0;
      var decreasingRangePositiveStep = stop < start && step2 > 1;
      if (sameStartStop || increasingRangeNegativeStep || decreasingRangePositiveStep) {
        return tfjsCore.util.makeZerosTypedArray(0, dtype);
      }
      var numElements = Math.abs(Math.ceil((stop - start) / step2));
      var values = tfjsCore.util.makeZerosTypedArray(numElements, dtype);
      if (stop < start && step2 === 1) {
        step2 = -1;
      }
      values[0] = start;
      for (var i = 1; i < values.length; i++) {
        values[i] = values[i - 1] + step2;
      }
      return values;
    }
    var rsqrtImpl = createSimpleUnaryImpl(function(xi) {
      return 1 / Math.sqrt(xi);
    });
    var rsqrt = unaryKernelFuncFromImpl(tfjsCore.Rsqrt, rsqrtImpl);
    var rsqrtConfig = {
      kernelName: tfjsCore.Rsqrt,
      backendName: "cpu",
      kernelFunc: rsqrt
    };
    function scatterImpl(indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices) {
      var flattenShape = [outputSize / sliceSize, sliceSize];
      var indicesData = indices.values;
      var updatesData = updates.values;
      if (outputSize === 0) {
        return tfjsCore.buffer(shape, updates.dtype);
      }
      var outBuf = defaultValue instanceof tfjsCore.TensorBuffer ? defaultValue : tfjsCore.buffer(flattenShape, updates.dtype);
      if (typeof defaultValue === "string") {
        outBuf.values.fill(defaultValue);
      } else if (typeof defaultValue === "number") {
        outBuf.values.fill(defaultValue);
      } else if (typeof defaultValue === "boolean") {
        outBuf.values.fill(+defaultValue);
      }
      for (var i = 0; i < numUpdates; i++) {
        var index = [];
        var flattenIndex = 0;
        for (var j = 0; j < sliceRank; j++) {
          var dim = indicesData[i * sliceRank + j];
          index.push(dim);
          flattenIndex += dim * strides[j];
        }
        if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {
          throw new Error("Invalid indices: ".concat(index, " does not index into ").concat(shape));
        }
        for (var k = 0; k < sliceSize; k++) {
          if (sumDupeIndices) {
            outBuf.values[flattenIndex * sliceSize + k] += updatesData[i * sliceSize + k];
          } else {
            outBuf.values[flattenIndex * sliceSize + k] = updates.rank === 0 ? updatesData[0] : updatesData[i * sliceSize + k];
          }
        }
      }
      return outBuf;
    }
    var sigmoidImpl = createSimpleUnaryImpl(function(xi) {
      return 1 / (1 + Math.exp(-xi));
    });
    var sigmoid = unaryKernelFunc(tfjsCore.Sigmoid, function(xi) {
      return 1 / (1 + Math.exp(-xi));
    });
    var sigmoidConfig = {
      kernelName: tfjsCore.Sigmoid,
      backendName: "cpu",
      kernelFunc: sigmoid
    };
    function sliceImpl(vals, begin, size, shape, dtype) {
      var isContinous = tfjsCore.slice_util.isSliceContinous(shape, begin, size);
      var length = tfjsCore.util.sizeFromShape(size);
      var xStrides = tfjsCore.util.computeStrides(shape);
      if (isContinous) {
        var flatOffset = tfjsCore.slice_util.computeFlatOffset(begin, xStrides);
        if (dtype === "string") {
          return vals.slice(flatOffset, flatOffset + length);
        }
        return vals.subarray(flatOffset, flatOffset + length);
      }
      var decodedData = dtype === "string" ? tfjsCore.backend_util.fromUint8ToStringArray(vals) : vals;
      var inBuf = tfjsCore.buffer(shape, dtype, decodedData);
      var outBuf = tfjsCore.buffer(size, dtype);
      for (var i = 0; i < outBuf.size; ++i) {
        var outLoc = outBuf.indexToLoc(i);
        var inLoc = outLoc.map(function(idx, j) {
          return idx + begin[j];
        });
        outBuf.set.apply(outBuf, __spreadArray([inBuf.get.apply(inBuf, __spreadArray([], __read(inLoc), false))], __read(outLoc), false));
      }
      if (dtype === "string") {
        return tfjsCore.backend_util.fromStringArrayToUint8(outBuf.values);
      }
      return outBuf.values;
    }
    function slice(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var begin = attrs.begin, size = attrs.size;
      assertNotComplex(x, "slice");
      var _a2 = __read(tfjsCore.slice_util.parseSliceParams(x, begin, size), 2), $begin = _a2[0], $size = _a2[1];
      tfjsCore.slice_util.assertParamsValid(x, $begin, $size);
      var vals = backend.data.get(x.dataId).values;
      var outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);
      return backend.makeTensorInfo($size, x.dtype, outVals);
    }
    var sliceConfig = {
      kernelName: tfjsCore.Slice,
      backendName: "cpu",
      kernelFunc: slice
    };
    function sparseFillEmptyRowsImpl(indices, indicesShape, indicesDType, values, valuesDType, denseShape, defaultValue) {
      var indicesCount = indicesShape[0];
      var denseRows = denseShape[0];
      var emptyRowIndicator = new Array(denseRows);
      var reverseIndexMap = new Array(indicesCount);
      var rank = indicesShape[1];
      if (denseRows === 0) {
        if (indicesCount !== 0) {
          throw new Error(tfjsCore.backend_util.getSparseFillEmptyRowsIndicesDenseShapeMismatch(indicesCount));
        }
        var outputIndices = tfjsCore.util.getArrayFromDType(indicesDType, 0);
        var outputValues = tfjsCore.util.getArrayFromDType(valuesDType, 0);
        return [
          outputIndices,
          [0, rank],
          outputValues,
          emptyRowIndicator,
          reverseIndexMap
        ];
      }
      var rowsAreOrdered = true;
      var lastIndicesRow = 0;
      var csrOffset = new Array(denseRows).fill(0);
      for (var i = 0; i < indicesCount; ++i) {
        var row = indices[i * rank];
        if (row < 0) {
          throw new Error(tfjsCore.backend_util.getSparseFillEmptyRowsNegativeIndexErrorMessage(i, row));
        }
        if (row >= denseRows) {
          throw new Error(tfjsCore.backend_util.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(i, row, denseRows));
        }
        ++csrOffset[row];
        rowsAreOrdered = rowsAreOrdered && row >= lastIndicesRow;
        lastIndicesRow = row;
      }
      var allRowsFull = true;
      for (var row = 0; row < denseRows; ++row) {
        var rowEmpty = csrOffset[row] === 0;
        emptyRowIndicator[row] = rowEmpty;
        allRowsFull = allRowsFull && !rowEmpty;
        csrOffset[row] = Math.max(csrOffset[row], 1);
        if (row > 0) {
          csrOffset[row] += csrOffset[row - 1];
        }
      }
      if (allRowsFull && rowsAreOrdered) {
        var outputIndices = indices;
        var outputValues = values;
        for (var i = 0; i < indicesCount; ++i) {
          reverseIndexMap[i] = i;
        }
        return [
          outputIndices,
          [indicesCount, rank],
          outputValues,
          emptyRowIndicator,
          reverseIndexMap
        ];
      } else {
        var fullIndicesCount = csrOffset[denseRows - 1];
        var outputIndices = tfjsCore.util.getArrayFromDType(indicesDType, fullIndicesCount * rank);
        var outputValues = tfjsCore.util.getArrayFromDType(valuesDType, fullIndicesCount);
        var filledCount = new Array(denseRows).fill(0);
        for (var i = 0; i < indicesCount; ++i) {
          var row = indices[i * rank];
          var offset = filledCount[row];
          var outputI = (row === 0 ? 0 : csrOffset[row - 1]) + offset;
          filledCount[row]++;
          for (var j = 0; j < rank; ++j) {
            outputIndices[outputI * rank + j] = indices[i * rank + j];
          }
          outputValues[outputI] = values[i];
          reverseIndexMap[i] = outputI;
        }
        for (var row = 0; row < denseRows; ++row) {
          var rowCount = filledCount[row];
          if (rowCount === 0) {
            var startingIndex = row === 0 ? 0 : csrOffset[row - 1];
            outputIndices[startingIndex * rank + 0] = row;
            for (var col = 1; col < rank; ++col) {
              outputIndices[startingIndex * rank + col] = 0;
            }
            outputValues[startingIndex] = defaultValue;
          }
        }
        return [
          outputIndices,
          [fullIndicesCount, rank],
          outputValues,
          emptyRowIndicator,
          reverseIndexMap
        ];
      }
    }
    function sparseReshapeImpl(inputIndices, inputIndicesShape, inputDType, inputShape, targetShape) {
      var denseSize = tfjsCore.util.sizeFromShape(inputShape);
      var nnz = inputIndicesShape[0];
      var outputRank = targetShape.length;
      var outputShape = [];
      var product = 1;
      var unknownIndex = -1;
      for (var d = 0; d < outputRank; ++d) {
        var size = targetShape[d];
        if (size === -1) {
          if (unknownIndex !== -1) {
            throw new Error(tfjsCore.backend_util.getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(unknownIndex, d));
          }
          unknownIndex = d;
          outputShape.push(1);
        } else {
          if (size < 0) {
            throw new Error(tfjsCore.backend_util.getSparseReshapeNegativeOutputDimErrorMessage(d, size));
          }
          product *= size;
          outputShape.push(size);
        }
      }
      if (unknownIndex !== -1) {
        if (product <= 0) {
          throw new Error(tfjsCore.backend_util.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());
        }
        var missing = Math.trunc(denseSize / product);
        if (product * missing !== denseSize) {
          throw new Error(tfjsCore.backend_util.getSparseReshapeInputOutputMultipleErrorMessage(inputShape, outputShape));
        }
        outputShape[unknownIndex] = missing;
      }
      var outputSize = tfjsCore.util.sizeFromShape(outputShape);
      if (outputSize !== denseSize) {
        throw new Error(tfjsCore.backend_util.getSparseReshapeInputOutputMismatchErrorMessage(inputShape, outputShape));
      }
      var inputRank = inputShape.length;
      var inputStrides = [];
      if (inputRank > 0) {
        inputStrides[inputRank - 1] = 1;
        for (var d = inputRank - 2; d >= 0; --d) {
          inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];
        }
      }
      var outputStrides = [];
      if (outputRank > 0) {
        outputStrides[outputRank - 1] = 1;
        for (var d = outputRank - 2; d >= 0; --d) {
          outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];
        }
      }
      var newIndices = tfjsCore.util.getArrayFromDType(inputDType, nnz * outputRank);
      for (var i = 0; i < nnz; ++i) {
        var id = 0;
        for (var j = 0; j < inputRank; ++j) {
          id += inputIndices[i * inputRank + j] * inputStrides[j];
        }
        for (var j = 0; j < outputRank; ++j) {
          newIndices[i * outputRank + j] = Math.trunc(id / outputStrides[j]);
          id %= outputStrides[j];
        }
      }
      return [newIndices, [nnz, outputRank], outputShape];
    }
    function sparseSegmentReductionImpl(input, inputShape, inputDType, indices, segmentIds, isMean, defaultValue) {
      if (isMean === void 0) {
        isMean = false;
      }
      if (defaultValue === void 0) {
        defaultValue = 0;
      }
      var numIndices = indices.length;
      var inputFlat = [inputShape[0], input.length / inputShape[0]];
      var numCol = inputFlat[1];
      var lastSegmentIdPlusOne = numIndices > 0 ? segmentIds[numIndices - 1] + 1 : 0;
      var outputRows = lastSegmentIdPlusOne;
      if (outputRows < 0) {
        throw new Error(tfjsCore.backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
      }
      var outputShape = inputShape.slice();
      outputShape[0] = outputRows;
      var outputLength = outputShape.reduce(function(product, value) {
        return product * value;
      }, 1);
      var output = tfjsCore.util.getArrayFromDType(inputDType, outputLength);
      if (numIndices === 0) {
        if (outputRows > 0) {
          output.fill(defaultValue);
        }
        return [output, outputShape];
      }
      if (outputRows <= 0) {
        throw new Error(tfjsCore.backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
      }
      var start = 0, end = 1;
      var uninitializedIndex = 0;
      var outIndex = segmentIds[start];
      while (true) {
        var nextIndex = 0;
        if (end < numIndices) {
          nextIndex = segmentIds[end];
          if (outIndex === nextIndex) {
            ++end;
            continue;
          }
          if (outIndex >= nextIndex) {
            throw new Error(tfjsCore.backend_util.getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage());
          }
        }
        if (outIndex < 0 || outIndex >= outputRows) {
          throw new Error(tfjsCore.backend_util.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(outIndex, outputRows));
        }
        if (outIndex > uninitializedIndex) {
          output.fill(defaultValue, uninitializedIndex * numCol, outIndex * numCol);
        }
        for (var i = start; i < end; ++i) {
          var index = indices[i];
          if (index < 0 || index >= inputFlat[0]) {
            throw new Error(tfjsCore.backend_util.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(i, indices[i], inputFlat[0]));
          }
          for (var j = 0; j < numCol; j++) {
            output[outIndex * numCol + j] += input[index * numCol + j];
          }
        }
        if (isMean) {
          for (var j = 0; j < numCol; j++) {
            output[outIndex * numCol + j] /= end - start;
          }
        }
        start = end;
        ++end;
        uninitializedIndex = outIndex + 1;
        outIndex = nextIndex;
        if (end > numIndices) {
          break;
        }
      }
      if (uninitializedIndex < outputRows) {
        output.fill(defaultValue, uninitializedIndex * numCol, outputRows * numCol);
      }
      return [output, outputShape];
    }
    var sqrtImpl = createSimpleUnaryImpl(function(xi) {
      return Math.sqrt(xi);
    });
    var sqrt = unaryKernelFunc(tfjsCore.Sqrt, function(xi) {
      return Math.sqrt(xi);
    });
    var sqrtConfig = {
      kernelName: tfjsCore.Sqrt,
      backendName: "cpu",
      kernelFunc: sqrt
    };
    var squaredDifferenceImpl = createSimpleBinaryKernelImpl(function(a, b) {
      var diff = a - b;
      return diff * diff;
    });
    var squaredDifference = binaryKernelFunc(tfjsCore.SquaredDifference, squaredDifferenceImpl);
    var squaredDifferenceConfig = {
      kernelName: tfjsCore.SquaredDifference,
      backendName: "cpu",
      kernelFunc: squaredDifference
    };
    var staticRegexReplaceImpl = createSimpleUnaryImpl(function(x, attrs) {
      var pattern = attrs.pattern, replaceGlobal = attrs.replaceGlobal, rewrite = attrs.rewrite;
      return x.replace(new RegExp(pattern, replaceGlobal ? "g" : ""), rewrite);
    });
    var staticRegexReplace = unaryKernelFuncFromImpl(tfjsCore.StaticRegexReplace, staticRegexReplaceImpl);
    var staticRegexReplaceConfig = {
      kernelName: tfjsCore.StaticRegexReplace,
      backendName: "cpu",
      kernelFunc: staticRegexReplace
    };
    function stridedSliceImpl(outShape, xBuf, strides, begin) {
      var outBuf = tfjsCore.buffer(outShape, xBuf.dtype);
      for (var i = 0; i < outBuf.size; i++) {
        var loc = outBuf.indexToLoc(i);
        var newLoc = new Array(loc.length);
        for (var j = 0; j < newLoc.length; j++) {
          newLoc[j] = loc[j] * strides[j] + begin[j];
        }
        outBuf.set.apply(outBuf, __spreadArray([xBuf.get.apply(xBuf, __spreadArray([], __read(newLoc), false))], __read(loc), false));
      }
      return outBuf;
    }
    var StringNGramsOp = (
      /** @class */
      function() {
        function StringNGramsOp2(separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences) {
          this.separator = tfjsCore.util.encodeString(separator);
          this.nGramWidths = nGramWidths;
          this.leftPad = tfjsCore.util.encodeString(leftPad);
          this.rightPad = tfjsCore.util.encodeString(rightPad);
          this.padWidth = padWidth;
          this.preserveShort = preserveShortSequences;
        }
        StringNGramsOp2.prototype.getPadWidth = function(nGramWidth) {
          return Math.min(this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);
        };
        StringNGramsOp2.prototype.getNumNGrams = function(length, nGramWidth) {
          var padWidth = this.getPadWidth(nGramWidth);
          return Math.max(0, length + 2 * padWidth - nGramWidth + 1);
        };
        StringNGramsOp2.prototype.createNGrams = function(data, splitIndex, output, outputStartIndex, numNGrams, nGramWidth) {
          var _loop_1 = function(nGramIndex2) {
            var padWidth = this_1.getPadWidth(nGramWidth);
            var leftPadding = Math.max(0, padWidth - nGramIndex2);
            var rightPadding = Math.max(0, padWidth - (numNGrams - (nGramIndex2 + 1)));
            var numTokens = nGramWidth - (leftPadding + rightPadding);
            var dataStartIndex = splitIndex + (leftPadding > 0 ? 0 : nGramIndex2 - padWidth);
            var nGramSize = 0;
            nGramSize += leftPadding * this_1.leftPad.length;
            for (var n = 0; n < numTokens; ++n) {
              nGramSize += data[dataStartIndex + n].length;
            }
            nGramSize += rightPadding * this_1.rightPad.length;
            var numSeparators = leftPadding + rightPadding + numTokens - 1;
            nGramSize += numSeparators * this_1.separator.length;
            output[outputStartIndex + nGramIndex2] = new Uint8Array(nGramSize);
            var nGram = output[outputStartIndex + nGramIndex2];
            var nextNGramIndex = 0;
            var appendToNGram = function(str) {
              return str.forEach(function(value) {
                return nGram[nextNGramIndex++] = value;
              });
            };
            for (var n = 0; n < leftPadding; ++n) {
              appendToNGram(this_1.leftPad);
              appendToNGram(this_1.separator);
            }
            for (var n = 0; n < numTokens - 1; ++n) {
              appendToNGram(data[dataStartIndex + n]);
              appendToNGram(this_1.separator);
            }
            if (numTokens > 0) {
              appendToNGram(data[dataStartIndex + numTokens - 1]);
              for (var n = 0; n < rightPadding; ++n) {
                appendToNGram(this_1.separator);
                appendToNGram(this_1.rightPad);
              }
            } else {
              for (var n = 0; n < rightPadding - 1; ++n) {
                appendToNGram(this_1.rightPad);
                appendToNGram(this_1.separator);
              }
              appendToNGram(this_1.rightPad);
            }
          };
          var this_1 = this;
          for (var nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {
            _loop_1(nGramIndex);
          }
        };
        StringNGramsOp2.prototype.compute = function(data, splits) {
          var _this = this;
          var inputDataSize = data.length;
          var splitsSize = splits.length;
          if (splitsSize > 0) {
            var prevSplit = splits[0];
            if (prevSplit !== 0) {
              throw new Error("First split value must be 0, got ".concat(prevSplit));
            }
            for (var i = 1; i < splitsSize; ++i) {
              var validSplits = splits[i] >= prevSplit;
              validSplits = validSplits && splits[i] <= inputDataSize;
              if (!validSplits) {
                throw new Error("Invalid split value ".concat(splits[i], ", must be in [").concat(prevSplit, ", ").concat(inputDataSize, "]"));
              }
              prevSplit = splits[i];
            }
            if (prevSplit !== inputDataSize) {
              throw new Error("Last split value must be data size. Expected ".concat(inputDataSize, ", got ").concat(prevSplit));
            }
          }
          var numBatchItems = splitsSize - 1;
          var nGramsSplits = tfjsCore.util.getArrayFromDType("int32", splitsSize);
          if (inputDataSize === 0 || splitsSize === 0) {
            var empty = new Array(inputDataSize);
            for (var i = 0; i <= numBatchItems; ++i) {
              nGramsSplits[i] = 0;
            }
            return [empty, nGramsSplits];
          }
          nGramsSplits[0] = 0;
          var _loop_2 = function(i2) {
            var length = splits[i2] - splits[i2 - 1];
            var numNGrams = 0;
            this_2.nGramWidths.forEach(function(nGramWidth) {
              numNGrams += _this.getNumNGrams(length, nGramWidth);
            });
            if (this_2.preserveShort && length > 0 && numNGrams === 0) {
              numNGrams = 1;
            }
            nGramsSplits[i2] = nGramsSplits[i2 - 1] + numNGrams;
          };
          var this_2 = this;
          for (var i = 1; i <= numBatchItems; ++i) {
            _loop_2(i);
          }
          var nGrams = new Array(nGramsSplits[numBatchItems]);
          var _loop_3 = function(i2) {
            var splitIndex = splits[i2];
            var outputStartIdx = nGramsSplits[i2];
            this_3.nGramWidths.forEach(function(nGramWidth2) {
              var length = splits[i2 + 1] - splits[i2];
              var numNGrams2 = _this.getNumNGrams(length, nGramWidth2);
              _this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams2, nGramWidth2);
              outputStartIdx += numNGrams2;
            });
            if (this_3.preserveShort && outputStartIdx === nGramsSplits[i2]) {
              var dataLength = splits[i2 + 1] - splits[i2];
              if (dataLength === 0) {
                return "continue";
              }
              var nGramWidth = dataLength + 2 * this_3.padWidth;
              var numNGrams = 1;
              this_3.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
            }
          };
          var this_3 = this;
          for (var i = 0; i < numBatchItems; ++i) {
            _loop_3(i);
          }
          return [nGrams, nGramsSplits];
        };
        return StringNGramsOp2;
      }()
    );
    function stringNGramsImpl(data, dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences) {
      return new StringNGramsOp(separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences).compute(data, dataSplits);
    }
    function split(str, delimiters, skipEmpty, result) {
      if (!str.length) {
        return;
      }
      if (delimiters.length === 0) {
        for (var i = 0; i < str.length; ++i) {
          result.push(str.subarray(i, i + 1));
        }
        return;
      }
      if (delimiters.length === 1) {
        var delimiter = delimiters[0];
        var f = str.indexOf(delimiter);
        while (f !== -1) {
          var token = str.subarray(0, f);
          if (!skipEmpty || token.length !== 0) {
            result.push(token);
          }
          str = str.subarray(f + 1);
          f = str.indexOf(delimiter);
        }
        if (!skipEmpty || str.length !== 0) {
          result.push(str);
        }
        return;
      }
      var tokenStart = 0;
      for (var i = 0; i < str.length + 1; i++) {
        if (i === str.length || delimiters.indexOf(str[i]) !== -1) {
          var token = str.subarray(tokenStart, i);
          if (!skipEmpty || token.length !== 0) {
            result.push(token);
          }
          tokenStart = i + 1;
        }
      }
    }
    function stringSplitImpl(input, delimiter, skipEmpty) {
      var batchSize = input.length;
      var tokens = [];
      var outputSize = 0;
      var maxNumEntries = 0;
      var numIndices = new Array(batchSize);
      for (var i = 0; i < batchSize; ++i) {
        var prevTokensLength = tokens.length;
        split(input[i], delimiter, skipEmpty, tokens);
        var nEntries = tokens.length - prevTokensLength;
        numIndices[i] = nEntries;
        outputSize += nEntries;
        maxNumEntries = Math.max(maxNumEntries, nEntries);
      }
      var indices = tfjsCore.util.getArrayFromDType("int32", outputSize * 2);
      var values = new Array(outputSize);
      var shape = [batchSize, maxNumEntries];
      var c = 0;
      for (var i = 0; i < batchSize; ++i) {
        for (var j = 0; j < numIndices[i]; ++j) {
          indices[c * 2] = i;
          indices[c * 2 + 1] = j;
          values[c] = tokens[c];
          ++c;
        }
      }
      return [indices, values, shape];
    }
    function stringToHashBucketFastImpl(input, numBuckets) {
      var output = tfjsCore.util.getArrayFromDType("int32", input.length);
      for (var i = 0; i < input.length; ++i) {
        output[i] = tfjsCore.util.fingerPrint64(input[i]).modulo(numBuckets).getLowBitsUnsigned();
      }
      return output;
    }
    var subImpl = createSimpleBinaryKernelImpl(function(aValue, bValue) {
      return aValue - bValue;
    });
    var subComplexImpl = createComplexBinaryKernelImpl(function(aReal, aImag, bReal, bImag) {
      return { real: aReal - bReal, imag: aImag - bImag };
    });
    var sub = binaryKernelFunc(tfjsCore.Sub, subImpl, subComplexImpl);
    var subConfig = {
      kernelName: tfjsCore.Sub,
      backendName: "cpu",
      kernelFunc: sub
    };
    function tileImpl(xBuf, reps) {
      var newShape = new Array(xBuf.rank);
      for (var i = 0; i < newShape.length; i++) {
        newShape[i] = xBuf.shape[i] * reps[i];
      }
      var result = tfjsCore.buffer(newShape, xBuf.dtype);
      for (var i = 0; i < result.values.length; ++i) {
        var newLoc = result.indexToLoc(i);
        var originalLoc = new Array(xBuf.rank);
        for (var j = 0; j < originalLoc.length; j++) {
          originalLoc[j] = newLoc[j] % xBuf.shape[j];
        }
        var originalIndex = xBuf.locToIndex(originalLoc);
        result.values[i] = xBuf.values[originalIndex];
      }
      return result;
    }
    var comparePair = function(a, b) {
      var valueDiff = b.value - a.value;
      return valueDiff === 0 ? a.index - b.index : valueDiff;
    };
    function select$1(array, k, left, right) {
      if (left === void 0) {
        left = 0;
      }
      if (right === void 0) {
        right = array.length - 1;
      }
      while (right > left) {
        if (right - left > 600) {
          var n = right - left + 1;
          var i_1 = k - left + 1;
          var z = Math.log(n);
          var s = 0.5 * Math.exp(2 * z / 3);
          var sd = 0.5 * Math.sqrt(z * s * (n - s) / n) * Math.sign(i_1 - n / 2);
          var newLeft = Math.max(left, Math.floor(k - i_1 * s / n + sd));
          var newRight = Math.min(right, Math.floor(k + (n - i_1) * s / n + sd));
          select$1(array, k, newLeft, newRight);
        }
        var t = array[k];
        var i = left;
        var j = right;
        tfjsCore.util.swap(array, left, k);
        if (comparePair(array[right], t) > 0) {
          tfjsCore.util.swap(array, left, right);
        }
        while (i < j) {
          tfjsCore.util.swap(array, i, j);
          i++;
          j--;
          while (comparePair(array[i], t) < 0) {
            i = i + 1;
          }
          while (comparePair(array[j], t) > 0) {
            j = j - 1;
          }
        }
        if (comparePair(array[left], t) === 0) {
          tfjsCore.util.swap(array, left, j);
        } else {
          j = j + 1;
          tfjsCore.util.swap(array, j, right);
        }
        if (j <= k) {
          left = j + 1;
        }
        if (k <= j) {
          right = j - 1;
        }
      }
    }
    function topKImpl(x, xShape, xDtype, k, sorted) {
      var lastDim = xShape[xShape.length - 1];
      var _a2 = __read([x.length / lastDim, lastDim], 2), batch = _a2[0], size = _a2[1];
      var allTopKVals = tfjsCore.util.getTypedArrayFromDType(xDtype, batch * k);
      var allTopKIndices = tfjsCore.util.getTypedArrayFromDType("int32", batch * k);
      var _loop_1 = function(b2) {
        var offset = b2 * size;
        var vals = x.subarray(offset, offset + size);
        var valAndInd = new Array(vals.length);
        vals.forEach(function(value, index) {
          return valAndInd[index] = { value, index };
        });
        if (k < valAndInd.length) {
          select$1(valAndInd, k);
          valAndInd = valAndInd.slice(0, k);
        }
        if (sorted) {
          valAndInd.sort(comparePair);
        }
        var outOffset = b2 * k;
        var topKVals = allTopKVals.subarray(outOffset, outOffset + k);
        var topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);
        for (var i = 0; i < k; i++) {
          topKVals[i] = valAndInd[i].value;
          topKIndices[i] = valAndInd[i].index;
        }
      };
      for (var b = 0; b < batch; b++) {
        _loop_1(b);
      }
      var outputShape = xShape.slice();
      outputShape[outputShape.length - 1] = k;
      return [
        tfjsCore.buffer(outputShape, xDtype, allTopKVals),
        tfjsCore.buffer(outputShape, "int32", allTopKIndices)
      ];
    }
    function uniqueImpl(values, axis, shape, dtype) {
      var $axis = tfjsCore.util.parseAxisParam(axis, shape)[0];
      var newShape = [1, shape[0], 1];
      for (var i = 0; i < $axis; i++) {
        newShape[0] *= shape[i];
      }
      newShape[1] = shape[$axis];
      for (var i = $axis + 1; i < shape.length; i++) {
        newShape[2] *= shape[i];
      }
      var uniqueElements = /* @__PURE__ */ new Map();
      var indices = new Int32Array(shape[$axis]);
      var inputBuffer = new tfjsCore.TensorBuffer(newShape, dtype, values);
      var uniqueIndices = [];
      var is1DTensor = newShape[0] === 1 && newShape[2] === 1;
      for (var i = 0; i < shape[$axis]; i++) {
        var element = void 0;
        if (is1DTensor) {
          element = values[i].toString();
        } else {
          var axisValues = [];
          for (var m = 0; m < newShape[0]; m++) {
            for (var n = 0; n < newShape[2]; n++) {
              axisValues.push(inputBuffer.get(m, i, n));
            }
          }
          element = axisValues.join(",");
        }
        var existingIndex = uniqueElements.get(element);
        if (existingIndex != null) {
          indices[i] = existingIndex;
        } else {
          var uniqueIndex = uniqueElements.size;
          uniqueElements.set(element, uniqueIndex);
          indices[i] = uniqueIndex;
          uniqueIndices.push(i);
        }
      }
      var outputTmpShape = newShape.slice();
      outputTmpShape[1] = uniqueElements.size;
      var outputBuffer = new tfjsCore.TensorBuffer(outputTmpShape, dtype);
      uniqueIndices.forEach(function(uniqueElementIndex, i2) {
        for (var m2 = 0; m2 < newShape[0]; m2++) {
          for (var n2 = 0; n2 < newShape[2]; n2++) {
            outputBuffer.set(inputBuffer.get(m2, uniqueElementIndex, n2), m2, i2, n2);
          }
        }
      });
      var outputShape = shape.slice();
      outputShape[$axis] = outputTmpShape[1];
      return {
        outputValues: outputBuffer.values,
        outputShape,
        indices
      };
    }
    var shared = {
      __proto__: null,
      addImpl,
      bincountImpl,
      bincountReduceImpl,
      bitwiseAndImpl,
      castImpl,
      ceilImpl,
      concatImpl,
      equalImpl,
      expImpl,
      expm1Impl,
      floorDivImpl,
      floorImpl,
      gatherNdImpl,
      gatherV2Impl,
      greaterEqualImpl,
      greaterImpl,
      lessEqualImpl,
      lessImpl,
      linSpaceImpl,
      logImpl,
      maxImpl,
      maximumImpl,
      minimumImpl,
      multiplyImpl,
      negImpl,
      notEqualImpl,
      prodImpl,
      raggedGatherImpl,
      raggedRangeImpl,
      raggedTensorToTensorImpl,
      rangeImpl,
      rsqrtImpl,
      scatterImpl,
      sigmoidImpl,
      simpleAbsImpl,
      sliceImpl,
      sparseFillEmptyRowsImpl,
      sparseReshapeImpl,
      sparseSegmentReductionImpl,
      sqrtImpl,
      squaredDifferenceImpl,
      staticRegexReplaceImpl,
      stridedSliceImpl,
      stringNGramsImpl,
      stringSplitImpl,
      stringToHashBucketFastImpl,
      subImpl,
      tileImpl,
      topKImpl,
      transposeImpl,
      uniqueImpl
    };
    var version = "4.15.0";
    tfjsCore.registerBackend(
      "cpu",
      function() {
        return new MathBackendCPU();
      },
      1
      /* priority */
    );
    var elu = unaryKernelFunc(tfjsCore.Elu, function(xi) {
      return xi >= 0 ? xi : Math.exp(xi) - 1;
    });
    var eluConfig = {
      kernelName: tfjsCore.Elu,
      backendName: "cpu",
      kernelFunc: elu
    };
    function leakyRelu(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var alpha = attrs.alpha;
      assertNotComplex([x], "leakyRelu");
      var xSize = tfjsCore.util.sizeFromShape(x.shape);
      var xVals = backend.data.get(x.dataId).values;
      var outVals = tfjsCore.util.getTypedArrayFromDType("float32", xSize);
      for (var i = 0; i < xVals.length; i++) {
        outVals[i] = xVals[i] < 0 ? alpha * xVals[i] : xVals[i];
      }
      return backend.makeTensorInfo(x.shape, "float32", outVals);
    }
    var leakyReluConfig = {
      kernelName: tfjsCore.LeakyRelu,
      backendName: "cpu",
      kernelFunc: leakyRelu
    };
    var preluImpl = createSimpleBinaryKernelImpl(function(xValue, aValue) {
      return xValue < 0 ? aValue * xValue : xValue;
    });
    function prelu(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x, alpha = inputs.alpha;
      assertNotComplex([x, alpha], "prelu");
      var aVals = backend.data.get(x.dataId).values;
      var bVals = backend.data.get(alpha.dataId).values;
      var _a2 = __read(preluImpl(x.shape, alpha.shape, aVals, bVals, "float32"), 2), resultData = _a2[0], resultShape = _a2[1];
      return backend.makeTensorInfo(resultShape, "float32", resultData);
    }
    var preluConfig = {
      kernelName: tfjsCore.Prelu,
      backendName: "cpu",
      kernelFunc: prelu
    };
    var relu = unaryKernelFunc(tfjsCore.Relu, function(xi) {
      return Math.max(0, xi);
    });
    var reluConfig = {
      kernelName: tfjsCore.Relu,
      backendName: "cpu",
      kernelFunc: relu
    };
    var relu6 = unaryKernelFunc(tfjsCore.Relu6, function(xi) {
      return Math.min(Math.max(0, xi), 6);
    });
    var relu6Config = {
      kernelName: tfjsCore.Relu6,
      backendName: "cpu",
      kernelFunc: relu6
    };
    function applyActivation(backend, x, activation, preluActivationWeights, leakyreluAlpha) {
      if (activation === "linear") {
        return identity({ inputs: { x }, backend });
      } else if (activation === "relu") {
        return relu({ inputs: { x }, backend });
      } else if (activation === "elu") {
        return elu({ inputs: { x }, backend });
      } else if (activation === "relu6") {
        return relu6({ inputs: { x }, backend });
      } else if (activation === "prelu") {
        return prelu({ inputs: { x, alpha: preluActivationWeights }, backend });
      } else if (activation === "leakyrelu") {
        return leakyRelu({ inputs: { x }, backend, attrs: { alpha: leakyreluAlpha } });
      } else if (activation === "sigmoid") {
        return sigmoid({ inputs: { x }, backend });
      }
      throw new Error("Activation ".concat(activation, " has not been implemented for the CPU backend."));
    }
    function reshape(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var shape = attrs.shape;
      var xSize = tfjsCore.util.sizeFromShape(x.shape);
      var $shape = tfjsCore.util.inferFromImplicitShape(shape, xSize);
      var $xSize = tfjsCore.util.sizeFromShape($shape);
      tfjsCore.util.assert(xSize === $xSize, function() {
        return "The new shape (".concat($shape, ") has ").concat($xSize, " elements and the old ") + "shape (".concat(x.shape, ") has ").concat(xSize, " elements. The new shape and old ") + "shape must have the same number of elements.";
      });
      backend.incRef(x.dataId);
      var xData = backend.data.get(x.dataId);
      if (xData.complexTensorInfos != null) {
        var real2 = xData.complexTensorInfos.real;
        var imag2 = xData.complexTensorInfos.imag;
        real2.shape = $shape;
        imag2.shape = $shape;
      }
      return { dataId: x.dataId, shape: $shape, dtype: x.dtype };
    }
    var reshapeConfig = {
      kernelName: tfjsCore.Reshape,
      backendName: "cpu",
      kernelFunc: reshape
    };
    function batchMatMul(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var a = inputs.a, b = inputs.b;
      var transposeA = attrs.transposeA, transposeB = attrs.transposeB;
      assertNotComplex([a, b], "matMul");
      var aRank = a.shape.length;
      var bRank = b.shape.length;
      var innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];
      var innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];
      var outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];
      var outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];
      var outerDimsA = a.shape.slice(0, -2);
      var outerDimsB = b.shape.slice(0, -2);
      var batchDimA = tfjsCore.util.sizeFromShape(outerDimsA);
      var batchDimB = tfjsCore.util.sizeFromShape(outerDimsB);
      var outShapeOuterDims = tfjsCore.broadcast_util.assertAndGetBroadcastShape(a.shape.slice(0, -2), b.shape.slice(0, -2));
      var outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
      tfjsCore.util.assert(innerShapeA === innerShapeB, function() {
        return "Error in matMul: inner shapes (".concat(innerShapeA, ") and (") + "".concat(innerShapeB, ") of Tensors with shapes ").concat(a.shape, " and ") + "".concat(b.shape, " and transposeA=").concat(transposeA) + " and transposeB=".concat(transposeB, " must match.");
      });
      var a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];
      var b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB];
      var a3d = reshape({ inputs: { x: a }, backend, attrs: { shape: a3dShape } });
      var b3d = reshape({ inputs: { x: b }, backend, attrs: { shape: b3dShape } });
      var sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];
      var leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];
      var rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];
      var batchDim = Math.max(batchDimA, batchDimB);
      var a3dValues = backend.data.get(a3d.dataId).values;
      var b3dValues = backend.data.get(b3d.dataId).values;
      var a3dStrides = tfjsCore.util.computeStrides(a3d.shape);
      var b3dStrides = tfjsCore.util.computeStrides(b3d.shape);
      var _a2 = __read(transposeA ? [a3dStrides[0], 1, a3dStrides[1]] : [a3dStrides[0], a3dStrides[1], 1], 3), aBatch = _a2[0], aOuterStep = _a2[1], aInnerStep = _a2[2];
      var _b = __read(transposeB ? [1, b3dStrides[1], b3dStrides[0]] : [b3dStrides[1], 1, b3dStrides[0]], 3), bInnerStep = _b[0], bOuterStep = _b[1], bBatch = _b[2];
      var size = leftDim * rightDim;
      var result = tfjsCore.buffer([batchDim, leftDim, rightDim], a3d.dtype);
      var resVals = result.values;
      var blockSize = backend.blockSize;
      for (var bi = 0; bi < batchDim; bi++) {
        var batchIndexA = bi % batchDimA;
        var batchIndexB = bi % batchDimB;
        for (var i0 = 0; i0 < leftDim; i0 += blockSize) {
          var iBlock = Math.min(i0 + blockSize, leftDim);
          for (var j0 = 0; j0 < rightDim; j0 += blockSize) {
            var jBlock = Math.min(j0 + blockSize, rightDim);
            for (var k0 = 0; k0 < sharedDim; k0 += blockSize) {
              var kBlock = Math.min(k0 + blockSize, sharedDim);
              for (var i = i0; i < iBlock; i++) {
                for (var j = j0; j < jBlock; j++) {
                  var sum2 = 0;
                  for (var k = k0; k < kBlock; k++) {
                    var aVal = (
                      // tslint:disable-next-line: max-line-length
                      a3dValues[batchIndexA * aBatch + i * aOuterStep + k * aInnerStep]
                    );
                    var bVal = (
                      // tslint:disable-next-line: max-line-length
                      b3dValues[k * bInnerStep + j * bOuterStep + batchIndexB * bBatch]
                    );
                    sum2 += aVal * bVal;
                  }
                  resVals[bi * size + (i * rightDim + j)] += sum2;
                }
              }
            }
          }
        }
      }
      backend.disposeIntermediateTensorInfo(a3d);
      backend.disposeIntermediateTensorInfo(b3d);
      return backend.makeTensorInfo(outShape, result.dtype, result.values);
    }
    var batchMatMulConfig = {
      kernelName: tfjsCore.BatchMatMul,
      backendName: "cpu",
      kernelFunc: batchMatMul
    };
    function _fusedMatMul(args) {
      var e_12, _a2;
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var a = inputs.a, b = inputs.b, bias = inputs.bias, preluActivationWeights = inputs.preluActivationWeights;
      var transposeA = attrs.transposeA, transposeB = attrs.transposeB, activation = attrs.activation, leakyreluAlpha = attrs.leakyreluAlpha;
      var current;
      var addRes;
      var activationRes;
      var intermediates = [];
      var matMulRes = batchMatMul({ inputs: { a, b }, attrs: { transposeA, transposeB }, backend });
      current = matMulRes;
      if (bias) {
        addRes = add({ inputs: { a: current, b: bias }, backend });
        intermediates.push(current);
        current = addRes;
      }
      if (activation) {
        activationRes = applyActivation(backend, current, activation, preluActivationWeights, leakyreluAlpha);
        intermediates.push(current);
        current = activationRes;
      }
      try {
        for (var intermediates_1 = __values(intermediates), intermediates_1_1 = intermediates_1.next(); !intermediates_1_1.done; intermediates_1_1 = intermediates_1.next()) {
          var i = intermediates_1_1.value;
          backend.disposeIntermediateTensorInfo(i);
        }
      } catch (e_1_1) {
        e_12 = { error: e_1_1 };
      } finally {
        try {
          if (intermediates_1_1 && !intermediates_1_1.done && (_a2 = intermediates_1.return))
            _a2.call(intermediates_1);
        } finally {
          if (e_12)
            throw e_12.error;
        }
      }
      return current;
    }
    var _fusedMatMulConfig = {
      kernelName: tfjsCore._FusedMatMul,
      backendName: "cpu",
      kernelFunc: _fusedMatMul
    };
    var acos = unaryKernelFunc(tfjsCore.Acos, function(xi) {
      return Math.acos(xi);
    });
    var acosConfig = {
      kernelName: tfjsCore.Acos,
      backendName: "cpu",
      kernelFunc: acos
    };
    var acosh = unaryKernelFunc(tfjsCore.Acosh, function(xi) {
      return Math.acosh(xi);
    });
    var acoshConfig = {
      kernelName: tfjsCore.Acosh,
      backendName: "cpu",
      kernelFunc: acosh
    };
    function addN(args) {
      var inputs = args.inputs, backend = args.backend;
      var tensors = inputs;
      assertNotComplex(inputs, "addN");
      var vals = tensors.map(function(t) {
        return backend.data.get(t.dataId).values;
      });
      var outBuf = tfjsCore.buffer(tensors[0].shape, tensors[0].dtype);
      var outVals = outBuf.values;
      for (var i = 0; i < tensors.length; i++) {
        var currVals = vals[i];
        for (var j = 0; j < outVals.length; j++) {
          outVals[j] += currVals[j];
        }
      }
      return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
    }
    var addNConfig = {
      kernelName: tfjsCore.AddN,
      backendName: "cpu",
      kernelFunc: addN
    };
    function all(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      assertNotComplex(x, "all");
      var origAxes = tfjsCore.util.parseAxisParam(axis, x.shape);
      var axes = origAxes;
      var permutedAxes = tfjsCore.backend_util.getAxesPermutation(axes, x.shape.length);
      var $x = x;
      if (permutedAxes != null) {
        $x = transpose({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
        axes = tfjsCore.backend_util.getInnerMostAxes(axes.length, x.shape.length);
      }
      tfjsCore.backend_util.assertAxesAreInnerMostDims("all", axes, $x.shape.length);
      var _a2 = __read(tfjsCore.backend_util.computeOutAndReduceShapes($x.shape, axes), 2), outShape = _a2[0], reduceShape = _a2[1];
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var vals = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape(outShape), $x.dtype);
      var aVals = backend.data.get($x.dataId).values;
      for (var i = 0; i < vals.length; ++i) {
        var offset = i * reduceSize;
        var all_1 = aVals[offset];
        for (var j = 0; j < reduceSize; ++j) {
          var value = aVals[offset + j];
          all_1 = all_1 && value;
        }
        vals[i] = all_1;
      }
      if (permutedAxes != null) {
        backend.disposeIntermediateTensorInfo($x);
      }
      var result = backend.makeTensorInfo(outShape, $x.dtype, vals);
      if (keepDims) {
        var expandedShape = tfjsCore.backend_util.expandShapeToKeepDim(outShape, origAxes);
        var reshapedResult = reshape({ inputs: { x: result }, backend, attrs: { shape: expandedShape } });
        backend.disposeIntermediateTensorInfo(result);
        return reshapedResult;
      }
      return result;
    }
    var allConfig = {
      kernelName: tfjsCore.All,
      backendName: "cpu",
      kernelFunc: all
    };
    function any(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      assertNotComplex(x, "any");
      var origAxes = tfjsCore.util.parseAxisParam(axis, x.shape);
      var axes = origAxes;
      var permutedAxes = tfjsCore.backend_util.getAxesPermutation(axes, x.shape.length);
      var $x = x;
      if (permutedAxes != null) {
        $x = transpose({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
        axes = tfjsCore.backend_util.getInnerMostAxes(axes.length, x.shape.length);
      }
      tfjsCore.backend_util.assertAxesAreInnerMostDims("any", axes, $x.shape.length);
      var _a2 = __read(tfjsCore.backend_util.computeOutAndReduceShapes($x.shape, axes), 2), outShape = _a2[0], reduceShape = _a2[1];
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var vals = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape(outShape), $x.dtype);
      var aVals = backend.data.get($x.dataId).values;
      for (var i = 0; i < vals.length; ++i) {
        var offset = i * reduceSize;
        var anyVal = aVals[offset];
        for (var j = 0; j < reduceSize; ++j) {
          var value = aVals[offset + j];
          anyVal = anyVal || value;
        }
        vals[i] = anyVal;
      }
      if (permutedAxes != null) {
        backend.disposeIntermediateTensorInfo($x);
      }
      var result = backend.makeTensorInfo(outShape, $x.dtype, vals);
      if (keepDims) {
        var expandedShape = tfjsCore.backend_util.expandShapeToKeepDim(outShape, origAxes);
        var reshapedResult = reshape({ inputs: { x: result }, backend, attrs: { shape: expandedShape } });
        backend.disposeIntermediateTensorInfo(result);
        return reshapedResult;
      }
      return result;
    }
    var anyConfig = {
      kernelName: tfjsCore.Any,
      backendName: "cpu",
      kernelFunc: any
    };
    function argMax(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis;
      assertNotComplex(x, "argMax");
      var axes = tfjsCore.util.parseAxisParam(axis, x.shape);
      var permutedAxes = tfjsCore.backend_util.getAxesPermutation(axes, x.shape.length);
      var $x = x;
      var intermediateTensorInfos = [];
      if (permutedAxes != null) {
        $x = transpose({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
        intermediateTensorInfos.push($x);
        axes = tfjsCore.backend_util.getInnerMostAxes(axes.length, $x.shape.length);
      }
      axes = [axes[0]];
      tfjsCore.backend_util.assertAxesAreInnerMostDims("argMax", axes, $x.shape.length);
      var _a2 = __read(tfjsCore.backend_util.computeOutAndReduceShapes($x.shape, axes), 2), outShape = _a2[0], reduceShape = _a2[1];
      var outSize = tfjsCore.util.sizeFromShape(outShape);
      var vals = tfjsCore.util.makeZerosTypedArray(outSize, "int32");
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var aVals = backend.data.get($x.dataId).values;
      for (var i = 0; i < vals.length; ++i) {
        var offset = i * reduceSize;
        var max2 = aVals[offset];
        var maxIndex = 0;
        for (var j = 0; j < reduceSize; ++j) {
          var value = aVals[offset + j];
          if (value > max2) {
            max2 = value;
            maxIndex = j;
          }
        }
        vals[i] = maxIndex;
      }
      intermediateTensorInfos.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return backend.makeTensorInfo(outShape, "int32", vals);
    }
    var argMaxConfig = {
      kernelName: tfjsCore.ArgMax,
      backendName: "cpu",
      kernelFunc: argMax
    };
    function argMin(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis;
      assertNotComplex(x, "argMin");
      var axes = tfjsCore.util.parseAxisParam(axis, x.shape);
      var permutedAxes = tfjsCore.backend_util.getAxesPermutation(axes, x.shape.length);
      var $x = x;
      var intermediateTensorInfos = [];
      if (permutedAxes != null) {
        $x = transpose({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
        intermediateTensorInfos.push($x);
        axes = tfjsCore.backend_util.getInnerMostAxes(axes.length, $x.shape.length);
      }
      axes = [axes[0]];
      tfjsCore.backend_util.assertAxesAreInnerMostDims("argMin", axes, $x.shape.length);
      var _a2 = __read(tfjsCore.backend_util.computeOutAndReduceShapes($x.shape, axes), 2), outShape = _a2[0], reduceShape = _a2[1];
      var outSize = tfjsCore.util.sizeFromShape(outShape);
      var vals = tfjsCore.util.makeZerosTypedArray(outSize, "int32");
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var aVals = backend.data.get($x.dataId).values;
      for (var i = 0; i < vals.length; ++i) {
        var offset = i * reduceSize;
        var min2 = aVals[offset];
        var minIndex = 0;
        for (var j = 0; j < reduceSize; ++j) {
          var value = aVals[offset + j];
          if (value < min2) {
            min2 = value;
            minIndex = j;
          }
        }
        vals[i] = minIndex;
      }
      intermediateTensorInfos.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return backend.makeTensorInfo(outShape, "int32", vals);
    }
    var argMinConfig = {
      kernelName: tfjsCore.ArgMin,
      backendName: "cpu",
      kernelFunc: argMin
    };
    var asin = unaryKernelFunc(tfjsCore.Asin, function(xi) {
      return Math.asin(xi);
    });
    var asinConfig = {
      kernelName: tfjsCore.Asin,
      backendName: "cpu",
      kernelFunc: asin
    };
    var asinh = unaryKernelFunc(tfjsCore.Asinh, function(xi) {
      return Math.asinh(xi);
    });
    var asinhConfig = {
      kernelName: tfjsCore.Asinh,
      backendName: "cpu",
      kernelFunc: asinh
    };
    var atan = unaryKernelFunc(tfjsCore.Atan, function(xi) {
      return Math.atan(xi);
    });
    var atanConfig = {
      kernelName: tfjsCore.Atan,
      backendName: "cpu",
      kernelFunc: atan
    };
    var atan2Impl = createSimpleBinaryKernelImpl(function(aValue, bValue) {
      return Math.atan2(aValue, bValue);
    });
    var atan2 = binaryKernelFunc(tfjsCore.Atan2, atan2Impl);
    var atan2Config = {
      kernelName: tfjsCore.Atan2,
      backendName: "cpu",
      kernelFunc: atan2
    };
    var atanh = unaryKernelFunc(tfjsCore.Atanh, function(xi) {
      return Math.atanh(xi);
    });
    var atanhConfig = {
      kernelName: tfjsCore.Atanh,
      backendName: "cpu",
      kernelFunc: atanh
    };
    function pool(xValues, xShape, dtype, strides, convInfo, poolType) {
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var dilationHeight = convInfo.dilationHeight;
      var dilationWidth = convInfo.dilationWidth;
      var effectiveFilterHeight = convInfo.effectiveFilterHeight;
      var effectiveFilterWidth = convInfo.effectiveFilterWidth;
      var padTop = convInfo.padInfo.top;
      var padLeft = convInfo.padInfo.left;
      var initialValue = poolType === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY;
      var output = tfjsCore.buffer(convInfo.outShape, dtype);
      var outputVals = output.values;
      var outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];
      var outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];
      var outputColStrides = convInfo.outShape[3];
      for (var b = 0; b < convInfo.batchSize; ++b) {
        var outputBatchOffset = b * outputBatchStrides;
        var inputBatchOffset = b * strides[0];
        for (var d = 0; d < convInfo.inChannels; ++d) {
          for (var yR = 0; yR < convInfo.outHeight; ++yR) {
            var xRCorner = yR * strideHeight - padTop;
            var xRMin = Math.max(0, xRCorner);
            var xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);
            var outputRowOffset = outputBatchOffset + yR * outputRowStrides;
            for (var yC = 0; yC < convInfo.outWidth; ++yC) {
              var xCCorner = yC * strideWidth - padLeft;
              var xCMin = Math.max(0, xCCorner);
              var xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);
              var minMaxValue = initialValue;
              var avgValue = 0;
              var count = 0;
              for (var xR = xRMin; xR < xRMax; xR += dilationHeight) {
                var xROffset = inputBatchOffset + xR * strides[1];
                for (var xC = xCMin; xC < xCMax; xC += dilationWidth) {
                  var xCOffset = xROffset + xC * strides[2];
                  var pixel = xValues[xCOffset + d];
                  if (poolType === "max" && pixel > minMaxValue) {
                    minMaxValue = pixel;
                  } else if (poolType === "avg") {
                    avgValue += pixel;
                    count++;
                  }
                }
                if (isNaN(minMaxValue)) {
                  break;
                }
              }
              var outputOffset = outputRowOffset + yC * outputColStrides + d;
              outputVals[outputOffset] = poolType === "avg" ? avgValue / count : minMaxValue;
            }
          }
        }
      }
      return output;
    }
    function maxPoolPositions(xValues, xShape, dtype, convInfo, flattenPositions, includeBatchInIndex) {
      if (flattenPositions === void 0) {
        flattenPositions = false;
      }
      if (includeBatchInIndex === void 0) {
        includeBatchInIndex = false;
      }
      var maxPositions = tfjsCore.buffer(convInfo.outShape, "int32");
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var dilationHeight = convInfo.dilationHeight;
      var dilationWidth = convInfo.dilationWidth;
      var effectiveFilterHeight = convInfo.effectiveFilterHeight;
      var effectiveFilterWidth = convInfo.effectiveFilterWidth;
      var padTop = convInfo.padInfo.top;
      var padLeft = convInfo.padInfo.left;
      var xBuf = tfjsCore.buffer(xShape, dtype, xValues);
      for (var b = 0; b < convInfo.batchSize; ++b) {
        for (var d = 0; d < convInfo.inChannels; ++d) {
          for (var yR = 0; yR < convInfo.outHeight; ++yR) {
            var xRCorner = yR * strideHeight - padTop;
            var xRMin = xRCorner;
            while (xRMin < 0) {
              xRMin += dilationHeight;
            }
            var xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);
            for (var yC = 0; yC < convInfo.outWidth; ++yC) {
              var xCCorner = yC * strideWidth - padLeft;
              var xCMin = xCCorner;
              while (xCMin < 0) {
                xCMin += dilationWidth;
              }
              var xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);
              var maxValue = Number.NEGATIVE_INFINITY;
              var maxPosition = -1;
              for (var xR = xRMin; xR < xRMax; xR += dilationHeight) {
                var wR = xR - xRCorner;
                for (var xC = xCMin; xC < xCMax; xC += dilationWidth) {
                  var wC = xC - xCCorner;
                  var pixel = xBuf.get(b, xR, xC, d);
                  if (pixel > maxValue) {
                    maxValue = pixel;
                    if (flattenPositions) {
                      maxPosition = includeBatchInIndex ? ((b * convInfo.inHeight + xR) * convInfo.inWidth + xC) * convInfo.inChannels + d : (xR * convInfo.inWidth + xC) * convInfo.inChannels + d;
                    } else {
                      maxPosition = wR * effectiveFilterWidth + wC;
                    }
                  }
                }
              }
              maxPositions.set(maxPosition, b, yR, yC, d);
            }
          }
        }
      }
      return maxPositions;
    }
    function pool3d(xValues, xShape, dtype, strides, convInfo, poolType) {
      var strideDepth = convInfo.strideDepth;
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var dilationDepth = convInfo.dilationDepth;
      var dilationHeight = convInfo.dilationHeight;
      var dilationWidth = convInfo.dilationWidth;
      var effectiveFilterDepth = convInfo.effectiveFilterDepth;
      var effectiveFilterHeight = convInfo.effectiveFilterHeight;
      var effectiveFilterWidth = convInfo.effectiveFilterWidth;
      var padFront = convInfo.padInfo.front;
      var padTop = convInfo.padInfo.top;
      var padLeft = convInfo.padInfo.left;
      var initialValue = poolType === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY;
      var output = tfjsCore.buffer(convInfo.outShape, dtype);
      var outputVals = output.values;
      var outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];
      var outputDepthStrides = convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];
      var outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];
      var outputColStrides = convInfo.outShape[4];
      for (var batch = 0; batch < convInfo.batchSize; ++batch) {
        var outputBatchOffset = batch * outputBatchStrides;
        var inputBatchOffset = batch * strides[0];
        for (var channel = 0; channel < convInfo.inChannels; ++channel) {
          for (var yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {
            var xDepthCorner = yDepth * strideDepth - padFront;
            var xDepthMin = xDepthCorner;
            while (xDepthMin < 0) {
              xDepthMin += dilationDepth;
            }
            var xDepthMax = Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);
            var outputDepthOffset = outputBatchOffset + yDepth * outputDepthStrides;
            for (var yRow = 0; yRow < convInfo.outHeight; ++yRow) {
              var xRowCorner = yRow * strideHeight - padTop;
              var xRowMin = xRowCorner;
              while (xRowMin < 0) {
                xRowMin += dilationHeight;
              }
              var xRowMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);
              var outputRowOffset = outputDepthOffset + yRow * outputRowStrides;
              for (var yCol = 0; yCol < convInfo.outWidth; ++yCol) {
                var xColCorner = yCol * strideWidth - padLeft;
                var xColMin = xColCorner;
                while (xColMin < 0) {
                  xColMin += dilationWidth;
                }
                var xColMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);
                var outputColOffset = outputRowOffset + yCol * outputColStrides;
                var minMaxValue = initialValue;
                var avgValue = 0;
                var count = 0;
                for (var xDepth = xDepthMin; xDepth < xDepthMax; xDepth += dilationDepth) {
                  var xDepthOffset = inputBatchOffset + xDepth * strides[1];
                  for (var xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {
                    var xRowOffset = xDepthOffset + xRow * strides[2];
                    for (var xCol = xColMin; xCol < xColMax; xCol += dilationWidth) {
                      var xColOffset = xRowOffset + xCol * strides[3];
                      var pixel = xValues[xColOffset + channel];
                      if (poolType === "max" && pixel > minMaxValue) {
                        minMaxValue = pixel;
                      } else if (poolType === "avg") {
                        avgValue += pixel;
                        count++;
                      }
                      if (isNaN(minMaxValue)) {
                        break;
                      }
                    }
                    if (isNaN(minMaxValue)) {
                      break;
                    }
                  }
                  if (isNaN(minMaxValue)) {
                    break;
                  }
                }
                var outputOffset = outputColOffset + channel;
                outputVals[outputOffset] = poolType === "avg" ? avgValue / Math.max(count, 1) : minMaxValue;
              }
            }
          }
        }
      }
      return output;
    }
    function maxPool3dPositions(xBuf, convInfo) {
      var maxPositions = tfjsCore.buffer(convInfo.outShape, "int32");
      var strideDepth = convInfo.strideDepth;
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var dilationDepth = convInfo.dilationDepth;
      var dilationHeight = convInfo.dilationHeight;
      var dilationWidth = convInfo.dilationWidth;
      var effectiveFilterDepth = convInfo.effectiveFilterDepth;
      var effectiveFilterHeight = convInfo.effectiveFilterHeight;
      var effectiveFilterWidth = convInfo.effectiveFilterWidth;
      var padFront = convInfo.padInfo.front;
      var padTop = convInfo.padInfo.top;
      var padLeft = convInfo.padInfo.left;
      for (var batch = 0; batch < convInfo.batchSize; ++batch) {
        for (var channel = 0; channel < convInfo.inChannels; ++channel) {
          for (var yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {
            var xDepthCorner = yDepth * strideDepth - padFront;
            var xDepthMin = xDepthCorner;
            while (xDepthMin < 0) {
              xDepthMin += dilationDepth;
            }
            var xDepthMax = Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);
            for (var yRow = 0; yRow < convInfo.outHeight; ++yRow) {
              var xRowCorner = yRow * strideHeight - padTop;
              var xRowMin = xRowCorner;
              while (xRowMin < 0) {
                xRowMin += dilationHeight;
              }
              var xRowMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);
              for (var yCol = 0; yCol < convInfo.outWidth; ++yCol) {
                var xColCorner = yCol * strideWidth - padLeft;
                var xColMin = xColCorner;
                while (xColMin < 0) {
                  xColMin += dilationWidth;
                }
                var xColMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);
                var maxValue = Number.NEGATIVE_INFINITY;
                var maxPosition = -1;
                for (var xDepth = xDepthMin; xDepth < xDepthMax; xDepth += dilationDepth) {
                  var wDepth = xDepth - xDepthCorner;
                  for (var xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {
                    var wRow = xRow - xRowCorner;
                    for (var xCol = xColMin; xCol < xColMax; xCol += dilationWidth) {
                      var wCol = xCol - xColCorner;
                      var pixel = xBuf.get(batch, xDepth, xRow, xCol, channel);
                      if (pixel >= maxValue) {
                        maxValue = pixel;
                        maxPosition = wDepth * effectiveFilterHeight * effectiveFilterWidth + wRow * effectiveFilterHeight + wCol;
                      }
                    }
                  }
                }
                maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);
              }
            }
          }
        }
      }
      return maxPositions;
    }
    function avgPool(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      assertNotComplex(x, "avgPool");
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      var dilations = 1;
      tfjsCore.util.assert(tfjsCore.backend_util.eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in avgPool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var convInfo = tfjsCore.backend_util.computePool2DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode);
      var res;
      if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && tfjsCore.util.arraysEqual(convInfo.inShape, convInfo.outShape)) {
        res = identity({ inputs: { x }, backend });
      } else {
        var xValues = backend.data.get(x.dataId).values;
        var strides_1 = tfjsCore.util.computeStrides(x.shape);
        var buffer = pool(xValues, x.shape, x.dtype, strides_1, convInfo, "avg");
        res = backend.makeTensorInfo(convInfo.outShape, x.dtype, buffer.values);
      }
      return res;
    }
    var avgPoolConfig = {
      kernelName: tfjsCore.AvgPool,
      backendName: "cpu",
      kernelFunc: avgPool
    };
    function avgPool3D(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode, dataFormat = attrs.dataFormat;
      assertNotComplex(x, "avgPool3d");
      var convInfo = tfjsCore.backend_util.computePool3DInfo(x.shape, filterSize, strides, 1, pad, dimRoundingMode, dataFormat);
      var xValues = backend.data.get(x.dataId).values;
      var outBuf = pool3d(xValues, x.shape, x.dtype, tfjsCore.util.computeStrides(x.shape), convInfo, "avg");
      return backend.makeTensorInfo(outBuf.shape, "float32", outBuf.values);
    }
    var avgPool3DConfig = {
      kernelName: tfjsCore.AvgPool3D,
      backendName: "cpu",
      kernelFunc: avgPool3D
    };
    function avgPool3DGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, input = inputs.input;
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      assertNotComplex([dy, input], "avgPool3DGrad");
      var convInfo = tfjsCore.backend_util.computePool3DInfo(input.shape, filterSize, strides, 1, pad, dimRoundingMode);
      var strideDepth = convInfo.strideDepth;
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var filterDepth = convInfo.filterDepth;
      var filterHeight = convInfo.filterHeight;
      var filterWidth = convInfo.filterWidth;
      var dilationDepth = convInfo.dilationDepth;
      var dilationHeight = convInfo.dilationHeight;
      var dilationWidth = convInfo.dilationWidth;
      var effectiveFilterDepth = convInfo.effectiveFilterDepth;
      var effectiveFilterHeight = convInfo.effectiveFilterHeight;
      var effectiveFilterWidth = convInfo.effectiveFilterWidth;
      var padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
      var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
      var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
      var dx = tfjsCore.buffer(input.shape, "float32");
      var avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);
      var dyBuf = backend.bufferSync(dy);
      for (var batch = 0; batch < convInfo.batchSize; ++batch) {
        for (var channel = 0; channel < convInfo.inChannels; ++channel) {
          for (var dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {
            for (var dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {
              for (var dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {
                var dyDepthCorner = dxDepth - padFront;
                var dyRowCorner = dxRow - padTop;
                var dyColCorner = dxCol - padLeft;
                var dotProd = 0;
                for (var wDepth = 0; wDepth < effectiveFilterDepth; wDepth += dilationDepth) {
                  var dyDepth = (dyDepthCorner + wDepth) / strideDepth;
                  if (dyDepth < 0 || dyDepth >= convInfo.outDepth || Math.floor(dyDepth) !== dyDepth) {
                    continue;
                  }
                  for (var wRow = 0; wRow < effectiveFilterHeight; wRow += dilationHeight) {
                    var dyRow = (dyRowCorner + wRow) / strideHeight;
                    if (dyRow < 0 || dyRow >= convInfo.outHeight || Math.floor(dyRow) !== dyRow) {
                      continue;
                    }
                    for (var wCol = 0; wCol < effectiveFilterWidth; wCol += dilationWidth) {
                      var dyCol = (dyColCorner + wCol) / strideWidth;
                      if (dyCol < 0 || dyCol >= convInfo.outWidth || Math.floor(dyCol) !== dyCol) {
                        continue;
                      }
                      var pixel = dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                      dotProd += pixel;
                    }
                  }
                }
                dx.set(dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol, channel);
              }
            }
          }
        }
      }
      return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);
    }
    var avgPool3DGradConfig = {
      kernelName: tfjsCore.AvgPool3DGrad,
      backendName: "cpu",
      kernelFunc: avgPool3DGrad
    };
    function avgPoolGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, input = inputs.input;
      var x = input;
      assertNotComplex([dy, input], "avgPoolGrad");
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad;
      var convInfo = tfjsCore.backend_util.computePool2DInfo(x.shape, filterSize, strides, 1, pad);
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var filterHeight = convInfo.filterHeight;
      var filterWidth = convInfo.filterWidth;
      var dilationHeight = convInfo.dilationHeight;
      var dilationWidth = convInfo.dilationWidth;
      var effectiveFilterHeight = convInfo.effectiveFilterHeight;
      var effectiveFilterWidth = convInfo.effectiveFilterWidth;
      var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
      var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
      var dx = tfjsCore.buffer(x.shape, "float32");
      var avgMultiplier = 1 / (filterHeight * filterWidth);
      var dyData = backend.data.get(dy.dataId).values;
      var dyBuf = tfjsCore.buffer(dy.shape, "float32", dyData);
      for (var b = 0; b < convInfo.batchSize; ++b) {
        for (var d = 0; d < convInfo.inChannels; ++d) {
          for (var dxR = 0; dxR < convInfo.inHeight; ++dxR) {
            for (var dxC = 0; dxC < convInfo.inWidth; ++dxC) {
              var dyRCorner = dxR - padTop;
              var dyCCorner = dxC - padLeft;
              var dotProd = 0;
              for (var wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {
                var dyR = (dyRCorner + wR) / strideHeight;
                if (dyR < 0 || dyR >= convInfo.outHeight || Math.floor(dyR) !== dyR) {
                  continue;
                }
                for (var wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {
                  var dyC = (dyCCorner + wC) / strideWidth;
                  if (dyC < 0 || dyC >= convInfo.outWidth || Math.floor(dyC) !== dyC) {
                    continue;
                  }
                  var pixel = dyBuf.get(b, dyR, dyC, d);
                  dotProd += pixel;
                }
              }
              dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);
            }
          }
        }
      }
      return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);
    }
    var avgPoolGradConfig = {
      kernelName: tfjsCore.AvgPoolGrad,
      backendName: "cpu",
      kernelFunc: avgPoolGrad
    };
    function batchNorm(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, scale2 = inputs.scale, offset = inputs.offset, mean2 = inputs.mean, variance = inputs.variance;
      tfjsCore.util.assert(mean2.shape.length === variance.shape.length, function() {
        return "Batch normalization gradient requires mean and variance to have equal ranks.";
      });
      tfjsCore.util.assert(offset == null || mean2.shape.length === offset.shape.length, function() {
        return "Batch normalization gradient requires mean and offset to have equal ranks.";
      });
      tfjsCore.util.assert(scale2 == null || mean2.shape.length === scale2.shape.length, function() {
        return "Batch normalization gradient requires mean and scale to have equal ranks.";
      });
      assertNotComplex([x, mean2, variance, scale2, offset], "batchNorm");
      var varianceEpsilon = attrs.varianceEpsilon;
      if (varianceEpsilon == null) {
        varianceEpsilon = 1e-3;
      }
      var xVals = backend.data.get(x.dataId).values;
      var mVals = backend.data.get(mean2.dataId).values;
      var varVals = backend.data.get(variance.dataId).values;
      var sVals = scale2 ? backend.data.get(scale2.dataId).values : new Float32Array([1]);
      var offVals = offset ? backend.data.get(offset.dataId).values : new Float32Array([0]);
      var outVals = new Float32Array(xVals.length);
      var offValsLength = offVals.length;
      var sValsLength = sVals.length;
      var varValsLength = varVals.length;
      var mValsLength = mVals.length;
      var offi = 0;
      var mi = 0;
      var si = 0;
      var vi = 0;
      for (var i = 0; i < xVals.length; ++i) {
        outVals[i] = offVals[offi++] + (xVals[i] - mVals[mi++]) * sVals[si++] / Math.sqrt(varVals[vi++] + varianceEpsilon);
        if (offi >= offValsLength) {
          offi = 0;
        }
        if (mi >= mValsLength) {
          mi = 0;
        }
        if (si >= sValsLength) {
          si = 0;
        }
        if (vi >= varValsLength) {
          vi = 0;
        }
      }
      return backend.makeTensorInfo(x.shape, x.dtype, outVals);
    }
    var batchNormConfig = {
      kernelName: tfjsCore.FusedBatchNorm,
      backendName: "cpu",
      kernelFunc: batchNorm
    };
    function batchToSpaceND(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var blockShape = attrs.blockShape, crops = attrs.crops;
      assertNotComplex([x], "batchToSpaceND");
      var prod2 = blockShape.reduce(function(a, b) {
        return a * b;
      });
      var reshaped = tfjsCore.backend_util.getReshaped(x.shape, blockShape, prod2);
      var permuted = tfjsCore.backend_util.getPermuted(reshaped.length, blockShape.length);
      var reshapedPermuted = tfjsCore.backend_util.getReshapedPermuted(x.shape, blockShape, prod2);
      var sliceBeginCoords = tfjsCore.backend_util.getSliceBeginCoords(crops, blockShape.length);
      var sliceSize = tfjsCore.backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);
      var xReshaped = reshape({ inputs: { x }, backend, attrs: { shape: reshaped } });
      var xTransposed = transpose({ inputs: { x: xReshaped }, backend, attrs: { perm: permuted } });
      var xTransposedReshaped = reshape({ inputs: { x: xTransposed }, backend, attrs: { shape: reshapedPermuted } });
      var result = slice({
        inputs: { x: xTransposedReshaped },
        backend,
        attrs: { begin: sliceBeginCoords, size: sliceSize }
      });
      backend.disposeIntermediateTensorInfo(xReshaped);
      backend.disposeIntermediateTensorInfo(xTransposed);
      backend.disposeIntermediateTensorInfo(xTransposedReshaped);
      return result;
    }
    var batchToSpaceNDConfig = {
      kernelName: tfjsCore.BatchToSpaceND,
      backendName: "cpu",
      kernelFunc: batchToSpaceND
    };
    function bincount(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, weights = inputs.weights;
      var size = attrs.size;
      var xVals = backend.data.get(x.dataId).values;
      var weightsVals = backend.data.get(weights.dataId).values;
      var outVals = bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);
      return backend.makeTensorInfo([size], weights.dtype, outVals);
    }
    var bincountConfig = {
      kernelName: tfjsCore.Bincount,
      backendName: "cpu",
      kernelFunc: bincount
    };
    function broadcastArgs(args) {
      var inputs = args.inputs, backend = args.backend;
      var s0 = inputs.s0, s1 = inputs.s1;
      var s0Vals = backend.data.get(s0.dataId).values;
      var s1Vals = backend.data.get(s1.dataId).values;
      var broadcastShape = tfjsCore.backend_util.assertAndGetBroadcastShape(Array.from(s0Vals), Array.from(s1Vals));
      return backend.makeTensorInfo([broadcastShape.length], "int32", Int32Array.from(broadcastShape));
    }
    var broadcastArgsConfig = {
      kernelName: tfjsCore.BroadcastArgs,
      backendName: "cpu",
      kernelFunc: broadcastArgs
    };
    var clipByValue = unaryKernelFunc(tfjsCore.ClipByValue, function(xi, attrs) {
      var clipAttrs = attrs;
      if (xi > clipAttrs.clipValueMax) {
        return clipAttrs.clipValueMax;
      }
      return xi < clipAttrs.clipValueMin ? clipAttrs.clipValueMin : xi;
    });
    var clipByValueConfig = {
      kernelName: tfjsCore.ClipByValue,
      backendName: "cpu",
      kernelFunc: clipByValue
    };
    var complexAbs = function(args) {
      var x = args.inputs.x;
      var cpuBackend = args.backend;
      var resultValues = new Float32Array(tfjsCore.util.sizeFromShape(x.shape));
      var complexVals = cpuBackend.data.get(x.dataId);
      var real2 = complexVals.complexTensorInfos.real;
      var imag2 = complexVals.complexTensorInfos.imag;
      var realVals = cpuBackend.data.get(real2.dataId).values;
      var imagVals = cpuBackend.data.get(imag2.dataId).values;
      for (var i = 0; i < realVals.length; i++) {
        var real_1 = realVals[i];
        var imag_1 = imagVals[i];
        resultValues[i] = Math.hypot(real_1, imag_1);
      }
      return cpuBackend.makeOutput(resultValues, x.shape, "float32");
    };
    var complexAbsConfig = {
      kernelName: tfjsCore.ComplexAbs,
      backendName: "cpu",
      kernelFunc: complexAbs
    };
    function imag(args) {
      var inputs = args.inputs, backend = args.backend;
      var input = inputs.input;
      var imag2 = backend.data.get(input.dataId).complexTensorInfos.imag;
      var imagVal = backend.data.get(imag2.dataId).values;
      return backend.makeTensorInfo(imag2.shape, imag2.dtype, imagVal);
    }
    var imagConfig = {
      kernelName: tfjsCore.Imag,
      backendName: "cpu",
      kernelFunc: imag
    };
    function concat(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var axis = attrs.axis;
      var $axis = tfjsCore.util.parseAxisParam(axis, inputs[0].shape)[0];
      var shapes = inputs.map(function(t) {
        return t.shape;
      });
      tfjsCore.backend_util.assertParamsConsistent(shapes, $axis);
      var outShape = tfjsCore.backend_util.computeOutShape(inputs.map(function(t) {
        return t.shape;
      }), $axis);
      if (tfjsCore.util.sizeFromShape(outShape) === 0) {
        return backend.makeTensorInfo(outShape, inputs[0].dtype, []);
      }
      var $inputs = inputs.filter(function(t) {
        return tfjsCore.util.sizeFromShape(t.shape) > 0;
      });
      if ($inputs.length === 1) {
        return identity({ inputs: { x: $inputs[0] }, backend });
      }
      if ($inputs[0].dtype === "complex64") {
        var reals = $inputs.map(function(t) {
          return real({ inputs: { input: t }, backend });
        });
        var imags = $inputs.map(function(t) {
          return imag({ inputs: { input: t }, backend });
        });
        var realConcated = concat({ inputs: reals, backend, attrs: { axis: $axis } });
        var imagConcated = concat({ inputs: imags, backend, attrs: { axis: $axis } });
        var result = complex({ inputs: { real: realConcated, imag: imagConcated }, backend });
        reals.forEach(function(r) {
          return backend.disposeIntermediateTensorInfo(r);
        });
        imags.forEach(function(i) {
          return backend.disposeIntermediateTensorInfo(i);
        });
        backend.disposeIntermediateTensorInfo(realConcated);
        backend.disposeIntermediateTensorInfo(imagConcated);
        return result;
      }
      var inputs2D = $inputs.map(function(t) {
        var innerSize = tfjsCore.util.sizeFromShape(t.shape.slice($axis));
        var shape = [-1, innerSize];
        return reshape({ inputs: { x: t }, backend, attrs: { shape } });
      });
      var inputsValShapes = inputs2D.map(function(t) {
        return { vals: backend.data.get(t.dataId).values, shape: t.shape };
      });
      outShape = tfjsCore.backend_util.computeOutShape(
        inputs2D.map(function(t) {
          return t.shape;
        }),
        1
        /* axis */
      );
      var simplyConcat = inputs2D[0].shape[0] === 1;
      var outVals = concatImpl(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);
      var finalOutShape = tfjsCore.backend_util.computeOutShape($inputs.map(function(t) {
        return t.shape;
      }), $axis);
      var outInfo = backend.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);
      inputs2D.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return outInfo;
    }
    var concatConfig = {
      kernelName: tfjsCore.Concat,
      backendName: "cpu",
      kernelFunc: concat
    };
    function conv2D(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter;
      var strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dilations = attrs.dilations, dimRoundingMode = attrs.dimRoundingMode;
      assertNotComplex([x, filter], "conv2d");
      var $dataFormat = tfjsCore.backend_util.convertConv2DDataFormat(dataFormat);
      var convInfo = tfjsCore.backend_util.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad, dimRoundingMode, false, $dataFormat);
      var filterHeight = convInfo.filterHeight;
      var filterWidth = convInfo.filterWidth;
      var dilationHeight = convInfo.dilationHeight;
      var dilationWidth = convInfo.dilationWidth;
      var padLeft = convInfo.padInfo.left;
      var padTop = convInfo.padInfo.top;
      var isChannelsLast = convInfo.dataFormat === "channelsLast";
      var y = new tfjsCore.TensorBuffer(convInfo.outShape, x.dtype);
      var xStrides = tfjsCore.util.computeStrides(x.shape);
      var filterStrides = tfjsCore.util.computeStrides(filter.shape);
      var xBatchStride = xStrides[0];
      var xRowStride = isChannelsLast ? xStrides[1] : xStrides[2];
      var xColStride = isChannelsLast ? xStrides[2] : 1;
      var xChannelStride = isChannelsLast ? 1 : xStrides[1];
      var yBatchStride = y.strides[0];
      var yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];
      var yColStride = isChannelsLast ? y.strides[2] : 1;
      var yChannelStride = isChannelsLast ? 1 : y.strides[1];
      var xVals = backend.data.get(x.dataId).values;
      var wVals = backend.data.get(filter.dataId).values;
      var yVals = y.values;
      for (var b = 0; b < convInfo.batchSize; ++b) {
        var xOffset1 = b * xBatchStride;
        var yOffset1 = b * yBatchStride;
        for (var yR = 0; yR < convInfo.outHeight; ++yR) {
          var yOffset2 = yOffset1 + yR * yRowStride;
          var xRCorner = yR * convInfo.strideHeight - padTop;
          for (var wR = 0; wR < filterHeight; ++wR) {
            var xR = xRCorner + wR * dilationHeight;
            if (xR < 0 || xR >= convInfo.inHeight) {
              continue;
            }
            var wOffset1 = wR * filterStrides[0];
            var xOffset2 = xOffset1 + xR * xRowStride;
            for (var yC = 0; yC < convInfo.outWidth; ++yC) {
              var yOffset3 = yOffset2 + yC * yColStride;
              var xCCorner = yC * convInfo.strideWidth - padLeft;
              for (var wC = 0; wC < filterWidth; ++wC) {
                var xC = xCCorner + wC * dilationWidth;
                if (xC < 0 || xC >= convInfo.inWidth) {
                  continue;
                }
                var wOffset2 = wOffset1 + wC * filterStrides[1];
                var xOffset3 = xOffset2 + xC * xColStride;
                var wOffset3 = wOffset2;
                for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {
                  var xVal = xVals[xOffset3 + d1 * xChannelStride];
                  for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {
                    yVals[yOffset3 + d2 * yChannelStride] += xVal * wVals[wOffset3 + d2];
                  }
                  wOffset3 += convInfo.outChannels;
                }
              }
            }
          }
        }
      }
      return backend.makeTensorInfo(y.shape, y.dtype, yVals);
    }
    var conv2DConfig = {
      kernelName: tfjsCore.Conv2D,
      backendName: "cpu",
      kernelFunc: conv2D
    };
    function conv2DBackpropFilter(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, dy = inputs.dy;
      var strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dimRoundingMode = attrs.dimRoundingMode, filterShape = attrs.filterShape;
      assertNotComplex([x, dy], "conv2dBackpropFilter");
      var $dataFormat = tfjsCore.backend_util.convertConv2DDataFormat(dataFormat);
      var convInfo = tfjsCore.backend_util.computeConv2DInfo(x.shape, filterShape, strides, 1, pad, dimRoundingMode, false, $dataFormat);
      var strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth;
      var isChannelsLast = convInfo.dataFormat === "channelsLast";
      var dW = new tfjsCore.TensorBuffer(convInfo.filterShape, "float32");
      var leftPad = convInfo.padInfo.left;
      var topPad = convInfo.padInfo.top;
      var xVals = backend.data.get(x.dataId).values;
      var dyVals = backend.data.get(dy.dataId).values;
      var xBuf = new tfjsCore.TensorBuffer(x.shape, x.dtype, xVals);
      var dyBuf = new tfjsCore.TensorBuffer(dy.shape, dy.dtype, dyVals);
      for (var wR = 0; wR < filterHeight; ++wR) {
        var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
        var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
        for (var wC = 0; wC < filterWidth; ++wC) {
          var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
          var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
          for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {
            for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {
              var dotProd = 0;
              for (var b = 0; b < convInfo.batchSize; ++b) {
                for (var yR = yRMin; yR < yRMax; ++yR) {
                  var xR = wR + yR * strideHeight - topPad;
                  for (var yC = yCMin; yC < yCMax; ++yC) {
                    var xC = wC + yC * strideWidth - leftPad;
                    if (isChannelsLast) {
                      dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);
                    } else {
                      dotProd += xBuf.get(b, d1, xR, xC) * dyBuf.get(b, d2, yR, yC);
                    }
                  }
                }
              }
              dW.set(dotProd, wR, wC, d1, d2);
            }
          }
        }
      }
      return backend.makeTensorInfo(dW.shape, dW.dtype, dW.values);
    }
    var conv2DBackpropFilterConfig = {
      kernelName: tfjsCore.Conv2DBackpropFilter,
      backendName: "cpu",
      kernelFunc: conv2DBackpropFilter
    };
    function conv2DBackpropInput(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, filter = inputs.filter;
      var inputShape = attrs.inputShape, strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dimRoundingMode = attrs.dimRoundingMode;
      assertNotComplex([dy, filter], "conv2dBackpropInput");
      var filterStrides = tfjsCore.util.computeStrides(filter.shape);
      var dyStrides = tfjsCore.util.computeStrides(dy.shape);
      var $dataFormat = tfjsCore.backend_util.convertConv2DDataFormat(dataFormat);
      var convInfo = tfjsCore.backend_util.computeConv2DInfo(inputShape, filter.shape, strides, 1, pad, dimRoundingMode, false, $dataFormat);
      var dx = new tfjsCore.TensorBuffer(convInfo.inShape, "float32");
      var dxValues = dx.values;
      var dyValues = backend.data.get(dy.dataId).values;
      var fltValues = backend.data.get(filter.dataId).values;
      var _a2 = __read(filterStrides, 3), fltS0 = _a2[0], fltS1 = _a2[1], fltS2 = _a2[2];
      var batchSize = convInfo.batchSize, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, outChannels = convInfo.outChannels, outHeight = convInfo.outHeight, outWidth = convInfo.outWidth, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth;
      $dataFormat = convInfo.dataFormat;
      var topPad = filterHeight - 1 - convInfo.padInfo.top;
      var leftPad = filterWidth - 1 - convInfo.padInfo.left;
      var isChannelsLast = $dataFormat === "channelsLast";
      var xBatchStride = dx.strides[0];
      var xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];
      var xColStride = isChannelsLast ? dx.strides[2] : 1;
      var xChannelStride = isChannelsLast ? 1 : dx.strides[1];
      var yBatchStride = dyStrides[0];
      var yRowStride = isChannelsLast ? dyStrides[1] : dyStrides[2];
      var yColStride = isChannelsLast ? dyStrides[2] : 1;
      var yChannelStride = isChannelsLast ? 1 : dyStrides[1];
      for (var b = 0; b < batchSize; ++b) {
        for (var d1 = 0; d1 < inChannels; ++d1) {
          for (var xR = 0; xR < inHeight; ++xR) {
            var xRCorner = xR - topPad;
            var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
            var yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
            for (var xC = 0; xC < inWidth; ++xC) {
              var xCCorner = xC - leftPad;
              var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
              var yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
              var dotProd = 0;
              for (var yR = xRMin; yR < yRMax; ++yR) {
                var wR = yR * strideHeight - xRCorner;
                for (var yC = xCMin; yC < yCMax; ++yC) {
                  var wC = yC * strideWidth - xCCorner;
                  var dyOffset = yBatchStride * b + yRowStride * yR + yColStride * yC;
                  var fltOffset = fltS0 * (filterHeight - 1 - wR) + fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;
                  for (var d2 = 0; d2 < outChannels; ++d2) {
                    var pixel = dyValues[dyOffset + yChannelStride * d2];
                    var weight = fltValues[fltOffset + d2];
                    dotProd += pixel * weight;
                  }
                }
              }
              var dxOffset = xBatchStride * b + xRowStride * xR + xColStride * xC + xChannelStride * d1;
              dxValues[dxOffset] = dotProd;
            }
          }
        }
      }
      return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);
    }
    var conv2DBackpropInputConfig = {
      kernelName: tfjsCore.Conv2DBackpropInput,
      backendName: "cpu",
      kernelFunc: conv2DBackpropInput
    };
    function conv3D(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter;
      var strides = attrs.strides, pad = attrs.pad, dilations = attrs.dilations;
      assertNotComplex([x, filter], "conv3d");
      var convInfo = tfjsCore.backend_util.computeConv3DInfo(x.shape, filter.shape, strides, dilations, pad);
      var filterDepth = convInfo.filterDepth, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, dilationDepth = convInfo.dilationDepth, dilationHeight = convInfo.dilationHeight, dilationWidth = convInfo.dilationWidth, padInfo = convInfo.padInfo;
      var padFront = padInfo.front;
      var padLeft = padInfo.left;
      var padTop = padInfo.top;
      var y = new tfjsCore.TensorBuffer(convInfo.outShape, x.dtype);
      var xVals = backend.data.get(x.dataId).values;
      var wVals = backend.data.get(filter.dataId).values;
      var yVals = y.values;
      var xStrides = tfjsCore.util.computeStrides(x.shape);
      var filterStrides = tfjsCore.util.computeStrides(filter.shape);
      for (var b = 0; b < convInfo.batchSize; ++b) {
        var xOffset1 = b * xStrides[0];
        var yOffset1 = b * y.strides[0];
        for (var yF = 0; yF < convInfo.outDepth; ++yF) {
          var yOffset2 = yOffset1 + yF * y.strides[1];
          var xFCorner = yF * convInfo.strideDepth - padFront;
          for (var wF = 0; wF < filterDepth; ++wF) {
            var xF = xFCorner + wF * dilationDepth;
            if (xF < 0 || xF >= convInfo.inDepth) {
              continue;
            }
            var wOffset1 = wF * filterStrides[0];
            var xOffset2 = xOffset1 + xF * xStrides[1];
            for (var yR = 0; yR < convInfo.outHeight; ++yR) {
              var yOffset3 = yOffset2 + yR * y.strides[2];
              var xRCorner = yR * convInfo.strideHeight - padTop;
              for (var wR = 0; wR < filterHeight; ++wR) {
                var xR = xRCorner + wR * dilationHeight;
                if (xR < 0 || xR >= convInfo.inHeight) {
                  continue;
                }
                var wOffset2 = wOffset1 + wR * filterStrides[1];
                var xOffset3 = xOffset2 + xR * xStrides[2];
                for (var yC = 0; yC < convInfo.outWidth; ++yC) {
                  var yOffset4 = yOffset3 + yC * convInfo.outChannels;
                  var xCCorner = yC * convInfo.strideWidth - padLeft;
                  for (var wC = 0; wC < filterWidth; ++wC) {
                    var xC = xCCorner + wC * dilationWidth;
                    if (xC < 0 || xC >= convInfo.inWidth) {
                      continue;
                    }
                    var wOffset3 = wOffset2 + wC * filterStrides[2];
                    var xOffset4 = xOffset3 + xC * convInfo.inChannels;
                    var wOffset4 = wOffset3;
                    for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {
                      var xVal = xVals[xOffset4 + d1];
                      for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {
                        yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];
                      }
                      wOffset4 += convInfo.outChannels;
                    }
                  }
                }
              }
            }
          }
        }
      }
      return backend.makeTensorInfo(y.shape, y.dtype, y.values);
    }
    var conv3DConfig = {
      kernelName: tfjsCore.Conv3D,
      backendName: "cpu",
      kernelFunc: conv3D
    };
    function conv3DBackpropFilterV2(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, dy = inputs.dy;
      var strides = attrs.strides, pad = attrs.pad, filterShape = attrs.filterShape;
      assertNotComplex([x, dy], "conv3dBackpropFilterV2");
      var xStrides = tfjsCore.util.computeStrides(x.shape);
      var dyStrides = tfjsCore.util.computeStrides(dy.shape);
      var convInfo = tfjsCore.backend_util.computeConv3DInfo(x.shape, filterShape, strides, 1, pad);
      var strideDepth = convInfo.strideDepth;
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var filterDepth = convInfo.filterDepth;
      var filterHeight = convInfo.filterHeight;
      var filterWidth = convInfo.filterWidth;
      var dw = new tfjsCore.TensorBuffer(convInfo.filterShape, "float32");
      var dwValues = dw.values;
      var _a2 = __read(dw.strides, 4), dwS0 = _a2[0], dwS1 = _a2[1], dwS2 = _a2[2], dwS3 = _a2[3];
      var dyValues = backend.data.get(dy.dataId).values;
      var _b = __read(dyStrides, 4), dyS0 = _b[0], dyS1 = _b[1], dyS2 = _b[2], dyS3 = _b[3];
      var xValues = backend.data.get(x.dataId).values;
      var _c = __read(xStrides, 4), xS0 = _c[0], xS1 = _c[1], xS2 = _c[2], xS3 = _c[3];
      var frontPad = convInfo.padInfo.front;
      var leftPad = convInfo.padInfo.left;
      var topPad = convInfo.padInfo.top;
      for (var wF = 0; wF < filterDepth; ++wF) {
        var yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));
        var yFMax = Math.min(convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);
        var wOffset1 = wF * dwS0;
        for (var wR = 0; wR < filterHeight; ++wR) {
          var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
          var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
          var wOffset2 = wR * dwS1 + wOffset1;
          for (var wC = 0; wC < filterWidth; ++wC) {
            var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
            var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
            var wOffset3 = wC * dwS2 + wOffset2;
            for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {
              var wOffset4 = d1 * dwS3 + wOffset3;
              for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {
                var dotProd = 0;
                for (var b = 0; b < convInfo.batchSize; ++b) {
                  var xOffset1 = b * xS0;
                  var yOffset1 = b * dyS0;
                  for (var yF = yFMin; yF < yFMax; ++yF) {
                    var xF = wF + yF * strideDepth - frontPad;
                    var xOffset2 = xF * xS1 + xOffset1;
                    var yOffset2 = yF * dyS1 + yOffset1;
                    for (var yR = yRMin; yR < yRMax; ++yR) {
                      var xR = wR + yR * strideHeight - topPad;
                      var xOffset3 = xR * xS2 + xOffset2;
                      var yOffset3 = yR * dyS2 + yOffset2;
                      for (var yC = yCMin; yC < yCMax; ++yC) {
                        var xC = wC + yC * strideWidth - leftPad;
                        var xOffset4 = xC * xS3 + xOffset3;
                        var yOffset4 = yC * dyS3 + yOffset3;
                        dotProd += xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];
                      }
                    }
                  }
                }
                dwValues[wOffset4 + d2] = dotProd;
              }
            }
          }
        }
      }
      return backend.makeTensorInfo(dw.shape, dw.dtype, dw.values);
    }
    var conv3DBackpropFilterV2Config = {
      kernelName: tfjsCore.Conv3DBackpropFilterV2,
      backendName: "cpu",
      kernelFunc: conv3DBackpropFilterV2
    };
    function conv3DBackpropInputV2(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, filter = inputs.filter;
      var pad = attrs.pad, strides = attrs.strides, inputShape = attrs.inputShape;
      assertNotComplex([dy], "conv3dBackpropInputV2");
      var dyStrides = tfjsCore.util.computeStrides(dy.shape);
      var filterStrides = tfjsCore.util.computeStrides(filter.shape);
      var convInfo = tfjsCore.backend_util.computeConv3DInfo(inputShape, filter.shape, strides, 1, pad);
      var dx = new tfjsCore.TensorBuffer(convInfo.inShape, "float32");
      var dxValues = dx.values;
      var _a2 = __read(dx.strides, 4), dxS0 = _a2[0], dxS1 = _a2[1], dxS2 = _a2[2], dxS3 = _a2[3];
      var dyValues = backend.data.get(dy.dataId).values;
      var _b = __read(dyStrides, 4), dyS0 = _b[0], dyS1 = _b[1], dyS2 = _b[2], dyS3 = _b[3];
      var fltValues = backend.data.get(filter.dataId).values;
      var _c = __read(filterStrides, 4), fltS0 = _c[0], fltS1 = _c[1], fltS2 = _c[2], fltS3 = _c[3];
      var batchSize = convInfo.batchSize, filterDepth = convInfo.filterDepth, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, inDepth = convInfo.inDepth, inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, outChannels = convInfo.outChannels, outDepth = convInfo.outDepth, outHeight = convInfo.outHeight, outWidth = convInfo.outWidth, strideDepth = convInfo.strideDepth, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth;
      var frontPad = filterDepth - 1 - convInfo.padInfo.front;
      var topPad = filterHeight - 1 - convInfo.padInfo.top;
      var leftPad = filterWidth - 1 - convInfo.padInfo.left;
      for (var b = 0; b < batchSize; ++b) {
        for (var d1 = 0; d1 < inChannels; ++d1) {
          for (var xF = 0; xF < inDepth; ++xF) {
            var xFCorner = xF - frontPad;
            var xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));
            var yFMax = Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);
            for (var xR = 0; xR < inHeight; ++xR) {
              var xRCorner = xR - topPad;
              var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
              var yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
              for (var xC = 0; xC < inWidth; ++xC) {
                var xCCorner = xC - leftPad;
                var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
                var yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
                var dotProd = 0;
                for (var yF = xFMin; yF < yFMax; ++yF) {
                  var wF = yF * strideDepth - xFCorner;
                  for (var yR = xRMin; yR < yRMax; ++yR) {
                    var wR = yR * strideHeight - xRCorner;
                    for (var yC = xCMin; yC < yCMax; ++yC) {
                      var wC = yC * strideWidth - xCCorner;
                      var dyOffset = dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;
                      var fltOffset = fltS0 * (filterDepth - 1 - wF) + fltS1 * (filterHeight - 1 - wR) + fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;
                      for (var d2 = 0; d2 < outChannels; ++d2) {
                        var pixel = dyValues[dyOffset + d2];
                        var weight = fltValues[fltOffset + d2];
                        dotProd += pixel * weight;
                      }
                    }
                  }
                }
                dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] = dotProd;
              }
            }
          }
        }
      }
      return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);
    }
    var conv3DBackpropInputV2Config = {
      kernelName: tfjsCore.Conv3DBackpropInputV2,
      backendName: "cpu",
      kernelFunc: conv3DBackpropInputV2
    };
    var cos = unaryKernelFunc(tfjsCore.Cos, function(xi) {
      return Math.cos(xi);
    });
    var cosConfig = {
      kernelName: tfjsCore.Cos,
      backendName: "cpu",
      kernelFunc: cos
    };
    var cosh = unaryKernelFunc(tfjsCore.Cosh, function(xi) {
      return Math.cosh(xi);
    });
    var coshConfig = {
      kernelName: tfjsCore.Cosh,
      backendName: "cpu",
      kernelFunc: cosh
    };
    function cropAndResize(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var image = inputs.image, boxes = inputs.boxes, boxInd = inputs.boxInd;
      var cropSize = attrs.cropSize, method = attrs.method, extrapolationValue = attrs.extrapolationValue;
      var _a2 = __read(image.shape, 4), batch = _a2[0], imageHeight = _a2[1], imageWidth = _a2[2], numChannels = _a2[3];
      var numBoxes = boxes.shape[0];
      var _b = __read(cropSize, 2), cropHeight = _b[0], cropWidth = _b[1];
      var output = tfjsCore.buffer([numBoxes, cropHeight, cropWidth, numChannels], "float32");
      var boxVals = backend.data.get(boxes.dataId).values;
      var boxIndVals = backend.data.get(boxInd.dataId).values;
      var imageVals = backend.data.get(image.dataId).values;
      var inStride = tfjsCore.util.computeStrides(image.shape);
      var outStride = tfjsCore.util.computeStrides(output.shape);
      for (var b = 0; b < numBoxes; b++) {
        var startInd = b * 4;
        var y1 = boxVals[startInd];
        var x1 = boxVals[startInd + 1];
        var y2 = boxVals[startInd + 2];
        var x2 = boxVals[startInd + 3];
        var bInd = boxIndVals[b];
        if (bInd >= batch) {
          continue;
        }
        var heightScale = cropHeight > 1 ? (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) : 0;
        var widthScale = cropWidth > 1 ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;
        for (var y = 0; y < cropHeight; y++) {
          var yInd = cropHeight > 1 ? y1 * (imageHeight - 1) + y * heightScale : 0.5 * (y1 + y2) * (imageHeight - 1);
          if (yInd < 0 || yInd > imageHeight - 1) {
            for (var x = 0; x < cropWidth; x++) {
              for (var c = 0; c < numChannels; c++) {
                var ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
                output.values[ind] = extrapolationValue;
              }
            }
            continue;
          }
          if (method === "bilinear") {
            var topInd = Math.floor(yInd);
            var bottomInd = Math.ceil(yInd);
            var yLerp = yInd - topInd;
            for (var x = 0; x < cropWidth; x++) {
              var xInd = cropWidth > 1 ? x1 * (imageWidth - 1) + x * widthScale : 0.5 * (x1 + x2) * (imageWidth - 1);
              if (xInd < 0 || xInd > imageWidth - 1) {
                for (var c = 0; c < numChannels; c++) {
                  var ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
                  output.values[ind] = extrapolationValue;
                }
                continue;
              }
              var leftInd = Math.floor(xInd);
              var rightInd = Math.ceil(xInd);
              var xLerp = xInd - leftInd;
              for (var c = 0; c < numChannels; c++) {
                var ind = c + leftInd * inStride[2] + topInd * inStride[1] + bInd * inStride[0];
                var topLeft = imageVals[ind];
                ind = c + rightInd * inStride[2] + topInd * inStride[1] + bInd * inStride[0];
                var topRight = imageVals[ind];
                ind = c + leftInd * inStride[2] + bottomInd * inStride[1] + bInd * inStride[0];
                var bottomLeft = imageVals[ind];
                ind = c + rightInd * inStride[2] + bottomInd * inStride[1] + bInd * inStride[0];
                var bottomRight = imageVals[ind];
                var top = topLeft + (topRight - topLeft) * xLerp;
                var bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;
                ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
                output.values[ind] = top + (bottom - top) * yLerp;
              }
            }
          } else {
            for (var x = 0; x < cropWidth; ++x) {
              var xInd = cropWidth > 1 ? x1 * (imageWidth - 1) + x * widthScale : 0.5 * (x1 + x2) * (imageWidth - 1);
              if (xInd < 0 || xInd > imageWidth - 1) {
                for (var c = 0; c < numChannels; c++) {
                  var ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
                  output.values[ind] = extrapolationValue;
                }
                continue;
              }
              var closestX = Math.round(xInd);
              var closestY = Math.round(yInd);
              for (var c = 0; c < numChannels; c++) {
                var inInd = c + closestX * inStride[2] + closestY * inStride[1] + bInd * inStride[0];
                var outInd = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
                output.values[outInd] = imageVals[inInd];
              }
            }
          }
        }
      }
      return backend.makeTensorInfo(output.shape, output.dtype, output.values);
    }
    var cropAndResizeConfig = {
      kernelName: tfjsCore.CropAndResize,
      backendName: "cpu",
      kernelFunc: cropAndResize
    };
    function cumprod(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, exclusive = attrs.exclusive, reverse2 = attrs.reverse;
      assertNotComplex(x, "cumprod");
      var permutation = tfjsCore.backend_util.getAxesPermutation([axis], x.shape.length);
      var $x = x;
      if (permutation != null) {
        $x = transpose({ inputs: { x }, backend, attrs: { perm: permutation } });
      }
      var permutedAxis = tfjsCore.backend_util.getInnerMostAxes(1, x.shape.length)[0];
      if (permutedAxis !== $x.shape.length - 1) {
        throw new Error("backend.cumprod in CPU expects an inner-most " + "axis=".concat($x.shape.length - 1, " but got axis=").concat(permutedAxis));
      }
      var resultDtype = tfjsCore.upcastType($x.dtype, "int32");
      var vals = tfjsCore.util.makeOnesTypedArray(tfjsCore.util.sizeFromShape($x.shape), resultDtype);
      var aVals = backend.data.get($x.dataId).values;
      var finalDim = $x.shape[$x.shape.length - 1];
      var indexAdjuster = reverse2 ? function(i2, j2) {
        return i2 + finalDim - j2 - 1;
      } : function(i2, j2) {
        return i2 + j2;
      };
      for (var i = 0; i < aVals.length; i += finalDim) {
        for (var j = 0; j < finalDim; j++) {
          var idx = indexAdjuster(i, j);
          if (j === 0) {
            vals[idx] = exclusive ? 1 : aVals[idx];
          } else {
            var prevIdx = indexAdjuster(i, j - 1);
            vals[idx] = exclusive ? aVals[prevIdx] * vals[prevIdx] : aVals[idx] * vals[prevIdx];
          }
        }
      }
      var result = backend.makeTensorInfo($x.shape, resultDtype, vals);
      if (permutation != null) {
        var reversePermutation = tfjsCore.backend_util.getUndoAxesPermutation(permutation);
        var reverseTransposedResult = transpose({ inputs: { x: result }, backend, attrs: { perm: reversePermutation } });
        backend.disposeIntermediateTensorInfo(result);
        backend.disposeIntermediateTensorInfo($x);
        return reverseTransposedResult;
      }
      return result;
    }
    var cumprodConfig = {
      kernelName: tfjsCore.Cumprod,
      backendName: "cpu",
      kernelFunc: cumprod
    };
    function cumsum(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, exclusive = attrs.exclusive, reverse2 = attrs.reverse;
      assertNotComplex(x, "cumsum");
      var permutation = tfjsCore.backend_util.getAxesPermutation([axis], x.shape.length);
      var $x = x;
      if (permutation != null) {
        $x = transpose({ inputs: { x }, backend, attrs: { perm: permutation } });
      }
      var permutedAxis = tfjsCore.backend_util.getInnerMostAxes(1, x.shape.length)[0];
      if (permutedAxis !== $x.shape.length - 1) {
        throw new Error("backend.cumsum in CPU expects an inner-most " + "axis=".concat($x.shape.length - 1, " but got axis=").concat(permutedAxis));
      }
      var resultDtype = tfjsCore.upcastType($x.dtype, "int32");
      var vals = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape($x.shape), resultDtype);
      var aVals = backend.data.get($x.dataId).values;
      var finalDim = $x.shape[$x.shape.length - 1];
      var indexAdjuster = reverse2 ? function(i2, j2) {
        return i2 + finalDim - j2 - 1;
      } : function(i2, j2) {
        return i2 + j2;
      };
      for (var i = 0; i < aVals.length; i += finalDim) {
        for (var j = 0; j < finalDim; j++) {
          var idx = indexAdjuster(i, j);
          if (j === 0) {
            vals[idx] = exclusive ? 0 : aVals[idx];
          } else {
            var prevIdx = indexAdjuster(i, j - 1);
            vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] : aVals[idx] + vals[prevIdx];
          }
        }
      }
      var result = backend.makeTensorInfo($x.shape, resultDtype, vals);
      if (permutation != null) {
        var reversePermutation = tfjsCore.backend_util.getUndoAxesPermutation(permutation);
        var reverseTransposedResult = transpose({ inputs: { x: result }, backend, attrs: { perm: reversePermutation } });
        backend.disposeIntermediateTensorInfo(result);
        backend.disposeIntermediateTensorInfo($x);
        return reverseTransposedResult;
      }
      return result;
    }
    var cumsumConfig = {
      kernelName: tfjsCore.Cumsum,
      backendName: "cpu",
      kernelFunc: cumsum
    };
    function denseBincount(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, weights = inputs.weights;
      var size = attrs.size, binaryOutput = attrs.binaryOutput;
      if (x.shape.length === 1) {
        var xVals = backend.data.get(x.dataId).values;
        var weightsVals = backend.data.get(weights.dataId).values;
        var outVals = bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);
        return backend.makeTensorInfo([size], weights.dtype, outVals);
      } else if (x.shape.length === 2) {
        var xBuf = backend.bufferSync(x);
        var weightsBuf = backend.bufferSync(weights);
        var outBuf = bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput);
        return backend.makeTensorInfo(outBuf.shape, weights.dtype, outBuf.values);
      }
      throw new Error("Error in denseBincount: input must be at most rank 2, but got rank" + "".concat(x.shape.length, "."));
    }
    var denseBincountConfig = {
      kernelName: tfjsCore.DenseBincount,
      backendName: "cpu",
      kernelFunc: denseBincount
    };
    function depthToSpace(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var blockSize = attrs.blockSize, dataFormat = attrs.dataFormat;
      tfjsCore.util.assert(dataFormat === "NHWC", function() {
        return "Only NHWC dataFormat supported on CPU for depthToSpace. Got ".concat(dataFormat);
      });
      var batchSize = x.shape[0];
      var inputHeight = x.shape[1];
      var inputWidth = x.shape[2];
      var inputDepth = x.shape[3];
      var outputHeight = inputHeight * blockSize;
      var outputWidth = inputWidth * blockSize;
      var outputDepth = inputDepth / (blockSize * blockSize);
      var xValues = backend.data.get(x.dataId).values;
      var result = new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);
      var outputIdx = 0;
      for (var b = 0; b < batchSize; ++b) {
        for (var h = 0; h < outputHeight; ++h) {
          var inH = Math.floor(h / blockSize);
          var offsetH = h % blockSize;
          for (var w = 0; w < outputWidth; ++w) {
            var inW = Math.floor(w / blockSize);
            var offsetW = w % blockSize;
            var offsetD = (offsetH * blockSize + offsetW) * outputDepth;
            for (var d = 0; d < outputDepth; ++d) {
              var inD = d + offsetD;
              var inputIdx = inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));
              result[outputIdx++] = xValues[inputIdx];
            }
          }
        }
      }
      return backend.makeTensorInfo([batchSize, outputHeight, outputWidth, outputDepth], x.dtype, result);
    }
    var depthToSpaceConfig = {
      kernelName: tfjsCore.DepthToSpace,
      backendName: "cpu",
      kernelFunc: depthToSpace
    };
    function depthwiseConv2dNative(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter;
      var strides = attrs.strides, pad = attrs.pad, dilations = attrs.dilations, dimRoundingMode = attrs.dimRoundingMode;
      assertNotComplex([x, filter], "depthwiseConv2DNative");
      var xStrides = tfjsCore.util.computeStrides(x.shape);
      var filterStrides = tfjsCore.util.computeStrides(filter.shape);
      var $dilations = dilations;
      if ($dilations == null) {
        $dilations = [1, 1];
      }
      tfjsCore.util.assert(tfjsCore.backend_util.eitherStridesOrDilationsAreOne(strides, $dilations), function() {
        return "Error in depthwiseConv2d: Either strides or dilations must be " + "1. Got strides ".concat(strides, " and dilations '").concat($dilations, "'");
      });
      var convInfo = tfjsCore.backend_util.computeConv2DInfo(
        x.shape,
        filter.shape,
        strides,
        $dilations,
        pad,
        dimRoundingMode,
        true
        /* depthwise */
      );
      var filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, dilationHeight = convInfo.dilationHeight, dilationWidth = convInfo.dilationWidth, padInfo = convInfo.padInfo;
      var padLeft = padInfo.left;
      var padTop = padInfo.top;
      var chMul = convInfo.outChannels / convInfo.inChannels;
      var y = new tfjsCore.TensorBuffer(convInfo.outShape, x.dtype);
      var xVals = backend.data.get(x.dataId).values;
      var wVals = backend.data.get(filter.dataId).values;
      var yVals = y.values;
      for (var b = 0; b < convInfo.batchSize; ++b) {
        var xOffset1 = b * xStrides[0];
        var yOffset1 = b * y.strides[0];
        for (var yR = 0; yR < convInfo.outHeight; ++yR) {
          var yOffset2 = yOffset1 + yR * y.strides[1];
          var xRCorner = yR * convInfo.strideHeight - padTop;
          for (var wR = 0; wR < filterHeight; ++wR) {
            var xR = xRCorner + wR * dilationHeight;
            if (xR < 0 || xR >= convInfo.inHeight) {
              continue;
            }
            var wOffset1 = wR * filterStrides[0];
            var xOffset2 = xOffset1 + xR * xStrides[1];
            for (var yC = 0; yC < convInfo.outWidth; ++yC) {
              var yOffset3 = yOffset2 + yC * y.strides[2];
              var xCCorner = yC * convInfo.strideWidth - padLeft;
              for (var wC = 0; wC < filterWidth; ++wC) {
                var xC = xCCorner + wC * dilationWidth;
                if (xC < 0 || xC >= convInfo.inWidth) {
                  continue;
                }
                var wOffset2 = wOffset1 + wC * filterStrides[1];
                var xOffset3 = xOffset2 + xC * convInfo.inChannels;
                var yOffset4 = yOffset3;
                var wOffset3 = wOffset2;
                for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {
                  var xVal = xVals[xOffset3 + d1];
                  for (var q = 0; q < chMul; ++q) {
                    yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];
                  }
                  yOffset4 += chMul;
                  wOffset3 += chMul;
                }
              }
            }
          }
        }
      }
      return backend.makeTensorInfo(y.shape, y.dtype, y.values);
    }
    var depthwiseConv2dNativeConfig = {
      kernelName: tfjsCore.DepthwiseConv2dNative,
      backendName: "cpu",
      kernelFunc: depthwiseConv2dNative
    };
    function depthwiseConv2dNativeBackpropFilter(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, dy = inputs.dy;
      var strides = attrs.strides, dilations = attrs.dilations, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode, filterShape = attrs.filterShape;
      assertNotComplex([x, dy], "depthwiseConv2dNativeBackpropFilter");
      var convInfo = tfjsCore.backend_util.computeConv2DInfo(
        x.shape,
        filterShape,
        strides,
        dilations,
        pad,
        dimRoundingMode,
        true
        /* depthwise */
      );
      var strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth;
      var dW = new tfjsCore.TensorBuffer(convInfo.filterShape, "float32");
      var leftPad = convInfo.padInfo.left;
      var topPad = convInfo.padInfo.top;
      var chMul = convInfo.outChannels / convInfo.inChannels;
      var xVals = backend.data.get(x.dataId).values;
      var xBuf = new tfjsCore.TensorBuffer(x.shape, x.dtype, xVals);
      var dyVals = backend.data.get(dy.dataId).values;
      var dyBuf = new tfjsCore.TensorBuffer(dy.shape, dy.dtype, dyVals);
      for (var wR = 0; wR < filterHeight; ++wR) {
        var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
        var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
        for (var wC = 0; wC < filterWidth; ++wC) {
          var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
          var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
          for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {
            var d1 = Math.trunc(d2 / chMul);
            var dm = d2 % chMul;
            var dotProd = 0;
            for (var b = 0; b < convInfo.batchSize; ++b) {
              for (var yR = yRMin; yR < yRMax; ++yR) {
                var xR = wR + yR * strideHeight - topPad;
                for (var yC = yCMin; yC < yCMax; ++yC) {
                  var xC = wC + yC * strideWidth - leftPad;
                  dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);
                }
              }
            }
            dW.set(dotProd, wR, wC, d1, dm);
          }
        }
      }
      return backend.makeTensorInfo(dW.shape, dW.dtype, dW.values);
    }
    var depthwiseConv2dNativeBackpropFilterConfig = {
      kernelName: tfjsCore.DepthwiseConv2dNativeBackpropFilter,
      backendName: "cpu",
      kernelFunc: depthwiseConv2dNativeBackpropFilter
    };
    function depthwiseConv2dNativeBackpropInput(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, filter = inputs.filter;
      var strides = attrs.strides, dilations = attrs.dilations, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode, inputShape = attrs.inputShape;
      assertNotComplex([dy, filter], "depthwiseConv2DNativeBackpropInput");
      var dyStrides = tfjsCore.util.computeStrides(dy.shape);
      var filterStrides = tfjsCore.util.computeStrides(filter.shape);
      var convInfo = tfjsCore.backend_util.computeConv2DInfo(
        inputShape,
        filter.shape,
        strides,
        dilations,
        pad,
        dimRoundingMode,
        true
        /* depthwise */
      );
      var dx = new tfjsCore.TensorBuffer(convInfo.inShape, "float32");
      var dxValues = dx.values;
      var _a2 = __read(dx.strides, 3), dxS0 = _a2[0], dxS1 = _a2[1], dxS2 = _a2[2];
      var dyValues = backend.data.get(dy.dataId).values;
      var _b = __read(dyStrides, 3), dyS0 = _b[0], dyS1 = _b[1], dyS2 = _b[2];
      var fltValues = backend.data.get(filter.dataId).values;
      var _c = __read(filterStrides, 3), fltS0 = _c[0], fltS1 = _c[1], fltS2 = _c[2];
      var batchSize = convInfo.batchSize, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, outChannels = convInfo.outChannels, outHeight = convInfo.outHeight, outWidth = convInfo.outWidth, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth;
      var topPad = filterHeight - 1 - convInfo.padInfo.top;
      var leftPad = filterWidth - 1 - convInfo.padInfo.left;
      var chMul = outChannels / inChannels;
      for (var b = 0; b < batchSize; ++b) {
        for (var d1 = 0; d1 < inChannels; ++d1) {
          for (var xR = 0; xR < inHeight; ++xR) {
            var xRCorner = xR - topPad;
            var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
            var yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
            for (var xC = 0; xC < inWidth; ++xC) {
              var xCCorner = xC - leftPad;
              var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
              var yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
              var dotProd = 0;
              for (var yR = xRMin; yR < yRMax; ++yR) {
                var wR = yR * strideHeight - xRCorner;
                for (var yC = xCMin; yC < yCMax; ++yC) {
                  var wC = yC * strideWidth - xCCorner;
                  var dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;
                  var fltOffset = fltS0 * (filterHeight - 1 - wR) + fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;
                  for (var dm = 0; dm < chMul; ++dm) {
                    var d2 = d1 * chMul + dm;
                    var pixel = dyValues[dyOffset + d2];
                    var weight = fltValues[fltOffset + dm];
                    dotProd += pixel * weight;
                  }
                }
              }
              dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;
            }
          }
        }
      }
      return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);
    }
    var depthwiseConv2dNativeBackpropInputConfig = {
      kernelName: tfjsCore.DepthwiseConv2dNativeBackpropInput,
      backendName: "cpu",
      kernelFunc: depthwiseConv2dNativeBackpropInput
    };
    function diag(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x;
      var xSize = tfjsCore.util.sizeFromShape(x.shape);
      var xVals = backend.data.get(x.dataId).values;
      var outBuf = tfjsCore.buffer([xSize, xSize], x.dtype);
      var vals = outBuf.values;
      for (var i = 0; i < xVals.length; i++) {
        vals[i * xSize + i] = xVals[i];
      }
      var outShape = __spreadArray(__spreadArray([], __read(x.shape), false), __read(x.shape), false);
      return backend.makeTensorInfo(outShape, outBuf.dtype, outBuf.values);
    }
    var diagConfig = {
      kernelName: tfjsCore.Diag,
      backendName: "cpu",
      kernelFunc: diag
    };
    var dilation2DConfig = {
      kernelName: tfjsCore.Dilation2D,
      backendName: "cpu",
      kernelFunc: function(_a2) {
        var inputs = _a2.inputs, backend = _a2.backend, attrs = _a2.attrs;
        var x = inputs.x, filter = inputs.filter;
        var strides = attrs.strides, pad = attrs.pad, dilations = attrs.dilations;
        var cpuBackend = backend;
        var xVals = cpuBackend.data.get(x.dataId).values;
        var xRank = x.shape.length;
        var filterVals = cpuBackend.data.get(filter.dataId).values;
        var filterRank = filter.shape.length;
        var _b = tfjsCore.backend_util.computeDilation2DInfo(x.shape, filter.shape, strides, pad, "NHWC", dilations), batchSize = _b.batchSize, inHeight = _b.inHeight, inWidth = _b.inWidth, inChannels = _b.inChannels, outHeight = _b.outHeight, outWidth = _b.outWidth, padInfo = _b.padInfo, strideHeight = _b.strideHeight, strideWidth = _b.strideWidth, filterHeight = _b.filterHeight, filterWidth = _b.filterWidth, dilationHeight = _b.dilationHeight, dilationWidth = _b.dilationWidth, outShape = _b.outShape;
        var outSize = tfjsCore.util.sizeFromShape(outShape);
        var outRank = outShape.length;
        var outputVals = tfjsCore.util.getArrayFromDType(x.dtype, outSize);
        for (var b = 0; b < batchSize; ++b) {
          for (var hOut = 0; hOut < outHeight; ++hOut) {
            var hBeg = hOut * strideHeight - padInfo.top;
            for (var wOut = 0; wOut < outWidth; ++wOut) {
              var wBeg = wOut * strideWidth - padInfo.left;
              for (var d = 0; d < inChannels; ++d) {
                var curVal = Number.MIN_SAFE_INTEGER;
                for (var h = 0; h < filterHeight; ++h) {
                  var hIn = hBeg + h * dilationHeight;
                  if (hIn >= 0 && hIn < inHeight) {
                    for (var w = 0; w < filterWidth; ++w) {
                      var wIn = wBeg + w * dilationWidth;
                      if (wIn >= 0 && wIn < inWidth) {
                        var xIndex = tfjsCore.util.locToIndex([b, hIn, wIn, d], xRank, tfjsCore.util.computeStrides(x.shape));
                        var filterIndex = tfjsCore.util.locToIndex([h, w, d], filterRank, tfjsCore.util.computeStrides(filter.shape));
                        var val = xVals[xIndex] + filterVals[filterIndex];
                        if (val > curVal) {
                          curVal = val;
                        }
                      }
                    }
                  }
                }
                var outputIndex = tfjsCore.util.locToIndex([b, hOut, wOut, d], outRank, tfjsCore.util.computeStrides(outShape));
                outputVals[outputIndex] = curVal;
              }
            }
          }
        }
        var dataId = cpuBackend.write(tfjsCore.util.toTypedArray(outputVals, x.dtype), outShape, x.dtype);
        return { dataId, shape: outShape, dtype: x.dtype };
      }
    };
    var dilation2DBackpropFilterConfig = {
      kernelName: tfjsCore.Dilation2DBackpropFilter,
      backendName: "cpu",
      kernelFunc: function(_a2) {
        var inputs = _a2.inputs, backend = _a2.backend, attrs = _a2.attrs;
        var x = inputs.x, filter = inputs.filter, dy = inputs.dy;
        var strides = attrs.strides, pad = attrs.pad, dilations = attrs.dilations;
        var cpuBackend = backend;
        var $x = tfjsCore.util.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);
        var $filter = tfjsCore.util.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);
        var _b = tfjsCore.backend_util.computeDilation2DInfo(x.shape, filter.shape, strides, pad, "NHWC", dilations), batchSize = _b.batchSize, inHeight = _b.inHeight, inWidth = _b.inWidth, inChannels = _b.inChannels, outHeight = _b.outHeight, outWidth = _b.outWidth, padInfo = _b.padInfo, strideHeight = _b.strideHeight, strideWidth = _b.strideWidth, filterHeight = _b.filterHeight, filterWidth = _b.filterWidth, dilationHeight = _b.dilationHeight, dilationWidth = _b.dilationWidth, outShape = _b.outShape;
        tfjsCore.util.assert(dy.rank === outShape.length, function() {
          return "Error in ".concat(tfjsCore.Dilation2DBackpropFilter, ", dy ") + "must have the same rank as output ".concat(outShape.length, ", but got ") + "".concat(dy.rank);
        });
        var $dy = tfjsCore.util.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values);
        var gradients = tfjsCore.util.makeZerosNestedTypedArray(filter.shape, filter.dtype);
        for (var b = 0; b < batchSize; ++b) {
          for (var hOut = 0; hOut < outHeight; ++hOut) {
            var hBeg = hOut * strideHeight - padInfo.top;
            for (var wOut = 0; wOut < outWidth; ++wOut) {
              var wBeg = wOut * strideWidth - padInfo.left;
              for (var d = 0; d < inChannels; ++d) {
                var curVal = Number.MIN_SAFE_INTEGER;
                var hMax = 0;
                var wMax = 0;
                for (var h = 0; h < filterHeight; ++h) {
                  var hIn = hBeg + h * dilationHeight;
                  if (hIn >= 0 && hIn < inHeight) {
                    for (var w = 0; w < filterWidth; ++w) {
                      var wIn = wBeg + w * dilationWidth;
                      if (wIn >= 0 && wIn < inWidth) {
                        var val = $x[b][hIn][wIn][d] + $filter[h][w][d];
                        if (val > curVal) {
                          curVal = val;
                          hMax = h;
                          wMax = w;
                        }
                      }
                    }
                  }
                }
                gradients[hMax][wMax][d] += $dy[b][hOut][wOut][d];
              }
            }
          }
        }
        var dataId = cpuBackend.write(tfjsCore.util.toTypedArray(gradients, x.dtype), filter.shape, filter.dtype);
        return { dataId, shape: filter.shape, dtype: filter.dtype };
      }
    };
    var dilation2DBackpropInputConfig = {
      kernelName: tfjsCore.Dilation2DBackpropInput,
      backendName: "cpu",
      kernelFunc: function(_a2) {
        var inputs = _a2.inputs, backend = _a2.backend, attrs = _a2.attrs;
        var x = inputs.x, filter = inputs.filter, dy = inputs.dy;
        var strides = attrs.strides, pad = attrs.pad, dilations = attrs.dilations;
        var cpuBackend = backend;
        var $x = tfjsCore.util.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);
        var $filter = tfjsCore.util.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);
        var _b = tfjsCore.backend_util.computeDilation2DInfo(x.shape, filter.shape, strides, pad, "NHWC", dilations), batchSize = _b.batchSize, inHeight = _b.inHeight, inWidth = _b.inWidth, inChannels = _b.inChannels, outHeight = _b.outHeight, outWidth = _b.outWidth, padInfo = _b.padInfo, strideHeight = _b.strideHeight, strideWidth = _b.strideWidth, filterHeight = _b.filterHeight, filterWidth = _b.filterWidth, dilationHeight = _b.dilationHeight, dilationWidth = _b.dilationWidth, outShape = _b.outShape;
        tfjsCore.util.assert(dy.rank === outShape.length, function() {
          return "Error in ".concat(tfjsCore.Dilation2DBackpropInput, ", dy ") + "must have the same rank as output ".concat(outShape.length, ", but got ") + "".concat(dy.rank);
        });
        var $dy = tfjsCore.util.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values);
        var gradients = tfjsCore.util.makeZerosNestedTypedArray(x.shape, x.dtype);
        for (var b = 0; b < batchSize; ++b) {
          for (var hOut = 0; hOut < outHeight; ++hOut) {
            var hBeg = hOut * strideHeight - padInfo.top;
            for (var wOut = 0; wOut < outWidth; ++wOut) {
              var wBeg = wOut * strideWidth - padInfo.left;
              for (var d = 0; d < inChannels; ++d) {
                var curVal = Number.MIN_SAFE_INTEGER;
                var hInMax = hBeg < 0 ? 0 : hBeg;
                var wInMax = wBeg < 0 ? 0 : wBeg;
                for (var h = 0; h < filterHeight; ++h) {
                  var hIn = hBeg + h * dilationHeight;
                  if (hIn >= 0 && hIn < inHeight) {
                    for (var w = 0; w < filterWidth; ++w) {
                      var wIn = wBeg + w * dilationWidth;
                      if (wIn >= 0 && wIn < inWidth) {
                        var val = $x[b][hIn][wIn][d] + $filter[h][w][d];
                        if (val > curVal) {
                          curVal = val;
                          hInMax = hIn;
                          wInMax = wIn;
                        }
                      }
                    }
                  }
                }
                gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];
              }
            }
          }
        }
        var dataId = cpuBackend.write(tfjsCore.util.toTypedArray(gradients, x.dtype), x.shape, x.dtype);
        return { dataId, shape: x.shape, dtype: x.dtype };
      }
    };
    function draw(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var image = inputs.image;
      var canvas = attrs.canvas, options = attrs.options;
      var _a2 = options || {}, contextOptions = _a2.contextOptions, imageOptions = _a2.imageOptions;
      var alpha = (imageOptions === null || imageOptions === void 0 ? void 0 : imageOptions.alpha) || 1;
      var contextType = (contextOptions === null || contextOptions === void 0 ? void 0 : contextOptions.contextType) || "2d";
      if (contextType !== "2d") {
        throw new Error("Context type ".concat(contextOptions.contextType, " is not supported by the CPU backend."));
      }
      var ctx = canvas.getContext(contextType, (contextOptions === null || contextOptions === void 0 ? void 0 : contextOptions.contextAttributes) || {});
      if (ctx == null) {
        throw new Error("Could not get the context with ".concat(contextType, " type."));
      }
      var _b = __read(image.shape.slice(0, 2), 2), height = _b[0], width = _b[1];
      var depth = image.shape.length === 2 ? 1 : image.shape[2];
      var data = backend.data.get(image.dataId).values;
      var multiplier = image.dtype === "float32" ? 255 : 1;
      var bytes = new Uint8ClampedArray(width * height * 4);
      for (var i = 0; i < height * width; ++i) {
        var rgba = [0, 0, 0, 255 * alpha];
        for (var d = 0; d < depth; d++) {
          var value = data[i * depth + d];
          if (image.dtype === "float32") {
            if (value < 0 || value > 1) {
              throw new Error("Tensor values for a float32 Tensor must be in the " + "range [0 - 1] but encountered ".concat(value, "."));
            }
          } else if (image.dtype === "int32") {
            if (value < 0 || value > 255) {
              throw new Error("Tensor values for a int32 Tensor must be in the " + "range [0 - 255] but encountered ".concat(value, "."));
            }
          }
          if (depth === 1) {
            rgba[0] = value * multiplier;
            rgba[1] = value * multiplier;
            rgba[2] = value * multiplier;
          } else {
            rgba[d] = value * multiplier;
          }
        }
        var j = i * 4;
        bytes[j + 0] = Math.round(rgba[0]);
        bytes[j + 1] = Math.round(rgba[1]);
        bytes[j + 2] = Math.round(rgba[2]);
        bytes[j + 3] = Math.round(rgba[3]);
      }
      canvas.width = width;
      canvas.height = height;
      var imageData = new ImageData(bytes, width, height);
      ctx.putImageData(imageData, 0, 0);
      return image;
    }
    var drawConfig = {
      kernelName: tfjsCore.Draw,
      backendName: "cpu",
      kernelFunc: draw
    };
    function sum(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      assertNotComplex(x, "sum");
      var $x;
      if (x.dtype === "bool") {
        $x = cast({ inputs: { x }, backend, attrs: { dtype: "int32" } });
      } else {
        $x = identity({ inputs: { x }, backend });
      }
      var xRank = $x.shape.length;
      var axes = tfjsCore.util.parseAxisParam(axis, $x.shape);
      var permutation = tfjsCore.backend_util.getAxesPermutation(axes, xRank);
      var reductionAxes = axes;
      var permutedX = $x;
      if (permutation != null) {
        permutedX = transpose({ inputs: { x: $x }, backend, attrs: { perm: permutation } });
        reductionAxes = tfjsCore.backend_util.getInnerMostAxes(reductionAxes.length, xRank);
      }
      tfjsCore.backend_util.assertAxesAreInnerMostDims("sum", reductionAxes, permutedX.shape.length);
      var _a2 = __read(tfjsCore.backend_util.computeOutAndReduceShapes(permutedX.shape, reductionAxes), 2), outShape = _a2[0], reduceShape = _a2[1];
      var resultDtype = tfjsCore.backend_util.upcastType(permutedX.dtype, "int32");
      var result = zeros(backend, outShape, resultDtype);
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var vals = backend.data.get(result.dataId).values;
      var aVals = backend.data.get(permutedX.dataId).values;
      for (var i = 0; i < vals.length; ++i) {
        var offset = i * reduceSize;
        var sum_1 = 0;
        for (var j = 0; j < reduceSize; ++j) {
          sum_1 += aVals[offset + j];
        }
        vals[i] = sum_1;
      }
      if (keepDims) {
        var newShape = tfjsCore.backend_util.expandShapeToKeepDim(result.shape, axes);
        var oldResult = result;
        result = reshape({ inputs: { x: result }, backend, attrs: { shape: newShape } });
        backend.disposeIntermediateTensorInfo(oldResult);
      }
      backend.disposeIntermediateTensorInfo($x);
      if (permutation != null) {
        backend.disposeIntermediateTensorInfo(permutedX);
      }
      return result;
    }
    var sumConfig = {
      kernelName: tfjsCore.Sum,
      backendName: "cpu",
      kernelFunc: sum
    };
    function einsum(args) {
      var e_12, _a2, e_2, _b;
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var equation = attrs.equation;
      var tensors = inputs;
      var _c = tfjsCore.backend_util.decodeEinsumEquation(equation, tensors.length), allDims = _c.allDims, summedDims = _c.summedDims, idDims = _c.idDims;
      tfjsCore.backend_util.checkEinsumDimSizes(allDims.length, idDims, tensors);
      var _d = tfjsCore.backend_util.getEinsumComputePath(summedDims, idDims), path = _d.path, steps = _d.steps;
      var nSteps = steps.length;
      var out = null;
      var numDimsRemaining = allDims.length;
      var tensorsToDispose = [];
      for (var i = 0; i < nSteps; ++i) {
        try {
          for (var _e = (e_12 = void 0, __values(steps[i])), _f = _e.next(); !_f.done; _f = _e.next()) {
            var idTerm = _f.value;
            var _g = tfjsCore.backend_util.getEinsumPermutation(numDimsRemaining, idDims[idTerm]), perm = _g.permutationIndices, dimsToExpand = _g.expandDims;
            var x = void 0;
            if (tfjsCore.backend_util.isIdentityPermutation(perm)) {
              x = tensors[idTerm];
            } else {
              x = transpose({ inputs: { x: tensors[idTerm] }, backend, attrs: { perm } });
              tensorsToDispose.push(x);
            }
            var targetShape = x.shape.slice();
            for (var k = 0; k < dimsToExpand.length; ++k) {
              targetShape.splice(dimsToExpand[k], 0, 1);
            }
            if (!tfjsCore.util.arraysEqual(x.shape, targetShape)) {
              x = reshape({ inputs: { x }, backend, attrs: { shape: targetShape } });
              tensorsToDispose.push(x);
            }
            if (out === null) {
              out = x;
            } else {
              out = multiply({ inputs: { a: x, b: out }, backend });
              tensorsToDispose.push(out);
            }
          }
        } catch (e_1_1) {
          e_12 = { error: e_1_1 };
        } finally {
          try {
            if (_f && !_f.done && (_a2 = _e.return))
              _a2.call(_e);
          } finally {
            if (e_12)
              throw e_12.error;
          }
        }
        if (i < nSteps - 1) {
          if (path[i] >= 0) {
            out = sum({
              inputs: { x: out },
              backend,
              attrs: {
                axis: path[i] - (allDims.length - numDimsRemaining),
                keepDims: false
              }
            });
            tensorsToDispose.push(out);
          }
          numDimsRemaining--;
        }
      }
      try {
        for (var tensorsToDispose_1 = __values(tensorsToDispose), tensorsToDispose_1_1 = tensorsToDispose_1.next(); !tensorsToDispose_1_1.done; tensorsToDispose_1_1 = tensorsToDispose_1.next()) {
          var tensorInfo = tensorsToDispose_1_1.value;
          if (tensorInfo === out) {
            continue;
          }
          backend.disposeIntermediateTensorInfo(tensorInfo);
        }
      } catch (e_2_1) {
        e_2 = { error: e_2_1 };
      } finally {
        try {
          if (tensorsToDispose_1_1 && !tensorsToDispose_1_1.done && (_b = tensorsToDispose_1.return))
            _b.call(tensorsToDispose_1);
        } finally {
          if (e_2)
            throw e_2.error;
        }
      }
      return out;
    }
    var einsumConfig = {
      kernelName: tfjsCore.Einsum,
      backendName: "cpu",
      kernelFunc: einsum
    };
    function eluGrad(args) {
      var inputs = args.inputs, backend = args.backend;
      var dy = inputs.dy, y = inputs.y;
      assertNotComplex([dy, y], "eluGrad");
      var resultValues = new Float32Array(tfjsCore.util.sizeFromShape(y.shape));
      var values = backend.data.get(y.dataId).values;
      var dyValues = backend.data.get(dy.dataId).values;
      for (var i = 0; i < values.length; ++i) {
        var v = values[i];
        if (v >= 0) {
          resultValues[i] = dyValues[i];
        } else {
          resultValues[i] = dyValues[i] * (v + 1);
        }
      }
      return backend.makeTensorInfo(y.shape, "float32", resultValues);
    }
    var eluGradConfig = {
      kernelName: tfjsCore.EluGrad,
      backendName: "cpu",
      kernelFunc: eluGrad
    };
    var p = tfjsCore.backend_util.ERF_P;
    var a1 = tfjsCore.backend_util.ERF_A1;
    var a2 = tfjsCore.backend_util.ERF_A2;
    var a3 = tfjsCore.backend_util.ERF_A3;
    var a4 = tfjsCore.backend_util.ERF_A4;
    var a5 = tfjsCore.backend_util.ERF_A5;
    var erf = unaryKernelFunc(tfjsCore.Erf, function(xi) {
      var sign2 = Math.sign(xi);
      var v = Math.abs(xi);
      var t = 1 / (1 + p * v);
      return sign2 * (1 - ((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t * Math.exp(-v * v));
    });
    var erfConfig = {
      kernelName: tfjsCore.Erf,
      backendName: "cpu",
      kernelFunc: erf
    };
    function expandDims(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var input = inputs.input;
      var dim = attrs.dim;
      var inputRank = input.shape.length;
      var newShape = input.shape.slice();
      var $dim = dim;
      if (dim < 0) {
        tfjsCore.util.assert(-(inputRank + 1) <= dim, function() {
          return "Axis must be in the interval [".concat(-(inputRank + 1), ", ").concat(inputRank, "]");
        });
        $dim = inputRank + dim + 1;
      }
      newShape.splice($dim, 0, 1);
      return reshape({ inputs: { x: input }, backend, attrs: { shape: newShape } });
    }
    var expandDimsConfig = {
      kernelName: tfjsCore.ExpandDims,
      backendName: "cpu",
      kernelFunc: expandDims
    };
    var realDivImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a / b;
    });
    var div = binaryKernelFunc(tfjsCore.RealDiv, realDivImpl);
    var realDivConfig = {
      kernelName: tfjsCore.RealDiv,
      backendName: "cpu",
      kernelFunc: div
    };
    function fftBatch(input, inverse, cpuBackend) {
      var inputShape = input.shape;
      var batch = inputShape[0];
      var innerDim = inputShape[1];
      var inputVals = cpuBackend.data.get(input.dataId);
      var real2D = inputVals.complexTensorInfos.real;
      var imag2D = inputVals.complexTensorInfos.imag;
      var resultShape = [batch, innerDim];
      var resultSize = tfjsCore.util.sizeFromShape(resultShape);
      var resultReal = tfjsCore.util.getTypedArrayFromDType("float32", resultSize);
      var resultImag = tfjsCore.util.getTypedArrayFromDType("float32", resultSize);
      for (var b = 0; b < batch; b++) {
        var r = slice({
          inputs: { x: real2D },
          backend: cpuBackend,
          attrs: { begin: [b, 0], size: [1, innerDim] }
        });
        var i = slice({
          inputs: { x: imag2D },
          backend: cpuBackend,
          attrs: { begin: [b, 0], size: [1, innerDim] }
        });
        var input_1 = complex({ inputs: { real: r, imag: i }, backend: cpuBackend });
        var _a2 = fftImpl(input_1, inverse, cpuBackend), real_1 = _a2.real, imag_1 = _a2.imag;
        var res = tfjsCore.backend_util.mergeRealAndImagArrays(real_1, imag_1);
        for (var d = 0; d < innerDim; d++) {
          var c = tfjsCore.backend_util.getComplexWithIndex(res, d);
          resultReal[b * innerDim + d] = c.real;
          resultImag[b * innerDim + d] = c.imag;
        }
        cpuBackend.disposeIntermediateTensorInfo(r);
        cpuBackend.disposeIntermediateTensorInfo(i);
        cpuBackend.disposeIntermediateTensorInfo(input_1);
      }
      var $realInfo = cpuBackend.makeTensorInfo(resultShape, "float32", resultReal);
      var $imagInfo = cpuBackend.makeTensorInfo(resultShape, "float32", resultImag);
      var result = complex({ inputs: { real: $realInfo, imag: $imagInfo }, backend: cpuBackend });
      cpuBackend.disposeIntermediateTensorInfo($realInfo);
      cpuBackend.disposeIntermediateTensorInfo($imagInfo);
      return result;
    }
    function fftImpl(input, inverse, cpuBackend) {
      var inputSize = tfjsCore.util.sizeFromShape(input.shape);
      var inputVals = cpuBackend.data.get(input.dataId);
      var realVals = cpuBackend.data.get(inputVals.complexTensorInfos.real.dataId).values;
      var imagVals = cpuBackend.data.get(inputVals.complexTensorInfos.imag.dataId).values;
      if (isExponentOf2(inputSize)) {
        var result = fftRadix2(realVals, imagVals, inputSize, inverse, cpuBackend);
        var resultShape = [input.shape[0], input.shape[1]];
        if (inverse) {
          var realInfo = cpuBackend.makeTensorInfo(resultShape, "float32", result.real);
          var imagInfo = cpuBackend.makeTensorInfo(resultShape, "float32", result.imag);
          var sizeInfo = cpuBackend.makeTensorInfo([], "float32", tfjsCore.util.createScalarValue(inputSize, "float32"));
          var sizeInfoCopy = identity({ inputs: { x: sizeInfo }, backend: cpuBackend });
          var divRealInfo = realDivConfig.kernelFunc({ inputs: { a: realInfo, b: sizeInfo }, backend: cpuBackend });
          var divImagInfo = realDivConfig.kernelFunc({ inputs: { a: imagInfo, b: sizeInfoCopy }, backend: cpuBackend });
          var divRealVals = cpuBackend.data.get(divRealInfo.dataId).values;
          var divImagVals = cpuBackend.data.get(divImagInfo.dataId).values;
          cpuBackend.disposeIntermediateTensorInfo(realInfo);
          cpuBackend.disposeIntermediateTensorInfo(imagInfo);
          cpuBackend.disposeIntermediateTensorInfo(sizeInfo);
          cpuBackend.disposeIntermediateTensorInfo(sizeInfoCopy);
          cpuBackend.disposeIntermediateTensorInfo(divRealInfo);
          cpuBackend.disposeIntermediateTensorInfo(divImagInfo);
          return { real: divRealVals, imag: divImagVals };
        }
        return result;
      } else {
        var data = tfjsCore.backend_util.mergeRealAndImagArrays(realVals, imagVals);
        var rawOutput = fourierTransformByMatmul(data, inputSize, inverse);
        return tfjsCore.backend_util.splitRealAndImagArrays(rawOutput);
      }
    }
    function isExponentOf2(size) {
      return (size & size - 1) === 0;
    }
    function fftRadix2(realVals, imagVals, size, inverse, cpuBackend) {
      if (size === 1) {
        return { real: realVals, imag: imagVals };
      }
      var data = tfjsCore.backend_util.mergeRealAndImagArrays(realVals, imagVals);
      var half = size / 2;
      var evenComplex = tfjsCore.backend_util.complexWithEvenIndex(data);
      var evenRealVals = evenComplex.real;
      var evenImagVals = evenComplex.imag;
      var evenShape = [evenRealVals.length];
      var evenRealInfo = cpuBackend.makeTensorInfo(evenShape, "float32", evenRealVals);
      var evenImagInfo = cpuBackend.makeTensorInfo(evenShape, "float32", evenImagVals);
      var evenTensorInfo = complex({ inputs: { real: evenRealInfo, imag: evenImagInfo }, backend: cpuBackend });
      var oddComplex = tfjsCore.backend_util.complexWithOddIndex(data);
      var oddRealVals = oddComplex.real;
      var oddImagVals = oddComplex.imag;
      var oddShape = [oddRealVals.length];
      var oddRealInfo = cpuBackend.makeTensorInfo(oddShape, "float32", oddRealVals);
      var oddImagInfo = cpuBackend.makeTensorInfo(oddShape, "float32", oddImagVals);
      var oddTensorInfo = complex({ inputs: { real: oddRealInfo, imag: oddImagInfo }, backend: cpuBackend });
      var $evenComplex = fftRadix2(evenRealVals, evenImagVals, half, inverse, cpuBackend);
      var $evenRealVals = $evenComplex.real;
      var $evenImagVals = $evenComplex.imag;
      var $evenShape = [$evenRealVals.length];
      var $evenRealInfo = cpuBackend.makeTensorInfo($evenShape, "float32", $evenRealVals);
      var $evenImagInfo = cpuBackend.makeTensorInfo($evenShape, "float32", $evenImagVals);
      var $evenTensorInfo = complex({
        inputs: { real: $evenRealInfo, imag: $evenImagInfo },
        backend: cpuBackend
      });
      var $oddComplex = fftRadix2(oddRealVals, oddImagVals, half, inverse, cpuBackend);
      var $oddRealVals = $oddComplex.real;
      var $oddImagVals = $oddComplex.imag;
      var $oddShape = [$oddRealVals.length];
      var $oddRealInfo = cpuBackend.makeTensorInfo($oddShape, "float32", $oddRealVals);
      var $oddImagInfo = cpuBackend.makeTensorInfo($oddShape, "float32", $oddImagVals);
      var $oddTensorInfo = complex({ inputs: { real: $oddRealInfo, imag: $oddImagInfo }, backend: cpuBackend });
      var e = tfjsCore.backend_util.exponents(size, inverse);
      var eShape = [e.real.length];
      var eRealInfo = cpuBackend.makeTensorInfo(eShape, "float32", e.real);
      var eImagInfo = cpuBackend.makeTensorInfo(eShape, "float32", e.imag);
      var complexInfo = complex({ inputs: { real: eRealInfo, imag: eImagInfo }, backend: cpuBackend });
      var exponentInfo = multiply({ inputs: { a: complexInfo, b: $oddTensorInfo }, backend: cpuBackend });
      var addPart = add({
        inputs: { a: $evenTensorInfo, b: exponentInfo },
        backend: cpuBackend
      });
      var subPart = sub({
        inputs: { a: $evenTensorInfo, b: exponentInfo },
        backend: cpuBackend
      });
      var addPartReal = real({ inputs: { input: addPart }, backend: cpuBackend });
      var subPartReal = real({ inputs: { input: subPart }, backend: cpuBackend });
      var addPartImag = imag({ inputs: { input: addPart }, backend: cpuBackend });
      var subPartImag = imag({ inputs: { input: subPart }, backend: cpuBackend });
      var $real = concat({
        inputs: [addPartReal, subPartReal],
        backend: cpuBackend,
        attrs: { axis: 0 }
      });
      var $imag = concat({
        inputs: [addPartImag, subPartImag],
        backend: cpuBackend,
        attrs: { axis: 0 }
      });
      var $realVals = cpuBackend.data.get($real.dataId).values;
      var $imagVals = cpuBackend.data.get($imag.dataId).values;
      cpuBackend.disposeIntermediateTensorInfo(evenRealInfo);
      cpuBackend.disposeIntermediateTensorInfo(evenImagInfo);
      cpuBackend.disposeIntermediateTensorInfo(evenTensorInfo);
      cpuBackend.disposeIntermediateTensorInfo(oddRealInfo);
      cpuBackend.disposeIntermediateTensorInfo(oddImagInfo);
      cpuBackend.disposeIntermediateTensorInfo(oddTensorInfo);
      cpuBackend.disposeIntermediateTensorInfo($evenRealInfo);
      cpuBackend.disposeIntermediateTensorInfo($evenImagInfo);
      cpuBackend.disposeIntermediateTensorInfo($evenTensorInfo);
      cpuBackend.disposeIntermediateTensorInfo($oddRealInfo);
      cpuBackend.disposeIntermediateTensorInfo($oddImagInfo);
      cpuBackend.disposeIntermediateTensorInfo($oddTensorInfo);
      cpuBackend.disposeIntermediateTensorInfo(eRealInfo);
      cpuBackend.disposeIntermediateTensorInfo(eImagInfo);
      cpuBackend.disposeIntermediateTensorInfo(complexInfo);
      cpuBackend.disposeIntermediateTensorInfo(exponentInfo);
      cpuBackend.disposeIntermediateTensorInfo(addPart);
      cpuBackend.disposeIntermediateTensorInfo(subPart);
      cpuBackend.disposeIntermediateTensorInfo(addPartReal);
      cpuBackend.disposeIntermediateTensorInfo(addPartImag);
      cpuBackend.disposeIntermediateTensorInfo(subPartReal);
      cpuBackend.disposeIntermediateTensorInfo(subPartImag);
      cpuBackend.disposeIntermediateTensorInfo($real);
      cpuBackend.disposeIntermediateTensorInfo($imag);
      return { real: $realVals, imag: $imagVals };
    }
    function fourierTransformByMatmul(data, size, inverse) {
      var ret = new Float32Array(size * 2);
      for (var r = 0; r < size; r++) {
        var real_2 = 0;
        var imag_2 = 0;
        for (var c = 0; c < size; c++) {
          var e = tfjsCore.backend_util.exponent(r * c, size, inverse);
          var term = tfjsCore.backend_util.getComplexWithIndex(data, c);
          real_2 += term.real * e.real - term.imag * e.imag;
          imag_2 += term.real * e.imag + term.imag * e.real;
        }
        if (inverse) {
          real_2 /= size;
          imag_2 /= size;
        }
        tfjsCore.backend_util.assignToTypedArray(ret, real_2, imag_2, r);
      }
      return ret;
    }
    function fft(args) {
      var inputs = args.inputs, backend = args.backend;
      var input = inputs.input;
      var inputSize = tfjsCore.util.sizeFromShape(input.shape);
      var innerDimensionSize = input.shape[input.shape.length - 1];
      var batch = inputSize / innerDimensionSize;
      var input2D = reshape({
        inputs: { x: input },
        backend,
        attrs: { shape: [batch, innerDimensionSize] }
      });
      var result = fftBatch(input2D, false, backend);
      var resultReshaped = reshape({ inputs: { x: result }, backend, attrs: { shape: input.shape } });
      backend.disposeIntermediateTensorInfo(input2D);
      backend.disposeIntermediateTensorInfo(result);
      return resultReshaped;
    }
    var fftConfig = {
      kernelName: tfjsCore.FFT,
      backendName: "cpu",
      kernelFunc: fft
    };
    function fill(args) {
      var backend = args.backend, attrs = args.attrs;
      var shape = attrs.shape, value = attrs.value, dtype = attrs.dtype;
      var $dtype = dtype || tfjsCore.util.inferDtype(value);
      var values = tfjsCore.util.getArrayFromDType($dtype, tfjsCore.util.sizeFromShape(shape));
      fillValues(values, value, $dtype);
      return backend.makeTensorInfo(shape, $dtype, values);
    }
    var fillConfig = {
      kernelName: tfjsCore.Fill,
      backendName: "cpu",
      kernelFunc: fill
    };
    function fillValues(values, value, dtype) {
      if (dtype === "string") {
        values.fill(value);
      } else {
        values.fill(value);
      }
    }
    var flipLeftRightConfig = {
      kernelName: tfjsCore.FlipLeftRight,
      backendName: "cpu",
      kernelFunc: function(_a2) {
        var inputs = _a2.inputs;
        _a2.attrs;
        var backend = _a2.backend;
        var image = inputs.image;
        var cpuBackend = backend;
        var output = tfjsCore.util.getTypedArrayFromDType(image.dtype, tfjsCore.util.sizeFromShape(image.shape));
        var _b = __read(image.shape, 4), batch = _b[0], imageHeight = _b[1], imageWidth = _b[2], numChannels = _b[3];
        var imageVals = cpuBackend.data.get(image.dataId).values;
        for (var batchIdx = 0; batchIdx < batch; batchIdx++) {
          var batchOffset = batchIdx * imageWidth * imageHeight * numChannels;
          for (var row = 0; row < imageHeight; row++) {
            var rowOffset = row * (imageWidth * numChannels);
            for (var col = 0; col < imageWidth; col++) {
              var colOffset = col * numChannels;
              for (var channel = 0; channel < numChannels; channel++) {
                var coordX = Math.round(imageWidth - col - 1);
                var outIdx = batchOffset + rowOffset + colOffset + channel;
                var outputValue = imageVals[outIdx];
                if (coordX >= 0 && coordX < imageWidth) {
                  var rotatedColOffset = coordX * numChannels;
                  var imageIdx = batchOffset + rowOffset + rotatedColOffset + channel;
                  outputValue = imageVals[imageIdx];
                }
                output[outIdx] = outputValue;
              }
            }
          }
        }
        var dataId = cpuBackend.write(output, image.shape, image.dtype);
        return { dataId, shape: image.shape, dtype: image.dtype };
      }
    };
    function fusedConv2D(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter, bias = inputs.bias, preluActivationWeights = inputs.preluActivationWeights;
      var strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dilations = attrs.dilations, dimRoundingMode = attrs.dimRoundingMode, activation = attrs.activation, leakyreluAlpha = attrs.leakyreluAlpha;
      var result = conv2D({
        inputs: { x, filter },
        backend,
        attrs: { strides, pad, dataFormat, dilations, dimRoundingMode }
      });
      if (bias) {
        var resultOld = result;
        if (dataFormat === "NCHW" && bias.shape.length === 1 && bias.shape[0] !== 1) {
          var reshapedBias = reshape({ inputs: { x: bias }, backend, attrs: { shape: [bias.shape[0], 1, 1] } });
          result = add({ inputs: { a: result, b: reshapedBias }, backend });
          backend.disposeIntermediateTensorInfo(reshapedBias);
        } else {
          result = add({ inputs: { a: result, b: bias }, backend });
        }
        backend.disposeIntermediateTensorInfo(resultOld);
      }
      if (activation) {
        var resultOld = result;
        if (dataFormat === "NCHW" && activation === "prelu" && preluActivationWeights.shape.length === 1 && preluActivationWeights.shape[0] !== 1) {
          var reshapedAlpha = reshape({
            inputs: { x: preluActivationWeights },
            backend,
            attrs: { shape: [preluActivationWeights.shape[0], 1, 1] }
          });
          result = applyActivation(backend, result, activation, reshapedAlpha, leakyreluAlpha);
          backend.disposeIntermediateTensorInfo(reshapedAlpha);
        } else {
          result = applyActivation(backend, result, activation, preluActivationWeights, leakyreluAlpha);
        }
        backend.disposeIntermediateTensorInfo(resultOld);
      }
      return result;
    }
    var fusedConv2DConfig = {
      kernelName: tfjsCore.FusedConv2D,
      backendName: "cpu",
      kernelFunc: fusedConv2D
    };
    function fusedDepthwiseConv2D(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter, bias = inputs.bias, preluActivationWeights = inputs.preluActivationWeights;
      var strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dilations = attrs.dilations, dimRoundingMode = attrs.dimRoundingMode, activation = attrs.activation, leakyreluAlpha = attrs.leakyreluAlpha;
      var result = depthwiseConv2dNative({
        inputs: { x, filter },
        backend,
        attrs: { strides, pad, dataFormat, dilations, dimRoundingMode }
      });
      if (bias) {
        var oldResult = result;
        result = add({ inputs: { a: result, b: bias }, backend });
        backend.disposeIntermediateTensorInfo(oldResult);
      }
      if (activation) {
        var oldResult = result;
        result = applyActivation(backend, result, activation, preluActivationWeights, leakyreluAlpha);
        backend.disposeIntermediateTensorInfo(oldResult);
      }
      return result;
    }
    var fusedDepthwiseConv2DConfig = {
      kernelName: tfjsCore.FusedDepthwiseConv2D,
      backendName: "cpu",
      kernelFunc: fusedDepthwiseConv2D
    };
    function gatherNd(args) {
      var inputs = args.inputs, backend = args.backend;
      var params = inputs.params, indices = inputs.indices;
      var paramsSize = tfjsCore.util.sizeFromShape(params.shape);
      var indicesShape = indices.shape;
      var sliceRank = indicesShape[indicesShape.length - 1];
      var _a2 = __read(tfjsCore.backend_util.prepareAndValidate(params, indices), 4), resultShape = _a2[0], numSlices = _a2[1], sliceSize = _a2[2], strides = _a2[3];
      if (numSlices === 0) {
        return backend.makeTensorInfo(resultShape, params.dtype, []);
      }
      var indicesData = backend.data.get(indices.dataId).values;
      var paramsBuf = backend.bufferSync(params);
      var outBuf = gatherNdImpl(indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize, strides, params.shape, paramsSize);
      return backend.makeTensorInfo(resultShape, params.dtype, outBuf.values);
    }
    var gatherNdConfig = {
      kernelName: tfjsCore.GatherNd,
      backendName: "cpu",
      kernelFunc: gatherNd
    };
    function gatherV2(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, indices = inputs.indices;
      var axis = attrs.axis, batchDims = attrs.batchDims;
      assertNotComplex([x, indices], "gatherV2");
      var parsedAxis = tfjsCore.util.parseAxisParam(axis, x.shape)[0];
      var indicesVals = backend.data.get(indices.dataId).values;
      var axisDim = x.shape[parsedAxis];
      var _loop_1 = function(i2) {
        var index = indicesVals[i2];
        tfjsCore.util.assert(index <= axisDim - 1 && index >= 0, function() {
          return "GatherV2: the index value ".concat(index, " is not in [0, ").concat(axisDim - 1, "]");
        });
      };
      for (var i = 0; i < indicesVals.length; ++i) {
        _loop_1(i);
      }
      var $batchDims = batchDims;
      if (batchDims == null) {
        $batchDims = 0;
      }
      var indicesSize = tfjsCore.util.sizeFromShape(indices.shape);
      var shapeInfo = tfjsCore.backend_util.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, $batchDims);
      var flattenX = reshape({
        inputs: { x },
        backend,
        attrs: {
          shape: [
            shapeInfo.batchSize,
            shapeInfo.outerSize,
            shapeInfo.dimSize,
            shapeInfo.sliceSize
          ]
        }
      });
      var flattenIndex = reshape({
        inputs: { x: indices },
        backend,
        attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] }
      });
      var flattenOutputShape = [
        shapeInfo.batchSize,
        shapeInfo.outerSize,
        indicesSize / shapeInfo.batchSize,
        shapeInfo.sliceSize
      ];
      var indicesBuf = backend.bufferSync(flattenIndex);
      var xBuf = backend.bufferSync(flattenX);
      var outBuf = gatherV2Impl(xBuf, indicesBuf, flattenOutputShape);
      backend.disposeIntermediateTensorInfo(flattenX);
      backend.disposeIntermediateTensorInfo(flattenIndex);
      return backend.makeTensorInfo(shapeInfo.outputShape, outBuf.dtype, outBuf.values);
    }
    var gatherV2Config = {
      kernelName: tfjsCore.GatherV2,
      backendName: "cpu",
      kernelFunc: gatherV2
    };
    function ifft(args) {
      var inputs = args.inputs, backend = args.backend;
      var input = inputs.input;
      var inputSize = tfjsCore.util.sizeFromShape(input.shape);
      var innerDimensionSize = input.shape[input.shape.length - 1];
      var batch = inputSize / innerDimensionSize;
      var input2D = reshape({
        inputs: { x: input },
        backend,
        attrs: { shape: [batch, innerDimensionSize] }
      });
      var result = fftBatch(input2D, true, backend);
      var resultReshaped = reshape({ inputs: { x: result }, backend, attrs: { shape: input.shape } });
      backend.disposeIntermediateTensorInfo(input2D);
      backend.disposeIntermediateTensorInfo(result);
      return resultReshaped;
    }
    var ifftConfig = {
      kernelName: tfjsCore.IFFT,
      backendName: "cpu",
      kernelFunc: ifft
    };
    var isFinite2 = unaryKernelFunc(tfjsCore.IsFinite, function(xi) {
      return Number.isFinite(xi) ? 1 : 0;
    }, "bool");
    var isFiniteConfig = {
      kernelName: tfjsCore.IsFinite,
      backendName: "cpu",
      kernelFunc: isFinite2
    };
    var isInf = unaryKernelFunc(tfjsCore.IsInf, function(xi) {
      return Math.abs(xi) === Infinity ? 1 : 0;
    }, "bool");
    var isInfConfig = {
      kernelName: tfjsCore.IsInf,
      backendName: "cpu",
      kernelFunc: isInf
    };
    var isNaN$1 = unaryKernelFunc(tfjsCore.IsNan, function(xi) {
      return Number.isNaN(xi) ? 1 : 0;
    }, "bool");
    var isNaNConfig = {
      kernelName: tfjsCore.IsNan,
      backendName: "cpu",
      kernelFunc: isNaN$1
    };
    function linSpace(args) {
      var backend = args.backend, attrs = args.attrs;
      var start = attrs.start, stop = attrs.stop, num = attrs.num;
      var outVals = linSpaceImpl(start, stop, num);
      return backend.makeTensorInfo([outVals.length], "float32", outVals);
    }
    var linSpaceConfig = {
      kernelName: tfjsCore.LinSpace,
      backendName: "cpu",
      kernelFunc: linSpace
    };
    var log1p = unaryKernelFunc(tfjsCore.Log1p, function(xi) {
      return Math.log1p(xi);
    });
    var log1pConfig = {
      kernelName: tfjsCore.Log1p,
      backendName: "cpu",
      kernelFunc: log1p
    };
    var logicalAndImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a && b;
    });
    var logicalAnd = binaryKernelFunc(tfjsCore.LogicalAnd, logicalAndImpl, null, "bool");
    var logicalAndConfig = {
      kernelName: tfjsCore.LogicalAnd,
      backendName: "cpu",
      kernelFunc: logicalAnd
    };
    var logicalNot = unaryKernelFunc(tfjsCore.LogicalNot, function(xi) {
      return xi ? 0 : 1;
    }, "bool");
    var logicalNotConfig = {
      kernelName: tfjsCore.LogicalNot,
      backendName: "cpu",
      kernelFunc: logicalNot
    };
    var logicalOrImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a || b;
    });
    var logicalOr = binaryKernelFunc(tfjsCore.LogicalOr, logicalOrImpl, null, "bool");
    var logicalOrConfig = {
      kernelName: tfjsCore.LogicalOr,
      backendName: "cpu",
      kernelFunc: logicalOr
    };
    function lRN(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var depthRadius = attrs.depthRadius, bias = attrs.bias, alpha = attrs.alpha, beta = attrs.beta;
      assertNotComplex(x, "LRN");
      var channels = x.shape[3];
      var maxD = channels - 1;
      var xValues = backend.data.get(x.dataId).values;
      var size = tfjsCore.util.sizeFromShape(x.shape);
      var result = new Float32Array(size);
      function sumAcrossChannels(offset2) {
        var currentChannel = offset2 % channels;
        var beginSumOffset = offset2 - currentChannel + Math.max(0, currentChannel - depthRadius);
        var endSumOffset = offset2 - currentChannel + Math.min(currentChannel + depthRadius, maxD);
        var sum3 = 0;
        for (; beginSumOffset <= endSumOffset; beginSumOffset++) {
          var z = xValues[beginSumOffset];
          sum3 += z * z;
        }
        return sum3;
      }
      for (var offset = 0; offset < size; offset++) {
        var sum2 = sumAcrossChannels(offset);
        var val = xValues[offset] * Math.pow(bias + alpha * sum2, -beta);
        result[offset] = val;
      }
      return backend.makeTensorInfo(x.shape, x.dtype, result);
    }
    var LRNConfig = {
      kernelName: tfjsCore.LRN,
      backendName: "cpu",
      kernelFunc: lRN
    };
    function lRNGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, y = inputs.y, dy = inputs.dy;
      var depthRadius = attrs.depthRadius, bias = attrs.bias, alpha = attrs.alpha, beta = attrs.beta;
      assertNotComplex(dy, "LRNGrad");
      var dySize = tfjsCore.util.sizeFromShape(dy.shape);
      var channels = dy.shape[3];
      var dyValues = backend.data.get(dy.dataId).values;
      var xValues = backend.data.get(x.dataId).values;
      var yValues = backend.data.get(y.dataId).values;
      var result = new Float32Array(dySize);
      var size = dySize;
      for (var offset = 0; offset < size; offset++) {
        var currentChannel = offset % channels;
        var depthBegin = offset - currentChannel + Math.max(0, currentChannel - depthRadius);
        var depthEnd = offset - currentChannel + Math.min(channels, currentChannel + depthRadius + 1);
        var norm = 0;
        for (var k = depthBegin; k < depthEnd; k++) {
          norm += Math.pow(xValues[k], 2);
        }
        norm = alpha * norm + bias;
        for (var k = depthBegin; k < depthEnd; k++) {
          var dyi = -2 * alpha * beta * xValues[k] * yValues[offset] / norm;
          if (offset === k) {
            dyi += Math.pow(norm, -beta);
          }
          dyi *= dyValues[offset];
          result[k] += dyi;
        }
      }
      return backend.makeTensorInfo(dy.shape, x.dtype, result);
    }
    var LRNGradConfig = {
      kernelName: tfjsCore.LRNGrad,
      backendName: "cpu",
      kernelFunc: lRNGrad
    };
    function max(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var reductionIndices = attrs.reductionIndices, keepDims = attrs.keepDims;
      var cpuBackend = backend;
      var xShape = x.shape;
      var xRank = xShape.length;
      var origAxes = tfjsCore.util.parseAxisParam(reductionIndices, xShape);
      var axes = origAxes;
      var permutedAxes = tfjsCore.backend_util.getAxesPermutation(axes, xRank);
      var xVals = cpuBackend.data.get(x.dataId).values;
      if (permutedAxes != null) {
        var newShape = new Array(xRank);
        for (var i = 0; i < newShape.length; i++) {
          newShape[i] = xShape[permutedAxes[i]];
        }
        xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);
        axes = tfjsCore.backend_util.getInnerMostAxes(axes.length, xRank);
        xShape = newShape;
      }
      assertNotComplex(x, "max");
      tfjsCore.backend_util.assertAxesAreInnerMostDims("max", axes, xRank);
      var _a2 = __read(tfjsCore.backend_util.computeOutAndReduceShapes(xShape, axes), 2), maxOutShape = _a2[0], reduceShape = _a2[1];
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);
      var dataId = cpuBackend.write(result, maxOutShape, x.dtype);
      var outShape = maxOutShape;
      if (keepDims) {
        var newShape = tfjsCore.backend_util.expandShapeToKeepDim(maxOutShape, origAxes);
        outShape = newShape;
      }
      return { dataId, shape: outShape, dtype: x.dtype };
    }
    var maxConfig = {
      kernelName: tfjsCore.Max,
      backendName: "cpu",
      kernelFunc: max
    };
    function maxPool(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      assertNotComplex(x, "maxPool");
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      var dilations = 1;
      tfjsCore.util.assert(tfjsCore.backend_util.eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in maxPool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var convInfo = tfjsCore.backend_util.computePool2DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode);
      var res;
      if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && tfjsCore.util.arraysEqual(convInfo.inShape, convInfo.outShape)) {
        res = identity({ inputs: { x }, backend });
      } else {
        var xValues = backend.data.get(x.dataId).values;
        var strides_1 = tfjsCore.util.computeStrides(x.shape);
        var buffer = pool(xValues, x.shape, x.dtype, strides_1, convInfo, "max");
        res = backend.makeTensorInfo(convInfo.outShape, x.dtype, buffer.values);
      }
      return res;
    }
    var maxPoolConfig = {
      kernelName: tfjsCore.MaxPool,
      backendName: "cpu",
      kernelFunc: maxPool
    };
    function maxPool3D(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode, dataFormat = attrs.dataFormat;
      assertNotComplex(x, "maxPool3d");
      var convInfo = tfjsCore.backend_util.computePool3DInfo(x.shape, filterSize, strides, 1, pad, dimRoundingMode, dataFormat);
      var xValues = backend.data.get(x.dataId).values;
      var outBuf = pool3d(xValues, x.shape, x.dtype, tfjsCore.util.computeStrides(x.shape), convInfo, "max");
      return backend.makeTensorInfo(outBuf.shape, "float32", outBuf.values);
    }
    var maxPool3DConfig = {
      kernelName: tfjsCore.MaxPool3D,
      backendName: "cpu",
      kernelFunc: maxPool3D
    };
    function maxPool3DGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, input = inputs.input;
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      assertNotComplex([dy, input], "maxPool3DGrad");
      var convInfo = tfjsCore.backend_util.computePool3DInfo(input.shape, filterSize, strides, 1, pad, dimRoundingMode);
      var inputBuf = backend.bufferSync(input);
      var maxPosBuf = maxPool3dPositions(inputBuf, convInfo);
      var strideDepth = convInfo.strideDepth;
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var dilationDepth = convInfo.dilationDepth;
      var dilationHeight = convInfo.dilationHeight;
      var dilationWidth = convInfo.dilationWidth;
      var effectiveFilterDepth = convInfo.effectiveFilterDepth;
      var effectiveFilterHeight = convInfo.effectiveFilterHeight;
      var effectiveFilterWidth = convInfo.effectiveFilterWidth;
      var padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
      var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
      var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
      var dx = tfjsCore.buffer(input.shape, "float32");
      var dyBuf = backend.bufferSync(dy);
      for (var batch = 0; batch < convInfo.batchSize; ++batch) {
        for (var channel = 0; channel < convInfo.inChannels; ++channel) {
          for (var dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {
            for (var dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {
              for (var dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {
                var dyDepthCorner = dxDepth - padFront;
                var dyRowCorner = dxRow - padTop;
                var dyColCorner = dxCol - padLeft;
                var dotProd = 0;
                for (var wDepth = 0; wDepth < effectiveFilterDepth; wDepth += dilationDepth) {
                  var dyDepth = (dyDepthCorner + wDepth) / strideDepth;
                  if (dyDepth < 0 || dyDepth >= convInfo.outDepth || Math.floor(dyDepth) !== dyDepth) {
                    continue;
                  }
                  for (var wRow = 0; wRow < effectiveFilterHeight; wRow += dilationHeight) {
                    var dyRow = (dyRowCorner + wRow) / strideHeight;
                    if (dyRow < 0 || dyRow >= convInfo.outHeight || Math.floor(dyRow) !== dyRow) {
                      continue;
                    }
                    for (var wCol = 0; wCol < effectiveFilterWidth; wCol += dilationWidth) {
                      var dyCol = (dyColCorner + wCol) / strideWidth;
                      if (dyCol < 0 || dyCol >= convInfo.outWidth || Math.floor(dyCol) !== dyCol) {
                        continue;
                      }
                      var maxPos = effectiveFilterDepth * effectiveFilterHeight * effectiveFilterWidth - 1 - maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                      var curPos = wDepth * effectiveFilterHeight * effectiveFilterWidth + wRow * effectiveFilterWidth + wCol;
                      var mask = maxPos === curPos ? 1 : 0;
                      if (mask === 0) {
                        continue;
                      }
                      var pixel = dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                      dotProd += pixel * mask;
                    }
                  }
                }
                dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);
              }
            }
          }
        }
      }
      return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);
    }
    var maxPool3DGradConfig = {
      kernelName: tfjsCore.MaxPool3DGrad,
      backendName: "cpu",
      kernelFunc: maxPool3DGrad
    };
    function maxPoolGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, input = inputs.input, output = inputs.output;
      var x = input;
      assertNotComplex([input, output], "maxPoolGrad");
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      var convInfo = tfjsCore.backend_util.computePool2DInfo(x.shape, filterSize, strides, 1, pad, dimRoundingMode);
      var xValues = backend.data.get(x.dataId).values;
      var maxPosBuf = tfjsCore.buffer(convInfo.outShape, x.dtype, maxPoolPositions(xValues, x.shape, x.dtype, convInfo).values);
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var dilationHeight = convInfo.dilationHeight;
      var dilationWidth = convInfo.dilationWidth;
      var effectiveFilterHeight = convInfo.effectiveFilterHeight;
      var effectiveFilterWidth = convInfo.effectiveFilterWidth;
      var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
      var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
      var dx = tfjsCore.buffer(x.shape, "float32");
      var dyData = backend.data.get(dy.dataId).values;
      var dyBuf = tfjsCore.buffer(dy.shape, "float32", dyData);
      for (var b = 0; b < convInfo.batchSize; ++b) {
        for (var d = 0; d < convInfo.inChannels; ++d) {
          for (var dxR = 0; dxR < convInfo.inHeight; ++dxR) {
            for (var dxC = 0; dxC < convInfo.inWidth; ++dxC) {
              var dyRCorner = dxR - padTop;
              var dyCCorner = dxC - padLeft;
              var dotProd = 0;
              for (var wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {
                var dyR = (dyRCorner + wR) / strideHeight;
                if (dyR < 0 || dyR >= convInfo.outHeight || Math.floor(dyR) !== dyR) {
                  continue;
                }
                for (var wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {
                  var dyC = (dyCCorner + wC) / strideWidth;
                  if (dyC < 0 || dyC >= convInfo.outWidth || Math.floor(dyC) !== dyC) {
                    continue;
                  }
                  var maxPos = effectiveFilterHeight * effectiveFilterWidth - 1 - maxPosBuf.get(b, dyR, dyC, d);
                  var curPos = wR * effectiveFilterWidth + wC;
                  var mask = maxPos === curPos ? 1 : 0;
                  if (mask === 0) {
                    continue;
                  }
                  var pixel = dyBuf.get(b, dyR, dyC, d);
                  dotProd += pixel * mask;
                }
              }
              dx.set(dotProd, b, dxR, dxC, d);
            }
          }
        }
      }
      return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);
    }
    var maxPoolGradConfig = {
      kernelName: tfjsCore.MaxPoolGrad,
      backendName: "cpu",
      kernelFunc: maxPoolGrad
    };
    function maxPoolWithArgmaxImpl(xValues, xShape, dtype, includeBatchInIndex, convInfo) {
      var strides = tfjsCore.util.computeStrides(xShape);
      var maxPools = pool(xValues, xShape, dtype, strides, convInfo, "max");
      var maxPositions = maxPoolPositions(xValues, xShape, dtype, convInfo, true, includeBatchInIndex);
      return [maxPools.values, maxPositions.values];
    }
    var maxPoolWithArgmaxConfig = {
      kernelName: tfjsCore.MaxPoolWithArgmax,
      backendName: "cpu",
      kernelFunc: function(_a2) {
        var inputs = _a2.inputs, attrs = _a2.attrs, backend = _a2.backend;
        var x = inputs.x;
        var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, includeBatchInIndex = attrs.includeBatchInIndex;
        var cpuBackend = backend;
        assertNotComplex(x, "MaxPoolWithArgmax");
        var values = cpuBackend.data.get(x.dataId).values;
        var convInfo = tfjsCore.backend_util.computePool2DInfo(x.shape, filterSize, strides, [1, 1], pad);
        var _b = __read(maxPoolWithArgmaxImpl(values, x.shape, x.dtype, includeBatchInIndex, convInfo), 2), pooled = _b[0], indexes = _b[1];
        var pooledDataId = cpuBackend.write(pooled, convInfo.outShape, x.dtype);
        var indexesDataId = cpuBackend.write(indexes, convInfo.outShape, x.dtype);
        return [
          { dataId: pooledDataId, shape: convInfo.outShape, dtype: x.dtype },
          { dataId: indexesDataId, shape: convInfo.outShape, dtype: "int32" }
        ];
      }
    };
    function mean(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      var axes = tfjsCore.util.parseAxisParam(axis, x.shape);
      var shapes = tfjsCore.backend_util.computeOutAndReduceShapes(x.shape, axes);
      var reduceShape = shapes[1];
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var toDispose = [];
      var reduceSizeScalar = backend.makeTensorInfo([], "float32", new Float32Array([reduceSize]));
      toDispose.push(reduceSizeScalar);
      var $x = cast({ inputs: { x }, backend, attrs: { dtype: "float32" } });
      toDispose.push($x);
      var res = div({ inputs: { a: $x, b: reduceSizeScalar }, backend });
      toDispose.push(res);
      var result = sum({ inputs: { x: res }, backend, attrs: { axis, keepDims } });
      toDispose.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return result;
    }
    var meanConfig = {
      kernelName: tfjsCore.Mean,
      backendName: "cpu",
      kernelFunc: mean
    };
    function min(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      assertNotComplex(x, "min");
      var origAxes = tfjsCore.util.parseAxisParam(axis, x.shape);
      var axes = origAxes;
      var permutedAxes = tfjsCore.backend_util.getAxesPermutation(axes, x.shape.length);
      var $x = x;
      if (permutedAxes != null) {
        $x = transpose({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
        axes = tfjsCore.backend_util.getInnerMostAxes(axes.length, x.shape.length);
      }
      tfjsCore.backend_util.assertAxesAreInnerMostDims("min", axes, $x.shape.length);
      var _a2 = __read(tfjsCore.backend_util.computeOutAndReduceShapes($x.shape, axes), 2), outShape = _a2[0], reduceShape = _a2[1];
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var vals = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape(outShape), $x.dtype);
      var aVals = backend.data.get($x.dataId).values;
      for (var i = 0; i < vals.length; ++i) {
        var offset = i * reduceSize;
        var min_1 = aVals[offset];
        for (var j = 0; j < reduceSize; ++j) {
          var value = aVals[offset + j];
          if (Number.isNaN(value) || value < min_1) {
            min_1 = value;
          }
        }
        vals[i] = min_1;
      }
      if (permutedAxes != null) {
        backend.disposeIntermediateTensorInfo($x);
      }
      var result = backend.makeTensorInfo(outShape, $x.dtype, vals);
      if (keepDims) {
        var expandedShape = tfjsCore.backend_util.expandShapeToKeepDim(outShape, origAxes);
        var reshapedResult = reshape({ inputs: { x: result }, backend, attrs: { shape: expandedShape } });
        backend.disposeIntermediateTensorInfo(result);
        return reshapedResult;
      }
      return result;
    }
    var minConfig = {
      kernelName: tfjsCore.Min,
      backendName: "cpu",
      kernelFunc: min
    };
    function mirrorPad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var paddings = attrs.paddings, mode = attrs.mode;
      assertNotComplex(x, "mirrorPad");
      var outShape = paddings.map(
        function(p2, i2) {
          return p2[0] + x.shape[i2] + p2[1];
        }
        /* afterPad */
      );
      var start = paddings.map(function(p2) {
        return p2[0];
      });
      var end = paddings.map(function(p2, i2) {
        return p2[0] + x.shape[i2];
      });
      var offset = mode === "reflect" ? 0 : 1;
      var xVals = backend.data.get(x.dataId).values;
      var xRank = x.shape.length;
      var xStrides = tfjsCore.util.computeStrides(x.shape);
      var resultSize = tfjsCore.util.sizeFromShape(outShape);
      var resultRank = outShape.length;
      var resultStrides = tfjsCore.util.computeStrides(outShape);
      var resVals = tfjsCore.util.getTypedArrayFromDType(x.dtype, resultSize);
      for (var i = 0; i < resultSize; i++) {
        var coords = tfjsCore.util.indexToLoc(i, resultRank, resultStrides);
        for (var i_1 = 0; i_1 < resultRank; i_1++) {
          if (coords[i_1] < start[i_1]) {
            coords[i_1] = start[i_1] * 2 - coords[i_1] - offset;
          } else if (coords[i_1] >= end[i_1]) {
            coords[i_1] = (end[i_1] - 1) * 2 - coords[i_1] + offset;
          }
        }
        coords = coords.map(function(c, i2) {
          return c - start[i2];
        });
        var inIndex = tfjsCore.util.locToIndex(coords, xRank, xStrides);
        resVals[i] = xVals[inIndex];
      }
      var outId = backend.write(resVals, outShape, x.dtype);
      return { dataId: outId, shape: outShape, dtype: x.dtype };
    }
    var mirrorPadConfig = {
      kernelName: tfjsCore.MirrorPad,
      backendName: "cpu",
      kernelFunc: mirrorPad
    };
    var modImpl = createSimpleBinaryKernelImpl(function(aValue, bValue) {
      var rem = aValue % bValue;
      if (aValue < 0 && bValue < 0 || aValue >= 0 && bValue >= 0) {
        return rem;
      } else {
        return (rem + bValue) % bValue;
      }
    });
    var mod = binaryKernelFunc(tfjsCore.Mod, modImpl);
    var modConfig = {
      kernelName: tfjsCore.Mod,
      backendName: "cpu",
      kernelFunc: mod
    };
    function softmax(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var logits = inputs.logits;
      var dim = attrs.dim;
      var logitsRank = logits.shape.length;
      var $dim = dim;
      if ($dim === -1) {
        $dim = logitsRank - 1;
      }
      if ($dim !== logitsRank - 1) {
        throw Error("Softmax along a non-last dimension is not yet supported. " + "Logits was rank ".concat(logitsRank, " and dim was ").concat($dim));
      }
      var axes = tfjsCore.util.parseAxisParam([$dim], logits.shape);
      var maxLogit = max({
        inputs: { x: logits },
        backend,
        attrs: { reductionIndices: axes, keepDims: false }
      });
      var expandedShape = tfjsCore.backend_util.expandShapeToKeepDim(maxLogit.shape, axes);
      var maxLogitReshaped = reshape({ inputs: { x: maxLogit }, backend, attrs: { shape: expandedShape } });
      var a = sub({ inputs: { a: logits, b: maxLogitReshaped }, backend });
      var b = exp({ inputs: { x: a }, backend });
      var sumExp = sum({ inputs: { x: b }, backend, attrs: { axis: axes, keepDims: false } });
      var sumReshaped = reshape({ inputs: { x: sumExp }, backend, attrs: { shape: expandedShape } });
      var result = div({ inputs: { a: b, b: sumReshaped }, backend });
      backend.disposeIntermediateTensorInfo(maxLogit);
      backend.disposeIntermediateTensorInfo(maxLogitReshaped);
      backend.disposeIntermediateTensorInfo(a);
      backend.disposeIntermediateTensorInfo(b);
      backend.disposeIntermediateTensorInfo(sumExp);
      backend.disposeIntermediateTensorInfo(sumReshaped);
      return result;
    }
    var softmaxConfig = {
      kernelName: tfjsCore.Softmax,
      backendName: "cpu",
      kernelFunc: softmax
    };
    function multinomial(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var logits = inputs.logits;
      var numSamples = attrs.numSamples, seed = attrs.seed, normalized = attrs.normalized;
      assertNotComplex(logits, "multinomial");
      var probabilities = normalized ? logits : softmax({ inputs: { logits }, backend, attrs: { dim: -1 } });
      var batchSize = probabilities.shape[0];
      var numEvents = probabilities.shape[1];
      var probVals = backend.data.get(probabilities.dataId).values;
      var resShape = [batchSize, numSamples];
      var resVals = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape(resShape), "int32");
      for (var b = 0; b < batchSize; ++b) {
        var offset = b * numEvents;
        var cdf = new Float32Array(numEvents - 1);
        cdf[0] = probVals[offset];
        for (var event = 1; event < cdf.length; ++event) {
          cdf[event] = cdf[event - 1] + probVals[offset + event];
        }
        var random = seedrandom__namespace.alea(seed.toString());
        var outOffset = b * numSamples;
        for (var sampleId = 0; sampleId < numSamples; ++sampleId) {
          var r = random();
          resVals[outOffset + sampleId] = cdf.length;
          for (var event = 0; event < cdf.length; event++) {
            if (r < cdf[event]) {
              resVals[outOffset + sampleId] = event;
              break;
            }
          }
        }
      }
      if (!normalized) {
        backend.disposeIntermediateTensorInfo(probabilities);
      }
      return backend.makeTensorInfo(resShape, "int32", resVals);
    }
    var multinomialConfig = {
      kernelName: tfjsCore.Multinomial,
      backendName: "cpu",
      kernelFunc: multinomial
    };
    var nonMaxSuppressionV3Impl = tfjsCore.kernel_impls.nonMaxSuppressionV3Impl;
    function nonMaxSuppressionV3(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var boxes = inputs.boxes, scores = inputs.scores;
      var maxOutputSize = attrs.maxOutputSize, iouThreshold = attrs.iouThreshold, scoreThreshold = attrs.scoreThreshold;
      assertNotComplex(boxes, "NonMaxSuppression");
      var boxesVals = backend.data.get(boxes.dataId).values;
      var scoresVals = backend.data.get(scores.dataId).values;
      var selectedIndices = nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold).selectedIndices;
      return backend.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices));
    }
    var nonMaxSuppressionV3Config = {
      kernelName: tfjsCore.NonMaxSuppressionV3,
      backendName: "cpu",
      kernelFunc: nonMaxSuppressionV3
    };
    var nonMaxSuppressionV4Impl = tfjsCore.kernel_impls.nonMaxSuppressionV4Impl;
    function nonMaxSuppressionV4(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var boxes = inputs.boxes, scores = inputs.scores;
      var maxOutputSize = attrs.maxOutputSize, iouThreshold = attrs.iouThreshold, scoreThreshold = attrs.scoreThreshold, padToMaxOutputSize = attrs.padToMaxOutputSize;
      assertNotComplex(boxes, "NonMaxSuppressionPadded");
      var boxesVals = backend.data.get(boxes.dataId).values;
      var scoresVals = backend.data.get(scores.dataId).values;
      var _a2 = nonMaxSuppressionV4Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize), selectedIndices = _a2.selectedIndices, validOutputs = _a2.validOutputs;
      return [
        backend.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
        backend.makeTensorInfo([], "int32", new Int32Array([validOutputs]))
      ];
    }
    var nonMaxSuppressionV4Config = {
      kernelName: tfjsCore.NonMaxSuppressionV4,
      backendName: "cpu",
      kernelFunc: nonMaxSuppressionV4
    };
    var nonMaxSuppressionV5Impl = tfjsCore.kernel_impls.nonMaxSuppressionV5Impl;
    function nonMaxSuppressionV5(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var boxes = inputs.boxes, scores = inputs.scores;
      var maxOutputSize = attrs.maxOutputSize, iouThreshold = attrs.iouThreshold, scoreThreshold = attrs.scoreThreshold, softNmsSigma = attrs.softNmsSigma;
      assertNotComplex(boxes, "NonMaxSuppressionWithScore");
      var boxesVals = backend.data.get(boxes.dataId).values;
      var scoresVals = backend.data.get(scores.dataId).values;
      var maxOutputSizeVal = maxOutputSize;
      var iouThresholdVal = iouThreshold;
      var scoreThresholdVal = scoreThreshold;
      var softNmsSigmaVal = softNmsSigma;
      var _a2 = nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal), selectedIndices = _a2.selectedIndices, selectedScores = _a2.selectedScores;
      return [
        backend.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
        backend.makeTensorInfo([selectedScores.length], "float32", new Float32Array(selectedScores))
      ];
    }
    var nonMaxSuppressionV5Config = {
      kernelName: tfjsCore.NonMaxSuppressionV5,
      backendName: "cpu",
      kernelFunc: nonMaxSuppressionV5
    };
    function oneHot(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var indices = inputs.indices;
      var dtype = attrs.dtype, depth = attrs.depth, onValue = attrs.onValue, offValue = attrs.offValue;
      assertNotComplex(indices, "oneHot");
      var indicesSize = tfjsCore.util.sizeFromShape(indices.shape);
      var res = new Float32Array(indicesSize * depth);
      res.fill(offValue);
      var indicesVal = backend.data.get(indices.dataId).values;
      for (var event = 0; event < indicesSize; ++event) {
        if (indicesVal[event] >= 0 && indicesVal[event] < depth) {
          res[event * depth + indicesVal[event]] = onValue;
        }
      }
      return backend.makeTensorInfo(__spreadArray(__spreadArray([], __read(indices.shape), false), [depth], false), dtype, res);
    }
    var oneHotConfig = {
      kernelName: tfjsCore.OneHot,
      backendName: "cpu",
      kernelFunc: oneHot
    };
    function zerosLike(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x;
      if (x.dtype === "string") {
        throw new Error("zerosLike is not supported for string tensors");
      } else if (x.dtype === "complex64") {
        var realPart = real({ inputs: { input: x }, backend });
        var r = zerosLike({ inputs: { x: realPart }, backend });
        var imagPart = imag({ inputs: { input: x }, backend });
        var i = zerosLike({ inputs: { x: imagPart }, backend });
        var result = complex({ inputs: { real: r, imag: i }, backend });
        backend.disposeIntermediateTensorInfo(realPart);
        backend.disposeIntermediateTensorInfo(r);
        backend.disposeIntermediateTensorInfo(imagPart);
        backend.disposeIntermediateTensorInfo(i);
        return result;
      } else {
        return fill({ backend, attrs: { shape: x.shape, value: 0, dtype: x.dtype } });
      }
    }
    var zerosLikeConfig = {
      kernelName: tfjsCore.ZerosLike,
      backendName: "cpu",
      kernelFunc: zerosLike
    };
    function onesLike(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x;
      if (x.dtype === "string") {
        throw new Error("onesLike is not supported for string tensors");
      } else if (x.dtype === "complex64") {
        var realPart = real({ inputs: { input: x }, backend });
        var r = onesLike({ inputs: { x: realPart }, backend });
        var imagPart = imag({ inputs: { input: x }, backend });
        var i = zerosLike({ inputs: { x: imagPart }, backend });
        var result = complex({ inputs: { real: r, imag: i }, backend });
        backend.disposeIntermediateTensorInfo(realPart);
        backend.disposeIntermediateTensorInfo(r);
        backend.disposeIntermediateTensorInfo(imagPart);
        backend.disposeIntermediateTensorInfo(i);
        return result;
      } else {
        return fill({ backend, attrs: { shape: x.shape, value: 1, dtype: x.dtype } });
      }
    }
    var onesLikeConfig = {
      kernelName: tfjsCore.OnesLike,
      backendName: "cpu",
      kernelFunc: onesLike
    };
    function pack(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var axis = attrs.axis;
      if (inputs.length === 1) {
        return expandDims({ inputs: { input: inputs[0] }, backend, attrs: { dim: axis } });
      }
      var shape = inputs[0].shape;
      var dtype = inputs[0].dtype;
      inputs.forEach(function(t) {
        tfjsCore.util.assertShapesMatch(shape, t.shape, "All tensors passed to stack must have matching shapes");
        tfjsCore.util.assert(dtype === t.dtype, function() {
          return "All tensors passed to stack must have matching dtypes";
        });
      });
      var intermediateTensorInfos = [];
      var expandedTensors = inputs.map(function(t) {
        var expandedT = expandDims({ inputs: { input: t }, backend, attrs: { dim: axis } });
        intermediateTensorInfos.push(expandedT);
        return expandedT;
      });
      var result = concat({ inputs: expandedTensors, backend, attrs: { axis } });
      intermediateTensorInfos.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return result;
    }
    var packConfig = {
      kernelName: tfjsCore.Pack,
      backendName: "cpu",
      kernelFunc: pack
    };
    function padV2(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var paddings = attrs.paddings, constantValue = attrs.constantValue;
      assertNotComplex(x, "pad");
      var outShape = paddings.map(
        function(p2, i2) {
          return p2[0] + x.shape[i2] + p2[1];
        }
        /* afterPad */
      );
      var start = paddings.map(function(p2) {
        return p2[0];
      });
      var xVals = backend.data.get(x.dataId).values;
      var xSize = tfjsCore.util.sizeFromShape(x.shape);
      var xRank = x.shape.length;
      var xStrides = tfjsCore.util.computeStrides(x.shape);
      var resultSize = tfjsCore.util.sizeFromShape(outShape);
      var resultRank = outShape.length;
      var resultStrides = tfjsCore.util.computeStrides(outShape);
      var resVals = tfjsCore.util.getTypedArrayFromDType(x.dtype, resultSize);
      if (constantValue !== 0) {
        resVals.fill(constantValue);
      }
      for (var i = 0; i < xSize; i++) {
        var coords = tfjsCore.util.indexToLoc(i, xRank, xStrides);
        var outCoords = coords.map(function(c, i2) {
          return c + start[i2];
        });
        var outIndex = tfjsCore.util.locToIndex(outCoords, resultRank, resultStrides);
        resVals[outIndex] = xVals[i];
      }
      var outId = backend.write(resVals, outShape, x.dtype);
      return { dataId: outId, shape: outShape, dtype: x.dtype };
    }
    var padV2Config = {
      kernelName: tfjsCore.PadV2,
      backendName: "cpu",
      kernelFunc: padV2
    };
    var powImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return Math.pow(a, b);
    });
    var pow = binaryKernelFunc(tfjsCore.Pow, powImpl);
    var powConfig = {
      kernelName: tfjsCore.Pow,
      backendName: "cpu",
      kernelFunc: pow
    };
    function raggedGather(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var paramsNestedSplits = inputs.paramsNestedSplits, paramsDenseValues = inputs.paramsDenseValues, indices = inputs.indices;
      attrs.outputRaggedRank;
      var $paramsNestedSplits = paramsNestedSplits.map(function(t) {
        return backend.data.get(t.dataId).values;
      });
      var $paramsNestedSplitsShapes = paramsNestedSplits.map(function(t) {
        return t.shape;
      });
      var $paramsDenseValues = backend.data.get(paramsDenseValues.dataId).values;
      var $indices = backend.data.get(indices.dataId).values;
      var _a2 = __read(raggedGatherImpl($paramsNestedSplits, $paramsNestedSplitsShapes, $paramsDenseValues, paramsDenseValues.shape, paramsDenseValues.dtype, $indices, indices.shape), 3), outputNestedSplits = _a2[0], outputDenseValues = _a2[1], outputDenseValuesShape = _a2[2];
      var outputNestedSplitsTensors = outputNestedSplits.map(function(splits) {
        return backend.makeTensorInfo([splits.length], "int32", splits);
      });
      var outputDenseValuesTensor = backend.makeTensorInfo(outputDenseValuesShape, paramsDenseValues.dtype, outputDenseValues);
      return outputNestedSplitsTensors.concat([outputDenseValuesTensor]);
    }
    var raggedGatherConfig = {
      kernelName: tfjsCore.RaggedGather,
      backendName: "cpu",
      kernelFunc: raggedGather
    };
    function raggedRange(args) {
      var inputs = args.inputs, backend = args.backend;
      var starts = inputs.starts, limits = inputs.limits, deltas = inputs.deltas;
      var $starts = backend.data.get(starts.dataId).values;
      var $limits = backend.data.get(limits.dataId).values;
      var $deltas = backend.data.get(deltas.dataId).values;
      var _a2 = __read(raggedRangeImpl($starts, starts.shape, starts.dtype, $limits, limits.shape, $deltas, deltas.shape), 2), rtNestedSplitsData = _a2[0], rtDenseValuesData = _a2[1];
      var rtNestedSplits = backend.makeTensorInfo([rtNestedSplitsData.length], "int32", rtNestedSplitsData);
      var rtDenseValues = backend.makeTensorInfo([rtDenseValuesData.length], starts.dtype, rtDenseValuesData);
      return [rtNestedSplits, rtDenseValues];
    }
    var raggedRangeConfig = {
      kernelName: tfjsCore.RaggedRange,
      backendName: "cpu",
      kernelFunc: raggedRange
    };
    function raggedTensorToTensor(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var shape = inputs.shape, values = inputs.values, defaultValue = inputs.defaultValue, rowPartitionTensors = inputs.rowPartitionTensors;
      var rowPartitionTypes = attrs.rowPartitionTypes;
      var $shape = backend.data.get(shape.dataId).values;
      var $values = backend.data.get(values.dataId).values;
      var $defaultValue = backend.data.get(defaultValue.dataId).values;
      var $rowPartitionValues = rowPartitionTensors.map(function(t) {
        return backend.data.get(t.dataId).values;
      });
      var rowPartitionValuesShapes = rowPartitionTensors.map(function(t) {
        return t.shape;
      });
      var _a2 = __read(raggedTensorToTensorImpl($shape, shape.shape, $values, values.shape, values.dtype, $defaultValue, defaultValue.shape, $rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes), 2), outputShape = _a2[0], output = _a2[1];
      return backend.makeTensorInfo(outputShape, values.dtype, output);
    }
    var raggedTensorToTensorConfig = {
      kernelName: tfjsCore.RaggedTensorToTensor,
      backendName: "cpu",
      kernelFunc: raggedTensorToTensor
    };
    function range(args) {
      var backend = args.backend, attrs = args.attrs;
      var start = attrs.start, stop = attrs.stop, dtype = attrs.dtype, step2 = attrs.step;
      var values = rangeImpl(start, stop, step2, dtype);
      return backend.makeTensorInfo([values.length], dtype, values);
    }
    var rangeConfig = {
      kernelName: tfjsCore.Range,
      backendName: "cpu",
      kernelFunc: range
    };
    var reciprocal = unaryKernelFunc(tfjsCore.Reciprocal, function(xi) {
      return 1 / xi;
    });
    var reciprocalConfig = {
      kernelName: tfjsCore.Reciprocal,
      backendName: "cpu",
      kernelFunc: reciprocal
    };
    function resizeBilinear(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var images = inputs.images;
      var alignCorners = attrs.alignCorners, halfPixelCenters = attrs.halfPixelCenters, size = attrs.size;
      assertNotComplex(images, "resizeBilinear");
      var imagesStrides = tfjsCore.util.computeStrides(images.shape);
      var _a2 = __read(size, 2), newHeight = _a2[0], newWidth = _a2[1];
      var _b = __read(images.shape, 4), batch = _b[0], oldHeight = _b[1], oldWidth = _b[2], numChannels = _b[3];
      var xValues = backend.data.get(images.dataId).values;
      var result = new Float32Array(tfjsCore.util.sizeFromShape([batch, newHeight, newWidth, numChannels]));
      var effectiveInputSize = [
        alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
        alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
      ];
      var effectiveOutputSize = [
        alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
        alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
      ];
      var outputIdx = 0;
      var effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];
      var effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];
      for (var b = 0; b < batch; b++) {
        for (var r = 0; r < newHeight; r++) {
          var sourceFracRow = void 0;
          if (halfPixelCenters) {
            sourceFracRow = effectiveRowSizeRatio * (r + 0.5) - 0.5;
          } else {
            sourceFracRow = effectiveRowSizeRatio * r;
          }
          var sourceRowFloor = Math.max(0, Math.floor(sourceFracRow));
          var rowFrac = sourceFracRow - sourceRowFloor;
          var sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));
          var topRowOffset = b * imagesStrides[0] + sourceRowFloor * imagesStrides[1];
          var botRowOffset = b * imagesStrides[0] + sourceRowCeil * imagesStrides[1];
          for (var c = 0; c < newWidth; c++) {
            var sourceFracCol = void 0;
            if (halfPixelCenters) {
              sourceFracCol = effectiveColSizeRatio * (c + 0.5) - 0.5;
            } else {
              sourceFracCol = effectiveColSizeRatio * c;
            }
            var sourceColFloor = Math.max(0, Math.floor(sourceFracCol));
            var colFrac = sourceFracCol - sourceColFloor;
            var sourceColCeil = Math.min(oldWidth - 1, Math.ceil(sourceFracCol));
            var topLeftOffest = topRowOffset + sourceColFloor * imagesStrides[2];
            var botLeftOffset = botRowOffset + sourceColFloor * imagesStrides[2];
            var topRightOffset = topRowOffset + sourceColCeil * imagesStrides[2];
            var botRightOffest = botRowOffset + sourceColCeil * imagesStrides[2];
            for (var d = 0; d < numChannels; d++) {
              var topLeft = xValues[topLeftOffest + d];
              var bottomLeft = xValues[botLeftOffset + d];
              var topRight = xValues[topRightOffset + d];
              var bottomRight = xValues[botRightOffest + d];
              var top = topLeft + (topRight - topLeft) * colFrac;
              var bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;
              var newValue = top + (bottom - top) * rowFrac;
              result[outputIdx++] = newValue;
            }
          }
        }
      }
      return backend.makeTensorInfo([batch, newHeight, newWidth, numChannels], "float32", result);
    }
    var resizeBilinearConfig = {
      kernelName: tfjsCore.ResizeBilinear,
      backendName: "cpu",
      kernelFunc: resizeBilinear
    };
    function resizeBilinearGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var images = inputs.images, dy = inputs.dy;
      var alignCorners = attrs.alignCorners;
      assertNotComplex([dy, images], "resizeBilinearGrad");
      var imagesStrides = tfjsCore.util.computeStrides(images.shape);
      var _a2 = __read(images.shape, 4), batch = _a2[0], xHeight = _a2[1], xWidth = _a2[2], depth = _a2[3];
      var _b = __read(dy.shape, 3), yHeight = _b[1], yWidth = _b[2];
      var output = new Float32Array(batch * xHeight * xWidth * depth);
      var effectiveXSize = [
        alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
        alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
      ];
      var effectiveYSize = [
        alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
        alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
      ];
      var heightScale = effectiveXSize[0] / effectiveYSize[0];
      var widthScale = effectiveXSize[1] / effectiveYSize[1];
      var dyValues = backend.data.get(dy.dataId).values;
      var offset = 0;
      for (var b = 0; b < batch; b++) {
        var bOffset = b * imagesStrides[0];
        for (var r = 0; r < yHeight; r++) {
          var dxR = r * heightScale;
          var topDxRIndex = Math.floor(dxR);
          var bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);
          var topDxROffset = bOffset + topDxRIndex * imagesStrides[1];
          var bottomDxROffset = bOffset + bottomDxRIndex * imagesStrides[1];
          var dxRLerp = dxR - topDxRIndex;
          var inverseDxRLerp = 1 - dxRLerp;
          for (var c = 0; c < yWidth; c++) {
            var dxC = c * widthScale;
            var leftDxCIndex = Math.floor(dxC);
            var rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);
            var dxCLerp = dxC - leftDxCIndex;
            var inverseDxCLerp = 1 - dxCLerp;
            var topLeftRCOffset = topDxROffset + leftDxCIndex * imagesStrides[2];
            var topRightRCOffset = topDxROffset + rightDxCIndex * imagesStrides[2];
            var bottomLeftRCOffset = bottomDxROffset + leftDxCIndex * imagesStrides[2];
            var bottomRightRCOffset = bottomDxROffset + rightDxCIndex * imagesStrides[2];
            var inverseDxRLerpTimesInverseDxCLerp = inverseDxRLerp * inverseDxCLerp;
            var inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;
            var dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;
            var dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;
            for (var d = 0; d < depth; d++) {
              var dyVal = dyValues[offset++];
              output[topLeftRCOffset + d] += dyVal * inverseDxRLerpTimesInverseDxCLerp;
              output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;
              output[bottomLeftRCOffset + d] += dyVal * dxRLerpTimesInverseDxCLerp;
              output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;
            }
          }
        }
      }
      return backend.makeTensorInfo([batch, xWidth, xHeight, depth], "float32", output);
    }
    var resizeBilinearGradConfig = {
      kernelName: tfjsCore.ResizeBilinearGrad,
      backendName: "cpu",
      kernelFunc: resizeBilinearGrad
    };
    function resizeNearestNeighbor(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var images = inputs.images;
      var alignCorners = attrs.alignCorners, halfPixelCenters = attrs.halfPixelCenters, size = attrs.size;
      assertNotComplex(images, "resizeNearestNeighbor");
      var imagesStrides = tfjsCore.util.computeStrides(images.shape);
      var _a2 = __read(size, 2), newHeight = _a2[0], newWidth = _a2[1];
      var _b = __read(images.shape, 4), batch = _b[0], oldHeight = _b[1], oldWidth = _b[2], numChannels = _b[3];
      var xValues = backend.data.get(images.dataId).values;
      var output = new Float32Array(batch * newHeight * newWidth * numChannels);
      var effectiveInputSize = [
        alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
        alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
      ];
      var effectiveOutputSize = [
        alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
        alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
      ];
      var effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];
      var effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];
      var outputOffset = 0;
      for (var b = 0; b < batch; b++) {
        var batchOffset = b * imagesStrides[0];
        for (var r = 0; r < newHeight; r++) {
          var sourceFracRow = halfPixelCenters ? effectiveRowSizeRatio * (r + 0.5) : effectiveRowSizeRatio * r;
          var sourceNearestRow = Math.min(oldHeight - 1, alignCorners ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));
          if (halfPixelCenters) {
            sourceNearestRow = Math.max(0, sourceNearestRow);
          }
          var rowOffset = batchOffset + sourceNearestRow * imagesStrides[1];
          for (var c = 0; c < newWidth; c++) {
            var sourceFracCol = halfPixelCenters ? effectiveColSizeRatio * (c + 0.5) : effectiveColSizeRatio * c;
            var sourceNearestCol = Math.min(oldWidth - 1, alignCorners ? Math.round(sourceFracCol) : Math.floor(sourceFracCol));
            if (halfPixelCenters) {
              sourceNearestCol = Math.max(0, sourceNearestCol);
            }
            var colOffset = rowOffset + sourceNearestCol * imagesStrides[2];
            for (var d = 0; d < numChannels; d++) {
              var newVal = xValues[colOffset + d];
              output[outputOffset++] = newVal;
            }
          }
        }
      }
      return backend.makeTensorInfo([batch, newHeight, newWidth, numChannels], images.dtype, output);
    }
    var resizeNearestNeighborConfig = {
      kernelName: tfjsCore.ResizeNearestNeighbor,
      backendName: "cpu",
      kernelFunc: resizeNearestNeighbor
    };
    function resizeNearestNeighborGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var images = inputs.images, dy = inputs.dy;
      var alignCorners = attrs.alignCorners;
      assertNotComplex([dy, images], "resizeNearestNeighborGrad");
      var imagesStrides = tfjsCore.util.computeStrides(images.shape);
      var dyStrides = tfjsCore.util.computeStrides(dy.shape);
      var _a2 = __read(images.shape, 4), batch = _a2[0], xHeight = _a2[1], xWidth = _a2[2], depth = _a2[3];
      var _b = __read(dy.shape, 3), yHeight = _b[1], yWidth = _b[2];
      var output = new Float32Array(batch * xHeight * xWidth * depth);
      var dyValues = backend.data.get(dy.dataId).values;
      var effectiveXSize = [
        alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
        alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
      ];
      var effectiveYSize = [
        alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
        alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
      ];
      var heightScale = effectiveXSize[0] / effectiveYSize[0];
      var widthScale = effectiveXSize[1] / effectiveYSize[1];
      var invHeightScale = 1 / heightScale;
      var invWidthScale = 1 / widthScale;
      var winHeight = Math.ceil(invHeightScale) * 2 + 2;
      var winWidth = Math.ceil(invWidthScale) * 2 + 2;
      for (var b = 0; b < batch; b++) {
        var batchOffset = b * imagesStrides[0];
        for (var r = 0; r < xHeight; r++) {
          var rowOffset = batchOffset + r * imagesStrides[1];
          var startRLerp = Math.floor(r * invHeightScale);
          var startDyR = Math.floor(startRLerp - winHeight / 2);
          for (var c = 0; c < xWidth; c++) {
            var colOffset = rowOffset + c * imagesStrides[2];
            var startCLerp = Math.floor(c * invWidthScale);
            var startDyC = Math.floor(startCLerp - winWidth / 2);
            for (var d = 0; d < depth; d++) {
              var accum = 0;
              for (var dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {
                var dyR = dyRIndex + startDyR;
                if (dyR < 0 || dyR >= yHeight) {
                  continue;
                }
                var dyROffset = batchOffset + dyR * dyStrides[1];
                var sourceFracRow = dyR * heightScale;
                var sourceNearestRow = Math.min(xHeight - 1, alignCorners ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));
                if (r !== sourceNearestRow) {
                  continue;
                }
                for (var dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {
                  var dyC = dyCIndex + startDyC;
                  if (dyC < 0 || dyC >= yWidth) {
                    continue;
                  }
                  var dyCOffset = dyROffset + dyC * dyStrides[2];
                  var sourceFracCol = dyC * widthScale;
                  var sourceNearestCol = Math.min(xWidth - 1, alignCorners ? Math.round(sourceFracCol) : Math.floor(sourceFracCol));
                  if (c === sourceNearestCol) {
                    accum += dyValues[dyCOffset + d];
                  }
                }
              }
              output[colOffset + d] = accum;
            }
          }
        }
      }
      return backend.makeTensorInfo(images.shape, images.dtype, output);
    }
    var resizeNearestNeighborGradConfig = {
      kernelName: tfjsCore.ResizeNearestNeighborGrad,
      backendName: "cpu",
      kernelFunc: resizeNearestNeighborGrad
    };
    function reverse(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var dims = attrs.dims;
      assertNotComplex(x, "reverse");
      var xRank = x.shape.length;
      var $dims = tfjsCore.util.parseAxisParam(dims, x.shape);
      if (xRank === 0) {
        return identity({ inputs: { x }, backend });
      }
      var outBuf = new tfjsCore.TensorBuffer(x.shape, x.dtype);
      var xBuf = backend.bufferSync(x);
      var _loop_1 = function(i2) {
        var outLoc = outBuf.indexToLoc(i2);
        var inLoc = outLoc.slice();
        $dims.forEach(function(d) {
          return inLoc[d] = x.shape[d] - 1 - inLoc[d];
        });
        outBuf.set.apply(outBuf, __spreadArray([xBuf.get.apply(xBuf, __spreadArray([], __read(inLoc), false))], __read(outLoc), false));
      };
      for (var i = 0; i < outBuf.size; i++) {
        _loop_1(i);
      }
      return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
    }
    var reverseConfig = {
      kernelName: tfjsCore.Reverse,
      backendName: "cpu",
      kernelFunc: reverse
    };
    var rotateWithOffsetConfig = {
      kernelName: tfjsCore.RotateWithOffset,
      backendName: "cpu",
      kernelFunc: function(_a2) {
        var inputs = _a2.inputs, attrs = _a2.attrs, backend = _a2.backend;
        var image = inputs.image;
        var radians = attrs.radians, fillValue = attrs.fillValue, center = attrs.center;
        var cpuBackend = backend;
        var output = tfjsCore.util.getTypedArrayFromDType(image.dtype, tfjsCore.util.sizeFromShape(image.shape));
        var _b = __read(image.shape, 4), batch = _b[0], imageHeight = _b[1], imageWidth = _b[2], numChannels = _b[3];
        var _c = __read(tfjsCore.backend_util.getImageCenter(center, imageHeight, imageWidth), 2), centerX = _c[0], centerY = _c[1];
        var fullOpacityValue = 255;
        var sinFactor = Math.sin(radians);
        var cosFactor = Math.cos(radians);
        var imageVals = cpuBackend.data.get(image.dataId).values;
        for (var batchIdx = 0; batchIdx < batch; batchIdx++) {
          var batchOffset = batchIdx * imageWidth * imageHeight * numChannels;
          for (var row = 0; row < imageHeight; row++) {
            var rowOffset = row * (imageWidth * numChannels);
            for (var col = 0; col < imageWidth; col++) {
              var colOffset = col * numChannels;
              for (var channel = 0; channel < numChannels; channel++) {
                var coords = [batch, row, col, channel];
                var x = coords[2];
                var y = coords[1];
                var coordX = (x - centerX) * cosFactor - (y - centerY) * sinFactor;
                var coordY = (x - centerX) * sinFactor + (y - centerY) * cosFactor;
                coordX = Math.round(coordX + centerX);
                coordY = Math.round(coordY + centerY);
                var outputValue = fillValue;
                if (typeof fillValue !== "number") {
                  if (channel === 3) {
                    outputValue = fullOpacityValue;
                  } else {
                    outputValue = fillValue[channel];
                  }
                }
                if (coordX >= 0 && coordX < imageWidth && coordY >= 0 && coordY < imageHeight) {
                  var rotatedRowOffset = coordY * (imageWidth * numChannels);
                  var rotatedColOffset = coordX * numChannels;
                  var imageIdx = batchOffset + rotatedRowOffset + rotatedColOffset + channel;
                  outputValue = imageVals[imageIdx];
                }
                var outIdx = batchOffset + rowOffset + colOffset + channel;
                output[outIdx] = outputValue;
              }
            }
          }
        }
        var dataId = cpuBackend.write(output, image.shape, image.dtype);
        return { dataId, shape: image.shape, dtype: image.dtype };
      }
    };
    var round = unaryKernelFunc(tfjsCore.Round, function(xi) {
      var base = Math.floor(xi);
      if (xi - base < 0.5) {
        return Math.floor(xi);
      } else if (xi - base > 0.5) {
        return Math.ceil(xi);
      } else {
        if (base % 2 === 0) {
          return base;
        } else {
          return base + 1;
        }
      }
    });
    var roundConfig = {
      kernelName: tfjsCore.Round,
      backendName: "cpu",
      kernelFunc: round
    };
    function scatterNd(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var indices = inputs.indices, updates = inputs.updates;
      var shape = attrs.shape;
      var _a2 = tfjsCore.backend_util.calculateShapes(updates, indices, shape), sliceRank = _a2.sliceRank, numUpdates = _a2.numUpdates, sliceSize = _a2.sliceSize, strides = _a2.strides, outputSize = _a2.outputSize;
      var sumDupeIndices = true;
      var indicesBuf = backend.bufferSync(indices);
      var updatesBuf = backend.bufferSync(updates);
      var outBuf = scatterImpl(indicesBuf, updatesBuf, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, 0, sumDupeIndices);
      return backend.makeTensorInfo(shape, outBuf.dtype, outBuf.values);
    }
    var scatterNdConfig = {
      kernelName: tfjsCore.ScatterNd,
      backendName: "cpu",
      kernelFunc: scatterNd
    };
    function lowerBound(array, value) {
      var left = 0;
      var right = array.length;
      var mid = 0;
      while (left < right) {
        mid = Math.floor((left + right) / 2);
        if (array[mid] < value) {
          left = mid + 1;
        } else {
          right = mid;
        }
      }
      return right;
    }
    function upperBound(array, value) {
      var left = 0;
      var right = array.length;
      var mid = 0;
      while (left < right) {
        mid = Math.floor((left + right) / 2);
        if (array[mid] <= value) {
          left = mid + 1;
        } else {
          right = mid;
        }
      }
      return right;
    }
    function searchSortedImpl(sortedInputs, values, batchSize, numInputs, numValues, side) {
      var output = tfjsCore.util.getArrayFromDType("int32", batchSize * numValues);
      for (var b = 0; b < batchSize; ++b) {
        var sortedInputsSlice = sortedInputs.slice(b * numInputs, (b + 1) * numInputs);
        var outputOffset = b * numValues;
        for (var i = 0; i < numValues; ++i) {
          output[outputOffset + i] = side === "left" ? lowerBound(sortedInputsSlice, values[i + outputOffset]) : upperBound(sortedInputsSlice, values[i + outputOffset]);
        }
      }
      return output;
    }
    function searchSorted(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var sortedSequence = inputs.sortedSequence, values = inputs.values;
      var side = attrs.side;
      var $sortedSequence = backend.data.get(sortedSequence.dataId).values;
      var $values = backend.data.get(values.dataId).values;
      var output = searchSortedImpl($sortedSequence, $values, sortedSequence.shape[0], sortedSequence.shape[1], values.shape[1], side);
      return backend.makeTensorInfo(values.shape, "int32", output);
    }
    var searchSortedConfig = {
      kernelName: tfjsCore.SearchSorted,
      backendName: "cpu",
      kernelFunc: searchSorted
    };
    function select(args) {
      var inputs = args.inputs, backend = args.backend;
      var condition = inputs.condition, t = inputs.t, e = inputs.e;
      assertNotComplex([condition, t, e], "select");
      var conditionRank = condition.shape.length;
      var values = backend.data.get(condition.dataId).values;
      var tValues = backend.data.get(t.dataId).values;
      var eValues = backend.data.get(e.dataId).values;
      var resultDtype = tfjsCore.upcastType(t.dtype, e.dtype);
      var newValues = tfjsCore.util.makeZerosTypedArray(tfjsCore.util.sizeFromShape(t.shape), resultDtype);
      var index = 0;
      var offset = conditionRank === 0 || conditionRank > 1 || t.shape.length === 1 ? 1 : tfjsCore.util.sizeFromShape(t.shape.slice(1));
      for (var i = 0; i < values.length; i++) {
        for (var j = 0; j < offset; j++) {
          if (values[i] === 1) {
            newValues[index++] = tValues[i];
          } else {
            newValues[index++] = eValues[i];
          }
        }
      }
      return backend.makeTensorInfo(t.shape, resultDtype, newValues);
    }
    var selectConfig = {
      kernelName: tfjsCore.Select,
      backendName: "cpu",
      kernelFunc: select
    };
    var scaleAlpha = tfjsCore.backend_util.SELU_SCALEALPHA;
    var scale = tfjsCore.backend_util.SELU_SCALE;
    var selu = unaryKernelFunc(tfjsCore.Selu, function(xi) {
      if (xi >= 0) {
        return scale * xi;
      } else {
        return scaleAlpha * (Math.exp(xi) - 1);
      }
    });
    var seluConfig = {
      kernelName: tfjsCore.Selu,
      backendName: "cpu",
      kernelFunc: selu
    };
    var sign = unaryKernelFunc(tfjsCore.Sign, function(xi) {
      if (xi < 0) {
        return -1;
      } else if (xi > 0) {
        return 1;
      } else {
        return 0;
      }
    });
    var signConfig = {
      kernelName: tfjsCore.Sign,
      backendName: "cpu",
      kernelFunc: sign
    };
    var sin = unaryKernelFunc(tfjsCore.Sin, function(xi) {
      return Math.sin(xi);
    });
    var sinConfig = {
      kernelName: tfjsCore.Sin,
      backendName: "cpu",
      kernelFunc: sin
    };
    var sinh = unaryKernelFunc(tfjsCore.Sinh, function(xi) {
      return Math.sinh(xi);
    });
    var sinhConfig = {
      kernelName: tfjsCore.Sinh,
      backendName: "cpu",
      kernelFunc: sinh
    };
    var epsilon = 11920928955078125e-23;
    var threshold = Math.log(epsilon) + 2;
    var softplus = unaryKernelFunc(tfjsCore.Softplus, function(xi) {
      var tooLarge = xi > -threshold;
      var tooSmall = xi < threshold;
      var expX = Math.exp(xi);
      var result;
      if (tooSmall) {
        result = expX;
      } else if (tooLarge) {
        result = xi;
      } else {
        result = Math.log(1 + expX);
      }
      return result;
    });
    var softplusConfig = {
      kernelName: tfjsCore.Softplus,
      backendName: "cpu",
      kernelFunc: softplus
    };
    function spaceToBatchND(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var blockShape = attrs.blockShape, paddings = attrs.paddings;
      assertNotComplex([x], "spaceToBatchND");
      var prod2 = tfjsCore.util.sizeFromShape(blockShape);
      var completePaddings = [[0, 0]];
      completePaddings.push.apply(completePaddings, __spreadArray([], __read(paddings), false));
      for (var i = 1 + blockShape.length; i < x.shape.length; ++i) {
        completePaddings.push([0, 0]);
      }
      var paddedX = padV2Config.kernelFunc({
        inputs: { x },
        backend,
        attrs: { paddings: completePaddings, constantValue: 0 }
      });
      var reshapedPaddedShape = tfjsCore.backend_util.getReshaped(paddedX.shape, blockShape, prod2, false);
      var permutedReshapedPaddedPermutation = tfjsCore.backend_util.getPermuted(reshapedPaddedShape.length, blockShape.length, false);
      var flattenShape = tfjsCore.backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod2, false);
      var reshapeInputs = { x: paddedX };
      var reshapeAttrs = { shape: reshapedPaddedShape };
      var paddedXReshaped = reshape({ inputs: reshapeInputs, backend, attrs: reshapeAttrs });
      var transposeInputs = { x: paddedXReshaped };
      var transposeAttrs = { perm: permutedReshapedPaddedPermutation };
      var paddedXT = transpose({ inputs: transposeInputs, backend, attrs: transposeAttrs });
      var resultReshapeInputs = { x: paddedXT };
      var resultReshapeAttrs = { shape: flattenShape };
      var result = reshape({ inputs: resultReshapeInputs, backend, attrs: resultReshapeAttrs });
      backend.disposeIntermediateTensorInfo(paddedX);
      backend.disposeIntermediateTensorInfo(paddedXReshaped);
      backend.disposeIntermediateTensorInfo(paddedXT);
      return result;
    }
    var spaceToBatchNDConfig = {
      kernelName: tfjsCore.SpaceToBatchND,
      backendName: "cpu",
      kernelFunc: spaceToBatchND
    };
    function sparseFillEmptyRows(args) {
      var inputs = args.inputs, backend = args.backend;
      var indices = inputs.indices, values = inputs.values, denseShape = inputs.denseShape, defaultValue = inputs.defaultValue;
      if (denseShape.shape.length !== 1) {
        throw new Error("Dense shape must be a vector, saw:\n        ".concat(denseShape.shape));
      }
      if (indices.shape.length !== 2) {
        throw new Error("Indices must be a matrix, saw:\n        ".concat(indices.shape));
      }
      if (values.shape.length !== 1) {
        throw new Error("Values must be a vector, saw:\n        ".concat(values.shape));
      }
      if (defaultValue.shape.length !== 0) {
        throw new Error("Default value must be a scalar, saw:\n        ".concat(defaultValue.shape));
      }
      var $indices = backend.data.get(indices.dataId).values;
      var $values = backend.data.get(values.dataId).values;
      var $denseShape = backend.data.get(denseShape.dataId).values;
      var $defaultValue = backend.data.get(defaultValue.dataId).values[0];
      var _a2 = __read(sparseFillEmptyRowsImpl($indices, indices.shape, indices.dtype, $values, values.dtype, $denseShape, $defaultValue), 5), outputIndices = _a2[0], outputIndicesShape = _a2[1], outputValues = _a2[2], emptyRowIndicator = _a2[3], reverseIndexMap = _a2[4];
      return [
        backend.makeTensorInfo(outputIndicesShape, indices.dtype, outputIndices),
        backend.makeTensorInfo([outputIndicesShape[0]], values.dtype, outputValues),
        backend.makeTensorInfo([emptyRowIndicator.length], "bool", new Uint8Array(emptyRowIndicator.map(function(value) {
          return Number(value);
        }))),
        backend.makeTensorInfo([reverseIndexMap.length], indices.dtype, new Int32Array(reverseIndexMap))
      ];
    }
    var sparseFillEmptyRowsConfig = {
      kernelName: tfjsCore.SparseFillEmptyRows,
      backendName: "cpu",
      kernelFunc: sparseFillEmptyRows
    };
    function sparseReshape(args) {
      var inputs = args.inputs, backend = args.backend;
      var inputIndices = inputs.inputIndices, inputShape = inputs.inputShape, newShape = inputs.newShape;
      if (inputIndices.shape.length !== 2) {
        throw new Error("Input indices should be a matrix but received shape\n        ".concat(inputIndices.shape));
      }
      if (inputShape.shape.length !== 1) {
        throw new Error("Input shape should be a vector but received shape\n        ".concat(inputShape.shape));
      }
      if (newShape.shape.length !== 1) {
        throw new Error("Target shape should be a vector but received shape ".concat(newShape.shape));
      }
      var $inputShape = Array.from(backend.data.get(inputShape.dataId).values);
      var $inputIndices = backend.data.get(inputIndices.dataId).values;
      var targetShape = Array.from(backend.data.get(newShape.dataId).values);
      var _a2 = __read(sparseReshapeImpl($inputIndices, inputIndices.shape, inputIndices.dtype, $inputShape, targetShape), 3), newIndices = _a2[0], indicesShape = _a2[1], outputShape = _a2[2];
      return [
        backend.makeTensorInfo(indicesShape, inputIndices.dtype, newIndices),
        backend.makeTensorInfo([outputShape.length], newShape.dtype, new Int32Array(outputShape))
      ];
    }
    var sparseReshapeConfig = {
      kernelName: tfjsCore.SparseReshape,
      backendName: "cpu",
      kernelFunc: sparseReshape
    };
    function sparseSegmentMean(args) {
      var inputs = args.inputs, backend = args.backend;
      var data = inputs.data, indices = inputs.indices, segmentIds = inputs.segmentIds;
      if (data.shape.length < 1) {
        throw new Error("Data should be at least 1 dimensional but received scalar");
      }
      if (indices.shape.length !== 1) {
        throw new Error("Indices should be a vector but received shape\n          ".concat(indices.shape));
      }
      if (segmentIds.shape.length !== 1) {
        throw new Error("Segment ids should be a vector but received shape\n          ".concat(segmentIds.shape));
      }
      if (indices.shape[0] !== segmentIds.shape[0]) {
        throw new Error("segmentIds and indices should have same size.");
      }
      var $data = backend.data.get(data.dataId).values;
      var $indices = backend.data.get(indices.dataId).values;
      var $segmentIds = backend.data.get(segmentIds.dataId).values;
      var _a2 = __read(sparseSegmentReductionImpl($data, data.shape, data.dtype, $indices, $segmentIds, true), 2), outputData = _a2[0], outputDataShape = _a2[1];
      return backend.makeTensorInfo(outputDataShape, data.dtype, outputData);
    }
    var sparseSegmentMeanConfig = {
      kernelName: tfjsCore.SparseSegmentMean,
      backendName: "cpu",
      kernelFunc: sparseSegmentMean
    };
    function sparseSegmentSum(args) {
      var inputs = args.inputs, backend = args.backend;
      var data = inputs.data, indices = inputs.indices, segmentIds = inputs.segmentIds;
      if (data.shape.length < 1) {
        throw new Error("Data should be at least 1 dimensional but received scalar");
      }
      if (indices.shape.length !== 1) {
        throw new Error("Indices should be a vector but received shape\n         ".concat(indices.shape));
      }
      if (segmentIds.shape.length !== 1) {
        throw new Error("Segment ids should be a vector but received shape\n         ".concat(segmentIds.shape));
      }
      if (indices.shape[0] !== segmentIds.shape[0]) {
        throw new Error("segmentIds and indices should have same size.");
      }
      var $data = backend.data.get(data.dataId).values;
      var $indices = backend.data.get(indices.dataId).values;
      var $segmentIds = backend.data.get(segmentIds.dataId).values;
      var _a2 = __read(sparseSegmentReductionImpl($data, data.shape, data.dtype, $indices, $segmentIds), 2), outputData = _a2[0], outputDataShape = _a2[1];
      return backend.makeTensorInfo(outputDataShape, data.dtype, outputData);
    }
    var sparseSegmentSumConfig = {
      kernelName: tfjsCore.SparseSegmentSum,
      backendName: "cpu",
      kernelFunc: sparseSegmentSum
    };
    function sparseToDense(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var sparseIndices = inputs.sparseIndices, sparseValues = inputs.sparseValues, defaultValue = inputs.defaultValue;
      var outputShape = attrs.outputShape;
      var _a2 = tfjsCore.backend_util.calculateShapes(sparseValues, sparseIndices, outputShape), sliceRank = _a2.sliceRank, numUpdates = _a2.numUpdates, sliceSize = _a2.sliceSize, strides = _a2.strides, outputSize = _a2.outputSize;
      var sumDupeIndices = false;
      var indicesBuf = backend.bufferSync(sparseIndices);
      var outBuf;
      switch (sparseValues.dtype) {
        case "bool": {
          var updatesBuf = backend.bufferSync(sparseValues);
          var $defaultValue = Boolean(backend.data.get(defaultValue.dataId).values[0]);
          outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
          break;
        }
        case "float32": {
          var updatesBuf = backend.bufferSync(sparseValues);
          var $defaultValue = backend.data.get(defaultValue.dataId).values[0];
          outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
          break;
        }
        case "int32": {
          var updatesBuf = backend.bufferSync(sparseValues);
          var $defaultValue = backend.data.get(defaultValue.dataId).values[0];
          outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
          break;
        }
        case "string": {
          var updatesBuf = backend.bufferSync(sparseValues);
          var $defaultValue = tfjsCore.util.decodeString(backend.data.get(defaultValue.dataId).values[0]);
          outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
          break;
        }
        default:
          throw new Error("Unsupported type ".concat(sparseValues.dtype));
      }
      return backend.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);
    }
    var sparseToDenseConfig = {
      kernelName: tfjsCore.SparseToDense,
      backendName: "cpu",
      kernelFunc: sparseToDense
    };
    function splitV(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var numOrSizeSplits = attrs.numOrSizeSplits, axis = attrs.axis;
      var $axis = tfjsCore.util.parseAxisParam(axis, x.shape)[0];
      var splitSizes = tfjsCore.backend_util.prepareSplitSize(x, numOrSizeSplits, $axis);
      var begin = new Array(x.shape.length).fill(0);
      var size = x.shape.slice();
      return splitSizes.map(function(s) {
        var sliceSize = __spreadArray([], __read(size), false);
        sliceSize[$axis] = s;
        var sliceT = slice({ inputs: { x }, backend, attrs: { begin, size: sliceSize } });
        begin[$axis] += s;
        return sliceT;
      });
    }
    var splitVConfig = {
      kernelName: tfjsCore.SplitV,
      backendName: "cpu",
      kernelFunc: splitV
    };
    var squareConfig = {
      kernelName: tfjsCore.Square,
      backendName: "cpu",
      kernelFunc: function(_a2) {
        var inputs = _a2.inputs, backend = _a2.backend;
        var x = inputs.x;
        var cpuBackend = backend;
        assertNotComplex(x, "square");
        var values = cpuBackend.data.get(x.dataId).values;
        var newValues = new Float32Array(values.length);
        for (var i = 0; i < values.length; ++i) {
          var value = values[i];
          newValues[i] = value * value;
        }
        var dataId = cpuBackend.write(newValues, x.shape, x.dtype);
        return { dataId, shape: x.shape, dtype: x.dtype };
      }
    };
    var step = unaryKernelFunc(tfjsCore.Step, function(xi, attrs) {
      var stepAttrs = attrs;
      if (isNaN(xi)) {
        return NaN;
      } else {
        return xi > 0 ? 1 : stepAttrs.alpha;
      }
    });
    var stepConfig = {
      kernelName: tfjsCore.Step,
      backendName: "cpu",
      kernelFunc: step
    };
    function stridedSlice(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var begin = attrs.begin, end = attrs.end, strides = attrs.strides, beginMask = attrs.beginMask, endMask = attrs.endMask, ellipsisMask = attrs.ellipsisMask, newAxisMask = attrs.newAxisMask, shrinkAxisMask = attrs.shrinkAxisMask;
      assertNotComplex(x, "stridedSlice");
      var _a2 = tfjsCore.slice_util.sliceInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask), finalShapeSparse = _a2.finalShapeSparse, finalShape = _a2.finalShape, isIdentity = _a2.isIdentity, sliceDim0 = _a2.sliceDim0, isSimpleSlice = _a2.isSimpleSlice, $begin = _a2.begin, $end = _a2.end, $strides = _a2.strides;
      var result;
      if (isIdentity) {
        result = reshape({ inputs: { x }, backend, attrs: { shape: finalShape } });
      } else if (sliceDim0 || isSimpleSlice) {
        tfjsCore.util.assert(x.shape.length >= 1, function() {
          return "Input must have rank at least 1, got: ".concat(x.shape.length);
        });
        var size = tfjsCore.slice_util.computeOutShape($begin, $end, $strides);
        var sliced = slice({ inputs: { x }, backend, attrs: { begin: $begin, size } });
        result = reshape({ inputs: { x: sliced }, backend, attrs: { shape: finalShape } });
        backend.disposeIntermediateTensorInfo(sliced);
      } else {
        var xBuf = backend.bufferSync(x);
        var outBuf = stridedSliceImpl(finalShapeSparse, xBuf, $strides, $begin);
        result = backend.makeTensorInfo(finalShape, outBuf.dtype, outBuf.values);
      }
      return result;
    }
    var stridedSliceConfig = {
      kernelName: tfjsCore.StridedSlice,
      backendName: "cpu",
      kernelFunc: stridedSlice
    };
    function stringNGrams(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var separator = attrs.separator, nGramWidths = attrs.nGramWidths, leftPad = attrs.leftPad, rightPad = attrs.rightPad, padWidth = attrs.padWidth, preserveShortSequences = attrs.preserveShortSequences;
      var data = inputs.data, dataSplits = inputs.dataSplits;
      var $data = backend.data.get(data.dataId).values;
      var $dataSplits = backend.data.get(dataSplits.dataId).values;
      var _a2 = __read(stringNGramsImpl($data, $dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences), 2), nGrams = _a2[0], nGramsSplits = _a2[1];
      return [
        backend.makeTensorInfo([nGrams.length], "string", nGrams),
        backend.makeTensorInfo(dataSplits.shape, "int32", nGramsSplits)
      ];
    }
    var stringNGramsConfig = {
      kernelName: tfjsCore.StringNGrams,
      backendName: "cpu",
      kernelFunc: stringNGrams
    };
    function stringSplit(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var skipEmpty = attrs.skipEmpty;
      var input = inputs.input, delimiter = inputs.delimiter;
      if (input.dtype !== "string") {
        throw new Error("Input must be of datatype string");
      }
      if (input.shape.length !== 1) {
        throw new Error("Input must be a vector, got shape: ".concat(input.shape));
      }
      if (delimiter.shape.length !== 0) {
        throw new Error("Delimiter must be a scalar, got shape: ".concat(delimiter.shape));
      }
      var $input = backend.data.get(input.dataId).values;
      var $delimiter = backend.data.get(delimiter.dataId).values[0];
      var _a2 = __read(stringSplitImpl($input, $delimiter, skipEmpty), 3), indices = _a2[0], values = _a2[1], shape = _a2[2];
      var outputSize = values.length;
      return [
        backend.makeTensorInfo([outputSize, 2], "int32", indices),
        backend.makeTensorInfo([outputSize], "string", values),
        backend.makeTensorInfo([2], "int32", new Int32Array(shape))
      ];
    }
    var stringSplitConfig = {
      kernelName: tfjsCore.StringSplit,
      backendName: "cpu",
      kernelFunc: stringSplit
    };
    function stringToHashBucketFast(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var numBuckets = attrs.numBuckets;
      var input = inputs.input;
      if (input.dtype !== "string") {
        throw new Error("Input must be of datatype string");
      }
      if (numBuckets <= 0) {
        throw new Error("Number of buckets must be at least 1");
      }
      var $input = backend.data.get(input.dataId).values;
      var output = stringToHashBucketFastImpl($input, numBuckets);
      return backend.makeTensorInfo(input.shape, "int32", output);
    }
    var stringToHashBucketFastConfig = {
      kernelName: tfjsCore.StringToHashBucketFast,
      backendName: "cpu",
      kernelFunc: stringToHashBucketFast
    };
    var tan = unaryKernelFunc(tfjsCore.Tan, function(xi) {
      return Math.tan(xi);
    });
    var tanConfig = {
      kernelName: tfjsCore.Tan,
      backendName: "cpu",
      kernelFunc: tan
    };
    var tanh = unaryKernelFunc(tfjsCore.Tanh, function(xi) {
      return Math.tanh(xi);
    });
    var tanhConfig = {
      kernelName: tfjsCore.Tanh,
      backendName: "cpu",
      kernelFunc: tanh
    };
    function tensorScatterUpdate(args) {
      var inputs = args.inputs, backend = args.backend;
      var tensor = inputs.tensor, indices = inputs.indices, updates = inputs.updates;
      var _a2 = tfjsCore.backend_util.calculateShapes(updates, indices, tensor.shape), sliceRank = _a2.sliceRank, numUpdates = _a2.numUpdates, sliceSize = _a2.sliceSize, strides = _a2.strides, outputSize = _a2.outputSize;
      var sumDupeIndices = false;
      var indicesBuf = backend.bufferSync(indices);
      var updatesBuf = backend.bufferSync(updates);
      var tensorBuf = backend.bufferSync(tensor);
      var outBuf = scatterImpl(indicesBuf, updatesBuf, tensor.shape, outputSize, sliceSize, numUpdates, sliceRank, strides, tensorBuf, sumDupeIndices);
      return backend.makeTensorInfo(tensor.shape, outBuf.dtype, outBuf.values);
    }
    var tensorScatterUpdateConfig = {
      kernelName: tfjsCore.TensorScatterUpdate,
      backendName: "cpu",
      kernelFunc: tensorScatterUpdate
    };
    function tile(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var reps = attrs.reps;
      assertNotComplex(x, "tile");
      var outBuf = tileImpl(backend.bufferSync(x), reps);
      return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
    }
    var tileConfig = {
      kernelName: tfjsCore.Tile,
      backendName: "cpu",
      kernelFunc: tile
    };
    function topK(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var k = attrs.k, sorted = attrs.sorted;
      assertNotComplex(x, "topk");
      var xVals = backend.data.get(x.dataId).values;
      var _a2 = __read(topKImpl(xVals, x.shape, x.dtype, k, sorted), 2), allTopKVals = _a2[0], allTopKIndices = _a2[1];
      return [
        backend.makeTensorInfo(allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),
        backend.makeTensorInfo(allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)
      ];
    }
    var topKConfig = {
      kernelName: tfjsCore.TopK,
      backendName: "cpu",
      kernelFunc: topK
    };
    function transform(args) {
      var inputs = args.inputs, attrs = args.attrs, backend = args.backend;
      var image = inputs.image, transforms = inputs.transforms;
      var interpolation = attrs.interpolation, fillMode = attrs.fillMode, fillValue = attrs.fillValue, outputShape = attrs.outputShape;
      var _a2 = __read(image.shape, 4), batch = _a2[0], imageHeight = _a2[1], imageWidth = _a2[2], numChannels = _a2[3];
      var _b = __read(outputShape != null ? outputShape : [imageHeight, imageWidth], 2), outHeight = _b[0], outWidth = _b[1];
      var outShape = [batch, outHeight, outWidth, numChannels];
      var inStrides = tfjsCore.util.computeStrides(image.shape);
      var batchInStride = inStrides[0];
      var rowInStride = inStrides[1];
      var colInStride = inStrides[2];
      var outStrides = tfjsCore.util.computeStrides(outShape);
      var batchOutStride = outStrides[0];
      var rowOutStride = outStrides[1];
      var colOutStride = outStrides[2];
      var outVals = tfjsCore.util.getTypedArrayFromDType(image.dtype, tfjsCore.util.sizeFromShape(outShape));
      outVals.fill(fillValue);
      var imageVals = backend.data.get(image.dataId).values;
      var transformVals = backend.data.get(transforms.dataId).values;
      for (var b = 0; b < batch; ++b) {
        var transform_1 = transforms.shape[0] === 1 ? transformVals : transformVals.subarray(b * 8, b * 8 + 8);
        for (var outY = 0; outY < outHeight; ++outY) {
          for (var outX = 0; outX < outWidth; ++outX) {
            for (var channel = 0; channel < numChannels; ++channel) {
              var val = void 0;
              var projection = transform_1[6] * outX + transform_1[7] * outY + 1;
              if (projection === 0) {
                continue;
              }
              var inX = (transform_1[0] * outX + transform_1[1] * outY + transform_1[2]) / projection;
              var inY = (transform_1[3] * outX + transform_1[4] * outY + transform_1[5]) / projection;
              var x = mapCoord(inX, imageWidth, fillMode);
              var y = mapCoord(inY, imageHeight, fillMode);
              switch (interpolation) {
                case "nearest":
                  val = nearestInterpolation(imageVals, imageHeight, imageWidth, batchInStride, rowInStride, colInStride, b, y, x, channel, fillValue);
                  break;
                case "bilinear":
                  val = bilinearInterpolation(imageVals, imageHeight, imageWidth, batchInStride, rowInStride, colInStride, b, y, x, channel, fillValue);
                  break;
                default:
                  throw new Error("Error in Transform: Expect 'nearest' or " + "'bilinear', but got ".concat(interpolation));
              }
              var ind = b * batchOutStride + outY * rowOutStride + outX * colOutStride + channel;
              outVals[ind] = val;
            }
          }
        }
        return backend.makeTensorInfo(outShape, image.dtype, outVals);
      }
      var dataId = backend.write(outVals, outShape, image.dtype);
      return { dataId, shape: image.shape, dtype: image.dtype };
    }
    var transformConfig = {
      kernelName: tfjsCore.Transform,
      backendName: "cpu",
      kernelFunc: transform
    };
    function mapCoord(outCoord, len, mode) {
      switch (mode) {
        case "reflect":
          return mapCoordReflect(outCoord, len);
        case "wrap":
          return mapCoordWrap(outCoord, len);
        case "nearest":
          return mapCoordNearest(outCoord, len);
        case "constant":
        default:
          return mapCoordConstant(outCoord);
      }
    }
    function mapCoordReflect(outCoord, len) {
      var inCoord = outCoord;
      if (inCoord < 0) {
        if (len <= 1) {
          inCoord = 0;
        } else {
          var sz2 = 2 * len;
          if (inCoord < sz2) {
            inCoord = sz2 * Math.trunc(-inCoord / sz2) + inCoord;
          }
          inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1;
        }
      } else if (inCoord > len - 1) {
        if (len <= 1) {
          inCoord = 0;
        } else {
          var sz2 = 2 * len;
          inCoord -= sz2 * Math.trunc(inCoord / sz2);
          if (inCoord >= len) {
            inCoord = sz2 - inCoord - 1;
          }
        }
      }
      return tfjsCore.util.clamp(0, inCoord, len - 1);
    }
    function mapCoordWrap(outCoord, len) {
      var inCoord = outCoord;
      if (inCoord < 0) {
        if (len <= 1) {
          inCoord = 0;
        } else {
          var sz = len - 1;
          inCoord += len * (Math.trunc(-inCoord / sz) + 1);
        }
      } else if (inCoord > len - 1) {
        if (len <= 1) {
          inCoord = 0;
        } else {
          var sz = len - 1;
          inCoord -= len * Math.trunc(inCoord / sz);
        }
      }
      return tfjsCore.util.clamp(0, inCoord, len - 1);
    }
    function mapCoordConstant(outCoord, len) {
      return outCoord;
    }
    function mapCoordNearest(outCoord, len) {
      return tfjsCore.util.clamp(0, outCoord, len - 1);
    }
    function readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
      var ind = batch * batchStride + y * rowStride + x * colStride + channel;
      if (0 <= y && y < imageHeight && 0 <= x && x < imageWidth) {
        return imageVals[ind];
      } else {
        return fillValue;
      }
    }
    function nearestInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
      var $y = Math.round(y);
      var $x = Math.round(x);
      return readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, $y, $x, channel, fillValue);
    }
    function bilinearInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
      var yFloor = Math.floor(y);
      var xFloor = Math.floor(x);
      var yCeil = yFloor + 1;
      var xCeil = xFloor + 1;
      var valueYFloor = (xCeil - x) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yFloor, xFloor, channel, fillValue) + (x - xFloor) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yFloor, xCeil, channel, fillValue);
      var valueYCeil = (xCeil - x) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yCeil, xFloor, channel, fillValue) + (x - xFloor) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yCeil, xCeil, channel, fillValue);
      return (yCeil - y) * valueYFloor + (y - yFloor) * valueYCeil;
    }
    function unique(args) {
      var inputs = args.inputs, attrs = args.attrs, backend = args.backend;
      var axis = attrs.axis;
      var x = inputs.x;
      assertNotComplex(x, "unique");
      var values = backend.data.get(x.dataId).values;
      var _a2 = uniqueImpl(values, axis, x.shape, x.dtype), outputValues = _a2.outputValues, outputShape = _a2.outputShape, indices = _a2.indices;
      return [
        backend.makeTensorInfo(outputShape, x.dtype, outputValues),
        backend.makeTensorInfo([indices.length], "int32", indices)
      ];
    }
    var uniqueConfig = {
      kernelName: tfjsCore.Unique,
      backendName: "cpu",
      kernelFunc: unique
    };
    function unpack(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var value = inputs.value;
      var axis = attrs.axis;
      if (axis < 0) {
        axis += value.shape.length;
      }
      var valueRank = value.shape.length;
      var num = value.shape[axis];
      var outShape = new Array(valueRank - 1);
      var outIndex = 0;
      for (var i = 0; i < valueRank; i++) {
        if (i !== axis) {
          outShape[outIndex++] = value.shape[i];
        }
      }
      var begin = new Array(valueRank).fill(0);
      var size = value.shape.slice();
      size[axis] = 1;
      var res = new Array(num);
      for (var i = 0; i < res.length; i++) {
        begin[axis] = i;
        var tempRes = slice({ inputs: { x: value }, backend, attrs: { begin, size } });
        res[i] = reshape({ inputs: { x: tempRes }, backend, attrs: { shape: outShape } });
        backend.disposeIntermediateTensorInfo(tempRes);
      }
      return res;
    }
    var unpackConfig = {
      kernelName: tfjsCore.Unpack,
      backendName: "cpu",
      kernelFunc: unpack
    };
    function unsortedSegmentSum(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, segmentIds = inputs.segmentIds;
      var numSegments = attrs.numSegments;
      assertNotComplex(x, "unsortedSegmentSum");
      var xRank = x.shape.length;
      var segmentIdsRank = segmentIds.shape.length;
      var res = [];
      var intermediates = [];
      var numIters = xRank - segmentIdsRank;
      var $segmentIds = segmentIds;
      for (var i = 0; i < numIters; ++i) {
        var expanded = expandDims({ inputs: { input: $segmentIds }, backend, attrs: { dim: i + 1 } });
        $segmentIds = expanded;
        intermediates.push(expanded);
      }
      for (var i = 0; i < numSegments; ++i) {
        var scalarValue = tfjsCore.util.createScalarValue(i, "int32");
        var segmentId = backend.makeTensorInfo([], "int32", scalarValue);
        var mask = equal({ inputs: { a: segmentId, b: $segmentIds }, backend });
        var maskCasted = cast({ inputs: { x: mask }, backend, attrs: { dtype: "float32" } });
        var mul = multiply({ inputs: { a: maskCasted, b: x }, backend });
        var sumTensorInfo = sum({ inputs: { x: mul }, backend, attrs: { axis: 0, keepDims: false } });
        res.push(sumTensorInfo);
        intermediates.push(segmentId);
        intermediates.push(mask);
        intermediates.push(maskCasted);
        intermediates.push(mul);
        intermediates.push(sumTensorInfo);
      }
      var result = pack({ inputs: res, backend, attrs: { axis: 0 } });
      intermediates.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return result;
    }
    var unsortedSegmentSumConfig = {
      kernelName: tfjsCore.UnsortedSegmentSum,
      backendName: "cpu",
      kernelFunc: unsortedSegmentSum
    };
    var e_1;
    var _a;
    var kernelConfigs = [
      _fusedMatMulConfig,
      absConfig,
      acosConfig,
      acoshConfig,
      addConfig,
      addNConfig,
      allConfig,
      anyConfig,
      argMaxConfig,
      argMinConfig,
      asinConfig,
      asinhConfig,
      atanConfig,
      atan2Config,
      atanhConfig,
      avgPoolConfig,
      avgPool3DConfig,
      avgPool3DGradConfig,
      avgPoolGradConfig,
      batchMatMulConfig,
      batchNormConfig,
      batchToSpaceNDConfig,
      bincountConfig,
      bitwiseAndConfig,
      broadcastArgsConfig,
      castConfig,
      ceilConfig,
      clipByValueConfig,
      complexConfig,
      complexAbsConfig,
      concatConfig,
      conv2DConfig,
      conv2DBackpropFilterConfig,
      conv2DBackpropInputConfig,
      conv3DConfig,
      conv3DBackpropFilterV2Config,
      conv3DBackpropInputV2Config,
      cosConfig,
      coshConfig,
      cropAndResizeConfig,
      cumprodConfig,
      cumsumConfig,
      denseBincountConfig,
      depthToSpaceConfig,
      depthwiseConv2dNativeConfig,
      depthwiseConv2dNativeBackpropFilterConfig,
      depthwiseConv2dNativeBackpropInputConfig,
      diagConfig,
      dilation2DConfig,
      dilation2DBackpropFilterConfig,
      dilation2DBackpropInputConfig,
      drawConfig,
      einsumConfig,
      eluConfig,
      eluGradConfig,
      equalConfig,
      erfConfig,
      expConfig,
      expandDimsConfig,
      expm1Config,
      fftConfig,
      fillConfig,
      flipLeftRightConfig,
      floorConfig,
      floorDivConfig,
      fusedConv2DConfig,
      fusedDepthwiseConv2DConfig,
      gatherNdConfig,
      gatherV2Config,
      greaterConfig,
      greaterEqualConfig,
      identityConfig,
      ifftConfig,
      imagConfig,
      isFiniteConfig,
      isInfConfig,
      isNaNConfig,
      leakyReluConfig,
      lessConfig,
      lessEqualConfig,
      linSpaceConfig,
      logConfig,
      log1pConfig,
      logicalAndConfig,
      logicalNotConfig,
      logicalOrConfig,
      LRNConfig,
      LRNGradConfig,
      maxConfig,
      maximumConfig,
      maxPoolConfig,
      maxPool3DConfig,
      maxPool3DGradConfig,
      maxPoolGradConfig,
      maxPoolWithArgmaxConfig,
      meanConfig,
      minConfig,
      minimumConfig,
      mirrorPadConfig,
      modConfig,
      multinomialConfig,
      multiplyConfig,
      negConfig,
      nonMaxSuppressionV3Config,
      nonMaxSuppressionV4Config,
      nonMaxSuppressionV5Config,
      notEqualConfig,
      oneHotConfig,
      onesLikeConfig,
      packConfig,
      padV2Config,
      powConfig,
      preluConfig,
      prodConfig,
      raggedGatherConfig,
      raggedRangeConfig,
      raggedTensorToTensorConfig,
      rangeConfig,
      realConfig,
      realDivConfig,
      reciprocalConfig,
      reluConfig,
      relu6Config,
      reshapeConfig,
      resizeBilinearConfig,
      resizeBilinearGradConfig,
      resizeNearestNeighborConfig,
      resizeNearestNeighborGradConfig,
      reverseConfig,
      rotateWithOffsetConfig,
      roundConfig,
      rsqrtConfig,
      scatterNdConfig,
      searchSortedConfig,
      selectConfig,
      seluConfig,
      sigmoidConfig,
      signConfig,
      sinConfig,
      sinhConfig,
      sliceConfig,
      softmaxConfig,
      softplusConfig,
      spaceToBatchNDConfig,
      sparseFillEmptyRowsConfig,
      sparseReshapeConfig,
      sparseSegmentMeanConfig,
      sparseSegmentSumConfig,
      sparseToDenseConfig,
      splitVConfig,
      sqrtConfig,
      squareConfig,
      squaredDifferenceConfig,
      staticRegexReplaceConfig,
      stepConfig,
      stridedSliceConfig,
      stringNGramsConfig,
      stringSplitConfig,
      stringToHashBucketFastConfig,
      subConfig,
      sumConfig,
      tanConfig,
      tanhConfig,
      tensorScatterUpdateConfig,
      tileConfig,
      topKConfig,
      transformConfig,
      transposeConfig,
      uniqueConfig,
      unpackConfig,
      unsortedSegmentSumConfig,
      zerosLikeConfig
    ];
    try {
      for (kernelConfigs_1 = __values(kernelConfigs), kernelConfigs_1_1 = kernelConfigs_1.next(); !kernelConfigs_1_1.done; kernelConfigs_1_1 = kernelConfigs_1.next()) {
        kernelConfig = kernelConfigs_1_1.value;
        tfjsCore.registerKernel(kernelConfig);
      }
    } catch (e_1_1) {
      e_1 = { error: e_1_1 };
    } finally {
      try {
        if (kernelConfigs_1_1 && !kernelConfigs_1_1.done && (_a = kernelConfigs_1.return))
          _a.call(kernelConfigs_1);
      } finally {
        if (e_1)
          throw e_1.error;
      }
    }
    var kernelConfig;
    var kernelConfigs_1;
    var kernelConfigs_1_1;
    exports.MathBackendCPU = MathBackendCPU;
    exports.shared = shared;
    exports.version_cpu = version;
  }
});

// node_modules/@tensorflow/tfjs-backend-webgl/dist/tf-backend-webgl.node.js
var require_tf_backend_webgl_node = __commonJS({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/tf-backend-webgl.node.js"(exports) {
    "use strict";
    var tf = require_tf_core_node();
    function _interopNamespaceDefault(e) {
      var n = /* @__PURE__ */ Object.create(null);
      if (e) {
        Object.keys(e).forEach(function(k) {
          if (k !== "default") {
            var d = Object.getOwnPropertyDescriptor(e, k);
            Object.defineProperty(n, k, d.get ? d : {
              enumerable: true,
              get: function() {
                return e[k];
              }
            });
          }
        });
      }
      n.default = e;
      return n;
    }
    var tf__namespace = /* @__PURE__ */ _interopNamespaceDefault(tf);
    var extendStatics = function(d, b) {
      extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(d2, b2) {
        d2.__proto__ = b2;
      } || function(d2, b2) {
        for (var p in b2)
          if (Object.prototype.hasOwnProperty.call(b2, p))
            d2[p] = b2[p];
      };
      return extendStatics(d, b);
    };
    function __extends(d, b) {
      if (typeof b !== "function" && b !== null)
        throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
      extendStatics(d, b);
      function __() {
        this.constructor = d;
      }
      d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    }
    function __awaiter(thisArg, _arguments, P, generator) {
      function adopt(value) {
        return value instanceof P ? value : new P(function(resolve) {
          resolve(value);
        });
      }
      return new (P || (P = Promise))(function(resolve, reject) {
        function fulfilled(value) {
          try {
            step2(generator.next(value));
          } catch (e) {
            reject(e);
          }
        }
        function rejected(value) {
          try {
            step2(generator["throw"](value));
          } catch (e) {
            reject(e);
          }
        }
        function step2(result) {
          result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step2((generator = generator.apply(thisArg, _arguments || [])).next());
      });
    }
    function __generator(thisArg, body) {
      var _ = { label: 0, sent: function() {
        if (t[0] & 1)
          throw t[1];
        return t[1];
      }, trys: [], ops: [] }, f, y, t, g;
      return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
      }), g;
      function verb(n) {
        return function(v) {
          return step2([n, v]);
        };
      }
      function step2(op) {
        if (f)
          throw new TypeError("Generator is already executing.");
        while (_)
          try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done)
              return t;
            if (y = 0, t)
              op = [op[0] & 2, t.value];
            switch (op[0]) {
              case 0:
              case 1:
                t = op;
                break;
              case 4:
                _.label++;
                return { value: op[1], done: false };
              case 5:
                _.label++;
                y = op[1];
                op = [0];
                continue;
              case 7:
                op = _.ops.pop();
                _.trys.pop();
                continue;
              default:
                if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {
                  _ = 0;
                  continue;
                }
                if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {
                  _.label = op[1];
                  break;
                }
                if (op[0] === 6 && _.label < t[1]) {
                  _.label = t[1];
                  t = op;
                  break;
                }
                if (t && _.label < t[2]) {
                  _.label = t[2];
                  _.ops.push(op);
                  break;
                }
                if (t[2])
                  _.ops.pop();
                _.trys.pop();
                continue;
            }
            op = body.call(thisArg, _);
          } catch (e) {
            op = [6, e];
            y = 0;
          } finally {
            f = t = 0;
          }
        if (op[0] & 5)
          throw op[1];
        return { value: op[0] ? op[1] : void 0, done: true };
      }
    }
    function __values(o) {
      var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
      if (m)
        return m.call(o);
      if (o && typeof o.length === "number")
        return {
          next: function() {
            if (o && i >= o.length)
              o = void 0;
            return { value: o && o[i++], done: !o };
          }
        };
      throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
    }
    function __read(o, n) {
      var m = typeof Symbol === "function" && o[Symbol.iterator];
      if (!m)
        return o;
      var i = m.call(o), r, ar = [], e;
      try {
        while ((n === void 0 || n-- > 0) && !(r = i.next()).done)
          ar.push(r.value);
      } catch (error) {
        e = { error };
      } finally {
        try {
          if (r && !r.done && (m = i["return"]))
            m.call(i);
        } finally {
          if (e)
            throw e.error;
        }
      }
      return ar;
    }
    function __spreadArray(to, from, pack2) {
      if (pack2 || arguments.length === 2)
        for (var i = 0, l = from.length, ar; i < l; i++) {
          if (ar || !(i in from)) {
            if (!ar)
              ar = Array.prototype.slice.call(from, 0, i);
            ar[i] = from[i];
          }
        }
      return to.concat(ar || Array.prototype.slice.call(from));
    }
    var contexts = {};
    var WEBGL_ATTRIBUTES = {
      alpha: false,
      antialias: false,
      premultipliedAlpha: false,
      preserveDrawingBuffer: false,
      depth: false,
      stencil: false,
      failIfMajorPerformanceCaveat: true
    };
    function setWebGLContext(webGLVersion, gl) {
      contexts[webGLVersion] = gl;
    }
    function getWebGLContext(webGLVersion, customCanvas) {
      if (!(webGLVersion in contexts) || customCanvas != null) {
        var newCtx = getWebGLRenderingContext(webGLVersion, customCanvas);
        if (newCtx !== null) {
          contexts[webGLVersion] = newCtx;
        } else {
          console.log("Could not get context for WebGL version", webGLVersion);
          return null;
        }
      }
      var gl = contexts[webGLVersion];
      if (gl == null || gl.isContextLost()) {
        delete contexts[webGLVersion];
        return getWebGLContext(webGLVersion);
      }
      gl.disable(gl.DEPTH_TEST);
      gl.disable(gl.STENCIL_TEST);
      gl.disable(gl.BLEND);
      gl.disable(gl.DITHER);
      gl.disable(gl.POLYGON_OFFSET_FILL);
      gl.disable(gl.SAMPLE_COVERAGE);
      gl.enable(gl.SCISSOR_TEST);
      gl.enable(gl.CULL_FACE);
      gl.cullFace(gl.BACK);
      return contexts[webGLVersion];
    }
    function createCanvas(webGLVersion) {
      if (!tf.env().getBool("IS_SAFARI") && typeof OffscreenCanvas !== "undefined" && webGLVersion === 2) {
        return new OffscreenCanvas(300, 150);
      } else if (typeof document !== "undefined") {
        return document.createElement("canvas");
      } else {
        throw new Error("Cannot create a canvas in this context");
      }
    }
    function getWebGLRenderingContext(webGLVersion, customCanvas) {
      if (webGLVersion !== 1 && webGLVersion !== 2) {
        throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");
      }
      var canvas = customCanvas == null ? createCanvas(webGLVersion) : customCanvas;
      canvas.addEventListener("webglcontextlost", function(ev) {
        ev.preventDefault();
        delete contexts[webGLVersion];
      }, false);
      if (tf.env().getBool("SOFTWARE_WEBGL_ENABLED")) {
        WEBGL_ATTRIBUTES.failIfMajorPerformanceCaveat = false;
      }
      if (webGLVersion === 1) {
        return (
          // tslint:disable-next-line
          canvas.getContext("webgl", WEBGL_ATTRIBUTES) || canvas.getContext("experimental-webgl", WEBGL_ATTRIBUTES)
        );
      }
      return canvas.getContext("webgl2", WEBGL_ATTRIBUTES);
    }
    var PackingScheme;
    (function(PackingScheme2) {
      PackingScheme2[PackingScheme2["DENSE"] = 0] = "DENSE";
      PackingScheme2[PackingScheme2["SHARED_BATCH"] = 1] = "SHARED_BATCH";
    })(PackingScheme || (PackingScheme = {}));
    var TextureUsage;
    (function(TextureUsage2) {
      TextureUsage2[TextureUsage2["RENDER"] = 0] = "RENDER";
      TextureUsage2[TextureUsage2["UPLOAD"] = 1] = "UPLOAD";
      TextureUsage2[TextureUsage2["PIXELS"] = 2] = "PIXELS";
      TextureUsage2[TextureUsage2["DOWNLOAD"] = 3] = "DOWNLOAD";
    })(TextureUsage || (TextureUsage = {}));
    var PhysicalTextureType;
    (function(PhysicalTextureType2) {
      PhysicalTextureType2[PhysicalTextureType2["UNPACKED_FLOAT16"] = 0] = "UNPACKED_FLOAT16";
      PhysicalTextureType2[PhysicalTextureType2["UNPACKED_FLOAT32"] = 1] = "UNPACKED_FLOAT32";
      PhysicalTextureType2[PhysicalTextureType2["PACKED_4X1_UNSIGNED_BYTE"] = 2] = "PACKED_4X1_UNSIGNED_BYTE";
      PhysicalTextureType2[PhysicalTextureType2["PACKED_2X2_FLOAT32"] = 3] = "PACKED_2X2_FLOAT32";
      PhysicalTextureType2[PhysicalTextureType2["PACKED_2X2_FLOAT16"] = 4] = "PACKED_2X2_FLOAT16";
    })(PhysicalTextureType || (PhysicalTextureType = {}));
    function getUnpackedMatrixTextureShapeWidthHeight(rows, columns) {
      return [columns, rows];
    }
    function getUnpackedArraySizeFromMatrixSize(matrixSize, channelsPerTexture) {
      return matrixSize * channelsPerTexture;
    }
    function getDenseTexShape(shape) {
      var size = tf.util.sizeFromShape(shape);
      var texelsNeeded = Math.ceil(size / 4);
      return tf.util.sizeToSquarishShape(texelsNeeded);
    }
    function getPackedMatrixTextureShapeWidthHeight(rows, columns) {
      return [
        Math.max(1, Math.ceil(columns / 2)),
        Math.max(1, Math.ceil(rows / 2))
      ];
    }
    function getPackedRGBAArraySizeFromMatrixShape(rows, columns) {
      var _a2 = __read(getPackedMatrixTextureShapeWidthHeight(rows, columns), 2), w = _a2[0], h = _a2[1];
      return w * h * 4;
    }
    function getTextureConfig(gl, textureHalfFloatExtension) {
      var glany = gl;
      var internalFormatFloat;
      var internalFormatHalfFloat;
      var internalFormatPackedHalfFloat;
      var internalFormatPackedFloat;
      var textureFormatFloat;
      var downloadTextureFormat;
      var downloadUnpackNumChannels;
      var defaultNumChannels;
      var textureTypeHalfFloat;
      var textureTypeFloat;
      if (tf.env().getNumber("WEBGL_VERSION") === 2) {
        internalFormatFloat = glany.R32F;
        internalFormatHalfFloat = glany.R16F;
        internalFormatPackedHalfFloat = glany.RGBA16F;
        internalFormatPackedFloat = glany.RGBA32F;
        textureFormatFloat = glany.RED;
        downloadUnpackNumChannels = 4;
        defaultNumChannels = 1;
        textureTypeHalfFloat = glany.HALF_FLOAT;
        textureTypeFloat = glany.FLOAT;
        downloadTextureFormat = glany.RGBA8;
      } else {
        internalFormatFloat = gl.RGBA;
        internalFormatHalfFloat = gl.RGBA;
        internalFormatPackedHalfFloat = gl.RGBA;
        internalFormatPackedFloat = glany.RGBA;
        textureFormatFloat = gl.RGBA;
        downloadUnpackNumChannels = 4;
        defaultNumChannels = 4;
        textureTypeHalfFloat = textureHalfFloatExtension != null ? textureHalfFloatExtension.HALF_FLOAT_OES : null;
        textureTypeFloat = gl.FLOAT;
        downloadTextureFormat = gl.RGBA;
      }
      return {
        internalFormatFloat,
        internalFormatHalfFloat,
        internalFormatPackedHalfFloat,
        internalFormatPackedFloat,
        textureFormatFloat,
        downloadTextureFormat,
        downloadUnpackNumChannels,
        defaultNumChannels,
        textureTypeHalfFloat,
        textureTypeFloat
      };
    }
    function callAndCheck(gl, func) {
      var returnValue = func();
      if (tf.env().getBool("DEBUG")) {
        checkWebGLError(gl);
      }
      return returnValue;
    }
    function checkWebGLError(gl) {
      var error = gl.getError();
      if (error !== gl.NO_ERROR) {
        throw new Error("WebGL Error: " + getWebGLErrorMessage(gl, error));
      }
    }
    var MIN_FLOAT16 = 596e-10;
    var MAX_FLOAT16 = 65504;
    function canBeRepresented(num) {
      if (tf.env().getBool("WEBGL_RENDER_FLOAT32_ENABLED") || num === 0 || MIN_FLOAT16 < Math.abs(num) && Math.abs(num) < MAX_FLOAT16) {
        return true;
      }
      return false;
    }
    function getWebGLErrorMessage(gl, status) {
      switch (status) {
        case gl.NO_ERROR:
          return "NO_ERROR";
        case gl.INVALID_ENUM:
          return "INVALID_ENUM";
        case gl.INVALID_VALUE:
          return "INVALID_VALUE";
        case gl.INVALID_OPERATION:
          return "INVALID_OPERATION";
        case gl.INVALID_FRAMEBUFFER_OPERATION:
          return "INVALID_FRAMEBUFFER_OPERATION";
        case gl.OUT_OF_MEMORY:
          return "OUT_OF_MEMORY";
        case gl.CONTEXT_LOST_WEBGL:
          return "CONTEXT_LOST_WEBGL";
        default:
          return "Unknown error code ".concat(status);
      }
    }
    function getExtensionOrThrow(gl, extensionName) {
      return throwIfNull(gl, function() {
        return gl.getExtension(extensionName);
      }, 'Extension "' + extensionName + '" not supported on this browser.');
    }
    function createVertexShader$1(gl, vertexShaderSource) {
      var vertexShader = throwIfNull(gl, function() {
        return gl.createShader(gl.VERTEX_SHADER);
      }, "Unable to create vertex WebGLShader.");
      callAndCheck(gl, function() {
        return gl.shaderSource(vertexShader, vertexShaderSource);
      });
      callAndCheck(gl, function() {
        return gl.compileShader(vertexShader);
      });
      if (gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS) === false) {
        console.log(gl.getShaderInfoLog(vertexShader));
        throw new Error("Failed to compile vertex shader.");
      }
      return vertexShader;
    }
    function createFragmentShader(gl, fragmentShaderSource) {
      var fragmentShader = throwIfNull(gl, function() {
        return gl.createShader(gl.FRAGMENT_SHADER);
      }, "Unable to create fragment WebGLShader.");
      callAndCheck(gl, function() {
        return gl.shaderSource(fragmentShader, fragmentShaderSource);
      });
      callAndCheck(gl, function() {
        return gl.compileShader(fragmentShader);
      });
      if (tf.env().get("ENGINE_COMPILE_ONLY")) {
        return fragmentShader;
      }
      if (gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS) === false) {
        logShaderSourceAndInfoLog(fragmentShaderSource, gl.getShaderInfoLog(fragmentShader));
        throw new Error("Failed to compile fragment shader.");
      }
      return fragmentShader;
    }
    var lineNumberRegex = /ERROR: [0-9]+:([0-9]+):/g;
    function logShaderSourceAndInfoLog(shaderSource, shaderInfoLog) {
      var lineNumberRegexResult = lineNumberRegex.exec(shaderInfoLog);
      if (lineNumberRegexResult == null) {
        console.log("Couldn't parse line number in error: ".concat(shaderInfoLog));
        console.log(shaderSource);
        return;
      }
      var lineNumber = +lineNumberRegexResult[1];
      var shaderLines = shaderSource.split("\n");
      var pad = shaderLines.length.toString().length + 2;
      var linesWithLineNumbers = shaderLines.map(function(line, lineNumber2) {
        return tf.util.rightPad((lineNumber2 + 1).toString(), pad) + line;
      });
      var maxLineLength = 0;
      for (var i = 0; i < linesWithLineNumbers.length; i++) {
        maxLineLength = Math.max(linesWithLineNumbers[i].length, maxLineLength);
      }
      var beforeErrorLines = linesWithLineNumbers.slice(0, lineNumber - 1);
      var errorLine = linesWithLineNumbers.slice(lineNumber - 1, lineNumber);
      var afterErrorLines = linesWithLineNumbers.slice(lineNumber);
      console.log(beforeErrorLines.join("\n"));
      console.log(shaderInfoLog.split("\n")[0]);
      console.log("%c ".concat(tf.util.rightPad(errorLine[0], maxLineLength)), "border:1px solid red; background-color:#e3d2d2; color:#a61717");
      console.log(afterErrorLines.join("\n"));
    }
    function createProgram(gl) {
      return throwIfNull(gl, function() {
        return gl.createProgram();
      }, "Unable to create WebGLProgram.");
    }
    function linkProgram(gl, program) {
      callAndCheck(gl, function() {
        return gl.linkProgram(program);
      });
      if (tf.env().get("ENGINE_COMPILE_ONLY")) {
        return;
      }
      if (gl.getProgramParameter(program, gl.LINK_STATUS) === false) {
        console.log(gl.getProgramInfoLog(program));
        throw new Error("Failed to link vertex and fragment shaders.");
      }
    }
    function validateProgram(gl, program) {
      callAndCheck(gl, function() {
        return gl.validateProgram(program);
      });
      if (gl.getProgramParameter(program, gl.VALIDATE_STATUS) === false) {
        console.log(gl.getProgramInfoLog(program));
        throw new Error("Shader program validation failed.");
      }
    }
    function createStaticVertexBuffer(gl, data) {
      var buffer = throwIfNull(gl, function() {
        return gl.createBuffer();
      }, "Unable to create WebGLBuffer");
      callAndCheck(gl, function() {
        return gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
      });
      callAndCheck(gl, function() {
        return gl.bufferData(gl.ARRAY_BUFFER, data, gl.STATIC_DRAW);
      });
      return buffer;
    }
    function createStaticIndexBuffer(gl, data) {
      var buffer = throwIfNull(gl, function() {
        return gl.createBuffer();
      }, "Unable to create WebGLBuffer");
      callAndCheck(gl, function() {
        return gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, buffer);
      });
      callAndCheck(gl, function() {
        return gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, data, gl.STATIC_DRAW);
      });
      return buffer;
    }
    function getNumChannels() {
      if (tf.env().getNumber("WEBGL_VERSION") === 2) {
        return 1;
      }
      return 4;
    }
    function createTexture(gl) {
      return throwIfNull(gl, function() {
        return gl.createTexture();
      }, "Unable to create WebGLTexture.");
    }
    function validateTextureSize(width, height) {
      var maxTextureSize = tf.env().getNumber("WEBGL_MAX_TEXTURE_SIZE");
      if (width <= 0 || height <= 0) {
        var requested = "[".concat(width, "x").concat(height, "]");
        throw new Error("Requested texture size " + requested + " is invalid.");
      }
      if (width > maxTextureSize || height > maxTextureSize) {
        var requested = "[".concat(width, "x").concat(height, "]");
        var max2 = "[".concat(maxTextureSize, "x").concat(maxTextureSize, "]");
        throw new Error("Requested texture size " + requested + " greater than WebGL maximum on this browser / GPU " + max2 + ".");
      }
    }
    function createFramebuffer(gl) {
      return throwIfNull(gl, function() {
        return gl.createFramebuffer();
      }, "Unable to create WebGLFramebuffer.");
    }
    function bindVertexBufferToProgramAttribute(gl, program, attribute, buffer, arrayEntriesPerItem, itemStrideInBytes, itemOffsetInBytes) {
      var loc = gl.getAttribLocation(program, attribute);
      if (loc === -1) {
        return false;
      }
      callAndCheck(gl, function() {
        return gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
      });
      callAndCheck(gl, function() {
        return gl.vertexAttribPointer(loc, arrayEntriesPerItem, gl.FLOAT, false, itemStrideInBytes, itemOffsetInBytes);
      });
      callAndCheck(gl, function() {
        return gl.enableVertexAttribArray(loc);
      });
      return true;
    }
    function bindTextureUnit(gl, texture, textureUnit) {
      validateTextureUnit(gl, textureUnit);
      callAndCheck(gl, function() {
        return gl.activeTexture(gl.TEXTURE0 + textureUnit);
      });
      callAndCheck(gl, function() {
        return gl.bindTexture(gl.TEXTURE_2D, texture);
      });
    }
    function unbindTextureUnit(gl, textureUnit) {
      validateTextureUnit(gl, textureUnit);
      callAndCheck(gl, function() {
        return gl.activeTexture(gl.TEXTURE0 + textureUnit);
      });
      callAndCheck(gl, function() {
        return gl.bindTexture(gl.TEXTURE_2D, null);
      });
    }
    function getProgramUniformLocationOrThrow(gl, program, uniformName) {
      return throwIfNull(gl, function() {
        return gl.getUniformLocation(program, uniformName);
      }, 'uniform "' + uniformName + '" not present in program.');
    }
    function getProgramUniformLocation(gl, program, uniformName) {
      return gl.getUniformLocation(program, uniformName);
    }
    function bindTextureToProgramUniformSampler(gl, texture, uniformSamplerLocation, textureUnit) {
      callAndCheck(gl, function() {
        return bindTextureUnit(gl, texture, textureUnit);
      });
      callAndCheck(gl, function() {
        return gl.uniform1i(uniformSamplerLocation, textureUnit);
      });
    }
    function bindCanvasToFramebuffer(gl) {
      callAndCheck(gl, function() {
        return gl.bindFramebuffer(gl.FRAMEBUFFER, null);
      });
      callAndCheck(gl, function() {
        return gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
      });
      callAndCheck(gl, function() {
        return gl.scissor(0, 0, gl.canvas.width, gl.canvas.height);
      });
    }
    function bindColorTextureToFramebuffer(gl, texture, framebuffer) {
      callAndCheck(gl, function() {
        return gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
      });
      callAndCheck(gl, function() {
        return gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);
      });
    }
    function unbindColorTextureFromFramebuffer(gl, framebuffer) {
      callAndCheck(gl, function() {
        return gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
      });
      callAndCheck(gl, function() {
        return gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, null, 0);
      });
    }
    function validateFramebuffer(gl) {
      var status = gl.checkFramebufferStatus(gl.FRAMEBUFFER);
      if (status !== gl.FRAMEBUFFER_COMPLETE) {
        throw new Error("Error binding framebuffer: " + getFramebufferErrorMessage(gl, status));
      }
    }
    function getFramebufferErrorMessage(gl, status) {
      switch (status) {
        case gl.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:
          return "FRAMEBUFFER_INCOMPLETE_ATTACHMENT";
        case gl.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:
          return "FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";
        case gl.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:
          return "FRAMEBUFFER_INCOMPLETE_DIMENSIONS";
        case gl.FRAMEBUFFER_UNSUPPORTED:
          return "FRAMEBUFFER_UNSUPPORTED";
        default:
          return "unknown error ".concat(status);
      }
    }
    function throwIfNull(gl, returnTOrNull, failureMessage) {
      var tOrNull = callAndCheck(gl, function() {
        return returnTOrNull();
      });
      if (tOrNull == null) {
        throw new Error(failureMessage);
      }
      return tOrNull;
    }
    function validateTextureUnit(gl, textureUnit) {
      var maxTextureUnit = gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1;
      var glTextureUnit = textureUnit + gl.TEXTURE0;
      if (glTextureUnit < gl.TEXTURE0 || glTextureUnit > maxTextureUnit) {
        var textureUnitRange = "[gl.TEXTURE0, gl.TEXTURE".concat(maxTextureUnit, "]");
        throw new Error("textureUnit must be in ".concat(textureUnitRange, "."));
      }
    }
    function getBatchDim(shape, dimsToSkip) {
      if (dimsToSkip === void 0) {
        dimsToSkip = 2;
      }
      return tf.util.sizeFromShape(shape.slice(0, shape.length - dimsToSkip));
    }
    function getRowsCols(shape) {
      if (shape.length === 0) {
        throw Error("Cannot get rows and columns of an empty shape array.");
      }
      return [
        shape.length > 1 ? shape[shape.length - 2] : 1,
        shape[shape.length - 1]
      ];
    }
    function getShapeAs3D(shape) {
      var shapeAs3D = [1, 1, 1];
      var isScalar = shape.length === 0 || shape.length === 1 && shape[0] === 1;
      if (!isScalar) {
        shapeAs3D = __spreadArray([getBatchDim(shape)], __read(getRowsCols(shape)), false);
      }
      return shapeAs3D;
    }
    function getTextureShapeFromLogicalShape(logShape, isPacked) {
      var _a2;
      if (isPacked === void 0) {
        isPacked = false;
      }
      var maxTexSize = tf.env().getNumber("WEBGL_MAX_TEXTURE_SIZE");
      var maxSizeForNarrowTex = tf.env().getNumber("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE");
      if (maxSizeForNarrowTex === Infinity && tf.env().getBool("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE")) {
        maxSizeForNarrowTex = maxTexSize / 2;
      }
      if (isPacked) {
        maxTexSize = maxTexSize * 2;
        maxSizeForNarrowTex = maxSizeForNarrowTex * 2;
        logShape = logShape.map(function(d, i) {
          return i >= logShape.length - 2 ? tf.util.nearestLargerEven(logShape[i]) : logShape[i];
        });
        if (logShape.length === 1) {
          logShape = [2, logShape[0]];
        }
      }
      if (logShape.length !== 2) {
        var squeezeResult = tf.util.squeezeShape(logShape);
        logShape = squeezeResult.newShape;
      }
      var size = tf.util.sizeFromShape(logShape);
      var textureShape = null;
      if (logShape.length <= 1 && size <= maxTexSize) {
        textureShape = [1, size];
      } else if (logShape.length === 2 && logShape[0] <= maxTexSize && logShape[1] <= maxTexSize) {
        textureShape = logShape;
      } else if (logShape.length === 3 && logShape[0] * logShape[1] <= maxTexSize && logShape[2] <= maxTexSize) {
        textureShape = [logShape[0] * logShape[1], logShape[2]];
      } else if (logShape.length === 3 && logShape[0] <= maxTexSize && logShape[1] * logShape[2] <= maxTexSize) {
        textureShape = [logShape[0], logShape[1] * logShape[2]];
      } else if (logShape.length === 4 && logShape[0] * logShape[1] * logShape[2] <= maxTexSize && logShape[3] <= maxTexSize) {
        textureShape = [logShape[0] * logShape[1] * logShape[2], logShape[3]];
      } else if (logShape.length === 4 && logShape[0] <= maxTexSize && logShape[1] * logShape[2] * logShape[3] <= maxTexSize) {
        textureShape = [logShape[0], logShape[1] * logShape[2] * logShape[3]];
      }
      var isLongNarrowTex = textureShape != null && Math.max.apply(Math, __spreadArray([], __read(textureShape), false)) > maxSizeForNarrowTex && Math.min.apply(Math, __spreadArray([], __read(textureShape), false)) <= (isPacked ? 2 : 1) && Math.min.apply(Math, __spreadArray([], __read(textureShape), false)) > 0;
      if (textureShape == null || isLongNarrowTex) {
        if (isPacked) {
          var batchDim = getBatchDim(logShape);
          var rows = 2, cols = 2;
          if (logShape.length) {
            _a2 = __read(getRowsCols(logShape), 2), rows = _a2[0], cols = _a2[1];
          }
          size = batchDim * (rows / 2) * (cols / 2);
          textureShape = tf.util.sizeToSquarishShape(size).map(function(d) {
            return d * 2;
          });
        } else {
          textureShape = tf.util.sizeToSquarishShape(size);
        }
      }
      return textureShape;
    }
    function isEven(n) {
      return n % 2 === 0;
    }
    function isReshapeFree(shape1, shape2) {
      shape1 = shape1.slice(-2);
      shape2 = shape2.slice(-2);
      if (tf.util.arraysEqual(shape1, shape2)) {
        return true;
      }
      if (!shape1.length || !shape2.length) {
        return true;
      }
      if (shape1[0] === 0 || shape1[1] === 0 || shape2[0] === 0 || shape2[1] === 0) {
        return true;
      }
      if (shape1.length !== shape2.length) {
        var shape1Cols = shape1[shape1.length - 1];
        var shape2Cols = shape2[shape2.length - 1];
        if (shape1Cols === shape2Cols) {
          return true;
        }
        if (isEven(shape1Cols) && isEven(shape2Cols) && (shape1[0] === 1 || shape2[0] === 1)) {
          return true;
        }
      }
      return shape1[1] === shape2[1] && isEven(shape1[0]) && isEven(shape2[0]);
    }
    var MAX_TEXTURE_SIZE;
    var MAX_TEXTURES_IN_SHADER;
    function getWebGLMaxTextureSize(webGLVersion) {
      if (MAX_TEXTURE_SIZE == null) {
        var gl = getWebGLContext(webGLVersion);
        MAX_TEXTURE_SIZE = gl.getParameter(gl.MAX_TEXTURE_SIZE);
      }
      return MAX_TEXTURE_SIZE;
    }
    function resetMaxTextureSize() {
      MAX_TEXTURE_SIZE = null;
    }
    function resetMaxTexturesInShader() {
      MAX_TEXTURES_IN_SHADER = null;
    }
    function getMaxTexturesInShader(webGLVersion) {
      if (MAX_TEXTURES_IN_SHADER == null) {
        var gl = getWebGLContext(webGLVersion);
        MAX_TEXTURES_IN_SHADER = gl.getParameter(gl.MAX_TEXTURE_IMAGE_UNITS);
      }
      return Math.min(16, MAX_TEXTURES_IN_SHADER);
    }
    function getWebGLDisjointQueryTimerVersion(webGLVersion) {
      if (webGLVersion === 0) {
        return 0;
      }
      var queryTimerVersion;
      var gl = getWebGLContext(webGLVersion);
      if (hasExtension(gl, "EXT_disjoint_timer_query_webgl2") && webGLVersion === 2) {
        queryTimerVersion = 2;
      } else if (hasExtension(gl, "EXT_disjoint_timer_query")) {
        queryTimerVersion = 1;
      } else {
        queryTimerVersion = 0;
      }
      return queryTimerVersion;
    }
    function hasExtension(gl, extensionName) {
      var ext = gl.getExtension(extensionName);
      return ext != null;
    }
    function isWebGLVersionEnabled(webGLVersion) {
      try {
        var gl = getWebGLContext(webGLVersion);
        if (gl != null) {
          return true;
        }
      } catch (e) {
        console.log("Error when getting WebGL context: ", e);
        return false;
      }
      return false;
    }
    function isCapableOfRenderingToFloatTexture(webGLVersion) {
      if (webGLVersion === 0) {
        return false;
      }
      var gl = getWebGLContext(webGLVersion);
      if (webGLVersion === 1) {
        if (!hasExtension(gl, "OES_texture_float")) {
          return false;
        }
      } else {
        if (!hasExtension(gl, "EXT_color_buffer_float")) {
          return false;
        }
      }
      var isFrameBufferComplete = createFloatTextureAndBindToFramebuffer(gl);
      return isFrameBufferComplete;
    }
    function isDownloadFloatTextureEnabled(webGLVersion) {
      if (webGLVersion === 0) {
        return false;
      }
      var gl = getWebGLContext(webGLVersion);
      if (webGLVersion === 1) {
        if (!hasExtension(gl, "OES_texture_float")) {
          return false;
        }
        if (!hasExtension(gl, "WEBGL_color_buffer_float")) {
          return false;
        }
      } else {
        if (hasExtension(gl, "EXT_color_buffer_float")) {
          return createFloatTextureAndBindToFramebuffer(gl);
        }
        var COLOR_BUFFER_HALF_FLOAT = "EXT_color_buffer_half_float";
        if (hasExtension(gl, COLOR_BUFFER_HALF_FLOAT)) {
          var textureHalfFloatExtension = gl.getExtension(COLOR_BUFFER_HALF_FLOAT);
          return createHalfFloatTextureAndBindToFramebuffer(gl, textureHalfFloatExtension);
        }
        return false;
      }
      var isFrameBufferComplete = createFloatTextureAndBindToFramebuffer(gl);
      return isFrameBufferComplete;
    }
    function createFloatTextureAndBindToFramebuffer(gl) {
      var texConfig = getTextureConfig(gl);
      var texture = gl.createTexture();
      gl.bindTexture(gl.TEXTURE_2D, texture);
      var width = 1;
      var height = 1;
      gl.texImage2D(gl.TEXTURE_2D, 0, texConfig.internalFormatFloat, width, height, 0, texConfig.textureFormatFloat, texConfig.textureTypeFloat, null);
      var frameBuffer = gl.createFramebuffer();
      gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
      gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);
      var isFrameBufferComplete = gl.checkFramebufferStatus(gl.FRAMEBUFFER) === gl.FRAMEBUFFER_COMPLETE;
      gl.bindTexture(gl.TEXTURE_2D, null);
      gl.bindFramebuffer(gl.FRAMEBUFFER, null);
      gl.deleteTexture(texture);
      gl.deleteFramebuffer(frameBuffer);
      return isFrameBufferComplete;
    }
    function createHalfFloatTextureAndBindToFramebuffer(gl, textureHalfFloatExtension) {
      var texConfig = getTextureConfig(gl, textureHalfFloatExtension);
      var texture = gl.createTexture();
      gl.bindTexture(gl.TEXTURE_2D, texture);
      var width = 1;
      var height = 1;
      gl.texImage2D(gl.TEXTURE_2D, 0, texConfig.internalFormatHalfFloat, width, height, 0, texConfig.textureFormatFloat, texConfig.textureTypeHalfFloat, null);
      var frameBuffer = gl.createFramebuffer();
      gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
      gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);
      var isFrameBufferComplete = gl.checkFramebufferStatus(gl.FRAMEBUFFER) === gl.FRAMEBUFFER_COMPLETE;
      gl.bindTexture(gl.TEXTURE_2D, null);
      gl.bindFramebuffer(gl.FRAMEBUFFER, null);
      gl.deleteTexture(texture);
      gl.deleteFramebuffer(frameBuffer);
      return isFrameBufferComplete;
    }
    function isWebGLFenceEnabled(webGLVersion) {
      if (webGLVersion !== 2) {
        return false;
      }
      var gl = getWebGLContext(webGLVersion);
      var isEnabled = gl.fenceSync != null;
      return isEnabled;
    }
    function assertNotComplex(tensor, opName) {
      if (!Array.isArray(tensor)) {
        tensor = [tensor];
      }
      tensor.forEach(function(t) {
        if (t != null) {
          tf.util.assert(t.dtype !== "complex64", function() {
            return "".concat(opName, " does not support complex64 tensors ") + "in the WebGL backend.";
          });
        }
      });
    }
    var webgl_util = {
      __proto__: null,
      assertNotComplex,
      bindCanvasToFramebuffer,
      bindColorTextureToFramebuffer,
      bindTextureToProgramUniformSampler,
      bindTextureUnit,
      bindVertexBufferToProgramAttribute,
      callAndCheck,
      canBeRepresented,
      createFragmentShader,
      createFramebuffer,
      createProgram,
      createStaticIndexBuffer,
      createStaticVertexBuffer,
      createTexture,
      createVertexShader: createVertexShader$1,
      getBatchDim,
      getExtensionOrThrow,
      getFramebufferErrorMessage,
      getMaxTexturesInShader,
      getNumChannels,
      getProgramUniformLocation,
      getProgramUniformLocationOrThrow,
      getRowsCols,
      getShapeAs3D,
      getTextureShapeFromLogicalShape,
      getWebGLDisjointQueryTimerVersion,
      getWebGLErrorMessage,
      getWebGLMaxTextureSize,
      hasExtension,
      isCapableOfRenderingToFloatTexture,
      isDownloadFloatTextureEnabled,
      isReshapeFree,
      isWebGLFenceEnabled,
      isWebGLVersionEnabled,
      linkProgram,
      logShaderSourceAndInfoLog,
      resetMaxTextureSize,
      resetMaxTexturesInShader,
      unbindColorTextureFromFramebuffer,
      unbindTextureUnit,
      validateFramebuffer,
      validateProgram,
      validateTextureSize
    };
    var ENV = tf.env();
    ENV.registerFlag("HAS_WEBGL", function() {
      return ENV.getNumber("WEBGL_VERSION") > 0;
    });
    ENV.registerFlag("WEBGL_VERSION", function() {
      if (isWebGLVersionEnabled(2)) {
        return 2;
      } else if (isWebGLVersionEnabled(1)) {
        return 1;
      }
      return 0;
    });
    ENV.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS", function() {
      return false;
    });
    ENV.registerFlag("WEBGL_BUFFER_SUPPORTED", function() {
      return ENV.get("WEBGL_VERSION") === 2;
    });
    ENV.registerFlag("WEBGL_CPU_FORWARD", function() {
      return true;
    });
    ENV.registerFlag("WEBGL_FORCE_F16_TEXTURES", function() {
      return false;
    });
    ENV.registerFlag("WEBGL_PACK", function() {
      return ENV.getBool("HAS_WEBGL");
    });
    ENV.registerFlag("WEBGL_PACK_NORMALIZATION", function() {
      return ENV.getBool("WEBGL_PACK");
    });
    ENV.registerFlag("WEBGL_PACK_CLIP", function() {
      return ENV.getBool("WEBGL_PACK");
    });
    ENV.registerFlag("WEBGL_PACK_DEPTHWISECONV", function() {
      return ENV.getBool("WEBGL_PACK");
    });
    ENV.registerFlag("WEBGL_PACK_BINARY_OPERATIONS", function() {
      return ENV.getBool("WEBGL_PACK");
    });
    ENV.registerFlag("WEBGL_PACK_UNARY_OPERATIONS", function() {
      return ENV.getBool("WEBGL_PACK");
    });
    ENV.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS", function() {
      return ENV.getBool("WEBGL_PACK");
    });
    ENV.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS", function() {
      return ENV.getBool("WEBGL_PACK");
    });
    ENV.registerFlag("WEBGL_PACK_REDUCE", function() {
      return ENV.getBool("WEBGL_PACK");
    });
    ENV.registerFlag("WEBGL_LAZILY_UNPACK", function() {
      return ENV.getBool("WEBGL_PACK");
    });
    ENV.registerFlag("WEBGL_CONV_IM2COL", function() {
      return ENV.getBool("WEBGL_PACK");
    });
    ENV.registerFlag("WEBGL_PACK_CONV2DTRANSPOSE", function() {
      return ENV.getBool("WEBGL_PACK");
    });
    ENV.registerFlag("WEBGL_MAX_TEXTURE_SIZE", function() {
      return getWebGLMaxTextureSize(ENV.getNumber("WEBGL_VERSION"));
    });
    ENV.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER", function() {
      return getMaxTexturesInShader(ENV.getNumber("WEBGL_VERSION"));
    });
    ENV.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION", function() {
      var webGLVersion = ENV.getNumber("WEBGL_VERSION");
      if (webGLVersion === 0) {
        return 0;
      }
      return getWebGLDisjointQueryTimerVersion(webGLVersion);
    });
    ENV.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE", function() {
      return ENV.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 && !tf.device_util.isMobile();
    });
    ENV.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE", function() {
      return isCapableOfRenderingToFloatTexture(ENV.getNumber("WEBGL_VERSION"));
    });
    ENV.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED", function() {
      return ENV.getBool("WEBGL_FORCE_F16_TEXTURES") ? false : ENV.getBool("WEBGL_RENDER_FLOAT32_CAPABLE");
    });
    ENV.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED", function() {
      return isDownloadFloatTextureEnabled(ENV.getNumber("WEBGL_VERSION"));
    });
    ENV.registerFlag("WEBGL_FENCE_API_ENABLED", function() {
      return isWebGLFenceEnabled(ENV.getNumber("WEBGL_VERSION"));
    });
    ENV.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM", function() {
      var useUniforms = ENV.getBool("WEBGL_RENDER_FLOAT32_ENABLED");
      return useUniforms ? 4 : 0;
    });
    ENV.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD", function() {
      return -1;
    }, function(threshold) {
      if (!(typeof threshold === "number")) {
        throw new Error("WEBGL_DELETE_TEXTURE_THRESHOLD must be a number but " + "got ".concat(threshold, "."));
      }
      if (threshold < 0 && threshold !== -1) {
        throw new Error("WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never " + "delete) or at least 0, but got ".concat(threshold, "."));
      }
    });
    ENV.registerFlag("WEBGL_FLUSH_THRESHOLD", function() {
      return tf.device_util.isMobile() ? 1 : -1;
    }, function(threshold) {
      if (!(typeof threshold === "number")) {
        throw new Error("WEBGL_FLUSH_THRESHOLD must be a number but got " + "".concat(threshold, "."));
      }
      if (threshold < 0 && threshold !== -1) {
        throw new Error("WEBGL_FLUSH_THRESHOLD must be -1 (indicating never " + "manual flush) or at least 0, but got ".concat(threshold, "."));
      }
    });
    ENV.registerFlag("CPU_HANDOFF_SIZE_THRESHOLD", function() {
      return 128;
    });
    ENV.registerFlag("WEBGL_USE_SHAPES_UNIFORMS", function() {
      return false;
    });
    ENV.registerFlag("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD", function() {
      return 1e5;
    });
    ENV.registerFlag("TOPK_K_CPU_HANDOFF_THRESHOLD", function() {
      return 128;
    });
    ENV.registerFlag("WEBGL_EXP_CONV", function() {
      return false;
    });
    ENV.registerFlag("SOFTWARE_WEBGL_ENABLED", function() {
      return ENV.getBool("IS_TEST");
    });
    ENV.registerFlag("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE", function() {
      return Infinity;
    });
    ENV.registerFlag("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE", function() {
      return false;
    });
    ENV.registerFlag("WEBGL2_ISNAN_CUSTOM", function() {
      return false;
    });
    ENV.registerFlag("ENGINE_COMPILE_ONLY", function() {
      return false;
    });
    function getGlslDifferences() {
      var version2;
      var attribute;
      var varyingVs;
      var varyingFs;
      var texture2D;
      var output;
      var defineOutput;
      var defineSpecialNaN;
      var defineSpecialInf;
      var defineRound;
      if (tf.env().getNumber("WEBGL_VERSION") === 2) {
        version2 = "#version 300 es";
        attribute = "in";
        varyingVs = "out";
        varyingFs = "in";
        texture2D = "texture";
        output = "outputColor";
        defineOutput = "out vec4 outputColor;";
        defineSpecialNaN = tf.env().getBool("WEBGL2_ISNAN_CUSTOM") ? "\n      bool isnan_custom(float val) {\n        uint floatToUint = floatBitsToUint(val);\n        return (floatToUint & 0x7fffffffu) > 0x7f800000u;\n      }\n\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan_custom(val.x),\n          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));\n      }\n\n      #define isnan(value) isnan_custom(value)\n    " : "";
        defineSpecialInf = "";
        defineRound = "\n      #define round(value) newRound(value)\n      int newRound(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 newRound(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    ";
      } else {
        version2 = "";
        attribute = "attribute";
        varyingVs = "varying";
        varyingFs = "varying";
        texture2D = "texture2D";
        output = "gl_FragColor";
        defineOutput = "";
        defineSpecialNaN = "\n      #define isnan(value) isnan_custom(value)\n      bool isnan_custom(float val) {\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\n      }\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\n      }\n    ";
        defineSpecialInf = "\n      uniform float INFINITY;\n\n      bool isinf(float val) {\n        return abs(val) == INFINITY;\n      }\n      bvec4 isinf(vec4 val) {\n        return equal(abs(val), vec4(INFINITY));\n      }\n    ";
        defineRound = "\n      int round(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 round(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    ";
      }
      return {
        version: version2,
        attribute,
        varyingVs,
        varyingFs,
        texture2D,
        output,
        defineOutput,
        defineSpecialNaN,
        defineSpecialInf,
        defineRound
      };
    }
    function getLogicalCoordinatesFromFlatIndex(coords2, shape, index) {
      if (index === void 0) {
        index = "index";
      }
      var strides = tf.util.computeStrides(shape);
      return strides.map(function(stride, i) {
        var line1 = "int ".concat(coords2[i], " = ").concat(index, " / ").concat(stride);
        var line2 = i === strides.length - 1 ? "int ".concat(coords2[i + 1], " = ").concat(index, " - ").concat(coords2[i], " * ").concat(stride) : "index -= ".concat(coords2[i], " * ").concat(stride);
        return "".concat(line1, "; ").concat(line2, ";");
      }).join("");
    }
    function getOutputLogicalCoordinatesFromFlatIndexByUniform(coords2, shape, index) {
      if (index === void 0) {
        index = "index";
      }
      var strides = tf.util.computeStrides(shape);
      return strides.map(function(_, i) {
        var line1 = "int ".concat(coords2[i], " = ").concat(index, " / outShapeStrides[").concat(i, "]");
        var line2 = i === strides.length - 1 ? "int ".concat(coords2[i + 1], " = ").concat(index, " - ").concat(coords2[i], " * outShapeStrides[").concat(i, "]") : "index -= ".concat(coords2[i], " * outShapeStrides[").concat(i, "]");
        return "".concat(line1, "; ").concat(line2, ";");
      }).join("");
    }
    function symbolicallyComputeStrides(indicesArr, variableName) {
      var numCoords = indicesArr.length;
      var shape = indicesArr.map(function(d) {
        return "".concat(variableName, "[").concat(d, "]");
      });
      var strides = new Array(numCoords - 1);
      strides[numCoords - 2] = shape[numCoords - 1];
      for (var i = numCoords - 3; i >= 0; --i) {
        strides[i] = "(".concat(strides[i + 1], " * ").concat(shape[i + 1], ")");
      }
      return strides;
    }
    function getLogicalCoordinatesFromFlatIndexByUniform(coords2, variableName, index) {
      if (index === void 0) {
        index = "index";
      }
      var indicesArray = coords2.map(function(_, i) {
        return i;
      });
      var strides = symbolicallyComputeStrides(indicesArray, variableName);
      return strides.map(function(_, i) {
        var line1 = "int ".concat(coords2[i], " = ").concat(index, " / ").concat(strides[i]);
        var line2 = i === strides.length - 1 ? "int ".concat(coords2[i + 1], " = ").concat(index, " - ").concat(coords2[i], " * ").concat(strides[i]) : "index -= ".concat(coords2[i], " * ").concat(strides[i]);
        return "".concat(line1, "; ").concat(line2, ";");
      }).join("");
    }
    function getFlatIndexFrom3D(shape) {
      var strides = tf.util.computeStrides(shape).map(function(d) {
        return d.toString();
      });
      return "\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * ".concat(strides[0], " + coords.y * ").concat(strides[1], " + coords.z;\n  }\n");
    }
    function getFlatIndexFrom3DOutput() {
      return "\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;\n  }\n";
    }
    var ENCODE_FLOAT_SNIPPET = "\n  const float FLOAT_MAX = 1.70141184e38;\n  const float FLOAT_MIN = 1.17549435e-38;\n\n  lowp vec4 encode_float(highp float v) {\n    if (isnan(v)) {\n      return vec4(255, 255, 255, 255);\n    }\n\n    highp float av = abs(v);\n\n    if(av < FLOAT_MIN) {\n      return vec4(0.0, 0.0, 0.0, 0.0);\n    } else if(v > FLOAT_MAX) {\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\n    } else if(v < -FLOAT_MAX) {\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\n    }\n\n    highp vec4 c = vec4(0,0,0,0);\n\n    highp float e = floor(log2(av));\n    highp float m = exp2(fract(log2(av))) - 1.0;\n\n    c[2] = floor(128.0 * m);\n    m -= c[2] / 128.0;\n    c[1] = floor(32768.0 * m);\n    m -= c[1] / 32768.0;\n    c[0] = floor(8388608.0 * m);\n\n    highp float ebias = e + 127.0;\n    c[3] = floor(ebias / 2.0);\n    ebias -= c[3] * 2.0;\n    c[2] += floor(ebias) * 128.0;\n\n    c[3] += 128.0 * step(0.0, -v);\n\n    return c / 255.0;\n  }\n";
    var getBroadcastDims = tf.backend_util.getBroadcastDims;
    function makeShader(inputsInfo, outputShape, program) {
      var prefixSnippets = [];
      inputsInfo.forEach(function(x) {
        var size = tf.util.sizeFromShape(x.shapeInfo.logicalShape);
        if (x.shapeInfo.isUniform) {
          prefixSnippets.push("uniform float ".concat(x.name).concat(size > 1 ? "[".concat(size, "]") : "", ";"));
        } else {
          prefixSnippets.push("uniform sampler2D ".concat(x.name, ";"));
          prefixSnippets.push("uniform int offset".concat(x.name, ";"));
        }
        if (program.enableShapeUniforms) {
          var uniformShape = getUniformInfoFromShape(program.packedInputs, x.shapeInfo.logicalShape, x.shapeInfo.texShape).uniformShape;
          switch (uniformShape.length) {
            case 1:
              prefixSnippets.push("uniform int ".concat(x.name, "Shape;"));
              break;
            case 2:
              prefixSnippets.push("uniform ivec2 ".concat(x.name, "Shape;"));
              break;
            case 3:
              prefixSnippets.push("uniform ivec3 ".concat(x.name, "Shape;"));
              break;
            case 4:
              prefixSnippets.push("uniform ivec4 ".concat(x.name, "Shape;"));
              break;
          }
          prefixSnippets.push("uniform ivec2 ".concat(x.name, "TexShape;"));
        }
      });
      if (program.enableShapeUniforms) {
        switch (outputShape.logicalShape.length) {
          case 1:
            prefixSnippets.push("uniform int outShape;");
            break;
          case 2:
            prefixSnippets.push("uniform ivec2 outShape;");
            prefixSnippets.push("uniform int outShapeStrides;");
            break;
          case 3:
            prefixSnippets.push("uniform ivec3 outShape;");
            prefixSnippets.push("uniform ivec2 outShapeStrides;");
            break;
          case 4:
            prefixSnippets.push("uniform ivec4 outShape;");
            prefixSnippets.push("uniform ivec3 outShapeStrides;");
            break;
        }
        prefixSnippets.push("uniform ivec2 outTexShape;");
      }
      if (program.customUniforms) {
        program.customUniforms.forEach(function(d) {
          prefixSnippets.push("uniform ".concat(d.type, " ").concat(d.name).concat(d.arrayIndex ? "[".concat(d.arrayIndex, "]") : "", ";"));
        });
      }
      var inputPrefixSnippet = prefixSnippets.join("\n");
      var inputSamplingSnippet = inputsInfo.map(function(x) {
        return getInputSamplingSnippet(x, outputShape, program.packedInputs, program.enableShapeUniforms);
      }).join("\n");
      var outTexShape = outputShape.texShape;
      var glsl = getGlslDifferences();
      var floatTextureSampleSnippet = getFloatTextureSampleSnippet(glsl);
      var outputSamplingSnippet;
      var floatTextureSetOutputSnippet;
      var shaderPrefix = getShaderPrefix(glsl);
      if (outputShape.isPacked) {
        outputSamplingSnippet = getPackedOutputSamplingSnippet(outputShape.logicalShape, outTexShape, program.enableShapeUniforms);
        floatTextureSetOutputSnippet = getFloatTextureSetRGBASnippet(glsl);
      } else {
        outputSamplingSnippet = getOutputSamplingSnippet(outputShape.logicalShape, outTexShape, program.enableShapeUniforms);
        floatTextureSetOutputSnippet = getFloatTextureSetRSnippet(glsl);
      }
      if (program.packedInputs) {
        shaderPrefix += SHADER_PACKED_PREFIX;
      }
      var source = [
        shaderPrefix,
        floatTextureSampleSnippet,
        floatTextureSetOutputSnippet,
        inputPrefixSnippet,
        outputSamplingSnippet,
        inputSamplingSnippet,
        program.userCode
      ].join("\n");
      return source;
    }
    function getSamplerFromInInfo(inInfo, enableShapeUniforms) {
      if (enableShapeUniforms === void 0) {
        enableShapeUniforms = false;
      }
      var shape = inInfo.shapeInfo.logicalShape;
      switch (shape.length) {
        case 0:
          return getSamplerScalar(inInfo, enableShapeUniforms);
        case 1:
          return getSampler1D(inInfo, enableShapeUniforms);
        case 2:
          return getSampler2D(inInfo, enableShapeUniforms);
        case 3:
          return getSampler3D(inInfo, enableShapeUniforms);
        case 4:
          return getSampler4D(inInfo, enableShapeUniforms);
        case 5:
          return getSampler5D(inInfo);
        case 6:
          return getSampler6D(inInfo);
        default:
          throw new Error("".concat(shape.length, "-D input sampling") + " is not yet supported");
      }
    }
    function getPackedSamplerFromInInfo(inInfo, enableShapeUniforms) {
      var shape = inInfo.shapeInfo.logicalShape;
      switch (shape.length) {
        case 0:
          return getPackedSamplerScalar(inInfo);
        case 1:
          return getPackedSampler1D(inInfo, enableShapeUniforms);
        case 2:
          return getPackedSampler2D(inInfo, enableShapeUniforms);
        case 3:
          return getPackedSampler3D(inInfo, enableShapeUniforms);
        default:
          return getPackedSamplerND(inInfo, enableShapeUniforms);
      }
    }
    function getInputSamplingSnippet(inInfo, outShapeInfo, usesPackedTextures, enableShapeUniforms) {
      if (usesPackedTextures === void 0) {
        usesPackedTextures = false;
      }
      var res = "";
      if (usesPackedTextures) {
        res += getPackedSamplerFromInInfo(inInfo, enableShapeUniforms);
      } else {
        res += getSamplerFromInInfo(inInfo, enableShapeUniforms);
      }
      var inShape = inInfo.shapeInfo.logicalShape;
      var outShape = outShapeInfo.logicalShape;
      if (inShape.length <= outShape.length) {
        if (usesPackedTextures) {
          res += getPackedSamplerAtOutputCoords(inInfo, outShapeInfo);
        } else {
          res += getSamplerAtOutputCoords(inInfo, outShapeInfo);
        }
      }
      return res;
    }
    function getPackedOutputSamplingSnippet(outShape, outTexShape, enableShapeUniforms) {
      switch (outShape.length) {
        case 0:
          return getOutputScalarCoords();
        case 1:
          return getOutputPacked1DCoords(outShape, outTexShape, enableShapeUniforms);
        case 2:
          return getOutputPacked2DCoords(outShape, outTexShape, enableShapeUniforms);
        case 3:
          return getOutputPacked3DCoords(outShape, outTexShape, enableShapeUniforms);
        default:
          return getOutputPackedNDCoords(outShape, outTexShape, enableShapeUniforms);
      }
    }
    function getOutputSamplingSnippet(outShape, outTexShape, enableShapeUniforms) {
      switch (outShape.length) {
        case 0:
          return getOutputScalarCoords();
        case 1:
          return getOutput1DCoords(outShape, outTexShape, enableShapeUniforms);
        case 2:
          return getOutput2DCoords(outShape, outTexShape, enableShapeUniforms);
        case 3:
          return getOutput3DCoords(outShape, outTexShape, enableShapeUniforms);
        case 4:
          return getOutput4DCoords(outShape, outTexShape, enableShapeUniforms);
        case 5:
          return getOutput5DCoords(outShape, outTexShape);
        case 6:
          return getOutput6DCoords(outShape, outTexShape);
        default:
          throw new Error("".concat(outShape.length, "-D output sampling is not yet supported"));
      }
    }
    function getFloatTextureSampleSnippet(glsl) {
      return "\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\n      return ".concat(glsl.texture2D, "(textureSampler, uv).r;\n    }\n  ");
    }
    function getFloatTextureSetRSnippet(glsl) {
      return "\n    void setOutput(float val) {\n      ".concat(glsl.output, " = vec4(val, 0, 0, 0);\n    }\n  ");
    }
    function getFloatTextureSetRGBASnippet(glsl) {
      return "\n    void setOutput(vec4 val) {\n      ".concat(glsl.output, " = val;\n    }\n  ");
    }
    function getShaderPrefix(glsl) {
      var SHADER_PREFIX = "".concat(glsl.version, "\n    precision highp float;\n    precision highp int;\n    precision highp sampler2D;\n    ").concat(glsl.varyingFs, " vec2 resultUV;\n    ").concat(glsl.defineOutput, "\n    const vec2 halfCR = vec2(0.5, 0.5);\n\n    struct ivec5\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n    };\n\n    struct ivec6\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n      int v;\n    };\n\n    uniform float NAN;\n    ").concat(glsl.defineSpecialNaN, "\n    ").concat(glsl.defineSpecialInf, "\n    ").concat(glsl.defineRound, "\n\n    int imod(int x, int y) {\n      return x - y * (x / y);\n    }\n\n    int idiv(int a, int b, float sign) {\n      int res = a / b;\n      int mod = imod(a, b);\n      if (sign < 0. && mod != 0) {\n        res -= 1;\n      }\n      return res;\n    }\n\n    //Based on the work of Dave Hoskins\n    //https://www.shadertoy.com/view/4djSRW\n    #define HASHSCALE1 443.8975\n    float random(float seed){\n      vec2 p = resultUV * seed;\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\n      p3 += dot(p3, p3.yzx + 19.19);\n      return fract((p3.x + p3.y) * p3.z);\n    }\n\n    ").concat(SAMPLE_1D_SNIPPET, "\n    ").concat(SAMPLE_2D_SNIPPET, "\n    ").concat(SAMPLE_3D_SNIPPET, "\n  ");
      return SHADER_PREFIX;
    }
    var SAMPLE_1D_SNIPPET = "\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\n  int texelIndex = index / 2;\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n";
    var SAMPLE_2D_SNIPPET = "\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\n  int texNumC, int row, int col) {\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n";
    var SAMPLE_3D_SNIPPET = "\nvec2 packedUVfrom3D(int texNumR, int texNumC,\n    int texelsInBatch, int texelsInLogicalRow, int b,\n    int row, int col) {\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n";
    var SHADER_PACKED_PREFIX = "\n  float getChannel(vec4 frag, vec2 innerDims) {\n    vec2 modCoord = mod(innerDims, 2.);\n    return modCoord.x == 0. ?\n      (modCoord.y == 0. ? frag.r : frag.g) :\n      (modCoord.y == 0. ? frag.b : frag.a);\n  }\n  float getChannel(vec4 frag, int dim) {\n    float modCoord = mod(float(dim), 2.);\n    return modCoord == 0. ? frag.r : frag.g;\n  }\n";
    function getOutputScalarCoords() {
      return "\n    int getOutputCoords() {\n      return 0;\n    }\n  ";
    }
    function getOutputPacked1DCoords(shape, texShape, enableShapeUniforms) {
      var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
      if (packedTexShape[0] === 1) {
        if (enableShapeUniforms) {
          return "\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));\n      }\n    ";
        }
        return "\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ".concat(packedTexShape[1], ".0);\n      }\n    ");
      }
      if (packedTexShape[1] === 1) {
        if (enableShapeUniforms) {
          return "\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));\n      }\n    ";
        }
        return "\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ".concat(packedTexShape[0], ".0);\n      }\n    ");
      }
      if (enableShapeUniforms) {
        return "\n    int getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);\n    }\n  ";
      }
      return "\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(packedTexShape[0], ", ").concat(packedTexShape[1], "));\n      return 2 * (resTexRC.x * ").concat(packedTexShape[1], " + resTexRC.y);\n    }\n  ");
    }
    function getOutput1DCoords(shape, texShape, enableShapeUniforms) {
      if (texShape[0] === 1) {
        if (enableShapeUniforms) {
          return "\n      int getOutputCoords() {\n        return int(resultUV.x * float(outTexShape[1]));\n      }\n    ";
        }
        return "\n      int getOutputCoords() {\n        return int(resultUV.x * ".concat(texShape[1], ".0);\n      }\n    ");
      }
      if (texShape[1] === 1) {
        if (enableShapeUniforms) {
          return "\n      int getOutputCoords() {\n        return int(resultUV.y * float(outTexShape[0]));\n      }\n    ";
        }
        return "\n      int getOutputCoords() {\n        return int(resultUV.y * ".concat(texShape[0], ".0);\n      }\n    ");
      }
      if (enableShapeUniforms) {
        return "\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      return resTexRC.x * outTexShape[1] + resTexRC.y;\n    }\n  ";
      }
      return "\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(texShape[0], ", ").concat(texShape[1], "));\n      return resTexRC.x * ").concat(texShape[1], " + resTexRC.y;\n    }\n  ");
    }
    function getOutputPacked3DCoords(shape, texShape, enableShapeUniforms) {
      if (enableShapeUniforms) {
        return "\n    ivec3 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec3(b, r, c);\n    }\n  ";
      }
      var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
      var texelsInLogicalRow = Math.ceil(shape[2] / 2);
      var texelsInBatch = texelsInLogicalRow * Math.ceil(shape[1] / 2);
      return "\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(packedTexShape[0], ", ").concat(packedTexShape[1], "));\n      int index = resTexRC.x * ").concat(packedTexShape[1], " + resTexRC.y;\n\n      int b = index / ").concat(texelsInBatch, ";\n      index -= b * ").concat(texelsInBatch, ";\n\n      int r = 2 * (index / ").concat(texelsInLogicalRow, ");\n      int c = imod(index, ").concat(texelsInLogicalRow, ") * 2;\n\n      return ivec3(b, r, c);\n    }\n  ");
    }
    function getOutput3DCoords(shape, texShape, enableShapeUniforms) {
      if (enableShapeUniforms) {
        var coordsFromIndexSnippet_1 = getOutputLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d"], shape);
        return "\n  ivec3 getOutputCoords() {\n    ivec2 resTexRC = ivec2(resultUV.yx *\n                           vec2(outTexShape[0], outTexShape[1]));\n    int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n    ".concat(coordsFromIndexSnippet_1, "\n    return ivec3(r, c, d);\n  }\n");
      }
      var coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], shape);
      return "\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(texShape[0], ", ").concat(texShape[1], "));\n      int index = resTexRC.x * ").concat(texShape[1], " + resTexRC.y;\n      ").concat(coordsFromIndexSnippet, "\n      return ivec3(r, c, d);\n    }\n  ");
    }
    function getOutputPackedNDCoords(shape, texShape, enableShapeUniforms) {
      if (enableShapeUniforms) {
        return "\n    ivec4 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatchN = texelsInBatch * outShape[1];\n\n      int b2 = index / texelsInBatchN;\n      index -= b2 * texelsInBatchN;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec4(b2, b, r, c);\n    }\n  ";
      }
      var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
      var texelsInLogicalRow = Math.ceil(shape[shape.length - 1] / 2);
      var texelsInBatch = texelsInLogicalRow * Math.ceil(shape[shape.length - 2] / 2);
      var texelsInBatchN = texelsInBatch;
      var batches = "";
      var coords2 = "b, r, c";
      for (var b = 2; b < shape.length - 1; b++) {
        texelsInBatchN *= shape[shape.length - b - 1];
        batches = "\n      int b".concat(b, " = index / ").concat(texelsInBatchN, ";\n      index -= b").concat(b, " * ").concat(texelsInBatchN, ";\n    ") + batches;
        coords2 = "b".concat(b, ", ") + coords2;
      }
      return "\n    ivec".concat(shape.length, " getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(").concat(packedTexShape[0], ", ").concat(packedTexShape[1], "));\n      int index = resTexRC.x * ").concat(packedTexShape[1], " + resTexRC.y;\n\n      ").concat(batches, "\n\n      int b = index / ").concat(texelsInBatch, ";\n      index -= b * ").concat(texelsInBatch, ";\n\n      int r = 2 * (index / ").concat(texelsInLogicalRow, ");\n      int c = imod(index, ").concat(texelsInLogicalRow, ") * 2;\n\n      return ivec").concat(shape.length, "(").concat(coords2, ");\n    }\n  ");
    }
    function getOutput4DCoords(shape, texShape, enableShapeUniforms) {
      if (enableShapeUniforms) {
        var coordsFromIndexSnippet_2 = getOutputLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d", "d2"], shape);
        return "\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      ".concat(coordsFromIndexSnippet_2, "\n      return ivec4(r, c, d, d2);\n    }\n  ");
      }
      var coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2"], shape);
      return "\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(".concat(texShape[0], ", ").concat(texShape[1], "));\n      int index = resTexRC.x * ").concat(texShape[1], " + resTexRC.y;\n      ").concat(coordsFromIndexSnippet, "\n      return ivec4(r, c, d, d2);\n    }\n  ");
    }
    function getOutput5DCoords(shape, texShape) {
      var coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2", "d3"], shape);
      return "\n    ivec5 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(".concat(texShape[0], ",\n                             ").concat(texShape[1], "));\n\n      int index = resTexRC.x * ").concat(texShape[1], " + resTexRC.y;\n\n      ").concat(coordsFromIndexSnippet, "\n\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\n      return outShape;\n    }\n  ");
    }
    function getOutput6DCoords(shape, texShape) {
      var coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2", "d3", "d4"], shape);
      return "\n    ivec6 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(".concat(texShape[0], ", ").concat(texShape[1], "));\n      int index = resTexRC.x * ").concat(texShape[1], " + resTexRC.y;\n\n      ").concat(coordsFromIndexSnippet, "\n\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\n      return result;\n    }\n  ");
    }
    function getOutputPacked2DCoords(shape, texShape, enableShapeUniforms) {
      var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
      if (tf.util.arraysEqual(shape, texShape)) {
        if (enableShapeUniforms) {
          return "\n      ivec2 getOutputCoords() {\n        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));\n      }\n    ";
        }
        return "\n      ivec2 getOutputCoords() {\n        return 2 * ivec2(resultUV.yx * vec2(".concat(packedTexShape[0], ", ").concat(packedTexShape[1], "));\n      }\n    ");
      }
      var texelsInLogicalRow = Math.ceil(shape[1] / 2);
      if (enableShapeUniforms) {
        return "\n    ivec2 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec2(r, c);\n    }\n  ";
      }
      return "\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(packedTexShape[0], ", ").concat(packedTexShape[1], "));\n\n      int index = resTexRC.x * ").concat(packedTexShape[1], " + resTexRC.y;\n      int r = 2 * (index / ").concat(texelsInLogicalRow, ");\n      int c = imod(index, ").concat(texelsInLogicalRow, ") * 2;\n\n      return ivec2(r, c);\n    }\n  ");
    }
    function getOutput2DCoords(shape, texShape, enableShapeUniforms) {
      if (tf.util.arraysEqual(shape, texShape)) {
        if (enableShapeUniforms) {
          return "\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));\n      }\n    ";
        }
        return "\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(".concat(texShape[0], ", ").concat(texShape[1], "));\n      }\n    ");
      }
      if (shape[1] === 1) {
        if (enableShapeUniforms) {
          return "\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    ";
        }
        return "\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(".concat(texShape[0], ", ").concat(texShape[1], "));\n        int index = resTexRC.x * ").concat(texShape[1], " + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    ");
      }
      if (shape[0] === 1) {
        if (enableShapeUniforms) {
          return "\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(0, index);\n      }\n    ";
        }
        return "\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(".concat(texShape[0], ", ").concat(texShape[1], "));\n        int index = resTexRC.x * ").concat(texShape[1], " + resTexRC.y;\n        return ivec2(0, index);\n      }\n    ");
      }
      if (enableShapeUniforms) {
        return "\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      int r = index / outShape[1];\n      int c = index - r * outShape[1];\n      return ivec2(r, c);\n    }\n  ";
      }
      return "\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(texShape[0], ", ").concat(texShape[1], "));\n      int index = resTexRC.x * ").concat(texShape[1], " + resTexRC.y;\n      int r = index / ").concat(shape[1], ";\n      int c = index - r * ").concat(shape[1], ";\n      return ivec2(r, c);\n    }\n  ");
    }
    function getFlatOffsetUniformName(texName) {
      return "offset".concat(texName);
    }
    function getPackedSamplerScalar(inputInfo) {
      var texName = inputInfo.name;
      var funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
      var glsl = getGlslDifferences();
      return "\n    vec4 ".concat(funcName, "() {\n      return ").concat(glsl.texture2D, "(").concat(texName, ", halfCR);\n    }\n  ");
    }
    function getSamplerScalar(inputInfo, enableShapeUniforms) {
      var texName = inputInfo.name;
      var funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
      if (inputInfo.shapeInfo.isUniform) {
        return "float ".concat(funcName, "() {return ").concat(texName, ";}");
      }
      var _a2 = __read(inputInfo.shapeInfo.texShape, 2), texNumR = _a2[0], texNumC = _a2[1];
      if (texNumR === 1 && texNumC === 1) {
        return "\n      float ".concat(funcName, "() {\n        return sampleTexture(").concat(texName, ", halfCR);\n      }\n    ");
      }
      var offset = getFlatOffsetUniformName(texName);
      if (enableShapeUniforms) {
        return "\n    float ".concat(funcName, "() {\n      vec2 uv = uvFromFlat(").concat(texName, "TexShape[0], ").concat(texName, "TexShape[1], ").concat(offset, ");\n      return sampleTexture(").concat(texName, ", uv);\n    }\n  ");
      }
      var _b = __read(inputInfo.shapeInfo.texShape, 2), tNumR = _b[0], tNumC = _b[1];
      return "\n    float ".concat(funcName, "() {\n      vec2 uv = uvFromFlat(").concat(tNumR, ", ").concat(tNumC, ", ").concat(offset, ");\n      return sampleTexture(").concat(texName, ", uv);\n    }\n  ");
    }
    function getPackedSampler1D(inputInfo, enableShapeUniforms) {
      var texName = inputInfo.name;
      var funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
      var texShape = inputInfo.shapeInfo.texShape;
      var glsl = getGlslDifferences();
      if (enableShapeUniforms) {
        return "\n    vec4 ".concat(funcName, "(int index) {\n      ivec2 packedTexShape = ivec2(ceil(float(").concat(texName, "TexShape[0]) / 2.0), ceil(float(").concat(texName, "TexShape[1]) / 2.0));\n      vec2 uv = packedUVfrom1D(\n        packedTexShape[0], packedTexShape[1], index);\n      return ").concat(glsl.texture2D, "(").concat(texName, ", uv);\n    }\n  ");
      }
      var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
      return "\n    vec4 ".concat(funcName, "(int index) {\n      vec2 uv = packedUVfrom1D(\n        ").concat(packedTexShape[0], ", ").concat(packedTexShape[1], ", index);\n      return ").concat(glsl.texture2D, "(").concat(texName, ", uv);\n    }\n  ");
    }
    function getSampler1D(inputInfo, enableShapeUniforms) {
      var texName = inputInfo.name;
      var funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
      if (inputInfo.shapeInfo.isUniform) {
        return "\n      float ".concat(funcName, "(int index) {\n        ").concat(getUniformSampler(inputInfo), "\n      }\n    ");
      }
      var texShape = inputInfo.shapeInfo.texShape;
      var tNumR = texShape[0];
      var tNumC = texShape[1];
      if (tNumC === 1 && tNumR === 1) {
        return "\n      float ".concat(funcName, "(int index) {\n        return sampleTexture(").concat(texName, ", halfCR);\n      }\n    ");
      }
      var offset = getFlatOffsetUniformName(texName);
      if (tNumC === 1) {
        if (enableShapeUniforms) {
          return "\n      float ".concat(funcName, "(int index) {\n        vec2 uv = vec2(0.5, (float(index + ").concat(offset, ") + 0.5) / float(").concat(texName, "TexShape[0]));\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
        }
        return "\n      float ".concat(funcName, "(int index) {\n        vec2 uv = vec2(0.5, (float(index + ").concat(offset, ") + 0.5) / ").concat(tNumR, ".0);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
      }
      if (tNumR === 1) {
        if (enableShapeUniforms) {
          return "\n      float ".concat(funcName, "(int index) {\n        vec2 uv = vec2((float(index + ").concat(offset, ") + 0.5) / float(").concat(texName, "TexShape[1]), 0.5);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
        }
        return "\n      float ".concat(funcName, "(int index) {\n        vec2 uv = vec2((float(index + ").concat(offset, ") + 0.5) / ").concat(tNumC, ".0, 0.5);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
      }
      if (enableShapeUniforms) {
        return "\n    float ".concat(funcName, "(int index) {\n      vec2 uv = uvFromFlat(").concat(texName, "TexShape[0], ").concat(texName, "TexShape[1], index + ").concat(offset, ");\n      return sampleTexture(").concat(texName, ", uv);\n    }\n  ");
      }
      return "\n    float ".concat(funcName, "(int index) {\n      vec2 uv = uvFromFlat(").concat(tNumR, ", ").concat(tNumC, ", index + ").concat(offset, ");\n      return sampleTexture(").concat(texName, ", uv);\n    }\n  ");
    }
    function getPackedSampler2D(inputInfo, enableShapeUniforms) {
      var shape = inputInfo.shapeInfo.logicalShape;
      var texName = inputInfo.name;
      var funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
      var texShape = inputInfo.shapeInfo.texShape;
      var texNumR = texShape[0];
      var texNumC = texShape[1];
      var glsl = getGlslDifferences();
      if (texShape != null && tf.util.arraysEqual(shape, texShape)) {
        if (enableShapeUniforms) {
          return "\n      vec4 ".concat(funcName, "(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(").concat(texName, "TexShape[1], ").concat(texName, "TexShape[0]);\n\n        return ").concat(glsl.texture2D, "(").concat(texName, ", uv);\n      }\n    ");
        }
        return "\n      vec4 ".concat(funcName, "(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(").concat(texNumC, ".0, ").concat(texNumR, ".0);\n\n        return ").concat(glsl.texture2D, "(").concat(texName, ", uv);\n      }\n    ");
      }
      if (enableShapeUniforms) {
        return "\n    vec4 ".concat(funcName, "(int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(").concat(texName, "TexShape[0]) / 2.0), ceil(float(").concat(texName, "TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(").concat(texName, "Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);\n      return ").concat(glsl.texture2D, "(").concat(texName, ", uv);\n    }\n  ");
      }
      var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
      var valuesPerRow = Math.ceil(shape[1] / 2);
      return "\n    vec4 ".concat(funcName, "(int row, int col) {\n      vec2 uv = packedUVfrom2D(").concat(valuesPerRow, ", ").concat(packedTexShape[0], ", ").concat(packedTexShape[1], ", row, col);\n      return ").concat(glsl.texture2D, "(").concat(texName, ", uv);\n    }\n  ");
    }
    function getSampler2D(inputInfo, enableShapeUniforms) {
      var shape = inputInfo.shapeInfo.logicalShape;
      var texName = inputInfo.name;
      var funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
      var texShape = inputInfo.shapeInfo.texShape;
      if (texShape != null && tf.util.arraysEqual(shape, texShape)) {
        if (enableShapeUniforms) {
          return "\n      float ".concat(funcName, "(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(").concat(texName, "TexShape[1], ").concat(texName, "TexShape[0]);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
        }
        var texNumR_1 = texShape[0];
        var texNumC_1 = texShape[1];
        return "\n    float ".concat(funcName, "(int row, int col) {\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(").concat(texNumC_1, ".0, ").concat(texNumR_1, ".0);\n      return sampleTexture(").concat(texName, ", uv);\n    }\n  ");
      }
      var _a2 = tf.util.squeezeShape(shape), newShape = _a2.newShape, keptDims = _a2.keptDims;
      var squeezedShape = newShape;
      if (squeezedShape.length < shape.length) {
        var newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);
        var params = ["row", "col"];
        return "\n      ".concat(getSamplerFromInInfo(newInputInfo, enableShapeUniforms), "\n      float ").concat(funcName, "(int row, int col) {\n        return ").concat(funcName, "(").concat(getSqueezedParams(params, keptDims), ");\n      }\n    ");
      }
      if (inputInfo.shapeInfo.isUniform) {
        return "\n      float ".concat(funcName, "(int row, int col) {\n        int index = round(dot(vec2(row, col), vec2(").concat(shape[1], ", 1)));\n        ").concat(getUniformSampler(inputInfo), "\n      }\n    ");
      }
      var texNumR = texShape[0];
      var texNumC = texShape[1];
      var offset = getFlatOffsetUniformName(texName);
      if (texNumC === 1) {
        if (enableShapeUniforms) {
          return "\n      float ".concat(funcName, "(int row, int col) {\n        float index = dot(vec3(row, col, ").concat(offset, "), vec3(").concat(texName, "Shape[1], 1, 1));\n        vec2 uv = vec2(0.5, (index + 0.5) / float(").concat(texName, "TexShape[0]));\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
        }
        return "\n    float ".concat(funcName, "(int row, int col) {\n      float index = dot(vec3(row, col, ").concat(offset, "), vec3(").concat(shape[1], ", 1, 1));\n      vec2 uv = vec2(0.5, (index + 0.5) / ").concat(texNumR, ".0);\n      return sampleTexture(").concat(texName, ", uv);\n    }\n  ");
      }
      if (texNumR === 1) {
        if (enableShapeUniforms) {
          return "\n      float ".concat(funcName, "(int row, int col) {\n        float index = dot(vec3(row, col, ").concat(offset, "), vec3(").concat(texName, "Shape[1], 1, 1));\n        vec2 uv = vec2((index + 0.5) / float(").concat(texName, "TexShape[1]), 0.5);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
        }
        return "\n    float ".concat(funcName, "(int row, int col) {\n      float index = dot(vec3(row, col, ").concat(offset, "), vec3(").concat(shape[1], ", 1, 1));\n      vec2 uv = vec2((index + 0.5) / ").concat(texNumC, ".0, 0.5);\n      return sampleTexture(").concat(texName, ", uv);\n    }\n  ");
      }
      if (enableShapeUniforms) {
        return "\n      float ".concat(funcName, "(int row, int col) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ").concat(texName, "Shape[1] + col + ").concat(offset, ";\n        vec2 uv = uvFromFlat(").concat(texName, "TexShape[0], ").concat(texName, "TexShape[1], index);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
      }
      return "\n  float ".concat(funcName, "(int row, int col) {\n    // Explicitly use integer operations as dot() only works on floats.\n    int index = row * ").concat(shape[1], " + col + ").concat(offset, ";\n    vec2 uv = uvFromFlat(").concat(texNumR, ", ").concat(texNumC, ", index);\n    return sampleTexture(").concat(texName, ", uv);\n  }\n");
    }
    function getPackedSampler3D(inputInfo, enableShapeUniforms) {
      var shape = inputInfo.shapeInfo.logicalShape;
      var texName = inputInfo.name;
      var funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
      var texShape = inputInfo.shapeInfo.texShape;
      var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
      if (shape[0] === 1) {
        var squeezedShape = shape.slice(1);
        var keptDims = [1, 2];
        var newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);
        var params = ["b", "row", "col"];
        return "\n        ".concat(getPackedSamplerFromInInfo(newInputInfo, enableShapeUniforms), "\n        vec4 ").concat(funcName, "(int b, int row, int col) {\n          return ").concat(funcName, "(").concat(getSqueezedParams(params, keptDims), ");\n        }\n      ");
      }
      var glsl = getGlslDifferences();
      if (enableShapeUniforms) {
        return "\n    vec4 ".concat(funcName, "(int b, int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(").concat(texName, "TexShape[0]) / 2.0), ceil(float(").concat(texName, "TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(").concat(texName, "Shape[2]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(").concat(texName, "Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom3D(\n        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);\n      return ").concat(glsl.texture2D, "(").concat(texName, ", uv);\n    }\n  ");
      }
      var texNumR = packedTexShape[0];
      var texNumC = packedTexShape[1];
      var valuesPerRow = Math.ceil(shape[2] / 2);
      var texelsInBatch = valuesPerRow * Math.ceil(shape[1] / 2);
      return "\n    vec4 ".concat(funcName, "(int b, int row, int col) {\n      vec2 uv = packedUVfrom3D(\n        ").concat(texNumR, ", ").concat(texNumC, ", ").concat(texelsInBatch, ", ").concat(valuesPerRow, ", b, row, col);\n      return ").concat(glsl.texture2D, "(").concat(texName, ", uv);\n    }\n  ");
    }
    function getSampler3D(inputInfo, enableShapeUniforms) {
      var shape = inputInfo.shapeInfo.logicalShape;
      var texName = inputInfo.name;
      var funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
      var stride0 = shape[1] * shape[2];
      var stride1 = shape[2];
      var _a2 = tf.util.squeezeShape(shape), newShape = _a2.newShape, keptDims = _a2.keptDims;
      var squeezedShape = newShape;
      if (squeezedShape.length < shape.length) {
        var newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);
        var params = ["row", "col", "depth"];
        return "\n        ".concat(getSamplerFromInInfo(newInputInfo, enableShapeUniforms), "\n        float ").concat(funcName, "(int row, int col, int depth) {\n          return ").concat(funcName, "(").concat(getSqueezedParams(params, keptDims), ");\n        }\n      ");
      }
      if (inputInfo.shapeInfo.isUniform) {
        return "\n      float ".concat(funcName, "(int row, int col, int depth) {\n        int index = round(dot(vec3(row, col, depth),\n                          vec3(").concat(stride0, ", ").concat(stride1, ", 1)));\n        ").concat(getUniformSampler(inputInfo), "\n      }\n    ");
      }
      var texShape = inputInfo.shapeInfo.texShape;
      var texNumR = texShape[0];
      var texNumC = texShape[1];
      var flatOffset = inputInfo.shapeInfo.flatOffset;
      if (texNumC === stride0 && flatOffset == null) {
        if (enableShapeUniforms) {
          return "\n      float ".concat(funcName, "(int row, int col, int depth) {\n        int stride1 = ").concat(texName, "Shape[2];\n        float texR = float(row);\n        float texC = dot(vec2(col, depth), vec2(stride1, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(texName, "TexShape[1], ").concat(texName, "TexShape[0]);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
        }
        return "\n        float ".concat(funcName, "(int row, int col, int depth) {\n          float texR = float(row);\n          float texC = dot(vec2(col, depth), vec2(").concat(stride1, ", 1));\n          vec2 uv = (vec2(texC, texR) + halfCR) /\n                     vec2(").concat(texNumC, ".0, ").concat(texNumR, ".0);\n          return sampleTexture(").concat(texName, ", uv);\n        }\n      ");
      }
      if (texNumC === stride1 && flatOffset == null) {
        if (enableShapeUniforms) {
          return "\n      float ".concat(funcName, "(int row, int col, int depth) {\n        float texR = dot(vec2(row, col), vec2(").concat(texName, "Shape[1], 1));\n        float texC = float(depth);\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(").concat(texName, "TexShape[1], ").concat(texName, "TexShape[0]);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
        }
        return "\n    float ".concat(funcName, "(int row, int col, int depth) {\n      float texR = dot(vec2(row, col), vec2(").concat(shape[1], ", 1));\n      float texC = float(depth);\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(").concat(texNumC, ".0, ").concat(texNumR, ".0);\n      return sampleTexture(").concat(texName, ", uv);\n    }\n  ");
      }
      var offset = getFlatOffsetUniformName(texName);
      if (enableShapeUniforms) {
        return "\n    float ".concat(funcName, "(int row, int col, int depth) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int stride0 = ").concat(texName, "Shape[1] * ").concat(texName, "Shape[2];\n      int stride1 = ").concat(texName, "Shape[2];\n      int index = row * stride0 + col * stride1 + depth + ").concat(offset, ";\n      vec2 uv = uvFromFlat(").concat(texName, "TexShape[0], ").concat(texName, "TexShape[1], index);\n      return sampleTexture(").concat(texName, ", uv);\n    }\n    ");
      }
      return "\n      float ".concat(funcName, "(int row, int col, int depth) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ").concat(stride0, " + col * ").concat(stride1, " + depth + ").concat(offset, ";\n        vec2 uv = uvFromFlat(").concat(texNumR, ", ").concat(texNumC, ", index);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n  ");
    }
    function getPackedSamplerND(inputInfo, enableShapeUniforms) {
      var texName = inputInfo.name;
      var funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
      var glsl = getGlslDifferences();
      if (enableShapeUniforms) {
        return "\n    vec4 ".concat(funcName, "(int b2, int b, int row, int col) {\n      int valuesPerRow = int(ceil(float(").concat(texName, "Shape[3]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(").concat(texName, "Shape[2]) / 2.0));\n      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);\n      texelsInBatch *= ").concat(texName, "Shape[1];\n      index = b2 * texelsInBatch + index;\n      ivec2 packedTexShape = ivec2(ceil(float(").concat(texName, "TexShape[0]) / 2.0), ceil(float(").concat(texName, "TexShape[1]) / 2.0));\n      int texR = index / packedTexShape[1];\n      int texC = index - texR * packedTexShape[1];\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return ").concat(glsl.texture2D, "(").concat(texName, ", uv);\n    }\n  ");
      }
      var shape = inputInfo.shapeInfo.logicalShape;
      var rank = shape.length;
      var texShape = inputInfo.shapeInfo.texShape;
      var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
      var texNumR = packedTexShape[0];
      var texNumC = packedTexShape[1];
      var valuesPerRow = Math.ceil(shape[rank - 1] / 2);
      var texelsInBatch = valuesPerRow * Math.ceil(shape[rank - 2] / 2);
      var params = "int b, int row, int col";
      var index = "b * ".concat(texelsInBatch, " + (row / 2) * ").concat(valuesPerRow, " + (col / 2)");
      for (var b = 2; b < rank - 1; b++) {
        params = "int b".concat(b, ", ") + params;
        texelsInBatch *= shape[rank - b - 1];
        index = "b".concat(b, " * ").concat(texelsInBatch, " + ") + index;
      }
      return "\n    vec4 ".concat(funcName, "(").concat(params, ") {\n      int index = ").concat(index, ";\n      int texR = index / ").concat(texNumC, ";\n      int texC = index - texR * ").concat(texNumC, ";\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(").concat(texNumC, ", ").concat(texNumR, ");\n      return ").concat(glsl.texture2D, "(").concat(texName, ", uv);\n    }\n  ");
    }
    function getSampler4D(inputInfo, enableShapeUniforms) {
      var shape = inputInfo.shapeInfo.logicalShape;
      var texName = inputInfo.name;
      var funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
      var stride2 = shape[3];
      var stride1 = shape[2] * stride2;
      var stride0 = shape[1] * stride1;
      var _a2 = tf.util.squeezeShape(shape), newShape = _a2.newShape, keptDims = _a2.keptDims;
      if (newShape.length < shape.length) {
        var newInputInfo = squeezeInputInfo(inputInfo, newShape);
        var params = ["row", "col", "depth", "depth2"];
        return "\n      ".concat(getSamplerFromInInfo(newInputInfo, enableShapeUniforms), "\n      float ").concat(funcName, "(int row, int col, int depth, int depth2) {\n        return ").concat(funcName, "(").concat(getSqueezedParams(params, keptDims), ");\n      }\n    ");
      }
      if (inputInfo.shapeInfo.isUniform) {
        return "\n      float ".concat(funcName, "(int row, int col, int depth, int depth2) {\n        int index = round(dot(vec4(row, col, depth, depth2),\n                          vec4(").concat(stride0, ", ").concat(stride1, ", ").concat(stride2, ", 1)));\n        ").concat(getUniformSampler(inputInfo), "\n      }\n    ");
      }
      var flatOffset = inputInfo.shapeInfo.flatOffset;
      var texShape = inputInfo.shapeInfo.texShape;
      var texNumR = texShape[0];
      var texNumC = texShape[1];
      var stride2Str = "int stride2 = ".concat(texName, "Shape[3];");
      var stride1Str = "int stride1 = ".concat(texName, "Shape[2] * stride2;");
      var stride0Str = "int stride0 = ".concat(texName, "Shape[1] * stride1;");
      if (texNumC === stride0 && flatOffset == null) {
        if (enableShapeUniforms) {
          return "\n      float ".concat(funcName, "(int row, int col, int depth, int depth2) {\n        ").concat(stride2Str, "\n        ").concat(stride1Str, "\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(stride1, stride2, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(texName, "TexShape[1], ").concat(texName, "TexShape[0]);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
        }
        return "\n      float ".concat(funcName, "(int row, int col, int depth, int depth2) {\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(").concat(stride1, ", ").concat(stride2, ", 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(texNumC, ".0, ").concat(texNumR, ".0);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
      }
      if (texNumC === stride2 && flatOffset == null) {
        if (enableShapeUniforms) {
          return "\n      float ".concat(funcName, "(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(").concat(texName, "Shape[1] * ").concat(texName, "Shape[2], ").concat(texName, "Shape[2], 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(").concat(texName, "TexShape[1], ").concat(texName, "TexShape[0]);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
        }
        return "\n      float ".concat(funcName, "(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(").concat(shape[1] * shape[2], ", ").concat(shape[2], ", 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(").concat(texNumC, ".0, ").concat(texNumR, ".0);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
      }
      var offset = getFlatOffsetUniformName(texName);
      if (enableShapeUniforms) {
        return "\n    float ".concat(funcName, "(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      ").concat(stride2Str, "\n      ").concat(stride1Str, "\n      ").concat(stride0Str, "\n      int index = row * stride0 + col * stride1 +\n          depth * stride2 + depth2;\n      vec2 uv = uvFromFlat(").concat(texName, "TexShape[0], ").concat(texName, "TexShape[1], index + ").concat(offset, ");\n      return sampleTexture(").concat(texName, ", uv);\n    }\n  ");
      }
      return "\n    float ".concat(funcName, "(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ").concat(stride0, " + col * ").concat(stride1, " +\n          depth * ").concat(stride2, " + depth2;\n      vec2 uv = uvFromFlat(").concat(texNumR, ", ").concat(texNumC, ", index + ").concat(offset, ");\n      return sampleTexture(").concat(texName, ", uv);\n    }\n  ");
    }
    function getSampler5D(inputInfo) {
      var shape = inputInfo.shapeInfo.logicalShape;
      var texName = inputInfo.name;
      var funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
      var stride3 = shape[4];
      var stride2 = shape[3] * stride3;
      var stride1 = shape[2] * stride2;
      var stride0 = shape[1] * stride1;
      var _a2 = tf.util.squeezeShape(shape), newShape = _a2.newShape, keptDims = _a2.keptDims;
      if (newShape.length < shape.length) {
        var newInputInfo = squeezeInputInfo(inputInfo, newShape);
        var params = ["row", "col", "depth", "depth2", "depth3"];
        return "\n      ".concat(getSamplerFromInInfo(newInputInfo), "\n      float ").concat(funcName, "(int row, int col, int depth, int depth2, int depth3) {\n        return ").concat(funcName, "(").concat(getSqueezedParams(params, keptDims), ");\n      }\n    ");
      }
      if (inputInfo.shapeInfo.isUniform) {
        return "\n      float ".concat(funcName, "(int row, int col, int depth, int depth2, int depth3) {\n        float index = dot(\n          vec4(row, col, depth, depth2),\n          vec4(").concat(stride0, ", ").concat(stride1, ", ").concat(stride2, ", ").concat(stride3, ")) +\n          depth3;\n        ").concat(getUniformSampler(inputInfo), "\n      }\n    ");
      }
      var flatOffset = inputInfo.shapeInfo.flatOffset;
      var texShape = inputInfo.shapeInfo.texShape;
      var texNumR = texShape[0];
      var texNumC = texShape[1];
      if (texNumC === stride0 && flatOffset == null) {
        return "\n      float ".concat(funcName, "(int row, int col, int depth, int depth2, int depth3) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n                         vec4(").concat(stride1, ", ").concat(stride2, ", ").concat(stride3, ", 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(texNumC, ".0, ").concat(texNumR, ".0);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
      }
      if (texNumC === stride3 && flatOffset == null) {
        return "\n      float ".concat(funcName, "(int row, int col, int depth, int depth2, int depth3) {\n        float texR = dot(\n          vec4(row, col, depth, depth2),\n          vec4(").concat(shape[1] * shape[2] * shape[3], ",\n               ").concat(shape[2] * shape[3], ", ").concat(shape[3], ", 1));\n        int texC = depth3;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(").concat(texNumC, ".0, ").concat(texNumR, ".0);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
      }
      var offset = getFlatOffsetUniformName(texName);
      return "\n    float ".concat(funcName, "(int row, int col, int depth, int depth2, int depth3) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ").concat(stride0, " + col * ").concat(stride1, " + depth * ").concat(stride2, " +\n          depth2 * ").concat(stride3, " + depth3 + ").concat(offset, ";\n      vec2 uv = uvFromFlat(").concat(texNumR, ", ").concat(texNumC, ", index);\n      return sampleTexture(").concat(texName, ", uv);\n    }\n  ");
    }
    function getSampler6D(inputInfo) {
      var shape = inputInfo.shapeInfo.logicalShape;
      var texName = inputInfo.name;
      var funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
      var _a2 = tf.util.squeezeShape(shape), newShape = _a2.newShape, keptDims = _a2.keptDims;
      if (newShape.length < shape.length) {
        var newInputInfo = squeezeInputInfo(inputInfo, newShape);
        var params = ["row", "col", "depth", "depth2", "depth3", "depth4"];
        return "\n      ".concat(getSamplerFromInInfo(newInputInfo), "\n      float ").concat(funcName, "(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        return ").concat(funcName, "(").concat(getSqueezedParams(params, keptDims), ");\n      }\n    ");
      }
      var stride4 = shape[5];
      var stride3 = shape[4] * stride4;
      var stride2 = shape[3] * stride3;
      var stride1 = shape[2] * stride2;
      var stride0 = shape[1] * stride1;
      if (inputInfo.shapeInfo.isUniform) {
        return "\n      float ".concat(funcName, "(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n        int index = round(dot(\n          vec4(row, col, depth, depth2),\n          vec4(").concat(stride0, ", ").concat(stride1, ", ").concat(stride2, ", ").concat(stride3, ")) +\n          dot(\n            vec2(depth3, depth4),\n            vec2(").concat(stride4, ", 1)));\n        ").concat(getUniformSampler(inputInfo), "\n      }\n    ");
      }
      var flatOffset = inputInfo.shapeInfo.flatOffset;
      var texShape = inputInfo.shapeInfo.texShape;
      var texNumR = texShape[0];
      var texNumC = texShape[1];
      if (texNumC === stride0 && flatOffset == null) {
        return "\n      float ".concat(funcName, "(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n          vec4(").concat(stride1, ", ").concat(stride2, ", ").concat(stride3, ", ").concat(stride4, ")) +\n               float(depth4);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(texNumC, ".0, ").concat(texNumR, ".0);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
      }
      if (texNumC === stride4 && flatOffset == null) {
        return "\n      float ".concat(funcName, "(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        float texR = dot(vec4(row, col, depth, depth2),\n          vec4(").concat(shape[1] * shape[2] * shape[3] * shape[4], ",\n               ").concat(shape[2] * shape[3] * shape[4], ",\n               ").concat(shape[3] * shape[4], ",\n               ").concat(shape[4], ")) + float(depth3);\n        int texC = depth4;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(").concat(texNumC, ".0, ").concat(texNumR, ".0);\n        return sampleTexture(").concat(texName, ", uv);\n      }\n    ");
      }
      var offset = getFlatOffsetUniformName(texName);
      return "\n    float ".concat(funcName, "(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ").concat(stride0, " + col * ").concat(stride1, " + depth * ").concat(stride2, " +\n          depth2 * ").concat(stride3, " + depth3 * ").concat(stride4, " + depth4 + ").concat(offset, ";\n      vec2 uv = uvFromFlat(").concat(texNumR, ", ").concat(texNumC, ", index);\n      return sampleTexture(").concat(texName, ", uv);\n    }\n  ");
    }
    function getUniformSampler(inputInfo) {
      var texName = inputInfo.name;
      var inSize = tf.util.sizeFromShape(inputInfo.shapeInfo.logicalShape);
      if (inSize < 2) {
        return "return ".concat(texName, ";");
      }
      return "\n    for (int i = 0; i < ".concat(inSize, "; i++) {\n      if (i == index) {\n        return ").concat(texName, "[i];\n      }\n    }\n  ");
    }
    function getPackedSamplerAtOutputCoords(inputInfo, outShapeInfo) {
      var texName = inputInfo.name;
      var texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);
      var funcName = "get" + texFuncSnippet + "AtOutCoords";
      var inRank = inputInfo.shapeInfo.logicalShape.length;
      var outRank = outShapeInfo.logicalShape.length;
      var broadcastDims = getBroadcastDims(inputInfo.shapeInfo.logicalShape, outShapeInfo.logicalShape);
      var type = getCoordsDataType(outRank);
      var rankDiff = outRank - inRank;
      var coordsSnippet;
      var fields = ["x", "y", "z", "w", "u", "v"];
      if (inRank === 0) {
        coordsSnippet = "";
      } else if (outRank < 2 && broadcastDims.length >= 1) {
        coordsSnippet = "coords = 0;";
      } else {
        coordsSnippet = broadcastDims.map(function(d) {
          return "coords.".concat(fields[d + rankDiff], " = 0;");
        }).join("\n");
      }
      var unpackedCoordsSnippet = "";
      if (outRank < 2 && inRank > 0) {
        unpackedCoordsSnippet = "coords";
      } else {
        unpackedCoordsSnippet = inputInfo.shapeInfo.logicalShape.map(function(s, i) {
          return "coords.".concat(fields[i + rankDiff]);
        }).join(", ");
      }
      var output = "return outputValue;";
      var inSize = tf.util.sizeFromShape(inputInfo.shapeInfo.logicalShape);
      var isInputScalar = inSize === 1;
      var outSize = tf.util.sizeFromShape(outShapeInfo.logicalShape);
      var isOutputScalar = outSize === 1;
      if (inRank === 1 && !isInputScalar && !isOutputScalar) {
        output = "\n      return vec4(outputValue.xy, outputValue.xy);\n    ";
      } else if (isInputScalar && !isOutputScalar) {
        if (outRank === 1) {
          output = "\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\n      ";
        } else {
          output = "\n        return vec4(outputValue.x);\n      ";
        }
      } else if (broadcastDims.length) {
        var rows = inRank - 2;
        var cols = inRank - 1;
        if (broadcastDims.indexOf(rows) > -1 && broadcastDims.indexOf(cols) > -1) {
          output = "return vec4(outputValue.x);";
        } else if (broadcastDims.indexOf(rows) > -1) {
          output = "return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);";
        } else if (broadcastDims.indexOf(cols) > -1) {
          output = "return vec4(outputValue.xx, outputValue.zz);";
        }
      }
      return "\n    vec4 ".concat(funcName, "() {\n      ").concat(type, " coords = getOutputCoords();\n      ").concat(coordsSnippet, "\n      vec4 outputValue = get").concat(texFuncSnippet, "(").concat(unpackedCoordsSnippet, ");\n      ").concat(output, "\n    }\n  ");
    }
    function getSamplerAtOutputCoords(inputInfo, outShapeInfo) {
      var texName = inputInfo.name;
      var texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);
      var funcName = "get" + texFuncSnippet + "AtOutCoords";
      var outTexShape = outShapeInfo.texShape;
      var inTexShape = inputInfo.shapeInfo.texShape;
      var inRank = inputInfo.shapeInfo.logicalShape.length;
      var outRank = outShapeInfo.logicalShape.length;
      if (!inputInfo.shapeInfo.isUniform && inRank === outRank && inputInfo.shapeInfo.flatOffset == null && tf.util.arraysEqual(inTexShape, outTexShape)) {
        return "\n      float ".concat(funcName, "() {\n        return sampleTexture(").concat(texName, ", resultUV);\n      }\n    ");
      }
      var type = getCoordsDataType(outRank);
      var broadcastDims = getBroadcastDims(inputInfo.shapeInfo.logicalShape, outShapeInfo.logicalShape);
      var rankDiff = outRank - inRank;
      var coordsSnippet;
      var fields = ["x", "y", "z", "w", "u", "v"];
      if (inRank === 0) {
        coordsSnippet = "";
      } else if (outRank < 2 && broadcastDims.length >= 1) {
        coordsSnippet = "coords = 0;";
      } else {
        coordsSnippet = broadcastDims.map(function(d) {
          return "coords.".concat(fields[d + rankDiff], " = 0;");
        }).join("\n");
      }
      var unpackedCoordsSnippet = "";
      if (outRank < 2 && inRank > 0) {
        unpackedCoordsSnippet = "coords";
      } else {
        unpackedCoordsSnippet = inputInfo.shapeInfo.logicalShape.map(function(s, i) {
          return "coords.".concat(fields[i + rankDiff]);
        }).join(", ");
      }
      return "\n    float ".concat(funcName, "() {\n      ").concat(type, " coords = getOutputCoords();\n      ").concat(coordsSnippet, "\n      return get").concat(texFuncSnippet, "(").concat(unpackedCoordsSnippet, ");\n    }\n  ");
    }
    function getCoordsDataType(rank) {
      if (rank <= 1) {
        return "int";
      } else if (rank === 2) {
        return "ivec2";
      } else if (rank === 3) {
        return "ivec3";
      } else if (rank === 4) {
        return "ivec4";
      } else if (rank === 5) {
        return "ivec5";
      } else if (rank === 6) {
        return "ivec6";
      } else {
        throw Error("GPU for rank ".concat(rank, " is not yet supported"));
      }
    }
    function getUniformInfoFromShape(isPacked, shape, texShape) {
      var _a2 = tf.util.squeezeShape(shape), newShape = _a2.newShape, keptDims = _a2.keptDims;
      var rank = shape.length;
      var useSqueezePackedShape = isPacked && rank === 3 && shape[0] === 1;
      var squeezeShape = useSqueezePackedShape ? shape.slice(1) : newShape;
      var useSqueezeShape = !isPacked && rank > 1 && !tf.util.arraysEqual(shape, texShape) && newShape.length < rank || useSqueezePackedShape;
      var uniformShape = useSqueezeShape ? squeezeShape : shape;
      return { useSqueezeShape, uniformShape, keptDims };
    }
    function squeezeInputInfo(inInfo, squeezedShape) {
      var newInputInfo = JSON.parse(JSON.stringify(inInfo));
      newInputInfo.shapeInfo.logicalShape = squeezedShape;
      return newInputInfo;
    }
    function getSqueezedParams(params, keptDims) {
      return keptDims.map(function(d) {
        return params[d];
      }).join(", ");
    }
    function compileProgram(gpgpu, program, inputs, output) {
      var inputInfos = inputs.map(function(input, i) {
        var shapeInfo = {
          logicalShape: input.shape,
          texShape: input.isUniform ? null : input.texData.texShape,
          isUniform: input.isUniform,
          isPacked: input.isUniform ? false : input.texData.isPacked,
          flatOffset: null
        };
        if (input.texData != null && input.texData.slice != null && input.texData.slice.flatOffset > 0) {
          shapeInfo.flatOffset = input.texData.slice.flatOffset;
        }
        return { name: program.variableNames[i], shapeInfo };
      });
      var inShapeInfos = inputInfos.map(function(x) {
        return x.shapeInfo;
      });
      var outShapeInfo = {
        logicalShape: output.shape,
        texShape: output.texData.texShape,
        isUniform: false,
        isPacked: output.texData.isPacked,
        flatOffset: null
      };
      var source = makeShader(inputInfos, outShapeInfo, program);
      var fragmentShader = createFragmentShader(gpgpu.gl, source);
      var webGLProgram = gpgpu.createProgram(fragmentShader);
      if (!tf.env().get("ENGINE_COMPILE_ONLY")) {
        gpgpu.buildVao(webGLProgram);
        return Object.assign({ program, fragmentShader, source, webGLProgram, inShapeInfos, outShapeInfo }, getUniformLocations(gpgpu, program, webGLProgram));
      } else {
        return {
          program,
          fragmentShader,
          source,
          webGLProgram,
          inShapeInfos,
          outShapeInfo,
          variablesLocations: null,
          customUniformLocations: null,
          infLoc: null,
          nanLoc: null,
          outShapeLocation: null,
          outShapeStridesLocation: null,
          outTexShapeLocation: null
        };
      }
    }
    function getUniformLocations(gpgpu, program, webGLProgram) {
      var e_12, _a2, e_2, _b;
      var variablesLocations = [];
      var customUniformLocations = [];
      var outShapeLocation;
      var outTexShapeLocation;
      var outShapeStridesLocation;
      var infLoc = null;
      var nanLoc = null;
      nanLoc = gpgpu.getUniformLocation(webGLProgram, "NAN", false);
      if (tf.env().getNumber("WEBGL_VERSION") === 1) {
        infLoc = gpgpu.getUniformLocation(webGLProgram, "INFINITY", false);
      }
      var shouldThrow = false;
      try {
        for (var _c = __values(program.variableNames), _d = _c.next(); !_d.done; _d = _c.next()) {
          var varName = _d.value;
          var varLocs = {
            name: varName,
            uniform: gpgpu.getUniformLocation(webGLProgram, varName, shouldThrow),
            offset: gpgpu.getUniformLocation(webGLProgram, "offset".concat(varName), shouldThrow)
          };
          if (program.enableShapeUniforms) {
            varLocs.shape = gpgpu.getUniformLocation(webGLProgram, "".concat(varName, "Shape"), shouldThrow);
            varLocs.texShape = gpgpu.getUniformLocation(webGLProgram, "".concat(varName, "TexShape"), shouldThrow);
          }
          variablesLocations.push(varLocs);
        }
      } catch (e_1_1) {
        e_12 = { error: e_1_1 };
      } finally {
        try {
          if (_d && !_d.done && (_a2 = _c.return))
            _a2.call(_c);
        } finally {
          if (e_12)
            throw e_12.error;
        }
      }
      if (program.enableShapeUniforms) {
        outShapeLocation = gpgpu.getUniformLocation(webGLProgram, "outShape", shouldThrow);
        outShapeStridesLocation = gpgpu.getUniformLocation(webGLProgram, "outShapeStrides", shouldThrow);
        outTexShapeLocation = gpgpu.getUniformLocation(webGLProgram, "outTexShape", shouldThrow);
      }
      if (program.customUniforms) {
        try {
          for (var _e = __values(program.customUniforms), _f = _e.next(); !_f.done; _f = _e.next()) {
            var d = _f.value;
            customUniformLocations.push(gpgpu.getUniformLocation(webGLProgram, d.name, shouldThrow));
          }
        } catch (e_2_1) {
          e_2 = { error: e_2_1 };
        } finally {
          try {
            if (_f && !_f.done && (_b = _e.return))
              _b.call(_e);
          } finally {
            if (e_2)
              throw e_2.error;
          }
        }
      }
      return {
        variablesLocations,
        customUniformLocations,
        infLoc,
        nanLoc,
        outShapeLocation,
        outShapeStridesLocation,
        outTexShapeLocation
      };
    }
    function validateBinaryAndProgram(shapeInfos, inputs) {
      if (shapeInfos.length !== inputs.length) {
        throw Error("Binary was compiled with ".concat(shapeInfos.length, " inputs, but ") + "was executed with ".concat(inputs.length, " inputs"));
      }
      shapeInfos.forEach(function(s, i) {
        var shapeA = s.logicalShape;
        var input = inputs[i];
        var shapeB = input.shape;
        if (!tf.util.arraysEqual(shapeA, shapeB)) {
          throw Error("Binary was compiled with different shapes than " + "the current args. Shapes ".concat(shapeA, " and ").concat(shapeB, " must match"));
        }
        if (s.isUniform && input.isUniform) {
          return;
        }
        var texShapeA = s.texShape;
        var texShapeB = input.isUniform ? null : input.texData.texShape;
        if (!tf.util.arraysEqual(texShapeA, texShapeB)) {
          throw Error("Binary was compiled with different texture shapes than the" + " current args. Shape ".concat(texShapeA, " and ").concat(texShapeB, " must match"));
        }
      });
    }
    function runProgram(gpgpu, binary, inputs, output, customUniformValues) {
      if (!binary.program.enableShapeUniforms) {
        validateBinaryAndProgram(binary.inShapeInfos, inputs);
        validateBinaryAndProgram([binary.outShapeInfo], [output]);
      }
      var outTex = output.texData.texture;
      var outTexShape = output.texData.texShape;
      if (output.texData.isPacked) {
        gpgpu.setOutputPackedMatrixTexture(outTex.texture, outTexShape[0], outTexShape[1]);
      } else {
        gpgpu.setOutputMatrixTexture(outTex.texture, outTexShape[0], outTexShape[1]);
      }
      gpgpu.setProgram(binary.webGLProgram);
      gpgpu.bindVertexArray(binary.webGLProgram.vao);
      if (tf.env().getNumber("WEBGL_VERSION") === 1) {
        if (binary.infLoc !== null) {
          gpgpu.gl.uniform1f(binary.infLoc, Infinity);
        }
      }
      if (binary.nanLoc !== null) {
        gpgpu.gl.uniform1f(binary.nanLoc, NaN);
      }
      for (var i = 0; i < inputs.length; ++i) {
        var input = inputs[i];
        var _a2 = binary.variablesLocations[i], varLoc = _a2.uniform, varOffsetLoc = _a2.offset, varShapeLoc = _a2.shape, varTexShapeLoc = _a2.texShape;
        if (varShapeLoc) {
          var uniformShape = getUniformInfoFromShape(binary.program.packedInputs, input.shape, input.texData.texShape).uniformShape;
          switch (uniformShape.length) {
            case 1:
              gpgpu.gl.uniform1iv(varShapeLoc, new Int32Array(uniformShape));
              break;
            case 2:
              gpgpu.gl.uniform2iv(varShapeLoc, new Int32Array(uniformShape));
              break;
            case 3:
              gpgpu.gl.uniform3iv(varShapeLoc, new Int32Array(uniformShape));
              break;
            case 4:
              gpgpu.gl.uniform4iv(varShapeLoc, new Int32Array(uniformShape));
              break;
          }
        }
        if (varTexShapeLoc) {
          gpgpu.gl.uniform2i(varTexShapeLoc, input.texData.texShape[0], input.texData.texShape[1]);
        }
        if (varLoc == null) {
          continue;
        }
        if (input.isUniform) {
          if (tf.util.sizeFromShape(input.shape) < 2) {
            gpgpu.gl.uniform1f(varLoc, input.uniformValues[0]);
          } else {
            var vals = input.uniformValues;
            if (!(vals instanceof Float32Array)) {
              vals = new Float32Array(vals);
            }
            gpgpu.gl.uniform1fv(varLoc, vals);
          }
          continue;
        }
        if (input.texData.slice != null && varOffsetLoc != null) {
          gpgpu.gl.uniform1i(varOffsetLoc, input.texData.slice.flatOffset);
        }
        gpgpu.setInputMatrixTexture(input.texData.texture.texture, varLoc, i);
      }
      var outShapeLoc = binary.outShapeLocation;
      if (outShapeLoc) {
        switch (output.shape.length) {
          case 1:
            gpgpu.gl.uniform1iv(outShapeLoc, new Int32Array(output.shape));
            break;
          case 2:
            gpgpu.gl.uniform2iv(outShapeLoc, new Int32Array(output.shape));
            break;
          case 3:
            gpgpu.gl.uniform3iv(outShapeLoc, new Int32Array(output.shape));
            break;
          case 4:
            gpgpu.gl.uniform4iv(outShapeLoc, new Int32Array(output.shape));
            break;
        }
      }
      if (binary.outShapeStridesLocation) {
        var strides = tf.util.computeStrides(output.shape);
        switch (output.shape.length) {
          case 2:
            gpgpu.gl.uniform1iv(binary.outShapeStridesLocation, new Int32Array(strides));
            break;
          case 3:
            gpgpu.gl.uniform2iv(binary.outShapeStridesLocation, new Int32Array(strides));
            break;
          case 4:
            gpgpu.gl.uniform3iv(binary.outShapeStridesLocation, new Int32Array(strides));
            break;
        }
      }
      if (binary.outTexShapeLocation) {
        gpgpu.gl.uniform2i(binary.outTexShapeLocation, output.texData.texShape[0], output.texData.texShape[1]);
      }
      if (binary.program.customUniforms && customUniformValues) {
        for (var i = 0; i < binary.program.customUniforms.length; ++i) {
          var d = binary.program.customUniforms[i];
          var customLoc = binary.customUniformLocations[i];
          var customValue = customUniformValues[i];
          if (d.type === "float") {
            gpgpu.gl.uniform1fv(customLoc, customValue);
          } else if (d.type === "vec2") {
            gpgpu.gl.uniform2fv(customLoc, customValue);
          } else if (d.type === "vec3") {
            gpgpu.gl.uniform3fv(customLoc, customValue);
          } else if (d.type === "vec4") {
            gpgpu.gl.uniform4fv(customLoc, customValue);
          } else if (d.type === "int") {
            gpgpu.gl.uniform1iv(customLoc, customValue);
          } else if (d.type === "ivec2") {
            gpgpu.gl.uniform2iv(customLoc, customValue);
          } else if (d.type === "ivec3") {
            gpgpu.gl.uniform3iv(customLoc, customValue);
          } else if (d.type === "ivec4") {
            gpgpu.gl.uniform4iv(customLoc, customValue);
          } else {
            throw Error("uniform type ".concat(d.type, " is not supported yet."));
          }
        }
      }
      gpgpu.executeProgram();
    }
    function makeShaderKey(program, inputs, output) {
      var keyInputs = "";
      inputs.concat(output).forEach(function(x) {
        var hasOffset = x.texData != null && x.texData.slice != null && x.texData.slice.flatOffset > 0;
        if (program.enableShapeUniforms && !x.isUniform) {
          var xTexShape = x.texData.texShape;
          var _a2 = getUniformInfoFromShape(program.packedInputs, x.shape, xTexShape), useSqueezeShape = _a2.useSqueezeShape, uniformShape = _a2.uniformShape, keptDims = _a2.keptDims;
          var rank1 = "", rank2 = "", rank34 = "";
          if (uniformShape.length === 1 && program.packedInputs) {
            var packedTexShape = [Math.ceil(xTexShape[0] / 2), Math.ceil(xTexShape[1] / 2)];
            rank1 = "".concat(packedTexShape[0] > 1, "_").concat(packedTexShape[1] > 1);
          } else if (uniformShape.length === 2 && !program.packedInputs) {
            rank2 = "".concat(uniformShape[0] > 1, "_").concat(uniformShape[1] > 1);
          } else if (uniformShape.length > 2 && !program.packedInputs) {
            var strides = tf.util.computeStrides(uniformShape);
            rank34 = "".concat(strides[0] === xTexShape[1], "_").concat(strides[strides.length - 1] === xTexShape[1]);
          }
          var xRank = x.shape.length;
          var isLogicalShapTexShapeEqual = uniformShape.length === 2 && tf.util.arraysEqual(x.shape, xTexShape);
          var isScalar = tf.util.sizeFromShape(x.shape) === 1;
          var broadcastDims = tf.backend_util.getBroadcastDims(x.shape, output.shape);
          var isInOutTexShapeEqual = !program.packedInputs && xRank === output.shape.length && tf.util.arraysEqual(xTexShape, output.texData.texShape);
          var isTexShapeGreaterThanOne = program.packedInputs || uniformShape.length > 2 ? "" : "".concat(xTexShape[0] > 1, "_").concat(xTexShape[1] > 1);
          keyInputs += "".concat(xRank, "_").concat(isInOutTexShapeEqual, "_").concat(useSqueezeShape ? keptDims : "", "_").concat(uniformShape.length, "_").concat(isScalar, "_").concat(broadcastDims, "_").concat(isLogicalShapTexShapeEqual, "_").concat(rank1, "_").concat(rank2, "_").concat(rank34, "_").concat(isTexShapeGreaterThanOne, "_").concat(hasOffset);
        } else {
          var texShape = x.isUniform ? "uniform" : x.texData.texShape;
          keyInputs += "".concat(x.shape, "_").concat(texShape, "_").concat(hasOffset);
        }
      });
      var keyUserCode = program.userCode;
      var key = program.constructor.name;
      key += "_" + keyInputs + "_" + keyUserCode + "".concat(tf.env().getNumber("WEBGL_VERSION"));
      return key;
    }
    function useShapeUniforms(rank) {
      return tf.env().getBool("WEBGL_USE_SHAPES_UNIFORMS") && rank <= 4;
    }
    var DecodeMatrixProgram = (
      /** @class */
      function() {
        function DecodeMatrixProgram2(outputShape) {
          this.variableNames = ["A"];
          this.packedInputs = false;
          this.packedOutput = true;
          this.outPackingScheme = PackingScheme.DENSE;
          this.customUniforms = [{ name: "texShape", type: "ivec2" }];
          var glsl = getGlslDifferences();
          this.outputShape = outputShape;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          this.userCode = "\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ".concat(this.enableShapeUniforms ? getOutputLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d"], outputShape) : getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], outputShape), "\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));\n        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getA(rc.x, rc.y, rc.z);\n        }\n\n        ").concat(glsl.output, " = result;\n      }\n    ");
        }
        return DecodeMatrixProgram2;
      }()
    );
    var DecodeMatrixPackedProgram = (
      /** @class */
      function() {
        function DecodeMatrixPackedProgram2(outputShape) {
          this.variableNames = ["A"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.outPackingScheme = PackingScheme.DENSE;
          this.customUniforms = [{ name: "texShape", type: "ivec2" }];
          var glsl = getGlslDifferences();
          this.outputShape = outputShape;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          this.userCode = "\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ".concat(this.enableShapeUniforms ? getOutputLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d"], outputShape) : getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], outputShape), "\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));\n        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\n        }\n\n        ").concat(glsl.output, " = result;\n      }\n    ");
        }
        return DecodeMatrixPackedProgram2;
      }()
    );
    var EncodeFloatProgram = (
      /** @class */
      function() {
        function EncodeFloatProgram2(outputShape) {
          this.variableNames = ["A"];
          this.outTexUsage = TextureUsage.DOWNLOAD;
          var glsl = getGlslDifferences();
          this.outputShape = outputShape;
          this.userCode = "\n      ".concat(ENCODE_FLOAT_SNIPPET, "\n\n      void main() {\n        float x = getAAtOutCoords();\n        ").concat(glsl.output, " = encode_float(x);\n      }\n    ");
        }
        return EncodeFloatProgram2;
      }()
    );
    var EncodeFloatPackedProgram = (
      /** @class */
      function() {
        function EncodeFloatPackedProgram2(outputShape) {
          this.variableNames = ["A"];
          this.packedInputs = true;
          this.packedOutput = false;
          this.outTexUsage = TextureUsage.DOWNLOAD;
          var glsl = getGlslDifferences();
          this.outputShape = outputShape;
          this.userCode = "\n      ".concat(ENCODE_FLOAT_SNIPPET, "\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\n        ").concat(glsl.output, " = encode_float(x);\n      }\n    ");
        }
        return EncodeFloatPackedProgram2;
      }()
    );
    var CHANNEL_CHAR_TO_INDEX_MAP = {
      "R": 0,
      "G": 1,
      "B": 2,
      "A": 3
    };
    var EncodeMatrixProgram = (
      /** @class */
      function() {
        function EncodeMatrixProgram2(outputShape, inputIsUnsignedByte, usedChannels) {
          if (inputIsUnsignedByte === void 0) {
            inputIsUnsignedByte = false;
          }
          if (usedChannels === void 0) {
            usedChannels = "RGBA";
          }
          this.variableNames = ["A"];
          this.customUniforms = [{ name: "texShape", type: "ivec2" }];
          var glsl = getGlslDifferences();
          this.outputShape = outputShape;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          var output = "result";
          if (inputIsUnsignedByte) {
            output = "floor(result * 255. + 0.5)";
          }
          var mainLoop = "";
          for (var usedChannelIndex = 0; usedChannelIndex < usedChannels.length; usedChannelIndex++) {
            var curChannel = usedChannels[usedChannelIndex];
            mainLoop += "\n          if(offset == ".concat(usedChannelIndex, ") {\n            result = values[").concat(CHANNEL_CHAR_TO_INDEX_MAP[curChannel], "];\n          }");
          }
          this.userCode = "\n      ".concat(this.enableShapeUniforms ? getFlatIndexFrom3DOutput() : getFlatIndexFrom3D(outputShape), "\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int flatIndex = getFlatIndex(coords);\n        float result = 0.;\n        int offset = imod(flatIndex, ").concat(usedChannels.length, ");\n\n        flatIndex = idiv(flatIndex, ").concat(usedChannels.length, ", 1.);\n\n        int r = flatIndex / texShape[1];\n        if (r < texShape[0]) {\n          int c = imod(flatIndex, texShape[1]);\n          vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);\n          vec4 values = ").concat(glsl.texture2D, "(A, uv);\n          ").concat(mainLoop, "\n        }\n        ").concat(glsl.output, " = vec4(").concat(output, ", 0., 0., 0.);\n      }\n    ");
        }
        return EncodeMatrixProgram2;
      }()
    );
    var EncodeMatrixPackedProgram = (
      /** @class */
      function() {
        function EncodeMatrixPackedProgram2(outputShape, inputIsUnsignedByte) {
          if (inputIsUnsignedByte === void 0) {
            inputIsUnsignedByte = false;
          }
          this.variableNames = ["A"];
          this.packedInputs = false;
          this.packedOutput = true;
          this.customUniforms = [{ name: "texShape", type: "ivec2" }];
          var glsl = getGlslDifferences();
          this.outputShape = outputShape;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          var mainLoop = "";
          var output = "result";
          if (inputIsUnsignedByte) {
            output = "floor(result * 255. + 0.5)";
          }
          for (var row = 0; row <= 1; row++) {
            for (var col = 0; col <= 1; col++) {
              var channel = row * 2 + col;
              mainLoop += "\n          localCoords = coords;\n          if(localCoords[2] + ".concat(col, " < ").concat(this.enableShapeUniforms ? "outShape[2]" : "".concat(outputShape[2]), ") {\n          localCoords[2] += ").concat(col, ";\n          if (localCoords[1] + ").concat(row, " < ").concat(this.enableShapeUniforms ? "outShape[1]" : "".concat(outputShape[1]), ") {\n            localCoords[1] += ").concat(row, ";\n\n            flatIndex = getFlatIndex(localCoords);\n            offset = imod(flatIndex, 4);\n\n            flatIndex = idiv(flatIndex, 4, 1.);\n\n            int r = flatIndex / texShape[1];\n            int c = imod(flatIndex, texShape[1]);\n            vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);\n            values = ").concat(glsl.texture2D, "(A, uv);\n\n            if (offset == 0) {\n              result[").concat(channel, "] = values[0];\n            } else if (offset == 1) {\n              result[").concat(channel, "] = values[1];\n            } else if (offset == 2) {\n              result[").concat(channel, "] = values[2];\n            } else {\n              result[").concat(channel, "] = values[3];\n            }\n          }\n        }\n        ");
            }
          }
          this.userCode = "\n        ".concat(this.enableShapeUniforms ? getFlatIndexFrom3DOutput() : getFlatIndexFrom3D(outputShape), "\n\n        void main() {\n          ivec3 coords = getOutputCoords();\n\n          vec4 result = vec4(0.);\n          int flatIndex, r, c, offset;\n          ivec3 localCoords;\n          vec2 uv;\n          vec4 values;\n\n          ").concat(mainLoop, "\n\n          ").concat(glsl.output, " = ").concat(output, ";\n        }\n    ");
        }
        return EncodeMatrixPackedProgram2;
      }()
    );
    function createVertexShader(gl) {
      var glsl = getGlslDifferences();
      var vertexShaderSource = "".concat(glsl.version, "\n    precision highp float;\n    ").concat(glsl.attribute, " vec3 clipSpacePos;\n    ").concat(glsl.attribute, " vec2 uv;\n    ").concat(glsl.varyingVs, " vec2 resultUV;\n\n    void main() {\n      gl_Position = vec4(clipSpacePos, 1);\n      resultUV = uv;\n    }");
      return createVertexShader$1(gl, vertexShaderSource);
    }
    function createVertexBuffer(gl) {
      var vertexArray = new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]);
      return createStaticVertexBuffer(gl, vertexArray);
    }
    function createIndexBuffer(gl) {
      var triangleVertexIndices = new Uint16Array([0, 1, 2, 2, 1, 3]);
      return createStaticIndexBuffer(gl, triangleVertexIndices);
    }
    function createAndConfigureTexture(gl, width, height, internalFormat, textureFormat, textureType) {
      validateTextureSize(width, height);
      var texture = createTexture(gl);
      var tex2d = gl.TEXTURE_2D;
      callAndCheck(gl, function() {
        return gl.bindTexture(tex2d, texture);
      });
      callAndCheck(gl, function() {
        return gl.texParameteri(tex2d, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
      });
      callAndCheck(gl, function() {
        return gl.texParameteri(tex2d, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
      });
      callAndCheck(gl, function() {
        return gl.texParameteri(tex2d, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
      });
      callAndCheck(gl, function() {
        return gl.texParameteri(tex2d, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
      });
      if (tf.env().getNumber("WEBGL_VERSION") === 1) {
        callAndCheck(gl, function() {
          return gl.texImage2D(tex2d, 0, internalFormat, width, height, 0, textureFormat, textureType, null);
        });
      } else {
        callAndCheck(gl, function() {
          return gl.texStorage2D(tex2d, 1, internalFormat, width, height);
        });
      }
      callAndCheck(gl, function() {
        return gl.bindTexture(gl.TEXTURE_2D, null);
      });
      return { texture, texShape: [height, width] };
    }
    function getInternalFormatForFloat32MatrixTexture(textureConfig) {
      return textureConfig.internalFormatFloat;
    }
    function createFloat32MatrixTexture(gl, rows, columns, textureConfig) {
      var _a2 = __read(getUnpackedMatrixTextureShapeWidthHeight(rows, columns), 2), width = _a2[0], height = _a2[1];
      return createAndConfigureTexture(gl, width, height, getInternalFormatForFloat32MatrixTexture(textureConfig), textureConfig.textureFormatFloat, gl.FLOAT);
    }
    function getInternalFormatForFloat16MatrixTexture(textureConfig) {
      return textureConfig.internalFormatHalfFloat;
    }
    function createFloat16MatrixTexture(gl, rows, columns, textureConfig) {
      var _a2 = __read(getUnpackedMatrixTextureShapeWidthHeight(rows, columns), 2), width = _a2[0], height = _a2[1];
      return createAndConfigureTexture(gl, width, height, getInternalFormatForFloat16MatrixTexture(textureConfig), textureConfig.textureFormatFloat, textureConfig.textureTypeHalfFloat);
    }
    function getInternalFormatForUnsignedBytesMatrixTexture(textureConfig) {
      return textureConfig.downloadTextureFormat;
    }
    function createUnsignedBytesMatrixTexture(gl, rows, columns, textureConfig) {
      var _a2 = __read(getUnpackedMatrixTextureShapeWidthHeight(rows, columns), 2), width = _a2[0], height = _a2[1];
      return createAndConfigureTexture(gl, width, height, getInternalFormatForUnsignedBytesMatrixTexture(textureConfig), gl.RGBA, gl.UNSIGNED_BYTE);
    }
    function getInternalFormatForPackedMatrixTexture(textureConfig) {
      return textureConfig.internalFormatPackedFloat;
    }
    function createPackedMatrixTexture(gl, rows, columns, textureConfig) {
      var _a2 = __read(getPackedMatrixTextureShapeWidthHeight(rows, columns), 2), width = _a2[0], height = _a2[1];
      return createAndConfigureTexture(gl, width, height, getInternalFormatForPackedMatrixTexture(textureConfig), gl.RGBA, gl.FLOAT);
    }
    function getInternalFormatForFloat16PackedMatrixTexture(textureConfig) {
      return textureConfig.internalFormatPackedHalfFloat;
    }
    function createFloat16PackedMatrixTexture(gl, rows, columns, textureConfig) {
      var _a2 = __read(getPackedMatrixTextureShapeWidthHeight(rows, columns), 2), width = _a2[0], height = _a2[1];
      return createAndConfigureTexture(gl, width, height, getInternalFormatForFloat16PackedMatrixTexture(textureConfig), gl.RGBA, textureConfig.textureTypeHalfFloat);
    }
    function bindVertexProgramAttributeStreams(gl, program, vertexBuffer) {
      var posOffset = 0;
      var uvOffset = 3 * 4;
      var stride = 3 * 4 + 2 * 4;
      callAndCheck(gl, function() {
        return gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer);
      });
      var success = bindVertexBufferToProgramAttribute(gl, program, "clipSpacePos", vertexBuffer, 3, stride, posOffset);
      return success && bindVertexBufferToProgramAttribute(gl, program, "uv", vertexBuffer, 2, stride, uvOffset);
    }
    function uploadDenseMatrixToTexture(gl, texture, width, height, data, textureConfig) {
      callAndCheck(gl, function() {
        return gl.bindTexture(gl.TEXTURE_2D, texture);
      });
      var dataForUpload, texelDataType, internalFormat;
      if (data instanceof Uint8Array) {
        dataForUpload = new Uint8Array(width * height * 4);
        texelDataType = gl.UNSIGNED_BYTE;
        internalFormat = gl.RGBA;
      } else {
        dataForUpload = new Float32Array(width * height * 4);
        texelDataType = gl.FLOAT;
        internalFormat = textureConfig.internalFormatPackedFloat;
      }
      dataForUpload.set(data);
      if (tf.env().getNumber("WEBGL_VERSION") === 2) {
        callAndCheck(gl, function() {
          return gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, width, height, gl.RGBA, texelDataType, dataForUpload);
        });
      } else {
        callAndCheck(gl, function() {
          return gl.texImage2D(gl.TEXTURE_2D, 0, internalFormat, width, height, 0, gl.RGBA, texelDataType, dataForUpload);
        });
      }
      callAndCheck(gl, function() {
        return gl.bindTexture(gl.TEXTURE_2D, null);
      });
    }
    function uploadPixelDataToTexture(gl, texture, pixels) {
      callAndCheck(gl, function() {
        return gl.bindTexture(gl.TEXTURE_2D, texture);
      });
      if (pixels.data instanceof Uint8Array) {
        if (tf.env().getNumber("WEBGL_VERSION") === 2) {
          callAndCheck(gl, function() {
            return gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, pixels.width, pixels.height, gl.RGBA, gl.UNSIGNED_BYTE, pixels.data);
          });
        } else {
          callAndCheck(gl, function() {
            return gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, pixels.width, pixels.height, 0, gl.RGBA, gl.UNSIGNED_BYTE, pixels.data);
          });
        }
      } else {
        if (tf.env().getNumber("WEBGL_VERSION") === 2) {
          callAndCheck(gl, function() {
            return gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, gl.RGBA, gl.UNSIGNED_BYTE, pixels);
          });
        } else {
          callAndCheck(gl, function() {
            return gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, pixels);
          });
        }
      }
      callAndCheck(gl, function() {
        return gl.bindTexture(gl.TEXTURE_2D, null);
      });
    }
    function createBufferFromOutputTexture(gl2, rows, columns, textureConfig) {
      var buffer = gl2.createBuffer();
      callAndCheck(gl2, function() {
        return gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer);
      });
      var bytesPerFloat = 4;
      var valuesPerTexel = 4;
      var bufferSizeBytes = bytesPerFloat * valuesPerTexel * rows * columns;
      callAndCheck(gl2, function() {
        return gl2.bufferData(gl2.PIXEL_PACK_BUFFER, bufferSizeBytes, gl2.STREAM_READ);
      });
      callAndCheck(gl2, function() {
        return gl2.readPixels(0, 0, columns, rows, gl2.RGBA, gl2.FLOAT, 0);
      });
      callAndCheck(gl2, function() {
        return gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null);
      });
      return buffer;
    }
    function downloadFloat32MatrixFromBuffer(gl, buffer, size) {
      var gl2 = gl;
      var downloadTarget = new Float32Array(size);
      gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer);
      gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER, 0, downloadTarget);
      gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null);
      return downloadTarget;
    }
    function downloadByteEncodedFloatMatrixFromOutputTexture(gl, rows, columns, textureConfig) {
      var _a2 = __read(getUnpackedMatrixTextureShapeWidthHeight(rows, columns), 2), w = _a2[0], h = _a2[1];
      var numChannels = 4;
      var downloadTarget = new Uint8Array(getUnpackedArraySizeFromMatrixSize(rows * columns, numChannels));
      callAndCheck(gl, function() {
        return gl.readPixels(0, 0, w, h, textureConfig.downloadTextureFormat, gl.UNSIGNED_BYTE, downloadTarget);
      });
      return new Float32Array(downloadTarget.buffer);
    }
    function downloadPackedMatrixFromBuffer(gl, buffer, batch, rows, cols, physicalRows, physicalCols, textureConfig) {
      var gl2 = gl;
      var downloadTarget = new Float32Array(getPackedRGBAArraySizeFromMatrixShape(physicalRows, physicalCols));
      gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer);
      gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER, 0, downloadTarget);
      gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null);
      return downloadTarget;
    }
    function downloadMatrixFromPackedOutputTexture(gl, physicalRows, physicalCols) {
      var packedRGBA = new Float32Array(physicalRows * physicalCols * 4);
      callAndCheck(gl, function() {
        return gl.readPixels(0, 0, physicalCols, physicalRows, gl.RGBA, gl.FLOAT, packedRGBA);
      });
      return packedRGBA;
    }
    var gpgpu_util = {
      __proto__: null,
      bindVertexProgramAttributeStreams,
      createBufferFromOutputTexture,
      createFloat16MatrixTexture,
      createFloat16PackedMatrixTexture,
      createFloat32MatrixTexture,
      createIndexBuffer,
      createPackedMatrixTexture,
      createUnsignedBytesMatrixTexture,
      createVertexBuffer,
      createVertexShader,
      downloadByteEncodedFloatMatrixFromOutputTexture,
      downloadFloat32MatrixFromBuffer,
      downloadMatrixFromPackedOutputTexture,
      downloadPackedMatrixFromBuffer,
      getInternalFormatForFloat16MatrixTexture,
      getInternalFormatForFloat16PackedMatrixTexture,
      getInternalFormatForFloat32MatrixTexture,
      getInternalFormatForPackedMatrixTexture,
      getInternalFormatForUnsignedBytesMatrixTexture,
      uploadDenseMatrixToTexture,
      uploadPixelDataToTexture
    };
    var GPGPUContext = (
      /** @class */
      function() {
        function GPGPUContext2(gl) {
          this.outputTexture = null;
          this.program = null;
          this.disposed = false;
          this.itemsToPoll = [];
          var glVersion = tf.env().getNumber("WEBGL_VERSION");
          if (gl != null) {
            this.gl = gl;
            setWebGLContext(glVersion, gl);
          } else {
            this.gl = getWebGLContext(glVersion);
          }
          gl = this.gl;
          if (tf.env().getNumber("WEBGL_VERSION") === 2) {
            var gl2_1 = gl;
            this.createVertexArray = function() {
              return callAndCheck(gl2_1, function() {
                return gl2_1.createVertexArray();
              });
            };
            this.bindVertexArray = function(vao) {
              return callAndCheck(gl2_1, function() {
                return gl2_1.bindVertexArray(vao);
              });
            };
            this.deleteVertexArray = function(vao) {
              return callAndCheck(gl2_1, function() {
                return gl2_1.deleteVertexArray(vao);
              });
            };
            this.getVertexArray = function() {
              return callAndCheck(gl2_1, function() {
                return gl2_1.getParameter(gl2_1.VERTEX_ARRAY_BINDING);
              });
            };
          } else if (gl != null) {
            var ext_1 = gl.getExtension("OES_vertex_array_object");
            if (ext_1 == null) {
              throw new Error("All WebGL1 implementations are expected to offer OES_vertex_array_object.");
            }
            this.createVertexArray = function() {
              return callAndCheck(gl, function() {
                return ext_1.createVertexArrayOES();
              });
            };
            this.bindVertexArray = function(vao) {
              return callAndCheck(gl, function() {
                return ext_1.bindVertexArrayOES(vao);
              });
            };
            this.deleteVertexArray = function(vao) {
              return callAndCheck(gl, function() {
                return ext_1.deleteVertexArrayOES(vao);
              });
            };
            this.getVertexArray = function() {
              return callAndCheck(gl, function() {
                return gl.getParameter(ext_1.VERTEX_ARRAY_BINDING_OES);
              });
            };
          }
          var COLOR_BUFFER_FLOAT = "WEBGL_color_buffer_float";
          var COLOR_BUFFER_HALF_FLOAT = "EXT_color_buffer_half_float";
          this.parallelCompilationExtension = this.gl.getExtension("KHR_parallel_shader_compile");
          if (tf.env().getNumber("WEBGL_VERSION") === 1) {
            var TEXTURE_FLOAT = "OES_texture_float";
            var TEXTURE_HALF_FLOAT = "OES_texture_half_float";
            this.textureFloatExtension = getExtensionOrThrow(this.gl, TEXTURE_FLOAT);
            if (hasExtension(this.gl, TEXTURE_HALF_FLOAT)) {
              this.textureHalfFloatExtension = getExtensionOrThrow(this.gl, TEXTURE_HALF_FLOAT);
            } else if (tf.env().get("WEBGL_FORCE_F16_TEXTURES")) {
              throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
            }
            this.colorBufferFloatExtension = this.gl.getExtension(COLOR_BUFFER_FLOAT);
            if (hasExtension(this.gl, COLOR_BUFFER_HALF_FLOAT)) {
              this.colorBufferHalfFloatExtension = getExtensionOrThrow(this.gl, COLOR_BUFFER_HALF_FLOAT);
            } else if (tf.env().get("WEBGL_FORCE_F16_TEXTURES")) {
              throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
            }
          } else {
            COLOR_BUFFER_FLOAT = "EXT_color_buffer_float";
            if (hasExtension(this.gl, COLOR_BUFFER_FLOAT)) {
              this.colorBufferFloatExtension = this.gl.getExtension(COLOR_BUFFER_FLOAT);
            } else if (hasExtension(this.gl, COLOR_BUFFER_HALF_FLOAT)) {
              this.colorBufferHalfFloatExtension = this.gl.getExtension(COLOR_BUFFER_HALF_FLOAT);
            } else {
              throw new Error("GL context does not support color renderable floats");
            }
          }
          this.vertexBuffer = createVertexBuffer(this.gl);
          this.indexBuffer = createIndexBuffer(this.gl);
          this.framebuffer = createFramebuffer(this.gl);
          this.textureConfig = getTextureConfig(this.gl, this.textureHalfFloatExtension);
        }
        Object.defineProperty(GPGPUContext2.prototype, "debug", {
          get: function() {
            return tf.env().getBool("DEBUG");
          },
          enumerable: false,
          configurable: true
        });
        GPGPUContext2.prototype.dispose = function() {
          var _this = this;
          if (this.disposed) {
            return;
          }
          if (this.program != null) {
            console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing.");
          }
          if (this.outputTexture != null) {
            console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");
          }
          var gl = this.gl;
          callAndCheck(gl, function() {
            return gl.finish();
          });
          callAndCheck(gl, function() {
            return gl.bindFramebuffer(gl.FRAMEBUFFER, null);
          });
          callAndCheck(gl, function() {
            return gl.deleteFramebuffer(_this.framebuffer);
          });
          callAndCheck(gl, function() {
            return gl.bindBuffer(gl.ARRAY_BUFFER, null);
          });
          callAndCheck(gl, function() {
            return gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null);
          });
          callAndCheck(gl, function() {
            return gl.deleteBuffer(_this.indexBuffer);
          });
          this.disposed = true;
        };
        GPGPUContext2.prototype.createFloat32MatrixTexture = function(rows, columns) {
          this.throwIfDisposed();
          return createFloat32MatrixTexture(this.gl, rows, columns, this.textureConfig);
        };
        GPGPUContext2.prototype.createFloat16MatrixTexture = function(rows, columns) {
          this.throwIfDisposed();
          return createFloat16MatrixTexture(this.gl, rows, columns, this.textureConfig);
        };
        GPGPUContext2.prototype.createUnsignedBytesMatrixTexture = function(rows, columns) {
          this.throwIfDisposed();
          return createUnsignedBytesMatrixTexture(this.gl, rows, columns, this.textureConfig);
        };
        GPGPUContext2.prototype.uploadPixelDataToTexture = function(texture, pixels) {
          this.throwIfDisposed();
          uploadPixelDataToTexture(this.gl, texture, pixels);
        };
        GPGPUContext2.prototype.uploadDenseMatrixToTexture = function(texture, width, height, data) {
          this.throwIfDisposed();
          uploadDenseMatrixToTexture(this.gl, texture, width, height, data, this.textureConfig);
        };
        GPGPUContext2.prototype.createFloat16PackedMatrixTexture = function(rows, columns) {
          this.throwIfDisposed();
          return createFloat16PackedMatrixTexture(this.gl, rows, columns, this.textureConfig);
        };
        GPGPUContext2.prototype.createPackedMatrixTexture = function(rows, columns) {
          this.throwIfDisposed();
          return createPackedMatrixTexture(this.gl, rows, columns, this.textureConfig);
        };
        GPGPUContext2.prototype.deleteMatrixTexture = function(texture) {
          var _this = this;
          this.throwIfDisposed();
          if (this.outputTexture === texture) {
            unbindColorTextureFromFramebuffer(this.gl, this.framebuffer);
            this.outputTexture = null;
          }
          callAndCheck(this.gl, function() {
            return _this.gl.deleteTexture(texture);
          });
        };
        GPGPUContext2.prototype.downloadByteEncodedFloatMatrixFromOutputTexture = function(texture, rows, columns) {
          var _this = this;
          return this.downloadMatrixDriver(texture, function() {
            return downloadByteEncodedFloatMatrixFromOutputTexture(_this.gl, rows, columns, _this.textureConfig);
          });
        };
        GPGPUContext2.prototype.downloadPackedMatrixFromBuffer = function(buffer, batch, rows, columns, physicalRows, physicalCols) {
          return downloadPackedMatrixFromBuffer(this.gl, buffer, batch, rows, columns, physicalRows, physicalCols, this.textureConfig);
        };
        GPGPUContext2.prototype.downloadFloat32MatrixFromBuffer = function(buffer, size) {
          return downloadFloat32MatrixFromBuffer(this.gl, buffer, size);
        };
        GPGPUContext2.prototype.createBufferFromTexture = function(texture, rows, columns) {
          this.bindTextureToFrameBuffer(texture);
          var result = createBufferFromOutputTexture(this.gl, rows, columns, this.textureConfig);
          this.unbindTextureToFrameBuffer();
          return result;
        };
        GPGPUContext2.prototype.createAndWaitForFence = function() {
          var fenceContext = this.createFence(this.gl);
          return this.pollFence(fenceContext);
        };
        GPGPUContext2.prototype.createFence = function(gl) {
          var _this = this;
          var query;
          var isFencePassed;
          if (tf.env().getBool("WEBGL_FENCE_API_ENABLED")) {
            var gl2_2 = gl;
            var sync_1 = gl2_2.fenceSync(gl2_2.SYNC_GPU_COMMANDS_COMPLETE, 0);
            gl.flush();
            isFencePassed = function() {
              var status = gl2_2.clientWaitSync(sync_1, 0, 0);
              return status === gl2_2.ALREADY_SIGNALED || status === gl2_2.CONDITION_SATISFIED;
            };
            query = sync_1;
          } else if (tf.env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0) {
            query = this.beginQuery();
            this.endQuery();
            isFencePassed = function() {
              return _this.isQueryAvailable(query, tf.env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"));
            };
          } else {
            isFencePassed = function() {
              return true;
            };
          }
          return { query, isFencePassed };
        };
        GPGPUContext2.prototype.downloadMatrixFromPackedTexture = function(texture, physicalRows, physicalCols) {
          var _this = this;
          return this.downloadMatrixDriver(texture, function() {
            return downloadMatrixFromPackedOutputTexture(_this.gl, physicalRows, physicalCols);
          });
        };
        GPGPUContext2.prototype.createProgram = function(fragmentShader) {
          var _this = this;
          this.throwIfDisposed();
          var gl = this.gl;
          if (this.vertexShader == null) {
            this.vertexShader = createVertexShader(gl);
          }
          var program = createProgram(gl);
          callAndCheck(gl, function() {
            return gl.attachShader(program, _this.vertexShader);
          });
          callAndCheck(gl, function() {
            return gl.attachShader(program, fragmentShader);
          });
          linkProgram(gl, program);
          var program2 = Object.assign(program, { vao: this.createVertexArray() });
          if (this.debug) {
            validateProgram(gl, program2);
          }
          return program2;
        };
        GPGPUContext2.prototype.buildVao = function(program) {
          var _this = this;
          this.setProgram(program);
          this.bindVertexArray(program.vao);
          var gl = this.gl;
          callAndCheck(gl, function() {
            return gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, _this.indexBuffer);
          });
          bindVertexProgramAttributeStreams(gl, program, this.vertexBuffer);
        };
        GPGPUContext2.prototype.deleteProgram = function(program) {
          var _this = this;
          this.throwIfDisposed();
          if (program === this.program) {
            this.program = null;
          }
          if (program != null) {
            callAndCheck(this.gl, function() {
              return _this.gl.deleteProgram(program);
            });
            this.deleteVertexArray(program.vao);
          }
        };
        GPGPUContext2.prototype.setProgram = function(program) {
          var _this = this;
          this.throwIfDisposed();
          this.program = program;
          if (this.program != null) {
            if (this.debug) {
              validateProgram(this.gl, this.program);
            }
          }
          callAndCheck(this.gl, function() {
            return _this.gl.useProgram(program);
          });
        };
        GPGPUContext2.prototype.getUniformLocation = function(program, uniformName, shouldThrow) {
          if (shouldThrow === void 0) {
            shouldThrow = true;
          }
          this.throwIfDisposed();
          if (shouldThrow) {
            return getProgramUniformLocationOrThrow(this.gl, program, uniformName);
          } else {
            return getProgramUniformLocation(this.gl, program, uniformName);
          }
        };
        GPGPUContext2.prototype.getAttributeLocation = function(program, attribute) {
          var _this = this;
          this.throwIfDisposed();
          return callAndCheck(this.gl, function() {
            return _this.gl.getAttribLocation(program, attribute);
          });
        };
        GPGPUContext2.prototype.getUniformLocationNoThrow = function(program, uniformName) {
          this.throwIfDisposed();
          return this.gl.getUniformLocation(program, uniformName);
        };
        GPGPUContext2.prototype.setInputMatrixTexture = function(inputMatrixTexture, uniformLocation, textureUnit) {
          this.throwIfDisposed();
          this.throwIfNoProgram();
          bindTextureToProgramUniformSampler(this.gl, inputMatrixTexture, uniformLocation, textureUnit);
        };
        GPGPUContext2.prototype.setOutputMatrixTexture = function(outputMatrixTexture, rows, columns) {
          this.setOutputMatrixTextureDriver(outputMatrixTexture, columns, rows);
        };
        GPGPUContext2.prototype.setOutputPackedMatrixTexture = function(outputPackedMatrixTexture, rows, columns) {
          this.throwIfDisposed();
          var _a2 = __read(getPackedMatrixTextureShapeWidthHeight(rows, columns), 2), width = _a2[0], height = _a2[1];
          this.setOutputMatrixTextureDriver(outputPackedMatrixTexture, width, height);
        };
        GPGPUContext2.prototype.setOutputMatrixWriteRegion = function(startRow, numRows, startColumn, numColumns) {
          this.setOutputMatrixWriteRegionDriver(startColumn, startRow, numColumns, numRows);
        };
        GPGPUContext2.prototype.setOutputPackedMatrixWriteRegion = function(startRow, numRows, startColumn, numColumns) {
          throw new Error("setOutputPackedMatrixWriteRegion not implemented.");
        };
        GPGPUContext2.prototype.debugValidate = function() {
          if (this.program != null) {
            validateProgram(this.gl, this.program);
          }
          validateFramebuffer(this.gl);
        };
        GPGPUContext2.prototype.executeProgram = function() {
          this.throwIfDisposed();
          this.throwIfNoProgram();
          var gl = this.gl;
          if (this.debug) {
            var boundVao = this.getVertexArray();
            console.assert(boundVao === this.program.vao, "VAO changed between setProgram and executeProgram!");
            this.debugValidate();
          }
          callAndCheck(gl, function() {
            return gl.drawElements(gl.TRIANGLES, 6, gl.UNSIGNED_SHORT, 0);
          });
        };
        GPGPUContext2.prototype.blockUntilAllProgramsCompleted = function() {
          var _this = this;
          this.throwIfDisposed();
          callAndCheck(this.gl, function() {
            return _this.gl.finish();
          });
        };
        GPGPUContext2.prototype.getQueryTimerExtension = function() {
          if (this.disjointQueryTimerExtension == null) {
            this.disjointQueryTimerExtension = getExtensionOrThrow(this.gl, tf.env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2 ? "EXT_disjoint_timer_query_webgl2" : "EXT_disjoint_timer_query");
          }
          return this.disjointQueryTimerExtension;
        };
        GPGPUContext2.prototype.getQueryTimerExtensionWebGL2 = function() {
          return this.getQueryTimerExtension();
        };
        GPGPUContext2.prototype.getQueryTimerExtensionWebGL1 = function() {
          return this.getQueryTimerExtension();
        };
        GPGPUContext2.prototype.beginQuery = function() {
          if (tf.env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2) {
            var gl2 = this.gl;
            var ext_2 = this.getQueryTimerExtensionWebGL2();
            var query_1 = gl2.createQuery();
            gl2.beginQuery(ext_2.TIME_ELAPSED_EXT, query_1);
            return query_1;
          }
          var ext = this.getQueryTimerExtensionWebGL1();
          var query = ext.createQueryEXT();
          ext.beginQueryEXT(ext.TIME_ELAPSED_EXT, query);
          return query;
        };
        GPGPUContext2.prototype.endQuery = function() {
          if (tf.env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2) {
            var gl2 = this.gl;
            var ext_3 = this.getQueryTimerExtensionWebGL2();
            gl2.endQuery(ext_3.TIME_ELAPSED_EXT);
            return;
          }
          var ext = this.getQueryTimerExtensionWebGL1();
          ext.endQueryEXT(ext.TIME_ELAPSED_EXT);
        };
        GPGPUContext2.prototype.waitForQueryAndGetTime = function(query) {
          return __awaiter(this, void 0, void 0, function() {
            var _this = this;
            return __generator(this, function(_a2) {
              switch (_a2.label) {
                case 0:
                  return [4, tf.util.repeatedTry(function() {
                    return _this.disposed || // while testing contexts are created / disposed
                    // in rapid succession, so without this check we
                    // may poll for the query timer indefinitely
                    _this.isQueryAvailable(query, tf.env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"));
                  })];
                case 1:
                  _a2.sent();
                  return [2, this.getQueryTime(query, tf.env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))];
              }
            });
          });
        };
        GPGPUContext2.prototype.getQueryTime = function(query, queryTimerVersion) {
          if (queryTimerVersion === 0) {
            return null;
          }
          if (queryTimerVersion === 2) {
            var gl2 = this.gl;
            var timeElapsedNanos = gl2.getQueryParameter(query, gl2.QUERY_RESULT);
            return timeElapsedNanos / 1e6;
          } else {
            var ext = this.getQueryTimerExtensionWebGL1();
            var timeElapsedNanos = ext.getQueryObjectEXT(query, ext.QUERY_RESULT_EXT);
            return timeElapsedNanos / 1e6;
          }
        };
        GPGPUContext2.prototype.isQueryAvailable = function(query, queryTimerVersion) {
          if (queryTimerVersion === 0) {
            return true;
          }
          if (queryTimerVersion === 2) {
            var gl2 = this.gl;
            var ext = this.getQueryTimerExtensionWebGL2();
            var available = gl2.getQueryParameter(query, gl2.QUERY_RESULT_AVAILABLE);
            if (this.disjoint == null) {
              this.disjoint = this.gl.getParameter(ext.GPU_DISJOINT_EXT);
            }
            return available && !this.disjoint;
          } else {
            var ext = this.getQueryTimerExtensionWebGL1();
            var available = ext.getQueryObjectEXT(query, ext.QUERY_RESULT_AVAILABLE_EXT);
            if (this.disjoint == null) {
              this.disjoint = this.gl.getParameter(ext.GPU_DISJOINT_EXT);
            }
            return available && !this.disjoint;
          }
        };
        GPGPUContext2.prototype.pollFence = function(fenceContext) {
          var _this = this;
          return new Promise(function(resolve) {
            _this.addItemToPoll(function() {
              return fenceContext.isFencePassed();
            }, function() {
              return resolve();
            });
          });
        };
        GPGPUContext2.prototype.pollItems = function() {
          var index = linearSearchLastTrue(this.itemsToPoll.map(function(x) {
            return x.isDoneFn;
          }));
          for (var i = 0; i <= index; ++i) {
            var resolveFn = this.itemsToPoll[i].resolveFn;
            resolveFn();
          }
          this.itemsToPoll = this.itemsToPoll.slice(index + 1);
        };
        GPGPUContext2.prototype.addItemToPoll = function(isDoneFn, resolveFn) {
          var _this = this;
          this.itemsToPoll.push({ isDoneFn, resolveFn });
          if (this.itemsToPoll.length > 1) {
            return;
          }
          var scheduleFn = void 0;
          if ("setTimeoutCustom" in tf.env().platform) {
            scheduleFn = tf.env().platform.setTimeoutCustom.bind(tf.env().platform);
          }
          tf.util.repeatedTry(function() {
            _this.pollItems();
            return _this.itemsToPoll.length === 0;
          }, function() {
            return 0;
          }, null, scheduleFn);
        };
        GPGPUContext2.prototype.bindTextureToFrameBuffer = function(texture) {
          this.throwIfDisposed();
          bindColorTextureToFramebuffer(this.gl, texture, this.framebuffer);
          if (this.debug) {
            validateFramebuffer(this.gl);
          }
        };
        GPGPUContext2.prototype.unbindTextureToFrameBuffer = function() {
          if (this.outputTexture != null) {
            bindColorTextureToFramebuffer(this.gl, this.outputTexture, this.framebuffer);
            if (this.debug) {
              validateFramebuffer(this.gl);
            }
          } else {
            unbindColorTextureFromFramebuffer(this.gl, this.framebuffer);
          }
        };
        GPGPUContext2.prototype.downloadMatrixDriver = function(texture, downloadAndDecode) {
          this.bindTextureToFrameBuffer(texture);
          var result = downloadAndDecode();
          this.unbindTextureToFrameBuffer();
          return result;
        };
        GPGPUContext2.prototype.setOutputMatrixTextureDriver = function(outputMatrixTextureMaybePacked, width, height) {
          this.throwIfDisposed();
          var gl = this.gl;
          bindColorTextureToFramebuffer(gl, outputMatrixTextureMaybePacked, this.framebuffer);
          if (this.debug) {
            validateFramebuffer(gl);
          }
          this.outputTexture = outputMatrixTextureMaybePacked;
          callAndCheck(gl, function() {
            return gl.viewport(0, 0, width, height);
          });
          callAndCheck(gl, function() {
            return gl.scissor(0, 0, width, height);
          });
        };
        GPGPUContext2.prototype.setOutputMatrixWriteRegionDriver = function(x, y, width, height) {
          var _this = this;
          this.throwIfDisposed();
          callAndCheck(this.gl, function() {
            return _this.gl.scissor(x, y, width, height);
          });
        };
        GPGPUContext2.prototype.throwIfDisposed = function() {
          if (this.disposed) {
            throw new Error("Attempted to use disposed GPGPUContext.");
          }
        };
        GPGPUContext2.prototype.throwIfNoProgram = function() {
          if (this.program == null) {
            throw new Error("No GPU program is currently set.");
          }
        };
        return GPGPUContext2;
      }()
    );
    function linearSearchLastTrue(arr) {
      var i = 0;
      for (; i < arr.length; ++i) {
        var isDone = arr[i]();
        if (!isDone) {
          break;
        }
      }
      return i - 1;
    }
    function simpleAbsImpl(vals) {
      var resultValues = new Float32Array(vals.length);
      for (var i = 0; i < vals.length; ++i) {
        resultValues[i] = Math.abs(vals[i]);
      }
      return resultValues;
    }
    function createSimpleBinaryKernelImpl(op) {
      return function(aShape, bShape, aVals, bVals, dtype) {
        var newShape = tf.backend_util.assertAndGetBroadcastShape(aShape, bShape);
        var resultRank = newShape.length;
        var resultStrides = tf.util.computeStrides(newShape);
        var resultSize = tf.util.sizeFromShape(newShape);
        var result = tf.util.getTypedArrayFromDType(dtype, resultSize);
        var aRank = aShape.length;
        var bRank = bShape.length;
        var aStrides = tf.util.computeStrides(aShape);
        var bStrides = tf.util.computeStrides(bShape);
        var aBroadcastDims = tf.backend_util.getBroadcastDims(aShape, newShape);
        var bBroadcastDims = tf.backend_util.getBroadcastDims(bShape, newShape);
        if (aBroadcastDims.length + bBroadcastDims.length === 0) {
          for (var i = 0; i < result.length; ++i) {
            result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);
          }
        } else {
          var _loop_1 = function(i2) {
            var loc = tf.util.indexToLoc(i2, resultRank, resultStrides);
            var aLoc = loc.slice(-aRank);
            aBroadcastDims.forEach(function(d) {
              return aLoc[d] = 0;
            });
            var aIndex = tf.util.locToIndex(aLoc, aRank, aStrides);
            var bLoc = loc.slice(-bRank);
            bBroadcastDims.forEach(function(d) {
              return bLoc[d] = 0;
            });
            var bIndex = tf.util.locToIndex(bLoc, bRank, bStrides);
            result[i2] = op(aVals[aIndex], bVals[bIndex]);
          };
          for (var i = 0; i < result.length; ++i) {
            _loop_1(i);
          }
        }
        return [result, newShape];
      };
    }
    function castImpl(values, shape, inputType, dtype) {
      if (dtype === "int32") {
        var resultValues = Int32Array.from(values);
        return [shape, "int32", resultValues];
      }
      if (dtype === "bool") {
        var zero = tf.util.toTypedArray([0], inputType);
        var _a2 = __read(createSimpleBinaryKernelImpl(function(a, b) {
          return a !== b ? 1 : 0;
        })(shape, [], values, zero, "bool"), 2), resultData = _a2[0], resultShape = _a2[1];
        return [resultShape, "bool", resultData];
      }
      throw new Error("Error in Cast: failed to cast ".concat(inputType, " to ").concat(dtype));
    }
    var addImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a + b;
    });
    function bincountImpl(xVals, weightsVals, weightsDtype, weightsShape, size) {
      var weightsSize = tf.util.sizeFromShape(weightsShape);
      var outVals = tf.util.makeZerosTypedArray(size, weightsDtype);
      for (var i = 0; i < xVals.length; i++) {
        var value = xVals[i];
        if (value < 0) {
          throw new Error("Input x must be non-negative!");
        }
        if (value >= size) {
          continue;
        }
        if (weightsSize > 0) {
          outVals[value] += weightsVals[i];
        } else {
          outVals[value] += 1;
        }
      }
      return outVals;
    }
    function bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput) {
      if (binaryOutput === void 0) {
        binaryOutput = false;
      }
      var numRows = xBuf.shape[0];
      var numCols = xBuf.shape[1];
      var outBuf = tf.buffer([numRows, size], weightsBuf.dtype);
      for (var i = 0; i < numRows; i++) {
        for (var j = 0; j < numCols; j++) {
          var value = xBuf.get(i, j);
          if (value < 0) {
            throw new Error("Input x must be non-negative!");
          }
          if (value >= size) {
            continue;
          }
          if (binaryOutput) {
            outBuf.set(1, i, value);
          } else {
            if (weightsBuf.size > 0) {
              outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j), i, value);
            } else {
              outBuf.set(outBuf.get(i, value) + 1, i, value);
            }
          }
        }
      }
      return outBuf;
    }
    var bitwiseAndImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a & b;
    });
    function createSimpleUnaryImpl(op) {
      return function(values, dtype, attrs) {
        var newValues = tf.util.getArrayFromDType(dtype, values.length);
        for (var i = 0; i < values.length; ++i) {
          newValues[i] = op(values[i], attrs);
        }
        return newValues;
      };
    }
    var ceilImpl = createSimpleUnaryImpl(function(xi) {
      return Math.ceil(xi);
    });
    function concatImpl$1(inputs, outShape, dtype, simplyConcat) {
      var outVals = tf.util.getArrayFromDType(dtype, tf.util.sizeFromShape(outShape));
      if (simplyConcat && dtype !== "string") {
        var offset_1 = 0;
        inputs.forEach(function(input) {
          var size = tf.util.sizeFromShape(input.shape);
          outVals.set(input.vals, offset_1);
          offset_1 += size;
        });
      } else {
        var colOffset_1 = 0;
        inputs.forEach(function(input) {
          var decodedData = dtype === "string" ? tf.backend_util.fromUint8ToStringArray(input.vals) : input.vals;
          var tIdx = 0;
          for (var row = 0; row < input.shape[0]; ++row) {
            var resIdx = row * outShape[1] + colOffset_1;
            for (var col = 0; col < input.shape[1]; ++col) {
              outVals[resIdx + col] = decodedData[tIdx++];
            }
          }
          colOffset_1 += input.shape[1];
        });
      }
      return outVals;
    }
    var equalImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a === b ? 1 : 0;
    });
    var expImpl = createSimpleUnaryImpl(function(xi) {
      return Math.exp(xi);
    });
    var expm1Impl = createSimpleUnaryImpl(function(xi) {
      return Math.expm1(xi);
    });
    var floorImpl = createSimpleUnaryImpl(function(xi) {
      return Math.floor(xi);
    });
    function gatherNdImpl(indicesData, paramsBuf, dtype, numSlices, sliceRank, sliceSize, strides, paramsShape, paramsSize) {
      var outBuf = tf.buffer([numSlices, sliceSize], dtype);
      for (var i = 0; i < numSlices; i++) {
        var index = [];
        var flattenIndex = 0;
        for (var j = 0; j < sliceRank; j++) {
          var dim = indicesData[i * sliceRank + j];
          flattenIndex += dim * strides[j];
          index.push(dim);
        }
        if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {
          throw new Error("Invalid indices: ".concat(index, " does not index into ").concat(paramsShape));
        }
        for (var k = 0; k < sliceSize; k++) {
          outBuf.values[i * sliceSize + k] = paramsBuf.get.apply(paramsBuf, __spreadArray([], __read(paramsBuf.indexToLoc(flattenIndex * sliceSize + k)), false));
        }
      }
      return outBuf;
    }
    function gatherV2Impl(xBuf, indicesBuf, flattenOutputShape) {
      var outBuf = tf.buffer(flattenOutputShape, xBuf.dtype);
      for (var i = 0; i < outBuf.size; ++i) {
        var newLoc = outBuf.indexToLoc(i);
        var originalLoc = newLoc.slice();
        var batchIdx = originalLoc[0];
        var indicesIdx = originalLoc[2];
        var indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);
        originalLoc[2] = indicesBuf.values[indicesIndex];
        var originalIndex = xBuf.locToIndex(originalLoc);
        if (0 <= originalIndex && originalIndex < xBuf.values.length) {
          outBuf.values[i] = xBuf.values[originalIndex];
        }
      }
      return outBuf;
    }
    var greaterImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a > b ? 1 : 0;
    });
    var greaterEqualImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a >= b ? 1 : 0;
    });
    var lessImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a < b ? 1 : 0;
    });
    var lessEqualImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a <= b ? 1 : 0;
    });
    function linSpaceImpl(start, stop, num) {
      var step2 = (stop - start) / (num - 1);
      var values = tf.util.makeZerosTypedArray(num, "float32");
      values[0] = start;
      for (var i = 1; i < values.length; i++) {
        values[i] = values[i - 1] + step2;
      }
      return values;
    }
    var logImpl = createSimpleUnaryImpl(function(xi) {
      return Math.log(xi);
    });
    function maxImpl$1(aVals, reduceSize, outShape, dtype) {
      var vals = tf.util.getTypedArrayFromDType(dtype, tf.util.sizeFromShape(outShape));
      for (var i = 0; i < vals.length; ++i) {
        var offset = i * reduceSize;
        var max2 = aVals[offset];
        for (var j = 0; j < reduceSize; ++j) {
          var value = aVals[offset + j];
          if (Number.isNaN(value) || value > max2) {
            max2 = value;
          }
        }
        vals[i] = max2;
      }
      return vals;
    }
    var maximumImpl = createSimpleBinaryKernelImpl(function(aValue, bValue) {
      return Math.max(aValue, bValue);
    });
    var minimumImpl = createSimpleBinaryKernelImpl(function(aValue, bValue) {
      return Math.min(aValue, bValue);
    });
    var multiplyImpl = createSimpleBinaryKernelImpl(function(aValue, bValue) {
      return aValue * bValue;
    });
    function negImpl(xVals, xShape, xDtype) {
      var minusOne = tf.util.createScalarValue(-1, xDtype);
      return multiplyImpl([], xShape, minusOne, xVals, xDtype);
    }
    var notEqualImpl = createSimpleBinaryKernelImpl(function(a, b) {
      return a !== b ? 1 : 0;
    });
    function transposeImpl$1(xVals, xShape, dtype, perm, newShape) {
      var xRank = xShape.length;
      var xSize = tf.util.sizeFromShape(xShape);
      var xStrides = tf.util.computeStrides(xShape);
      var newStrides = tf.util.computeStrides(newShape);
      var result = tf.util.getTypedArrayFromDType(dtype, tf.util.sizeFromShape(newShape));
      for (var i = 0; i < xSize; ++i) {
        var loc = tf.util.indexToLoc(i, xRank, xStrides);
        var newLoc = new Array(loc.length);
        for (var i_1 = 0; i_1 < newLoc.length; i_1++) {
          newLoc[i_1] = loc[perm[i_1]];
        }
        var newIndex = tf.util.locToIndex(newLoc, xRank, newStrides);
        result[newIndex] = xVals[i];
      }
      return result;
    }
    function prodImpl(xShape, xDtype, xVals, reductionAxes) {
      var _a2 = __read(tf.backend_util.computeOutAndReduceShapes(xShape, reductionAxes), 2), outShape = _a2[0], reduceShape = _a2[1];
      var outDtype = tf.upcastType(xDtype, "int32");
      var outVals = tf.util.makeZerosTypedArray(tf.util.sizeFromShape(outShape), outDtype);
      var reduceSize = tf.util.sizeFromShape(reduceShape);
      for (var i = 0; i < outVals.length; ++i) {
        var offset = i * reduceSize;
        var prod_1 = 1;
        for (var j = 0; j < reduceSize; ++j) {
          prod_1 *= xVals[offset + j];
        }
        outVals[i] = prod_1;
      }
      return { outVals, outShape, outDtype };
    }
    function validateIndices(indices, indicesShape, numParams) {
      indices.forEach(function(index, i) {
        if (index < 0 || index >= numParams) {
          var locString = tf.util.indexToLoc(i, indicesShape.length, tf.util.computeStrides(indicesShape)).join(",");
          throw new Error("indices[".concat(locString, "] = ").concat(index, " is not in [0, ").concat(numParams, ")"));
        }
      });
    }
    function validateSplits(paramsNestedSplits, numParamsDenseValues) {
      for (var dim = 0; dim < paramsNestedSplits.length; ++dim) {
        var splits = paramsNestedSplits[dim];
        var lastSplit = dim === paramsNestedSplits.length - 1 ? numParamsDenseValues : paramsNestedSplits[dim + 1].length;
        if (splits.length === 0) {
          throw new Error("Ragged splits may not be empty");
        }
        if (splits[0] < 0) {
          throw new Error("Ragged splits must be non-negative");
        }
        if (splits[splits.length - 1] > lastSplit) {
          throw new Error("Ragged splits must not point past values");
        }
        for (var i = 1; i < splits.length; ++i) {
          if (splits[i - 1] > splits[i]) {
            throw new Error("Ragged splits must be sorted in ascending order");
          }
        }
      }
    }
    function makeSplits(indices, indicesShape, paramsNestedSplits, numParamsDenseValues) {
      var valueSlices = [];
      var numValues = 0;
      var numSplits = indicesShape.length - 1 + paramsNestedSplits.length;
      var outSplits = new Array(numSplits).fill(null).map(function() {
        return [0];
      });
      validateSplits(paramsNestedSplits, numParamsDenseValues);
      var nrows = 1;
      for (var dim = 0; dim < indicesShape.length - 1; ++dim) {
        nrows *= indicesShape[dim];
        var rowLength = indicesShape[dim + 1];
        for (var i = 1; i < nrows + 1; ++i) {
          outSplits[dim].push(i * rowLength);
        }
      }
      for (var i = 0; i < indices.length; ++i) {
        var start = indices[i];
        var limit = indices[i] + 1;
        for (var dim = 0; dim < paramsNestedSplits.length; ++dim) {
          var splits = paramsNestedSplits[dim];
          var outDim = dim + indicesShape.length - 1;
          if (outDim >= 0) {
            var outSplitsOutDim = outSplits[outDim];
            var delta = outSplitsOutDim[outSplitsOutDim.length - 1] - splits[start];
            for (var j = start; j < limit; ++j) {
              outSplits[outDim].push(splits[j + 1] + delta);
            }
          }
          start = splits[start];
          limit = splits[limit];
        }
        if (limit !== start) {
          valueSlices.push([start, limit]);
          numValues += limit - start;
        }
      }
      return { outSplits, valueSlices, numValues };
    }
    function getSplits(outSplits) {
      var splitsOut = [];
      var _loop_1 = function(i2) {
        var numSplits = outSplits[i2].length;
        var splits = tf.util.getArrayFromDType("int32", numSplits);
        splitsOut.push(splits);
        outSplits[i2].forEach(function(value, j) {
          return splits[j] = value;
        });
      };
      for (var i = 0; i < outSplits.length; ++i) {
        _loop_1(i);
      }
      return splitsOut;
    }
    function computeFlatOuterDims(orig, numOutDims) {
      var outDims = orig.slice(0, numOutDims);
      while (outDims.length < numOutDims) {
        outDims.push(1);
      }
      for (var inDim = numOutDims; inDim < orig.length; inDim++) {
        outDims[numOutDims - 1] *= orig[inDim];
      }
      return outDims;
    }
    function writeValueSlices(paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize, values, valuesShape) {
      var e_12, _a2;
      var denseM = computeFlatOuterDims(paramsDenseValuesShape, 2)[1];
      var valuesM = computeFlatOuterDims(valuesShape, 2)[1];
      var outPos = 0;
      try {
        for (var valueSlices_1 = __values(valueSlices), valueSlices_1_1 = valueSlices_1.next(); !valueSlices_1_1.done; valueSlices_1_1 = valueSlices_1.next()) {
          var slice2 = valueSlices_1_1.value;
          for (var i = slice2[0]; i < slice2[1]; ++i) {
            for (var j = 0; j < valueSize; ++j) {
              values[outPos * valuesM + j] = paramsDenseValues[i * denseM + j];
            }
            ++outPos;
          }
        }
      } catch (e_1_1) {
        e_12 = { error: e_1_1 };
      } finally {
        try {
          if (valueSlices_1_1 && !valueSlices_1_1.done && (_a2 = valueSlices_1.return))
            _a2.call(valueSlices_1);
        } finally {
          if (e_12)
            throw e_12.error;
        }
      }
    }
    function getValues(paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, valueSlices, numValues) {
      var valuesShape = paramsDenseValuesShape.slice();
      valuesShape[0] = numValues;
      var valuesOut = tf.util.getArrayFromDType(paramsDenseValuesDType, tf.util.sizeFromShape(valuesShape));
      var numElements = paramsDenseValues.length;
      var valueSize = numElements === 0 ? 0 : numElements / paramsDenseValuesShape[0];
      writeValueSlices(paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize, valuesOut, valuesShape);
      return [valuesOut, valuesShape];
    }
    function raggedGatherImpl(paramsNestedSplits, paramsNestedSplitsShapes, paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, indices, indicesShape, outputRaggedRank) {
      if (paramsNestedSplits.length === 0) {
        throw new Error("paramsNestedSplits must be non empty");
      }
      if (paramsNestedSplitsShapes[0].length === 0) {
        throw new Error("Split tensors must not be scalars");
      }
      var numParams = paramsNestedSplitsShapes[0][0] - 1;
      validateIndices(indices, indicesShape, numParams);
      if (paramsDenseValuesShape.length === 0) {
        throw new Error("params.rank must be nonzero");
      }
      var numParamsDenseValues = paramsDenseValuesShape[0];
      var _a2 = makeSplits(indices, indicesShape, paramsNestedSplits, numParamsDenseValues), outSplits = _a2.outSplits, valueSlices = _a2.valueSlices, numValues = _a2.numValues;
      var outputNestedSplits = getSplits(outSplits);
      var outputDenseValues = getValues(paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, valueSlices, numValues);
      return [outputNestedSplits, outputDenseValues[0], outputDenseValues[1]];
    }
    var INT32_MAX = 2147483647;
    function raggedRangeImpl(starts, startsShape, startsDType, limits, limitsShape, deltas, deltasShape) {
      if (startsShape.length > 1) {
        throw new Error("starts must be a scalar or vector");
      }
      if (limitsShape.length > 1) {
        throw new Error("limits must be a scalar or vector");
      }
      if (deltasShape.length > 1) {
        throw new Error("deltas must be a scalar or vector");
      }
      var broadcastStarts = startsShape.length === 0;
      var broadcastLimits = limitsShape.length === 0;
      var broadcastDeltas = deltasShape.length === 0;
      var inSizes = [];
      if (!broadcastStarts) {
        inSizes.push(startsShape[0]);
      }
      if (!broadcastLimits) {
        inSizes.push(limitsShape[0]);
      }
      if (!broadcastDeltas) {
        inSizes.push(deltasShape[0]);
      }
      for (var i = 1; i < inSizes.length; ++i) {
        if (inSizes[i] !== inSizes[i - 1]) {
          throw new Error("starts, limits, and deltas must have the same shape");
        }
      }
      var nRows = inSizes.length === 0 ? 1 : inSizes[0];
      var rtNestedSplits = tf.util.getArrayFromDType("int32", nRows + 1);
      rtNestedSplits[0] = 0;
      for (var row = 0; row < nRows; ++row) {
        var start = broadcastStarts ? starts[0] : starts[row];
        var limit = broadcastLimits ? limits[0] : limits[row];
        var delta = broadcastDeltas ? deltas[0] : deltas[row];
        if (delta === 0) {
          throw new Error("Requires delta != 0");
        }
        var size = (
          // The number of elements in the specified range.
          void 0
        );
        if (delta > 0 && limit < start || delta < 0 && limit > start) {
          size = 0;
        } else {
          size = Math.ceil(Math.abs((limit - start) / delta));
          if (size > INT32_MAX) {
            throw new Error("Requires ((limit - start) / delta) <= ".concat(INT32_MAX));
          }
        }
        rtNestedSplits[row + 1] = rtNestedSplits[row] + size;
      }
      var nVals = rtNestedSplits[nRows];
      var rtDenseValues = tf.util.getArrayFromDType(startsDType, nVals);
      var valueIndex = 0;
      for (var row = 0; row < nRows; ++row) {
        var rowSize = rtNestedSplits[row + 1] - rtNestedSplits[row];
        var value = broadcastStarts ? starts[0] : starts[row];
        var delta = broadcastDeltas ? deltas[0] : deltas[row];
        for (var i = 0; i < rowSize; ++i) {
          rtDenseValues[valueIndex++] = value;
          value += delta;
        }
      }
      return [rtNestedSplits, rtDenseValues];
    }
    var RowPartitionType = tf.backend_util.RowPartitionType;
    var RaggedTensorToTensorOp = (
      /** @class */
      function() {
        function RaggedTensorToTensorOp2(shape, shapeShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypeStrings) {
          this.shape = shape;
          this.shapeShape = shapeShape;
          this.values = values;
          this.valuesShape = valuesShape;
          this.valuesDType = valuesDType;
          this.defaultValue = defaultValue;
          this.defaultValueShape = defaultValueShape;
          this.rowPartitionValues = rowPartitionValues;
          this.rowPartitionValuesShapes = rowPartitionValuesShapes;
          this.rowPartitionTypes = tf.backend_util.getRowPartitionTypesHelper(rowPartitionTypeStrings);
          this.raggedRank = tf.backend_util.getRaggedRank(this.rowPartitionTypes);
        }
        RaggedTensorToTensorOp2.prototype.getRowPartitionTypeByDimension = function(dimension) {
          if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {
            return this.rowPartitionTypes[dimension + 1];
          } else {
            return this.rowPartitionTypes[dimension];
          }
        };
        RaggedTensorToTensorOp2.prototype.getRowPartitionTensor = function(dimension) {
          if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {
            return this.rowPartitionValues[dimension + 1];
          } else {
            return this.rowPartitionValues[dimension];
          }
        };
        RaggedTensorToTensorOp2.prototype.getMaxWidth = function(dimension) {
          var rowPartitionTensor = this.getRowPartitionTensor(dimension - 1);
          switch (this.getRowPartitionTypeByDimension(dimension - 1)) {
            case RowPartitionType.VALUE_ROWIDS:
              return RaggedTensorToTensorOp2.getMaxWidthValueRowID(rowPartitionTensor);
            case RowPartitionType.ROW_SPLITS:
              return RaggedTensorToTensorOp2.getMaxWidthRowSplit(rowPartitionTensor);
            default:
              throw new Error("Cannot handle partition type ".concat(RowPartitionType[this.getRowPartitionTypeByDimension(dimension - 1)]));
          }
        };
        RaggedTensorToTensorOp2.getMaxWidthRowSplit = function(rowSplit) {
          var tensorLength = rowSplit.length;
          if (tensorLength === 0 || tensorLength === 1) {
            return 0;
          }
          var maxWidth = 0;
          for (var i = 0; i < tensorLength - 1; ++i) {
            var currentWidth = rowSplit[i + 1] - rowSplit[i];
            if (currentWidth > maxWidth) {
              maxWidth = currentWidth;
            }
          }
          return maxWidth;
        };
        RaggedTensorToTensorOp2.getMaxWidthValueRowID = function(valueRowIds) {
          var indexLength = valueRowIds.length;
          if (indexLength === 0) {
            return 0;
          }
          var firstEqualIndex = 0;
          var firstEqualIndexValue = valueRowIds[0];
          var maxWidth = 0;
          for (var i = 1; i < indexLength; ++i) {
            var value = valueRowIds[i];
            if (value !== firstEqualIndexValue) {
              firstEqualIndexValue = value;
              maxWidth = Math.max(i - firstEqualIndex, maxWidth);
              firstEqualIndex = i;
            }
          }
          return Math.max(indexLength - firstEqualIndex, maxWidth);
        };
        RaggedTensorToTensorOp2.prototype.tensorShapeFromTensor = function(t, tShape, isPartial) {
          if (isPartial === void 0) {
            isPartial = true;
          }
          if (tShape.length === 0) {
            if (t[0] === -1) {
              return [];
            }
            throw new Error("The only valid scalar shape tensor is the fully unknown shape specified as -1.");
          }
          return makeShape(t, isPartial);
        };
        RaggedTensorToTensorOp2.prototype.calculateOutputSize = function(firstDim) {
          var valueShape = this.valuesShape;
          var defaultValueShape = this.defaultValueShape;
          tf.backend_util.validateDefaultValueShape(defaultValueShape, valueShape);
          var shape = this.tensorShapeFromTensor(this.shape, this.shapeShape);
          var outputShape = tf.backend_util.combineRaggedTensorToTensorShapes(this.raggedRank, shape, valueShape);
          var result = outputShape;
          if (result[0] < 0) {
            result[0] = firstDim;
          }
          for (var i = 1; i <= this.raggedRank; ++i) {
            if (result[i] < 0) {
              result[i] = this.getMaxWidth(i);
            }
          }
          return result;
        };
        RaggedTensorToTensorOp2.prototype.calculateFirstParentOutputIndex = function(firstDimension, outputIndexMultiplier, firstDimensionOutput) {
          var minDimension = Math.min(firstDimension, firstDimensionOutput);
          var result = [];
          var currentOutputIndex = 0;
          for (var i = 0; i < minDimension; ++i, currentOutputIndex += outputIndexMultiplier) {
            result.push(currentOutputIndex);
          }
          for (var i = minDimension; i < firstDimension; ++i) {
            result.push(-1);
          }
          tf.util.assert(result.length === firstDimension, function() {
            return "Final length of result must be equal to firstDimension.";
          });
          return result;
        };
        RaggedTensorToTensorOp2.prototype.calculateOutputIndexRowSplit = function(rowSplit, parentOutputIndex, outputIndexMultiplier, outputSize) {
          var rowSplitSize = rowSplit.length;
          var result = [];
          for (var i = 0; i < rowSplitSize - 1; ++i) {
            var rowLength = rowSplit[i + 1] - rowSplit[i];
            var realLength = Math.min(outputSize, rowLength);
            var parentOutputIndexCurrent = parentOutputIndex[i];
            if (parentOutputIndexCurrent === -1) {
              realLength = 0;
            }
            for (var j = 0; j < realLength; ++j) {
              result.push(parentOutputIndexCurrent);
              parentOutputIndexCurrent += outputIndexMultiplier;
            }
            for (var j = 0; j < rowLength - realLength; ++j) {
              result.push(-1);
            }
          }
          if (rowSplitSize > 0 && result.length !== rowSplit[rowSplitSize - 1]) {
            throw new Error("Invalid row split size.");
          }
          return result;
        };
        RaggedTensorToTensorOp2.prototype.calculateOutputIndexValueRowID = function(valueRowIds, parentOutputIndex, outputIndexMultiplier, outputSize) {
          var indexSize = valueRowIds.length;
          var result = [];
          if (indexSize === 0) {
            return [];
          }
          var currentOutputColumn = 0;
          var currentValueRowId = valueRowIds[0];
          if (currentValueRowId >= parentOutputIndex.length) {
            throw new Error("Got currentValueRowId=".concat(currentValueRowId, ", which is not less than ").concat(parentOutputIndex.length));
          }
          var currentOutputIndex = parentOutputIndex[currentValueRowId];
          result.push(currentOutputIndex);
          for (var i = 1; i < indexSize; ++i) {
            var nextValueRowId = valueRowIds[i];
            if (nextValueRowId === currentValueRowId) {
              if (currentOutputIndex >= 0) {
                ++currentOutputColumn;
                if (currentOutputColumn < outputSize) {
                  currentOutputIndex += outputIndexMultiplier;
                } else {
                  currentOutputIndex = -1;
                }
              }
            } else {
              currentOutputColumn = 0;
              currentValueRowId = nextValueRowId;
              if (nextValueRowId >= parentOutputIndex.length) {
                throw new Error("Got nextValueRowId=".concat(nextValueRowId, " which is not less than ").concat(parentOutputIndex.length));
              }
              currentOutputIndex = parentOutputIndex[nextValueRowId];
            }
            result.push(currentOutputIndex);
          }
          if (result.length !== valueRowIds.length) {
            throw new Error("Invalid row ids.");
          }
          return result;
        };
        RaggedTensorToTensorOp2.prototype.calculateOutputIndex = function(dimension, parentOutputIndex, outputIndexMultiplier, outputSize) {
          var rowPartitionTensor = this.getRowPartitionTensor(dimension);
          var partitionType = this.getRowPartitionTypeByDimension(dimension);
          switch (partitionType) {
            case RowPartitionType.VALUE_ROWIDS:
              return this.calculateOutputIndexValueRowID(rowPartitionTensor, parentOutputIndex, outputIndexMultiplier, outputSize);
            case RowPartitionType.ROW_SPLITS:
              if (rowPartitionTensor.length - 1 > parentOutputIndex.length) {
                throw new Error("Row partition size is greater than output size: ".concat(rowPartitionTensor.length - 1, " > ").concat(parentOutputIndex.length));
              }
              return this.calculateOutputIndexRowSplit(rowPartitionTensor, parentOutputIndex, outputIndexMultiplier, outputSize);
            default:
              throw new Error("Unsupported partition type: ".concat(RowPartitionType[partitionType]));
          }
        };
        RaggedTensorToTensorOp2.prototype.getFirstDimensionSize = function() {
          var firstPartitionTensor = this.rowPartitionValues[0];
          if (this.rowPartitionTypes.length === 0) {
            throw new Error("No row_partition_types given.");
          }
          var firstPartitionType = this.rowPartitionTypes[0];
          switch (firstPartitionType) {
            case RowPartitionType.FIRST_DIM_SIZE:
              return firstPartitionTensor[0];
            case RowPartitionType.VALUE_ROWIDS:
              throw new Error("Cannot handle VALUE_ROWIDS in first dimension.");
            case RowPartitionType.ROW_SPLITS:
              return this.rowPartitionValuesShapes[0][0] - 1;
            default:
              throw new Error("Cannot handle type ".concat(RowPartitionType[firstPartitionType]));
          }
        };
        RaggedTensorToTensorOp2.prototype.compute = function() {
          var firstPartitionTensor = this.rowPartitionValues[0];
          if (firstPartitionTensor.length <= 0) {
            throw new Error("Invalid first partition input. Tensor requires at least one element.");
          }
          var firstDimension = this.getFirstDimensionSize();
          var outputSize = this.calculateOutputSize(firstDimension);
          var multiplier = new Array(this.raggedRank + 1);
          multiplier[multiplier.length - 1] = 1;
          for (var i = multiplier.length - 2; i >= 0; --i) {
            multiplier[i] = multiplier[i + 1] * outputSize[i + 1];
          }
          var outputShape = makeShape(outputSize, false);
          var outputTensor = tf.util.getArrayFromDType(this.valuesDType, tf.util.sizeFromShape(outputShape));
          var fullSize = multiplier[0] * outputSize[0];
          if (fullSize > 0) {
            var outputIndex = this.calculateFirstParentOutputIndex(firstDimension, multiplier[0], outputSize[0]);
            for (var i = 1; i <= this.raggedRank; ++i) {
              var newOutputIndex = this.calculateOutputIndex(i - 1, outputIndex, multiplier[i], outputSize[i]);
              outputIndex = newOutputIndex;
            }
            this.setOutput(this.raggedRank, outputIndex, outputTensor, outputShape);
          }
          return [outputShape, outputTensor];
        };
        RaggedTensorToTensorOp2.prototype.setOutput = function(raggedRank, outputIndex, outputTensor, outputShape) {
          if (outputTensor.length === 0) {
            return;
          }
          var valuesBase = this.values;
          var outputBase = outputTensor;
          var elementShape = outputShape.slice();
          elementShape = elementShape.slice(raggedRank + 1);
          var valueElementSize = tf.util.sizeFromShape(elementShape);
          var outputIndexSize = outputIndex.length;
          var defaultValue = this.defaultValue;
          if (defaultValue.length !== valueElementSize && defaultValue.length !== 1) {
            var srcShape_1 = this.defaultValueShape;
            tf.tidy(function() {
              var defaultValueTensor = tf.reshape(defaultValue, srcShape_1);
              var bCastDefault = tf.broadcastTo(defaultValueTensor, elementShape);
              defaultValue = bCastDefault.dataSync();
            });
          }
          var srcStart = 0;
          var dstStart = 0;
          var dstEnd = 0;
          for (var srcI = 0; srcI <= outputIndexSize; ++srcI) {
            var dstI = srcI < outputIndexSize ? outputIndex[srcI] : -1;
            if (dstI === dstEnd) {
              ++dstEnd;
              continue;
            }
            if (dstStart < dstEnd) {
              var src = valuesBase.subarray(srcStart * valueElementSize);
              var dst = outputBase.subarray(dstStart * valueElementSize);
              var nVals = (dstEnd - dstStart) * valueElementSize;
              copyArray(dst, src, nVals);
            }
            if (srcI >= outputIndexSize) {
              var outputSize = outputTensor.length;
              dstI = Math.floor(outputSize / valueElementSize);
            }
            if (dstI > dstEnd) {
              if (this.defaultValue.length === 1) {
                outputBase.subarray(dstEnd * valueElementSize, dstI * valueElementSize).fill(this.defaultValue[0]);
                dstEnd = dstI;
              } else {
                while (dstI > dstEnd) {
                  var dst = outputBase.slice(dstEnd * valueElementSize);
                  copyArray(dst, defaultValue, valueElementSize);
                  ++dstEnd;
                }
              }
            }
            if (dstI < 0) {
              srcStart = srcI + 1;
              dstStart = dstEnd;
            } else {
              srcStart = srcI;
              dstStart = dstEnd;
              dstEnd = dstStart + 1;
            }
          }
        };
        return RaggedTensorToTensorOp2;
      }()
    );
    function copyArray(dst, src, size) {
      for (var i = 0; i < size; i++) {
        dst[i] = src[i];
      }
    }
    function makeShape(shape, isPartial) {
      var e_12, _a2;
      var out = [];
      try {
        for (var shape_1 = __values(shape), shape_1_1 = shape_1.next(); !shape_1_1.done; shape_1_1 = shape_1.next()) {
          var dim = shape_1_1.value;
          if (dim < 0) {
            if (!isPartial) {
              throw new Error("Dimension ".concat(dim, " must be >= 0"));
            }
            if (dim < -1) {
              throw new Error("Dimension ".concat(dim, " must be >= -1"));
            }
            dim = -1;
          }
          out.push(dim);
        }
      } catch (e_1_1) {
        e_12 = { error: e_1_1 };
      } finally {
        try {
          if (shape_1_1 && !shape_1_1.done && (_a2 = shape_1.return))
            _a2.call(shape_1);
        } finally {
          if (e_12)
            throw e_12.error;
        }
      }
      return out;
    }
    function raggedTensorToTensorImpl(shape, shapesShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes) {
      return new RaggedTensorToTensorOp(shape, shapesShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes).compute();
    }
    function rangeImpl(start, stop, step2, dtype) {
      var sameStartStop = start === stop;
      var increasingRangeNegativeStep = start < stop && step2 < 0;
      var decreasingRangePositiveStep = stop < start && step2 > 1;
      if (sameStartStop || increasingRangeNegativeStep || decreasingRangePositiveStep) {
        return tf.util.makeZerosTypedArray(0, dtype);
      }
      var numElements = Math.abs(Math.ceil((stop - start) / step2));
      var values = tf.util.makeZerosTypedArray(numElements, dtype);
      if (stop < start && step2 === 1) {
        step2 = -1;
      }
      values[0] = start;
      for (var i = 1; i < values.length; i++) {
        values[i] = values[i - 1] + step2;
      }
      return values;
    }
    var rsqrtImpl = createSimpleUnaryImpl(function(xi) {
      return 1 / Math.sqrt(xi);
    });
    function scatterImpl(indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices) {
      var flattenShape = [outputSize / sliceSize, sliceSize];
      var indicesData = indices.values;
      var updatesData = updates.values;
      if (outputSize === 0) {
        return tf.buffer(shape, updates.dtype);
      }
      var outBuf = defaultValue instanceof tf.TensorBuffer ? defaultValue : tf.buffer(flattenShape, updates.dtype);
      if (typeof defaultValue === "string") {
        outBuf.values.fill(defaultValue);
      } else if (typeof defaultValue === "number") {
        outBuf.values.fill(defaultValue);
      } else if (typeof defaultValue === "boolean") {
        outBuf.values.fill(+defaultValue);
      }
      for (var i = 0; i < numUpdates; i++) {
        var index = [];
        var flattenIndex = 0;
        for (var j = 0; j < sliceRank; j++) {
          var dim = indicesData[i * sliceRank + j];
          index.push(dim);
          flattenIndex += dim * strides[j];
        }
        if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {
          throw new Error("Invalid indices: ".concat(index, " does not index into ").concat(shape));
        }
        for (var k = 0; k < sliceSize; k++) {
          if (sumDupeIndices) {
            outBuf.values[flattenIndex * sliceSize + k] += updatesData[i * sliceSize + k];
          } else {
            outBuf.values[flattenIndex * sliceSize + k] = updates.rank === 0 ? updatesData[0] : updatesData[i * sliceSize + k];
          }
        }
      }
      return outBuf;
    }
    var sigmoidImpl = createSimpleUnaryImpl(function(xi) {
      return 1 / (1 + Math.exp(-xi));
    });
    function sliceImpl(vals, begin, size, shape, dtype) {
      var isContinous = tf.slice_util.isSliceContinous(shape, begin, size);
      var length = tf.util.sizeFromShape(size);
      var xStrides = tf.util.computeStrides(shape);
      if (isContinous) {
        var flatOffset = tf.slice_util.computeFlatOffset(begin, xStrides);
        if (dtype === "string") {
          return vals.slice(flatOffset, flatOffset + length);
        }
        return vals.subarray(flatOffset, flatOffset + length);
      }
      var decodedData = dtype === "string" ? tf.backend_util.fromUint8ToStringArray(vals) : vals;
      var inBuf = tf.buffer(shape, dtype, decodedData);
      var outBuf = tf.buffer(size, dtype);
      for (var i = 0; i < outBuf.size; ++i) {
        var outLoc = outBuf.indexToLoc(i);
        var inLoc = outLoc.map(function(idx, j) {
          return idx + begin[j];
        });
        outBuf.set.apply(outBuf, __spreadArray([inBuf.get.apply(inBuf, __spreadArray([], __read(inLoc), false))], __read(outLoc), false));
      }
      if (dtype === "string") {
        return tf.backend_util.fromStringArrayToUint8(outBuf.values);
      }
      return outBuf.values;
    }
    function sparseFillEmptyRowsImpl(indices, indicesShape, indicesDType, values, valuesDType, denseShape, defaultValue) {
      var indicesCount = indicesShape[0];
      var denseRows = denseShape[0];
      var emptyRowIndicator = new Array(denseRows);
      var reverseIndexMap = new Array(indicesCount);
      var rank = indicesShape[1];
      if (denseRows === 0) {
        if (indicesCount !== 0) {
          throw new Error(tf.backend_util.getSparseFillEmptyRowsIndicesDenseShapeMismatch(indicesCount));
        }
        var outputIndices = tf.util.getArrayFromDType(indicesDType, 0);
        var outputValues = tf.util.getArrayFromDType(valuesDType, 0);
        return [
          outputIndices,
          [0, rank],
          outputValues,
          emptyRowIndicator,
          reverseIndexMap
        ];
      }
      var rowsAreOrdered = true;
      var lastIndicesRow = 0;
      var csrOffset = new Array(denseRows).fill(0);
      for (var i = 0; i < indicesCount; ++i) {
        var row = indices[i * rank];
        if (row < 0) {
          throw new Error(tf.backend_util.getSparseFillEmptyRowsNegativeIndexErrorMessage(i, row));
        }
        if (row >= denseRows) {
          throw new Error(tf.backend_util.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(i, row, denseRows));
        }
        ++csrOffset[row];
        rowsAreOrdered = rowsAreOrdered && row >= lastIndicesRow;
        lastIndicesRow = row;
      }
      var allRowsFull = true;
      for (var row = 0; row < denseRows; ++row) {
        var rowEmpty = csrOffset[row] === 0;
        emptyRowIndicator[row] = rowEmpty;
        allRowsFull = allRowsFull && !rowEmpty;
        csrOffset[row] = Math.max(csrOffset[row], 1);
        if (row > 0) {
          csrOffset[row] += csrOffset[row - 1];
        }
      }
      if (allRowsFull && rowsAreOrdered) {
        var outputIndices = indices;
        var outputValues = values;
        for (var i = 0; i < indicesCount; ++i) {
          reverseIndexMap[i] = i;
        }
        return [
          outputIndices,
          [indicesCount, rank],
          outputValues,
          emptyRowIndicator,
          reverseIndexMap
        ];
      } else {
        var fullIndicesCount = csrOffset[denseRows - 1];
        var outputIndices = tf.util.getArrayFromDType(indicesDType, fullIndicesCount * rank);
        var outputValues = tf.util.getArrayFromDType(valuesDType, fullIndicesCount);
        var filledCount = new Array(denseRows).fill(0);
        for (var i = 0; i < indicesCount; ++i) {
          var row = indices[i * rank];
          var offset = filledCount[row];
          var outputI = (row === 0 ? 0 : csrOffset[row - 1]) + offset;
          filledCount[row]++;
          for (var j = 0; j < rank; ++j) {
            outputIndices[outputI * rank + j] = indices[i * rank + j];
          }
          outputValues[outputI] = values[i];
          reverseIndexMap[i] = outputI;
        }
        for (var row = 0; row < denseRows; ++row) {
          var rowCount = filledCount[row];
          if (rowCount === 0) {
            var startingIndex = row === 0 ? 0 : csrOffset[row - 1];
            outputIndices[startingIndex * rank + 0] = row;
            for (var col = 1; col < rank; ++col) {
              outputIndices[startingIndex * rank + col] = 0;
            }
            outputValues[startingIndex] = defaultValue;
          }
        }
        return [
          outputIndices,
          [fullIndicesCount, rank],
          outputValues,
          emptyRowIndicator,
          reverseIndexMap
        ];
      }
    }
    function sparseReshapeImpl(inputIndices, inputIndicesShape, inputDType, inputShape, targetShape) {
      var denseSize = tf.util.sizeFromShape(inputShape);
      var nnz = inputIndicesShape[0];
      var outputRank = targetShape.length;
      var outputShape = [];
      var product = 1;
      var unknownIndex = -1;
      for (var d = 0; d < outputRank; ++d) {
        var size = targetShape[d];
        if (size === -1) {
          if (unknownIndex !== -1) {
            throw new Error(tf.backend_util.getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(unknownIndex, d));
          }
          unknownIndex = d;
          outputShape.push(1);
        } else {
          if (size < 0) {
            throw new Error(tf.backend_util.getSparseReshapeNegativeOutputDimErrorMessage(d, size));
          }
          product *= size;
          outputShape.push(size);
        }
      }
      if (unknownIndex !== -1) {
        if (product <= 0) {
          throw new Error(tf.backend_util.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());
        }
        var missing = Math.trunc(denseSize / product);
        if (product * missing !== denseSize) {
          throw new Error(tf.backend_util.getSparseReshapeInputOutputMultipleErrorMessage(inputShape, outputShape));
        }
        outputShape[unknownIndex] = missing;
      }
      var outputSize = tf.util.sizeFromShape(outputShape);
      if (outputSize !== denseSize) {
        throw new Error(tf.backend_util.getSparseReshapeInputOutputMismatchErrorMessage(inputShape, outputShape));
      }
      var inputRank = inputShape.length;
      var inputStrides = [];
      if (inputRank > 0) {
        inputStrides[inputRank - 1] = 1;
        for (var d = inputRank - 2; d >= 0; --d) {
          inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];
        }
      }
      var outputStrides = [];
      if (outputRank > 0) {
        outputStrides[outputRank - 1] = 1;
        for (var d = outputRank - 2; d >= 0; --d) {
          outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];
        }
      }
      var newIndices = tf.util.getArrayFromDType(inputDType, nnz * outputRank);
      for (var i = 0; i < nnz; ++i) {
        var id = 0;
        for (var j = 0; j < inputRank; ++j) {
          id += inputIndices[i * inputRank + j] * inputStrides[j];
        }
        for (var j = 0; j < outputRank; ++j) {
          newIndices[i * outputRank + j] = Math.trunc(id / outputStrides[j]);
          id %= outputStrides[j];
        }
      }
      return [newIndices, [nnz, outputRank], outputShape];
    }
    function sparseSegmentReductionImpl(input, inputShape, inputDType, indices, segmentIds, isMean, defaultValue) {
      if (isMean === void 0) {
        isMean = false;
      }
      if (defaultValue === void 0) {
        defaultValue = 0;
      }
      var numIndices = indices.length;
      var inputFlat = [inputShape[0], input.length / inputShape[0]];
      var numCol = inputFlat[1];
      var lastSegmentIdPlusOne = numIndices > 0 ? segmentIds[numIndices - 1] + 1 : 0;
      var outputRows = lastSegmentIdPlusOne;
      if (outputRows < 0) {
        throw new Error(tf.backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
      }
      var outputShape = inputShape.slice();
      outputShape[0] = outputRows;
      var outputLength = outputShape.reduce(function(product, value) {
        return product * value;
      }, 1);
      var output = tf.util.getArrayFromDType(inputDType, outputLength);
      if (numIndices === 0) {
        if (outputRows > 0) {
          output.fill(defaultValue);
        }
        return [output, outputShape];
      }
      if (outputRows <= 0) {
        throw new Error(tf.backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
      }
      var start = 0, end = 1;
      var uninitializedIndex = 0;
      var outIndex = segmentIds[start];
      while (true) {
        var nextIndex = 0;
        if (end < numIndices) {
          nextIndex = segmentIds[end];
          if (outIndex === nextIndex) {
            ++end;
            continue;
          }
          if (outIndex >= nextIndex) {
            throw new Error(tf.backend_util.getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage());
          }
        }
        if (outIndex < 0 || outIndex >= outputRows) {
          throw new Error(tf.backend_util.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(outIndex, outputRows));
        }
        if (outIndex > uninitializedIndex) {
          output.fill(defaultValue, uninitializedIndex * numCol, outIndex * numCol);
        }
        for (var i = start; i < end; ++i) {
          var index = indices[i];
          if (index < 0 || index >= inputFlat[0]) {
            throw new Error(tf.backend_util.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(i, indices[i], inputFlat[0]));
          }
          for (var j = 0; j < numCol; j++) {
            output[outIndex * numCol + j] += input[index * numCol + j];
          }
        }
        if (isMean) {
          for (var j = 0; j < numCol; j++) {
            output[outIndex * numCol + j] /= end - start;
          }
        }
        start = end;
        ++end;
        uninitializedIndex = outIndex + 1;
        outIndex = nextIndex;
        if (end > numIndices) {
          break;
        }
      }
      if (uninitializedIndex < outputRows) {
        output.fill(defaultValue, uninitializedIndex * numCol, outputRows * numCol);
      }
      return [output, outputShape];
    }
    var sqrtImpl = createSimpleUnaryImpl(function(xi) {
      return Math.sqrt(xi);
    });
    var staticRegexReplaceImpl = createSimpleUnaryImpl(function(x, attrs) {
      var pattern = attrs.pattern, replaceGlobal = attrs.replaceGlobal, rewrite = attrs.rewrite;
      return x.replace(new RegExp(pattern, replaceGlobal ? "g" : ""), rewrite);
    });
    function stridedSliceImpl(outShape, xBuf, strides, begin) {
      var outBuf = tf.buffer(outShape, xBuf.dtype);
      for (var i = 0; i < outBuf.size; i++) {
        var loc = outBuf.indexToLoc(i);
        var newLoc = new Array(loc.length);
        for (var j = 0; j < newLoc.length; j++) {
          newLoc[j] = loc[j] * strides[j] + begin[j];
        }
        outBuf.set.apply(outBuf, __spreadArray([xBuf.get.apply(xBuf, __spreadArray([], __read(newLoc), false))], __read(loc), false));
      }
      return outBuf;
    }
    var StringNGramsOp = (
      /** @class */
      function() {
        function StringNGramsOp2(separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences) {
          this.separator = tf.util.encodeString(separator);
          this.nGramWidths = nGramWidths;
          this.leftPad = tf.util.encodeString(leftPad);
          this.rightPad = tf.util.encodeString(rightPad);
          this.padWidth = padWidth;
          this.preserveShort = preserveShortSequences;
        }
        StringNGramsOp2.prototype.getPadWidth = function(nGramWidth) {
          return Math.min(this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);
        };
        StringNGramsOp2.prototype.getNumNGrams = function(length, nGramWidth) {
          var padWidth = this.getPadWidth(nGramWidth);
          return Math.max(0, length + 2 * padWidth - nGramWidth + 1);
        };
        StringNGramsOp2.prototype.createNGrams = function(data, splitIndex, output, outputStartIndex, numNGrams, nGramWidth) {
          var _loop_1 = function(nGramIndex2) {
            var padWidth = this_1.getPadWidth(nGramWidth);
            var leftPadding = Math.max(0, padWidth - nGramIndex2);
            var rightPadding = Math.max(0, padWidth - (numNGrams - (nGramIndex2 + 1)));
            var numTokens = nGramWidth - (leftPadding + rightPadding);
            var dataStartIndex = splitIndex + (leftPadding > 0 ? 0 : nGramIndex2 - padWidth);
            var nGramSize = 0;
            nGramSize += leftPadding * this_1.leftPad.length;
            for (var n = 0; n < numTokens; ++n) {
              nGramSize += data[dataStartIndex + n].length;
            }
            nGramSize += rightPadding * this_1.rightPad.length;
            var numSeparators = leftPadding + rightPadding + numTokens - 1;
            nGramSize += numSeparators * this_1.separator.length;
            output[outputStartIndex + nGramIndex2] = new Uint8Array(nGramSize);
            var nGram = output[outputStartIndex + nGramIndex2];
            var nextNGramIndex = 0;
            var appendToNGram = function(str) {
              return str.forEach(function(value) {
                return nGram[nextNGramIndex++] = value;
              });
            };
            for (var n = 0; n < leftPadding; ++n) {
              appendToNGram(this_1.leftPad);
              appendToNGram(this_1.separator);
            }
            for (var n = 0; n < numTokens - 1; ++n) {
              appendToNGram(data[dataStartIndex + n]);
              appendToNGram(this_1.separator);
            }
            if (numTokens > 0) {
              appendToNGram(data[dataStartIndex + numTokens - 1]);
              for (var n = 0; n < rightPadding; ++n) {
                appendToNGram(this_1.separator);
                appendToNGram(this_1.rightPad);
              }
            } else {
              for (var n = 0; n < rightPadding - 1; ++n) {
                appendToNGram(this_1.rightPad);
                appendToNGram(this_1.separator);
              }
              appendToNGram(this_1.rightPad);
            }
          };
          var this_1 = this;
          for (var nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {
            _loop_1(nGramIndex);
          }
        };
        StringNGramsOp2.prototype.compute = function(data, splits) {
          var _this = this;
          var inputDataSize = data.length;
          var splitsSize = splits.length;
          if (splitsSize > 0) {
            var prevSplit = splits[0];
            if (prevSplit !== 0) {
              throw new Error("First split value must be 0, got ".concat(prevSplit));
            }
            for (var i = 1; i < splitsSize; ++i) {
              var validSplits = splits[i] >= prevSplit;
              validSplits = validSplits && splits[i] <= inputDataSize;
              if (!validSplits) {
                throw new Error("Invalid split value ".concat(splits[i], ", must be in [").concat(prevSplit, ", ").concat(inputDataSize, "]"));
              }
              prevSplit = splits[i];
            }
            if (prevSplit !== inputDataSize) {
              throw new Error("Last split value must be data size. Expected ".concat(inputDataSize, ", got ").concat(prevSplit));
            }
          }
          var numBatchItems = splitsSize - 1;
          var nGramsSplits = tf.util.getArrayFromDType("int32", splitsSize);
          if (inputDataSize === 0 || splitsSize === 0) {
            var empty = new Array(inputDataSize);
            for (var i = 0; i <= numBatchItems; ++i) {
              nGramsSplits[i] = 0;
            }
            return [empty, nGramsSplits];
          }
          nGramsSplits[0] = 0;
          var _loop_2 = function(i2) {
            var length = splits[i2] - splits[i2 - 1];
            var numNGrams = 0;
            this_2.nGramWidths.forEach(function(nGramWidth) {
              numNGrams += _this.getNumNGrams(length, nGramWidth);
            });
            if (this_2.preserveShort && length > 0 && numNGrams === 0) {
              numNGrams = 1;
            }
            nGramsSplits[i2] = nGramsSplits[i2 - 1] + numNGrams;
          };
          var this_2 = this;
          for (var i = 1; i <= numBatchItems; ++i) {
            _loop_2(i);
          }
          var nGrams = new Array(nGramsSplits[numBatchItems]);
          var _loop_3 = function(i2) {
            var splitIndex = splits[i2];
            var outputStartIdx = nGramsSplits[i2];
            this_3.nGramWidths.forEach(function(nGramWidth2) {
              var length = splits[i2 + 1] - splits[i2];
              var numNGrams2 = _this.getNumNGrams(length, nGramWidth2);
              _this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams2, nGramWidth2);
              outputStartIdx += numNGrams2;
            });
            if (this_3.preserveShort && outputStartIdx === nGramsSplits[i2]) {
              var dataLength = splits[i2 + 1] - splits[i2];
              if (dataLength === 0) {
                return "continue";
              }
              var nGramWidth = dataLength + 2 * this_3.padWidth;
              var numNGrams = 1;
              this_3.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
            }
          };
          var this_3 = this;
          for (var i = 0; i < numBatchItems; ++i) {
            _loop_3(i);
          }
          return [nGrams, nGramsSplits];
        };
        return StringNGramsOp2;
      }()
    );
    function stringNGramsImpl(data, dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences) {
      return new StringNGramsOp(separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences).compute(data, dataSplits);
    }
    function split(str, delimiters, skipEmpty, result) {
      if (!str.length) {
        return;
      }
      if (delimiters.length === 0) {
        for (var i = 0; i < str.length; ++i) {
          result.push(str.subarray(i, i + 1));
        }
        return;
      }
      if (delimiters.length === 1) {
        var delimiter = delimiters[0];
        var f = str.indexOf(delimiter);
        while (f !== -1) {
          var token = str.subarray(0, f);
          if (!skipEmpty || token.length !== 0) {
            result.push(token);
          }
          str = str.subarray(f + 1);
          f = str.indexOf(delimiter);
        }
        if (!skipEmpty || str.length !== 0) {
          result.push(str);
        }
        return;
      }
      var tokenStart = 0;
      for (var i = 0; i < str.length + 1; i++) {
        if (i === str.length || delimiters.indexOf(str[i]) !== -1) {
          var token = str.subarray(tokenStart, i);
          if (!skipEmpty || token.length !== 0) {
            result.push(token);
          }
          tokenStart = i + 1;
        }
      }
    }
    function stringSplitImpl(input, delimiter, skipEmpty) {
      var batchSize = input.length;
      var tokens = [];
      var outputSize = 0;
      var maxNumEntries = 0;
      var numIndices = new Array(batchSize);
      for (var i = 0; i < batchSize; ++i) {
        var prevTokensLength = tokens.length;
        split(input[i], delimiter, skipEmpty, tokens);
        var nEntries = tokens.length - prevTokensLength;
        numIndices[i] = nEntries;
        outputSize += nEntries;
        maxNumEntries = Math.max(maxNumEntries, nEntries);
      }
      var indices = tf.util.getArrayFromDType("int32", outputSize * 2);
      var values = new Array(outputSize);
      var shape = [batchSize, maxNumEntries];
      var c = 0;
      for (var i = 0; i < batchSize; ++i) {
        for (var j = 0; j < numIndices[i]; ++j) {
          indices[c * 2] = i;
          indices[c * 2 + 1] = j;
          values[c] = tokens[c];
          ++c;
        }
      }
      return [indices, values, shape];
    }
    function stringToHashBucketFastImpl(input, numBuckets) {
      var output = tf.util.getArrayFromDType("int32", input.length);
      for (var i = 0; i < input.length; ++i) {
        output[i] = tf.util.fingerPrint64(input[i]).modulo(numBuckets).getLowBitsUnsigned();
      }
      return output;
    }
    var subImpl = createSimpleBinaryKernelImpl(function(aValue, bValue) {
      return aValue - bValue;
    });
    function tileImpl(xBuf, reps) {
      var newShape = new Array(xBuf.rank);
      for (var i = 0; i < newShape.length; i++) {
        newShape[i] = xBuf.shape[i] * reps[i];
      }
      var result = tf.buffer(newShape, xBuf.dtype);
      for (var i = 0; i < result.values.length; ++i) {
        var newLoc = result.indexToLoc(i);
        var originalLoc = new Array(xBuf.rank);
        for (var j = 0; j < originalLoc.length; j++) {
          originalLoc[j] = newLoc[j] % xBuf.shape[j];
        }
        var originalIndex = xBuf.locToIndex(originalLoc);
        result.values[i] = xBuf.values[originalIndex];
      }
      return result;
    }
    var comparePair = function(a, b) {
      var valueDiff = b.value - a.value;
      return valueDiff === 0 ? a.index - b.index : valueDiff;
    };
    function select$1(array, k, left, right) {
      if (left === void 0) {
        left = 0;
      }
      if (right === void 0) {
        right = array.length - 1;
      }
      while (right > left) {
        if (right - left > 600) {
          var n = right - left + 1;
          var i_1 = k - left + 1;
          var z = Math.log(n);
          var s = 0.5 * Math.exp(2 * z / 3);
          var sd = 0.5 * Math.sqrt(z * s * (n - s) / n) * Math.sign(i_1 - n / 2);
          var newLeft = Math.max(left, Math.floor(k - i_1 * s / n + sd));
          var newRight = Math.min(right, Math.floor(k + (n - i_1) * s / n + sd));
          select$1(array, k, newLeft, newRight);
        }
        var t = array[k];
        var i = left;
        var j = right;
        tf.util.swap(array, left, k);
        if (comparePair(array[right], t) > 0) {
          tf.util.swap(array, left, right);
        }
        while (i < j) {
          tf.util.swap(array, i, j);
          i++;
          j--;
          while (comparePair(array[i], t) < 0) {
            i = i + 1;
          }
          while (comparePair(array[j], t) > 0) {
            j = j - 1;
          }
        }
        if (comparePair(array[left], t) === 0) {
          tf.util.swap(array, left, j);
        } else {
          j = j + 1;
          tf.util.swap(array, j, right);
        }
        if (j <= k) {
          left = j + 1;
        }
        if (k <= j) {
          right = j - 1;
        }
      }
    }
    function topKImpl(x, xShape, xDtype, k, sorted) {
      var lastDim = xShape[xShape.length - 1];
      var _a2 = __read([x.length / lastDim, lastDim], 2), batch = _a2[0], size = _a2[1];
      var allTopKVals = tf.util.getTypedArrayFromDType(xDtype, batch * k);
      var allTopKIndices = tf.util.getTypedArrayFromDType("int32", batch * k);
      var _loop_1 = function(b2) {
        var offset = b2 * size;
        var vals = x.subarray(offset, offset + size);
        var valAndInd = new Array(vals.length);
        vals.forEach(function(value, index) {
          return valAndInd[index] = { value, index };
        });
        if (k < valAndInd.length) {
          select$1(valAndInd, k);
          valAndInd = valAndInd.slice(0, k);
        }
        if (sorted) {
          valAndInd.sort(comparePair);
        }
        var outOffset = b2 * k;
        var topKVals = allTopKVals.subarray(outOffset, outOffset + k);
        var topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);
        for (var i = 0; i < k; i++) {
          topKVals[i] = valAndInd[i].value;
          topKIndices[i] = valAndInd[i].index;
        }
      };
      for (var b = 0; b < batch; b++) {
        _loop_1(b);
      }
      var outputShape = xShape.slice();
      outputShape[outputShape.length - 1] = k;
      return [
        tf.buffer(outputShape, xDtype, allTopKVals),
        tf.buffer(outputShape, "int32", allTopKIndices)
      ];
    }
    function uniqueImpl(values, axis, shape, dtype) {
      var $axis = tf.util.parseAxisParam(axis, shape)[0];
      var newShape = [1, shape[0], 1];
      for (var i = 0; i < $axis; i++) {
        newShape[0] *= shape[i];
      }
      newShape[1] = shape[$axis];
      for (var i = $axis + 1; i < shape.length; i++) {
        newShape[2] *= shape[i];
      }
      var uniqueElements = /* @__PURE__ */ new Map();
      var indices = new Int32Array(shape[$axis]);
      var inputBuffer = new tf.TensorBuffer(newShape, dtype, values);
      var uniqueIndices = [];
      var is1DTensor = newShape[0] === 1 && newShape[2] === 1;
      for (var i = 0; i < shape[$axis]; i++) {
        var element = void 0;
        if (is1DTensor) {
          element = values[i].toString();
        } else {
          var axisValues = [];
          for (var m = 0; m < newShape[0]; m++) {
            for (var n = 0; n < newShape[2]; n++) {
              axisValues.push(inputBuffer.get(m, i, n));
            }
          }
          element = axisValues.join(",");
        }
        var existingIndex = uniqueElements.get(element);
        if (existingIndex != null) {
          indices[i] = existingIndex;
        } else {
          var uniqueIndex = uniqueElements.size;
          uniqueElements.set(element, uniqueIndex);
          indices[i] = uniqueIndex;
          uniqueIndices.push(i);
        }
      }
      var outputTmpShape = newShape.slice();
      outputTmpShape[1] = uniqueElements.size;
      var outputBuffer = new tf.TensorBuffer(outputTmpShape, dtype);
      uniqueIndices.forEach(function(uniqueElementIndex, i2) {
        for (var m2 = 0; m2 < newShape[0]; m2++) {
          for (var n2 = 0; n2 < newShape[2]; n2++) {
            outputBuffer.set(inputBuffer.get(m2, uniqueElementIndex, n2), m2, i2, n2);
          }
        }
      });
      var outputShape = shape.slice();
      outputShape[$axis] = outputTmpShape[1];
      return {
        outputValues: outputBuffer.values,
        outputShape,
        indices
      };
    }
    var addImplCPU = addImpl;
    var bincountImplCPU = bincountImpl;
    var bincountReduceImplCPU = bincountReduceImpl;
    var bitwiseAndImplCPU = bitwiseAndImpl;
    var castImplCPU = castImpl;
    var ceilImplCPU = ceilImpl;
    var concatImplCPU = concatImpl$1;
    var equalImplCPU = equalImpl;
    var expImplCPU = expImpl;
    var expm1ImplCPU = expm1Impl;
    var floorImplCPU = floorImpl;
    var gatherNdImplCPU = gatherNdImpl;
    var gatherV2ImplCPU = gatherV2Impl;
    var greaterImplCPU = greaterImpl;
    var greaterEqualImplCPU = greaterEqualImpl;
    var lessImplCPU = lessImpl;
    var lessEqualImplCPU = lessEqualImpl;
    var linSpaceImplCPU = linSpaceImpl;
    var logImplCPU = logImpl;
    var maxImplCPU = maxImpl$1;
    var maximumImplCPU = maximumImpl;
    var minimumImplCPU = minimumImpl;
    var multiplyImplCPU = multiplyImpl;
    var negImplCPU = negImpl;
    var notEqualImplCPU = notEqualImpl;
    var prodImplCPU = prodImpl;
    var raggedGatherImplCPU = raggedGatherImpl;
    var raggedRangeImplCPU = raggedRangeImpl;
    var raggedTensorToTensorImplCPU = raggedTensorToTensorImpl;
    var rangeImplCPU = rangeImpl;
    var rsqrtImplCPU = rsqrtImpl;
    var scatterImplCPU = scatterImpl;
    var sigmoidImplCPU = sigmoidImpl;
    var simpleAbsImplCPU = simpleAbsImpl;
    var sliceImplCPU = sliceImpl;
    var sparseFillEmptyRowsImplCPU = sparseFillEmptyRowsImpl;
    var sparseReshapeImplCPU = sparseReshapeImpl;
    var sparseSegmentReductionImplCPU = sparseSegmentReductionImpl;
    var sqrtImplCPU = sqrtImpl;
    var staticRegexReplaceImplCPU = staticRegexReplaceImpl;
    var stridedSliceImplCPU = stridedSliceImpl;
    var stringNGramsImplCPU = stringNGramsImpl;
    var stringSplitImplCPU = stringSplitImpl;
    var stringToHashBucketFastImplCPU = stringToHashBucketFastImpl;
    var subImplCPU = subImpl;
    var tileImplCPU = tileImpl;
    var topKImplCPU = topKImpl;
    var transposeImplCPU = transposeImpl$1;
    var uniqueImplCPU = uniqueImpl;
    function getVecChannels(name, rank) {
      return ["x", "y", "z", "w", "u", "v"].slice(0, rank).map(function(d) {
        return "".concat(name, ".").concat(d);
      });
    }
    function getChannels(name, rank) {
      if (rank === 1) {
        return [name];
      }
      return getVecChannels(name, rank);
    }
    function getSourceCoords$2(rank, dims) {
      if (rank === 1) {
        return "rc";
      }
      var coords2 = "";
      for (var i = 0; i < rank; i++) {
        coords2 += dims[i];
        if (i < rank - 1) {
          coords2 += ",";
        }
      }
      return coords2;
    }
    var PackProgram = (
      /** @class */
      function() {
        function PackProgram2(outputShape) {
          this.variableNames = ["A"];
          this.packedInputs = false;
          this.packedOutput = true;
          this.outputShape = outputShape;
          this.rank = outputShape.length;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          if (this.rank === 0) {
            this.userCode = "\n        void main() {\n          setOutput(vec4(getA(), 0., 0., 0.));\n        }\n      ";
          } else {
            var channels = getChannels("rc", this.rank);
            var dtype = getCoordsDataType(this.rank);
            var outOfBoundsCondition = this.getOutOfBoundsCondition(channels);
            var setup = this.getSetup(channels);
            var output = this.getOutput(channels);
            this.userCode = "\n        void main() {\n          ".concat(dtype, " rc = getOutputCoords();\n\n          if(").concat(outOfBoundsCondition, ") {\n            setOutput(vec4(0));\n          } else {\n            ").concat(setup, "\n\n            setOutput(vec4(").concat(output, "));\n          }\n        }\n      ");
          }
        }
        PackProgram2.prototype.getSourceCoordsArr = function(dims) {
          var coords2 = [];
          for (var row = 0; row <= 1; row++) {
            for (var col = 0; col <= 1; col++) {
              var coord = "".concat(row === 0 ? "r" : "rp1", ", ").concat(col === 0 ? "c" : "cp1");
              for (var d = 2; d < this.rank; d++) {
                coord = "".concat(dims[dims.length - 1 - d], ",") + coord;
              }
              coords2.push(coord);
            }
          }
          return coords2;
        };
        PackProgram2.prototype.getOutOfBoundsCondition = function(dims) {
          if (this.rank === 1) {
            return "rc > ".concat(this.enableShapeUniforms ? "outShape" : this.outputShape[0]);
          }
          var cond = "";
          for (var i = this.rank - 2; i < this.rank; i++) {
            cond += "".concat(dims[i], " >= ").concat(this.enableShapeUniforms ? "outShape[".concat(i, "]") : this.outputShape[i]);
            if (i < this.rank - 1) {
              cond += "||";
            }
          }
          return cond;
        };
        PackProgram2.prototype.getSetup = function(dims) {
          if (this.rank === 1) {
            return "";
          }
          var innerDims = dims.slice(-2);
          var col = this.enableShapeUniforms ? "outShape[".concat(this.rank, " - 1]") : this.outputShape[this.rank - 1];
          var row = this.enableShapeUniforms ? "outShape[".concat(this.rank, " - 2]") : this.outputShape[this.rank - 2];
          return "\n      int r = ".concat(innerDims[0], ";\n      int c = ").concat(innerDims[1], ";\n      int rp1 = r + 1;\n      int cp1 = c + 1;\n\n      bool cEdge = cp1 >= ").concat(col, ";\n      bool rEdge = rp1 >= ").concat(row, ";\n    ");
        };
        PackProgram2.prototype.getOutput = function(dims) {
          var sourceCoords = this.getSourceCoordsArr(dims);
          if (this.rank === 1) {
            var outShape = this.enableShapeUniforms ? "outShape" : this.outputShape[0];
            return "getA(rc), (rc + 1 >= ".concat(outShape, " ? 0. : getA(rc + 1)), 0, 0");
          }
          return "getA(".concat(sourceCoords[0], "),\n            cEdge ? 0. : getA(").concat(sourceCoords[1], "),\n            rEdge ? 0. : getA(").concat(sourceCoords[2], "),\n            rEdge || cEdge ? 0. : getA(").concat(sourceCoords[3], ")");
        };
        return PackProgram2;
      }()
    );
    var ReshapePackedProgram = (
      /** @class */
      function() {
        function ReshapePackedProgram2(outputShape, inputShape) {
          this.variableNames = ["A"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.customUniforms = [{ name: "inputShape", type: "ivec3" }];
          this.outputShape = outputShape;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          var mainLoop = "";
          for (var i = 0; i < 4; i++) {
            var thisRC = "thisRC = rc;";
            if (i % 2 === 1) {
              thisRC += "thisRC.z += 1;";
            }
            if (i > 1) {
              thisRC += "thisRC.y += 1;";
            }
            mainLoop += "\n        ".concat(thisRC, "\n        ").concat(i > 0 ? "if(thisRC.y < rows && thisRC.z < cols){" : "", "\n          int flatIndex = getFlatIndex(thisRC);\n\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\n\n          result[").concat(i, "] =\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\n        ").concat(i > 0 ? "}" : "", "\n      ");
          }
          this.userCode = "\n      ".concat(getReshapedInputCoords(inputShape, this.enableShapeUniforms), "\n      ").concat(this.enableShapeUniforms ? getFlatIndexFrom3DOutput() : getFlatIndexFrom3D(outputShape), "\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0.);\n\n        ivec3 thisRC;\n        int rows = ").concat(this.enableShapeUniforms ? "outShape[1]" : outputShape[1], ";\n        int cols = ").concat(this.enableShapeUniforms ? "outShape[2]" : outputShape[2], ";\n\n        ").concat(mainLoop, "\n\n        setOutput(result);\n      }\n    ");
        }
        return ReshapePackedProgram2;
      }()
    );
    function getReshapedInputCoords(shape, enableShapeUniforms) {
      var coordsFromIndexSnippet = enableShapeUniforms ? getLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d"], "inputShape") : getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], shape);
      return "\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\n      ".concat(coordsFromIndexSnippet, "\n      return ivec3(r, c, d);\n    }\n  ");
    }
    var TextureManager = (
      /** @class */
      function() {
        function TextureManager2(gpgpu) {
          this.gpgpu = gpgpu;
          this.numUsedTextures = 0;
          this.numFreeTextures = 0;
          this._numBytesAllocated = 0;
          this._numBytesFree = 0;
          this.freeTextures = {};
          this.usedTextures = {};
          this.logEnabled = false;
        }
        TextureManager2.prototype.acquireTexture = function(shapeRC, usage, isPacked) {
          var physicalTexType = getPhysicalFromLogicalTextureType(usage, isPacked);
          var shapeKey = getKeyFromTextureShape(shapeRC, physicalTexType, isPacked);
          if (!(shapeKey in this.freeTextures)) {
            this.freeTextures[shapeKey] = [];
          }
          if (!(shapeKey in this.usedTextures)) {
            this.usedTextures[shapeKey] = [];
          }
          var texBytes = computeBytes(shapeRC, physicalTexType, this.gpgpu.gl, this.gpgpu.textureConfig, isPacked);
          if (this.freeTextures[shapeKey].length > 0) {
            this.numFreeTextures--;
            this.numUsedTextures++;
            this._numBytesFree -= texBytes;
            this.log();
            var newTexture_1 = this.freeTextures[shapeKey].pop();
            this.usedTextures[shapeKey].push(newTexture_1);
            return newTexture_1;
          }
          var newTexture;
          if (physicalTexType === PhysicalTextureType.PACKED_2X2_FLOAT32) {
            newTexture = this.gpgpu.createPackedMatrixTexture(shapeRC[0], shapeRC[1]);
          } else if (physicalTexType === PhysicalTextureType.PACKED_2X2_FLOAT16) {
            newTexture = this.gpgpu.createFloat16PackedMatrixTexture(shapeRC[0], shapeRC[1]);
          } else if (physicalTexType === PhysicalTextureType.UNPACKED_FLOAT32) {
            newTexture = this.gpgpu.createFloat32MatrixTexture(shapeRC[0], shapeRC[1]);
          } else if (physicalTexType === PhysicalTextureType.UNPACKED_FLOAT16) {
            newTexture = this.gpgpu.createFloat16MatrixTexture(shapeRC[0], shapeRC[1]);
          } else if (physicalTexType === PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE) {
            newTexture = this.gpgpu.createUnsignedBytesMatrixTexture(shapeRC[0], shapeRC[1]);
          }
          this.usedTextures[shapeKey].push(newTexture);
          this.numUsedTextures++;
          this._numBytesAllocated += texBytes;
          this.log();
          return newTexture;
        };
        TextureManager2.prototype.releaseTexture = function(texture, shape, logicalTexType, isPacked) {
          if (this.freeTextures == null) {
            return;
          }
          var physicalTexType = getPhysicalFromLogicalTextureType(logicalTexType, isPacked);
          var shapeKey = getKeyFromTextureShape(shape, physicalTexType, isPacked);
          if (!(shapeKey in this.freeTextures)) {
            this.freeTextures[shapeKey] = [];
          }
          var texBytes = computeBytes(shape, physicalTexType, this.gpgpu.gl, this.gpgpu.textureConfig, isPacked);
          var deleteTexThreshold = tf.env().getNumber("WEBGL_DELETE_TEXTURE_THRESHOLD");
          if (deleteTexThreshold !== -1 && this._numBytesAllocated > deleteTexThreshold) {
            this.gpgpu.deleteMatrixTexture(texture.texture);
            this._numBytesAllocated -= texBytes;
          } else {
            this.freeTextures[shapeKey].push(texture);
            this.numFreeTextures++;
            this._numBytesFree += texBytes;
          }
          this.numUsedTextures--;
          var texList = this.usedTextures[shapeKey];
          var texIndex = texList && texList.indexOf(texture);
          if (texIndex == null || texIndex < 0) {
            throw new Error("Cannot release a texture that was never provided by this texture manager");
          }
          texList[texIndex] = texList[texList.length - 1];
          texList.pop();
          this.log();
        };
        TextureManager2.prototype.log = function() {
          if (!this.logEnabled) {
            return;
          }
          var total = this.numFreeTextures + this.numUsedTextures;
          console.log("Free/Used", "".concat(this.numFreeTextures, " / ").concat(this.numUsedTextures), "(".concat(total, ")"));
          var freeRatio = this._numBytesFree / this._numBytesAllocated;
          console.log("Bytes allocated: ".concat(this._numBytesAllocated));
          console.log("Bytes unused: ".concat(this._numBytesFree, " (").concat(Math.round(100 * freeRatio), "%)"));
        };
        Object.defineProperty(TextureManager2.prototype, "numBytesAllocated", {
          get: function() {
            return this._numBytesAllocated;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(TextureManager2.prototype, "numBytesFree", {
          get: function() {
            return this._numBytesFree;
          },
          enumerable: false,
          configurable: true
        });
        TextureManager2.prototype.getNumUsedTextures = function() {
          return this.numUsedTextures;
        };
        TextureManager2.prototype.getNumFreeTextures = function() {
          return this.numFreeTextures;
        };
        TextureManager2.prototype.dispose = function() {
          var _this = this;
          if (this.freeTextures == null) {
            return;
          }
          for (var texShape in this.freeTextures) {
            this.freeTextures[texShape].forEach(function(tex) {
              _this.gpgpu.deleteMatrixTexture(tex.texture);
            });
          }
          for (var texShape in this.usedTextures) {
            this.usedTextures[texShape].forEach(function(tex) {
              _this.gpgpu.deleteMatrixTexture(tex.texture);
            });
          }
          this.freeTextures = null;
          this.usedTextures = null;
          this.numUsedTextures = 0;
          this.numFreeTextures = 0;
          this._numBytesAllocated = 0;
          this._numBytesFree = 0;
        };
        return TextureManager2;
      }()
    );
    function numBytesForInternalFormat(gl, internalFormat) {
      var glany = gl;
      if (internalFormat === glany.R32F) {
        return 4;
      } else if (internalFormat === glany.R16F) {
        return 2;
      } else if (internalFormat === glany.RGBA32F) {
        return 16;
      } else if (internalFormat === gl.RGBA) {
        return 16;
      } else if (internalFormat === glany.RGBA16F) {
        return 8;
      } else if (internalFormat === glany.RGBA8) {
        return 4;
      }
      throw new Error("Unknown internal format ".concat(internalFormat));
    }
    function computeBytes(shape, physicalTexType, gl, textureConfig, isPacked) {
      var internalFormat = internalFormatForPhysicalTexType(physicalTexType, textureConfig);
      var numElements;
      if (isPacked) {
        var _a2 = __read(getPackedMatrixTextureShapeWidthHeight(shape[0], shape[1]), 2), packedWidth = _a2[0], packedHeight = _a2[1];
        numElements = packedWidth * packedHeight;
      } else {
        var _b = __read(getUnpackedMatrixTextureShapeWidthHeight(shape[0], shape[1]), 2), width = _b[0], height = _b[1];
        numElements = width * height;
      }
      var bytesPerElement = numBytesForInternalFormat(gl, internalFormat);
      return numElements * bytesPerElement;
    }
    function internalFormatForPhysicalTexType(physicalTexType, textureConfig) {
      switch (physicalTexType) {
        case PhysicalTextureType.PACKED_2X2_FLOAT32:
          return getInternalFormatForPackedMatrixTexture(textureConfig);
        case PhysicalTextureType.PACKED_2X2_FLOAT16:
          return getInternalFormatForFloat16PackedMatrixTexture(textureConfig);
        case PhysicalTextureType.UNPACKED_FLOAT32:
          return getInternalFormatForFloat32MatrixTexture(textureConfig);
        case PhysicalTextureType.UNPACKED_FLOAT16:
          return getInternalFormatForFloat16MatrixTexture(textureConfig);
        case PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE:
          return getInternalFormatForUnsignedBytesMatrixTexture(textureConfig);
        default:
          throw new Error("Unknown physical texture type ".concat(physicalTexType));
      }
    }
    function getPhysicalTextureForRendering(isPacked) {
      if (tf.env().getBool("WEBGL_RENDER_FLOAT32_ENABLED")) {
        if (isPacked) {
          return PhysicalTextureType.PACKED_2X2_FLOAT32;
        }
        return PhysicalTextureType.UNPACKED_FLOAT32;
      }
      if (isPacked) {
        return PhysicalTextureType.PACKED_2X2_FLOAT16;
      }
      return PhysicalTextureType.UNPACKED_FLOAT16;
    }
    function getPhysicalFromLogicalTextureType(logicalTexType, isPacked) {
      if (logicalTexType === TextureUsage.UPLOAD) {
        return PhysicalTextureType.PACKED_2X2_FLOAT32;
      } else if (logicalTexType === TextureUsage.RENDER || logicalTexType == null) {
        return getPhysicalTextureForRendering(isPacked);
      } else if (logicalTexType === TextureUsage.DOWNLOAD || logicalTexType === TextureUsage.PIXELS) {
        return PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE;
      }
      throw new Error("Unknown logical texture type ".concat(logicalTexType));
    }
    function getKeyFromTextureShape(shapeRowsCol, physicalTexType, isPacked) {
      return "".concat(shapeRowsCol[0], "_").concat(shapeRowsCol[1], "_").concat(physicalTexType, "_").concat(isPacked);
    }
    var UnaryOpProgram = (
      /** @class */
      function() {
        function UnaryOpProgram2(aShape, opSnippet) {
          this.variableNames = ["A"];
          this.outputShape = aShape;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          this.userCode = "\n      float unaryOperation(float x) {\n        ".concat(opSnippet, "\n      }\n\n      void main() {\n        float x = getAAtOutCoords();\n        float y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    ");
        }
        return UnaryOpProgram2;
      }()
    );
    var CHECK_NAN_SNIPPET$1 = "if (isnan(x)) return x;";
    var LINEAR$1 = "return x;";
    var ABS$1 = "return abs(x);";
    var ELU$2 = "return (x >= 0.0) ? x : (exp(x) - 1.0);";
    var RELU$2 = CHECK_NAN_SNIPPET$1 + "\n  return (x < 0.0) ? 0.0 : x;\n";
    var RELU6$2 = CHECK_NAN_SNIPPET$1 + "\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n";
    var CLONE = "return x;";
    var SIGMOID$2 = "return 1.0 / (1.0 + exp(-1.0 * x));";
    var LINEAR = "return x;";
    var ELU$1 = "\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n";
    var RELU$1 = "\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n";
    var RELU6$1 = "\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n";
    var SIGMOID$1 = "return 1.0 / (1.0 + exp(-1.0 * x));";
    var UnaryOpPackedProgram = (
      /** @class */
      function() {
        function UnaryOpPackedProgram2(aShape, opSnippet) {
          this.variableNames = ["A"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.outputShape = aShape;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          this.userCode = "\n      vec4 unaryOperation(vec4 x) {\n        ".concat(opSnippet, "\n      }\n\n      void main() {\n        vec4 x = getAAtOutCoords();\n        vec4 y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    ");
        }
        return UnaryOpPackedProgram2;
      }()
    );
    var UnpackProgram = (
      /** @class */
      function() {
        function UnpackProgram2(outputShape) {
          this.variableNames = ["A"];
          this.packedInputs = true;
          this.packedOutput = false;
          this.outputShape = outputShape;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          var rank = outputShape.length;
          var channels = getChannels("rc", rank);
          var dtype = getCoordsDataType(rank);
          var sourceCoords = getSourceCoords$2(rank, channels);
          var innerDims = channels.slice(-2);
          var coords2 = rank <= 1 ? "rc" : "vec2(".concat(innerDims.join(","), ")");
          this.userCode = "\n      void main() {\n        ".concat(dtype, " rc = getOutputCoords();\n        vec4 packedInput = getA(").concat(sourceCoords, ");\n\n        setOutput(getChannel(packedInput, ").concat(coords2, "));\n      }\n    ");
        }
        return UnpackProgram2;
      }()
    );
    var whereImpl = tf.kernel_impls.whereImpl;
    var EPSILON_FLOAT32 = 1e-7;
    var EPSILON_FLOAT16 = 1e-4;
    var binaryCaches = {};
    function getBinaryCache(webGLVersion) {
      if (webGLVersion in binaryCaches) {
        return binaryCaches[webGLVersion];
      }
      binaryCaches[webGLVersion] = {};
      return binaryCaches[webGLVersion];
    }
    var CPU_HANDOFF_SIZE_THRESHOLD = tf.env().getNumber("CPU_HANDOFF_SIZE_THRESHOLD");
    var BEFORE_PAGING_CONSTANT = 600;
    function numMBBeforeWarning() {
      if (tf.env().global.screen == null) {
        return 1024;
      }
      return tf.env().global.screen.height * tf.env().global.screen.width * window.devicePixelRatio * BEFORE_PAGING_CONSTANT / 1024 / 1024;
    }
    var MathBackendWebGL = (
      /** @class */
      function(_super) {
        __extends(MathBackendWebGL2, _super);
        function MathBackendWebGL2(gpuResource) {
          var _this = _super.call(this) || this;
          _this.pendingRead = /* @__PURE__ */ new WeakMap();
          _this.pendingDisposal = /* @__PURE__ */ new WeakSet();
          _this.dataRefCount = /* @__PURE__ */ new WeakMap();
          _this.numBytesInGPU = 0;
          _this.uploadWaitMs = 0;
          _this.downloadWaitMs = 0;
          _this.lastGlFlushTime = 0;
          _this.warnedAboutMemory = false;
          _this.pendingDeletes = 0;
          _this.disposed = false;
          if (!tf.env().getBool("HAS_WEBGL")) {
            throw new Error("WebGL is not supported on this device");
          }
          var newGPGPU;
          if (gpuResource != null) {
            if (gpuResource instanceof GPGPUContext) {
              newGPGPU = gpuResource;
            } else {
              var gl = getWebGLContext(tf.env().getNumber("WEBGL_VERSION"), gpuResource);
              newGPGPU = new GPGPUContext(gl);
            }
            _this.binaryCache = {};
            _this.gpgpuCreatedLocally = false;
          } else {
            var gl = getWebGLContext(tf.env().getNumber("WEBGL_VERSION"));
            newGPGPU = new GPGPUContext(gl);
            _this.binaryCache = getBinaryCache(tf.env().getNumber("WEBGL_VERSION"));
            _this.gpgpuCreatedLocally = true;
          }
          _this.gpgpu = newGPGPU;
          _this.canvas = _this.gpgpu.gl.canvas;
          _this.textureManager = new TextureManager(_this.gpgpu);
          _this.numMBBeforeWarning = numMBBeforeWarning();
          _this.texData = new tf.DataStorage(_this, tf.engine());
          return _this;
        }
        MathBackendWebGL2.prototype.nextDataId = function() {
          return MathBackendWebGL2.nextDataId++;
        };
        MathBackendWebGL2.prototype.numDataIds = function() {
          return this.texData.numDataIds() - this.pendingDeletes;
        };
        MathBackendWebGL2.prototype.writeTexture = function(texture, shape, dtype, texHeight, texWidth, channels) {
          var input = this.makeTensorInfo(shape, dtype);
          var inData = this.texData.get(input.dataId);
          inData.isPacked = false;
          inData.texture = { texture, texShape: [texHeight, texWidth] };
          inData.texShape = [texHeight, texWidth];
          var shapeAs3D = getShapeAs3D(shape);
          var program = new EncodeMatrixProgram(shapeAs3D, false, channels);
          var output = this.runWebGLProgram(program, [input], dtype, [[texHeight, texWidth]]);
          output.shape = shape;
          inData.texture = null;
          this.disposeIntermediateTensorInfo(input);
          return output.dataId;
        };
        MathBackendWebGL2.prototype.write = function(values, shape, dtype) {
          if (tf.env().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS") || tf.env().getBool("DEBUG")) {
            this.checkNumericalProblems(values);
          }
          if (dtype === "complex64" && values != null) {
            throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");
          }
          var dataId = { id: this.nextDataId() };
          this.texData.set(dataId, { shape, dtype, values, usage: TextureUsage.UPLOAD, refCount: 1 });
          return dataId;
        };
        MathBackendWebGL2.prototype.refCount = function(dataId) {
          if (this.texData.has(dataId)) {
            var tensorData = this.texData.get(dataId);
            return tensorData.refCount;
          }
          return 0;
        };
        MathBackendWebGL2.prototype.incRef = function(dataId) {
          var texData = this.texData.get(dataId);
          texData.refCount++;
        };
        MathBackendWebGL2.prototype.decRef = function(dataId) {
          if (this.texData.has(dataId)) {
            var texData = this.texData.get(dataId);
            texData.refCount--;
          }
        };
        MathBackendWebGL2.prototype.move = function(dataId, values, shape, dtype, refCount) {
          if (tf.env().getBool("DEBUG")) {
            this.checkNumericalProblems(values);
          }
          if (dtype === "complex64") {
            throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");
          }
          this.texData.set(dataId, { shape, dtype, values, usage: TextureUsage.UPLOAD, refCount });
        };
        MathBackendWebGL2.prototype.disposeIntermediateTensorInfo = function(tensorInfo) {
          this.disposeData(tensorInfo.dataId);
        };
        MathBackendWebGL2.prototype.readSync = function(dataId) {
          var texData = this.texData.get(dataId);
          var values = texData.values, dtype = texData.dtype, complexTensorInfos = texData.complexTensorInfos, slice2 = texData.slice, shape = texData.shape, isPacked = texData.isPacked;
          if (slice2 != null) {
            var program = void 0;
            if (isPacked) {
              program = new UnaryOpPackedProgram(shape, CLONE);
            } else {
              program = new UnaryOpProgram(shape, CLONE);
            }
            var res = this.runWebGLProgram(program, [{ dataId, shape, dtype }], dtype);
            var data = this.readSync(res.dataId);
            this.disposeIntermediateTensorInfo(res);
            return data;
          }
          if (values != null) {
            return this.convertAndCacheOnCPU(dataId);
          }
          if (dtype === "string") {
            return values;
          }
          var shouldTimeProgram = this.activeTimers != null;
          var start;
          if (shouldTimeProgram) {
            start = tf.util.now();
          }
          var result;
          if (dtype === "complex64") {
            var realValues = this.readSync(complexTensorInfos.real.dataId);
            var imagValues = this.readSync(complexTensorInfos.imag.dataId);
            result = tf.backend_util.mergeRealAndImagArrays(realValues, imagValues);
          } else {
            result = this.getValuesFromTexture(dataId);
          }
          if (shouldTimeProgram) {
            this.downloadWaitMs += tf.util.now() - start;
          }
          return this.convertAndCacheOnCPU(dataId, result);
        };
        MathBackendWebGL2.prototype.read = function(dataId) {
          return __awaiter(this, void 0, void 0, function() {
            var subscribers_1, texData, values, shape, slice2, dtype, complexTensorInfos, isPacked, program, res, data, buffer, tmpDownloadTarget, tmpData, vals, ps, realValues, imagValues, size, gl_1, dTypeVals, subscribers;
            var _b;
            return __generator(this, function(_c) {
              switch (_c.label) {
                case 0:
                  if (this.pendingRead.has(dataId)) {
                    subscribers_1 = this.pendingRead.get(dataId);
                    return [2, new Promise(function(resolve) {
                      return subscribers_1.push(resolve);
                    })];
                  }
                  texData = this.texData.get(dataId);
                  values = texData.values, shape = texData.shape, slice2 = texData.slice, dtype = texData.dtype, complexTensorInfos = texData.complexTensorInfos, isPacked = texData.isPacked;
                  if (slice2 != null) {
                    program = void 0;
                    if (isPacked) {
                      program = new UnaryOpPackedProgram(shape, CLONE);
                    } else {
                      program = new UnaryOpProgram(shape, CLONE);
                    }
                    res = this.runWebGLProgram(program, [{ dataId, shape, dtype }], dtype);
                    data = this.read(res.dataId);
                    this.disposeIntermediateTensorInfo(res);
                    return [2, data];
                  }
                  if (values != null) {
                    return [2, this.convertAndCacheOnCPU(dataId)];
                  }
                  if (tf.env().getBool("DEBUG")) {
                    if (!tf.env().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED") && tf.env().getNumber("WEBGL_VERSION") === 2) {
                      throw new Error("tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.");
                    }
                  }
                  buffer = null;
                  if (dtype !== "complex64" && tf.env().get("WEBGL_BUFFER_SUPPORTED")) {
                    tmpDownloadTarget = this.decode(dataId);
                    tmpData = this.texData.get(tmpDownloadTarget.dataId);
                    buffer = (_b = this.gpgpu).createBufferFromTexture.apply(_b, __spreadArray([tmpData.texture.texture], __read(getDenseTexShape(shape)), false));
                  }
                  this.pendingRead.set(dataId, []);
                  if (!(dtype !== "complex64"))
                    return [3, 2];
                  return [4, this.gpgpu.createAndWaitForFence()];
                case 1:
                  _c.sent();
                  _c.label = 2;
                case 2:
                  if (!(dtype === "complex64"))
                    return [3, 4];
                  return [4, Promise.all([
                    this.read(complexTensorInfos.real.dataId),
                    this.read(complexTensorInfos.imag.dataId)
                  ])];
                case 3:
                  ps = _c.sent();
                  realValues = ps[0];
                  imagValues = ps[1];
                  vals = tf.backend_util.mergeRealAndImagArrays(realValues, imagValues);
                  return [3, 5];
                case 4:
                  if (buffer == null) {
                    vals = this.getValuesFromTexture(dataId);
                  } else {
                    size = tf.util.sizeFromShape(shape);
                    vals = this.gpgpu.downloadFloat32MatrixFromBuffer(buffer, size);
                  }
                  _c.label = 5;
                case 5:
                  if (tmpDownloadTarget != null) {
                    this.disposeIntermediateTensorInfo(tmpDownloadTarget);
                  }
                  if (buffer != null) {
                    gl_1 = this.gpgpu.gl;
                    callAndCheck(gl_1, function() {
                      return gl_1.deleteBuffer(buffer);
                    });
                  }
                  dTypeVals = this.convertAndCacheOnCPU(dataId, vals);
                  subscribers = this.pendingRead.get(dataId);
                  this.pendingRead.delete(dataId);
                  subscribers.forEach(function(resolve) {
                    return resolve(dTypeVals);
                  });
                  if (this.pendingDisposal.has(dataId)) {
                    this.pendingDisposal.delete(dataId);
                    if (this.disposeData(dataId)) {
                      tf.engine().removeDataId(dataId, this);
                    }
                    this.pendingDeletes--;
                  }
                  return [2, dTypeVals];
              }
            });
          });
        };
        MathBackendWebGL2.prototype.readToGPU = function(dataId, options) {
          if (options === void 0) {
            options = {};
          }
          var texData = this.texData.get(dataId);
          var values = texData.values, shape = texData.shape, slice2 = texData.slice, dtype = texData.dtype, isPacked = texData.isPacked, texture = texData.texture;
          if (dtype === "complex64") {
            throw new Error("Does not support reading texture for complex64 dtype.");
          }
          if (slice2 != null) {
            var program = void 0;
            if (isPacked) {
              program = new UnaryOpPackedProgram(shape, CLONE);
            } else {
              program = new UnaryOpProgram(shape, CLONE);
            }
            var res = this.runWebGLProgram(program, [{ dataId, shape, dtype }], dtype);
            var gpuResouorce = this.readToGPU(res, options);
            this.disposeIntermediateTensorInfo(res);
            return gpuResouorce;
          }
          if (texture == null) {
            if (values != null) {
              throw new Error("Data is not on GPU but on CPU.");
            } else {
              throw new Error("There is no data on GPU or CPU.");
            }
          }
          var tmpTarget = this.decode(dataId, options.customTexShape);
          var tensorRef = tf.engine().makeTensorFromTensorInfo(tmpTarget);
          var tmpData = this.texData.get(tmpTarget.dataId);
          return Object.assign({ tensorRef }, tmpData.texture);
        };
        MathBackendWebGL2.prototype.bufferSync = function(t) {
          var data = this.readSync(t.dataId);
          if (t.dtype === "string") {
            try {
              var strings = data.map(function(d) {
                return tf.util.decodeString(d);
              });
              return tf.buffer(t.shape, t.dtype, strings);
            } catch (_a2) {
              throw new Error("Failed to decode encoded string bytes into utf-8");
            }
          }
          return tf.buffer(t.shape, t.dtype, data);
        };
        MathBackendWebGL2.prototype.checkNumericalProblems = function(values) {
          if (values == null) {
            return;
          }
          for (var i = 0; i < values.length; i++) {
            var num = values[i];
            if (!canBeRepresented(num)) {
              if (tf.env().getBool("WEBGL_RENDER_FLOAT32_CAPABLE")) {
                throw Error("The value ".concat(num, " cannot be represented with your ") + "current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'");
              }
              throw Error("The value ".concat(num, " cannot be represented on this device."));
            }
          }
        };
        MathBackendWebGL2.prototype.getValuesFromTexture = function(dataId) {
          var _b;
          var _c = this.texData.get(dataId), shape = _c.shape, dtype = _c.dtype, isPacked = _c.isPacked;
          var size = tf.util.sizeFromShape(shape);
          if (tf.env().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")) {
            var tmpTarget = this.decode(dataId);
            var tmpData_1 = this.texData.get(tmpTarget.dataId);
            var vals_1 = (_b = this.gpgpu).downloadMatrixFromPackedTexture.apply(_b, __spreadArray([tmpData_1.texture.texture], __read(getDenseTexShape(shape)), false)).subarray(0, size);
            this.disposeIntermediateTensorInfo(tmpTarget);
            return vals_1;
          }
          var shouldUsePackedProgram = tf.env().getBool("WEBGL_PACK") && isPacked === true;
          var outputShape = shouldUsePackedProgram ? getShapeAs3D(shape) : shape;
          var program = shouldUsePackedProgram ? new EncodeFloatPackedProgram(outputShape) : new EncodeFloatProgram(outputShape);
          var output = this.runWebGLProgram(program, [{ shape: outputShape, dtype, dataId }], "float32");
          var tmpData = this.texData.get(output.dataId);
          var vals = this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(tmpData.texture.texture, tmpData.texShape[0], tmpData.texShape[1]).subarray(0, size);
          this.disposeIntermediateTensorInfo(output);
          return vals;
        };
        MathBackendWebGL2.prototype.timerAvailable = function() {
          return tf.env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0;
        };
        MathBackendWebGL2.prototype.time = function(f) {
          var _this = this;
          var oldActiveTimers = this.activeTimers;
          var newActiveTimers = [];
          var outerMostTime = false;
          if (this.programTimersStack == null) {
            this.programTimersStack = newActiveTimers;
            outerMostTime = true;
          } else {
            this.activeTimers.push(newActiveTimers);
          }
          this.activeTimers = newActiveTimers;
          f();
          var flattenedActiveTimerQueries = tf.util.flatten(this.activeTimers.map(function(d) {
            return d.query;
          })).filter(function(d) {
            return d != null;
          });
          var flattenedActiveTimerNames = tf.util.flatten(this.activeTimers.map(function(d) {
            return d.name;
          })).filter(function(d) {
            return d != null;
          });
          this.activeTimers = oldActiveTimers;
          if (outerMostTime) {
            this.programTimersStack = null;
          }
          var res = {
            uploadWaitMs: this.uploadWaitMs,
            downloadWaitMs: this.downloadWaitMs,
            kernelMs: null,
            wallMs: null
            // will be filled by the engine
          };
          return function() {
            return __awaiter(_this, void 0, void 0, function() {
              var kernelMs_1;
              return __generator(this, function(_b) {
                switch (_b.label) {
                  case 0:
                    if (!(tf.env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0))
                      return [3, 2];
                    return [4, Promise.all(flattenedActiveTimerQueries)];
                  case 1:
                    kernelMs_1 = _b.sent();
                    res["kernelMs"] = tf.util.sum(kernelMs_1);
                    res["getExtraProfileInfo"] = function() {
                      return kernelMs_1.map(function(d, i) {
                        return { name: flattenedActiveTimerNames[i], ms: d };
                      }).map(function(d) {
                        return "".concat(d.name, ": ").concat(d.ms);
                      }).join(", ");
                    };
                    return [3, 3];
                  case 2:
                    res["kernelMs"] = {
                      error: "WebGL query timers are not supported in this environment."
                    };
                    _b.label = 3;
                  case 3:
                    this.uploadWaitMs = 0;
                    this.downloadWaitMs = 0;
                    return [2, res];
                }
              });
            });
          }();
        };
        MathBackendWebGL2.prototype.memory = function() {
          return {
            unreliable: false,
            numBytesInGPU: this.numBytesInGPU,
            numBytesInGPUAllocated: this.textureManager.numBytesAllocated,
            numBytesInGPUFree: this.textureManager.numBytesFree
          };
        };
        MathBackendWebGL2.prototype.startTimer = function() {
          if (tf.env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
            return this.gpgpu.beginQuery();
          }
          return { startMs: tf.util.now(), endMs: null };
        };
        MathBackendWebGL2.prototype.endTimer = function(query) {
          if (tf.env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
            this.gpgpu.endQuery();
            return query;
          }
          query.endMs = tf.util.now();
          return query;
        };
        MathBackendWebGL2.prototype.getQueryTime = function(query) {
          return __awaiter(this, void 0, void 0, function() {
            var timerQuery;
            return __generator(this, function(_b) {
              if (tf.env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
                return [2, this.gpgpu.waitForQueryAndGetTime(query)];
              }
              timerQuery = query;
              return [2, timerQuery.endMs - timerQuery.startMs];
            });
          });
        };
        MathBackendWebGL2.prototype.disposeData = function(dataId, force) {
          if (force === void 0) {
            force = false;
          }
          if (this.pendingDisposal.has(dataId)) {
            return false;
          }
          if (!this.texData.has(dataId)) {
            return true;
          }
          if (force) {
            this.texData.get(dataId).refCount = 0;
          } else {
            this.texData.get(dataId).refCount--;
          }
          if (!force && this.texData.get(dataId).refCount > 0) {
            return false;
          }
          if (this.pendingRead.has(dataId)) {
            this.pendingDisposal.add(dataId);
            this.pendingDeletes++;
            return false;
          }
          this.releaseGPUData(dataId);
          var complexTensorInfos = this.texData.get(dataId).complexTensorInfos;
          if (complexTensorInfos != null) {
            this.disposeData(complexTensorInfos.real.dataId, force);
            this.disposeData(complexTensorInfos.imag.dataId, force);
          }
          this.texData.delete(dataId);
          return true;
        };
        MathBackendWebGL2.prototype.releaseGPUData = function(dataId) {
          var _b = this.texData.get(dataId), texture = _b.texture, dtype = _b.dtype, texShape = _b.texShape, usage = _b.usage, isPacked = _b.isPacked, slice2 = _b.slice;
          var key = slice2 && slice2.origDataId || dataId;
          var refCount = this.dataRefCount.get(key);
          if (refCount > 1) {
            this.dataRefCount.set(key, refCount - 1);
          } else {
            this.dataRefCount.delete(key);
            if (texture != null) {
              this.numBytesInGPU -= this.computeBytes(texShape, dtype);
              this.textureManager.releaseTexture(texture, texShape, usage, isPacked);
            }
          }
          var texData = this.texData.get(dataId);
          texData.texture = null;
          texData.texShape = null;
          texData.isPacked = false;
          texData.slice = null;
        };
        MathBackendWebGL2.prototype.getTexture = function(dataId) {
          this.uploadToGPU(dataId);
          return this.texData.get(dataId).texture.texture;
        };
        MathBackendWebGL2.prototype.getDataInfo = function(dataId) {
          return this.texData.get(dataId);
        };
        MathBackendWebGL2.prototype.shouldExecuteOnCPU = function(inputs, sizeThreshold) {
          var _this = this;
          if (sizeThreshold === void 0) {
            sizeThreshold = CPU_HANDOFF_SIZE_THRESHOLD;
          }
          return tf.env().getBool("WEBGL_CPU_FORWARD") && inputs.every(function(input) {
            return _this.texData.get(input.dataId).texture == null && tf.util.sizeFromShape(input.shape) < sizeThreshold;
          });
        };
        MathBackendWebGL2.prototype.getGPGPUContext = function() {
          return this.gpgpu;
        };
        MathBackendWebGL2.prototype.where = function(condition) {
          tf.backend_util.warn("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");
          var condVals = condition.dataSync();
          return whereImpl(condition.shape, condVals);
        };
        MathBackendWebGL2.prototype.packedUnaryOp = function(x, op, dtype) {
          var program = new UnaryOpPackedProgram(x.shape, op);
          var outInfo = this.compileAndRun(program, [x], dtype);
          return tf.engine().makeTensorFromTensorInfo(outInfo);
        };
        MathBackendWebGL2.prototype.abs = function(x) {
          if (this.shouldExecuteOnCPU([x]) && x.dtype !== "complex64") {
            var outValues = simpleAbsImplCPU(this.texData.get(x.dataId).values);
            return this.makeOutput(x.shape, x.dtype, outValues);
          }
          if (tf.env().getBool("WEBGL_PACK_UNARY_OPERATIONS")) {
            return this.packedUnaryOp(x, ABS$1, x.dtype);
          }
          var program = new UnaryOpProgram(x.shape, ABS$1);
          var outInfo = this.compileAndRun(program, [x]);
          return tf.engine().makeTensorFromTensorInfo(outInfo);
        };
        MathBackendWebGL2.prototype.makeTensorInfo = function(shape, dtype, values) {
          var dataId;
          if (dtype === "string" && values != null && values.length > 0 && tf.util.isString(values[0])) {
            var encodedValues = values.map(function(d) {
              return tf.util.encodeString(d);
            });
            dataId = this.write(encodedValues, shape, dtype);
          } else {
            dataId = this.write(values, shape, dtype);
          }
          this.texData.get(dataId).usage = null;
          return { dataId, shape, dtype };
        };
        MathBackendWebGL2.prototype.makeOutput = function(shape, dtype, values) {
          return tf.engine().makeTensorFromTensorInfo(this.makeTensorInfo(shape, dtype, values), this);
        };
        MathBackendWebGL2.prototype.unpackTensor = function(input) {
          var program = new UnpackProgram(input.shape);
          return this.runWebGLProgram(program, [input], input.dtype);
        };
        MathBackendWebGL2.prototype.packTensor = function(input) {
          var program = new PackProgram(input.shape);
          var preventEagerUnpackingOutput = true;
          return this.runWebGLProgram(program, [input], input.dtype, null, preventEagerUnpackingOutput);
        };
        MathBackendWebGL2.prototype.packedReshape = function(input, afterShape) {
          var input3DShape = __spreadArray([
            getBatchDim(input.shape)
          ], __read(getRowsCols(input.shape)), false);
          var input3D = {
            dtype: input.dtype,
            shape: input3DShape,
            dataId: input.dataId
          };
          var afterShapeAs3D = __spreadArray([
            getBatchDim(afterShape)
          ], __read(getRowsCols(afterShape)), false);
          var program = new ReshapePackedProgram(afterShapeAs3D, input3DShape);
          var preventEagerUnpackingOfOutput = true;
          var customValues = [input3DShape];
          var output = this.runWebGLProgram(program, [input3D], input.dtype, customValues, preventEagerUnpackingOfOutput);
          return { dataId: output.dataId, shape: afterShape, dtype: output.dtype };
        };
        MathBackendWebGL2.prototype.decode = function(dataId, customTexShape) {
          var texData = this.texData.get(dataId);
          var isPacked = texData.isPacked, shape = texData.shape, dtype = texData.dtype;
          if (customTexShape != null) {
            var size = tf.util.sizeFromShape(shape);
            var texSize = customTexShape[0] * customTexShape[1] * 4;
            tf.util.assert(size <= texSize, function() {
              return "customTexShape is too small. Row * Column * 4 should be equal or larger than the size of the tensor data.";
            });
          }
          var shapeAs3D = getShapeAs3D(shape);
          var program;
          if (isPacked) {
            program = new DecodeMatrixPackedProgram(shapeAs3D);
          } else {
            program = new DecodeMatrixProgram(shapeAs3D);
          }
          var preventEagerUnpackingOfOutput = true;
          var customValues = [customTexShape != null ? customTexShape : getDenseTexShape(shapeAs3D)];
          var out = this.runWebGLProgram(program, [{ shape: shapeAs3D, dtype, dataId }], dtype, customValues, preventEagerUnpackingOfOutput, customTexShape);
          return { dtype, shape, dataId: out.dataId };
        };
        MathBackendWebGL2.prototype.runWebGLProgram = function(program, inputs, outputDtype, customUniformValues, preventEagerUnpackingOfOutput, customTexShape) {
          var _this = this;
          if (preventEagerUnpackingOfOutput === void 0) {
            preventEagerUnpackingOfOutput = false;
          }
          var output = this.makeTensorInfo(program.outputShape, outputDtype);
          var outData = this.texData.get(output.dataId);
          if (program.packedOutput) {
            outData.isPacked = true;
          }
          if (program.outPackingScheme === PackingScheme.DENSE) {
            var texelShape = customTexShape != null ? customTexShape : getDenseTexShape(program.outputShape);
            outData.texShape = texelShape.map(function(d) {
              return d * 2;
            });
          }
          if (program.outTexUsage != null) {
            outData.usage = program.outTexUsage;
          }
          if (tf.util.sizeFromShape(output.shape) === 0) {
            outData.values = tf.util.getTypedArrayFromDType(output.dtype, 0);
            return output;
          }
          var dataToDispose = [];
          var inputsData = inputs.map(function(input) {
            if (input.dtype === "complex64") {
              throw new Error("GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.");
            }
            var texData = _this.texData.get(input.dataId);
            if (texData.texture == null) {
              if (!program.packedInputs && tf.util.sizeFromShape(input.shape) <= tf.env().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM")) {
                return {
                  shape: input.shape,
                  texData: null,
                  isUniform: true,
                  uniformValues: texData.values
                };
              }
              if (program.packedInputs) {
                texData.isPacked = true;
                texData.shape = input.shape;
              }
            }
            _this.uploadToGPU(input.dataId);
            if (!!texData.isPacked !== !!program.packedInputs) {
              input = texData.isPacked ? _this.unpackTensor(input) : _this.packTensor(input);
              dataToDispose.push(input);
              texData = _this.texData.get(input.dataId);
            } else if (texData.isPacked && !isReshapeFree(texData.shape, input.shape)) {
              var savedInput = input;
              var targetShape = input.shape;
              input.shape = texData.shape;
              input = _this.packedReshape(input, targetShape);
              dataToDispose.push(input);
              texData = _this.texData.get(input.dataId);
              savedInput.shape = targetShape;
            }
            return { shape: input.shape, texData, isUniform: false };
          });
          this.uploadToGPU(output.dataId);
          var outputData = { shape: output.shape, texData: outData, isUniform: false };
          var key = makeShaderKey(program, inputsData, outputData);
          var binary = this.getAndSaveBinary(key, function() {
            return compileProgram(_this.gpgpu, program, inputsData, outputData);
          });
          var shouldTimeProgram = this.activeTimers != null;
          var query;
          if (shouldTimeProgram) {
            query = this.startTimer();
          }
          if (!tf.env().get("ENGINE_COMPILE_ONLY")) {
            runProgram(this.gpgpu, binary, inputsData, outputData, customUniformValues);
          }
          dataToDispose.forEach(function(info) {
            return _this.disposeIntermediateTensorInfo(info);
          });
          if (shouldTimeProgram) {
            query = this.endTimer(query);
            this.activeTimers.push({ name: program.constructor.name, query: this.getQueryTime(query) });
          }
          var glFlushThreshold = tf.env().getNumber("WEBGL_FLUSH_THRESHOLD");
          if (glFlushThreshold > 0) {
            var time = tf.util.now();
            if (time - this.lastGlFlushTime > glFlushThreshold) {
              this.gpgpu.gl.flush();
              this.lastGlFlushTime = time;
            }
          }
          if (!tf.env().getBool("WEBGL_LAZILY_UNPACK") && outData.isPacked && preventEagerUnpackingOfOutput === false) {
            var unpacked = this.unpackTensor(output);
            this.disposeIntermediateTensorInfo(output);
            return unpacked;
          }
          return output;
        };
        MathBackendWebGL2.prototype.compileAndRun = function(program, inputs, outputDtype, customUniformValues, preventEagerUnpackingOfOutput) {
          if (preventEagerUnpackingOfOutput === void 0) {
            preventEagerUnpackingOfOutput = false;
          }
          outputDtype = outputDtype || inputs[0].dtype;
          var outInfo = this.runWebGLProgram(program, inputs, outputDtype, customUniformValues, preventEagerUnpackingOfOutput);
          return outInfo;
        };
        MathBackendWebGL2.prototype.getAndSaveBinary = function(key, getBinary) {
          if (!(key in this.binaryCache)) {
            this.binaryCache[key] = getBinary();
          }
          return this.binaryCache[key];
        };
        MathBackendWebGL2.prototype.getTextureManager = function() {
          return this.textureManager;
        };
        MathBackendWebGL2.prototype.dispose = function() {
          var _this = this;
          if (this.disposed) {
            return;
          }
          if (!tf.env().getBool("IS_TEST")) {
            var allKeys = Object.keys(this.binaryCache);
            allKeys.forEach(function(key) {
              _this.gpgpu.deleteProgram(_this.binaryCache[key].webGLProgram);
              delete _this.binaryCache[key];
            });
          }
          this.textureManager.dispose();
          if (this.canvas != null && (typeof HTMLCanvasElement !== "undefined" && this.canvas instanceof HTMLCanvasElement)) {
            this.canvas.remove();
          } else {
            this.canvas = null;
          }
          if (this.gpgpuCreatedLocally) {
            this.gpgpu.program = null;
            this.gpgpu.dispose();
          }
          this.disposed = true;
        };
        MathBackendWebGL2.prototype.floatPrecision = function() {
          var _this = this;
          if (this.floatPrecisionValue == null) {
            this.floatPrecisionValue = tf.tidy(function() {
              if (!tf.env().get("WEBGL_RENDER_FLOAT32_ENABLED")) {
                var debugFlag = tf.env().getBool("DEBUG");
                tf.env().set("DEBUG", false);
                var underflowCheckValue = _this.abs(tf.scalar(1e-8)).dataSync()[0];
                tf.env().set("DEBUG", debugFlag);
                if (underflowCheckValue > 0) {
                  return 32;
                }
              }
              return 16;
            });
          }
          return this.floatPrecisionValue;
        };
        MathBackendWebGL2.prototype.epsilon = function() {
          return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;
        };
        MathBackendWebGL2.prototype.uploadToGPU = function(dataId) {
          var _b;
          var texData = this.texData.get(dataId);
          var shape = texData.shape, dtype = texData.dtype, values = texData.values, texture = texData.texture, usage = texData.usage, isPacked = texData.isPacked;
          if (texture != null) {
            return;
          }
          var shouldTimeProgram = this.activeTimers != null;
          var start;
          if (shouldTimeProgram) {
            start = tf.util.now();
          }
          var texShape = texData.texShape;
          if (texShape == null) {
            texShape = getTextureShapeFromLogicalShape(shape, isPacked);
            texData.texShape = texShape;
          }
          if (values != null) {
            var shapeAs3D = getShapeAs3D(shape);
            var program = void 0;
            var width = texShape[1], height = texShape[0];
            var isByteArray = values instanceof Uint8Array || values instanceof Uint8ClampedArray;
            if (isPacked || !isByteArray) {
              _b = __read(getPackedMatrixTextureShapeWidthHeight(texShape[0], texShape[1]), 2), width = _b[0], height = _b[1];
            }
            if (isPacked) {
              program = new EncodeMatrixPackedProgram(shapeAs3D, isByteArray);
            } else {
              program = new EncodeMatrixProgram(shapeAs3D, isByteArray);
            }
            var tempDenseInputTexShape = isByteArray ? [height, width] : texShape;
            var tempDenseInputHandle = this.makeTensorInfo(tempDenseInputTexShape, dtype);
            var tempDenseInputTexData = this.texData.get(tempDenseInputHandle.dataId);
            if (isByteArray) {
              tempDenseInputTexData.usage = TextureUsage.PIXELS;
            } else {
              tempDenseInputTexData.usage = TextureUsage.UPLOAD;
            }
            tempDenseInputTexData.texShape = tempDenseInputTexShape;
            this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(tempDenseInputHandle.dataId), width, height, values);
            var customValues = [[height, width]];
            var preventEagerUnpacking = true;
            var encodedOutputTarget = this.runWebGLProgram(program, [tempDenseInputHandle], dtype, customValues, preventEagerUnpacking);
            var outputTexData = this.texData.get(encodedOutputTarget.dataId);
            texData.texShape = outputTexData.texShape;
            texData.isPacked = outputTexData.isPacked;
            texData.usage = outputTexData.usage;
            if (!tf.env().get("ENGINE_COMPILE_ONLY")) {
              texData.texture = outputTexData.texture;
              texData.values = null;
              this.texData.delete(encodedOutputTarget.dataId);
            } else {
              this.disposeData(encodedOutputTarget.dataId);
            }
            this.disposeIntermediateTensorInfo(tempDenseInputHandle);
            if (shouldTimeProgram) {
              this.uploadWaitMs += tf.util.now() - start;
            }
          } else {
            var newTexture = this.acquireTexture(texShape, usage, dtype, isPacked);
            texData.texture = newTexture;
          }
        };
        MathBackendWebGL2.prototype.convertAndCacheOnCPU = function(dataId, float32Values) {
          var texData = this.texData.get(dataId);
          var dtype = texData.dtype;
          if (float32Values != null) {
            texData.values = float32ToTypedArray(float32Values, dtype);
          }
          return texData.values;
        };
        MathBackendWebGL2.prototype.acquireTexture = function(texShape, texType, dtype, isPacked) {
          this.numBytesInGPU += this.computeBytes(texShape, dtype);
          if (!this.warnedAboutMemory && this.numBytesInGPU > this.numMBBeforeWarning * 1024 * 1024) {
            var mb = (this.numBytesInGPU / 1024 / 1024).toFixed(2);
            this.warnedAboutMemory = true;
            console.warn("High memory usage in GPU: ".concat(mb, " MB, ") + "most likely due to a memory leak");
          }
          return this.textureManager.acquireTexture(texShape, texType, isPacked);
        };
        MathBackendWebGL2.prototype.computeBytes = function(shape, dtype) {
          return shape[0] * shape[1] * tf.util.bytesPerElement(dtype);
        };
        MathBackendWebGL2.prototype.checkCompileCompletion = function() {
          var e_12, _b;
          try {
            for (var _c = __values(Object.entries(this.binaryCache)), _d = _c.next(); !_d.done; _d = _c.next()) {
              var _e = __read(_d.value, 2), binary = _e[1];
              this.checkCompletion_(binary);
            }
          } catch (e_1_1) {
            e_12 = { error: e_1_1 };
          } finally {
            try {
              if (_d && !_d.done && (_b = _c.return))
                _b.call(_c);
            } finally {
              if (e_12)
                throw e_12.error;
            }
          }
        };
        MathBackendWebGL2.prototype.checkCompileCompletionAsync = function() {
          return __awaiter(this, void 0, void 0, function() {
            var ps, _b, _c, _d, binary, _loop_1, _e, _f, _g, binary;
            var e_2, _h, e_3, _j;
            var _this = this;
            return __generator(this, function(_k) {
              ps = [];
              if (this.gpgpu.parallelCompilationExtension) {
                try {
                  for (_b = __values(Object.entries(this.binaryCache)), _c = _b.next(); !_c.done; _c = _b.next()) {
                    _d = __read(_c.value, 2), binary = _d[1];
                    ps.push(this.checkCompletionAsync_(binary));
                  }
                } catch (e_2_1) {
                  e_2 = { error: e_2_1 };
                } finally {
                  try {
                    if (_c && !_c.done && (_h = _b.return))
                      _h.call(_b);
                  } finally {
                    if (e_2)
                      throw e_2.error;
                  }
                }
                return [2, Promise.all(ps)];
              } else {
                _loop_1 = function(binary2) {
                  var p = new Promise(function(resolve) {
                    try {
                      _this.checkCompletion_(binary2);
                      resolve(true);
                    } catch (error) {
                      throw error;
                    }
                  });
                  ps.push(p);
                };
                try {
                  for (_e = __values(Object.entries(this.binaryCache)), _f = _e.next(); !_f.done; _f = _e.next()) {
                    _g = __read(_f.value, 2), binary = _g[1];
                    _loop_1(binary);
                  }
                } catch (e_3_1) {
                  e_3 = { error: e_3_1 };
                } finally {
                  try {
                    if (_f && !_f.done && (_j = _e.return))
                      _j.call(_e);
                  } finally {
                    if (e_3)
                      throw e_3.error;
                  }
                }
                return [2, Promise.all(ps)];
              }
            });
          });
        };
        MathBackendWebGL2.prototype.checkCompletionAsync_ = function(binary) {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  if (!this.gpgpu.gl.getProgramParameter(binary.webGLProgram, this.gpgpu.parallelCompilationExtension.COMPLETION_STATUS_KHR))
                    return [3, 1];
                  return [2, this.checkCompletion_(binary)];
                case 1:
                  return [4, tf.nextFrame()];
                case 2:
                  _b.sent();
                  return [2, this.checkCompletionAsync_(binary)];
              }
            });
          });
        };
        MathBackendWebGL2.prototype.checkCompletion_ = function(binary) {
          if (this.gpgpu.gl.getProgramParameter(binary.webGLProgram, this.gpgpu.gl.LINK_STATUS) === false) {
            console.log(this.gpgpu.gl.getProgramInfoLog(binary.webGLProgram));
            if (this.gpgpu.gl.getShaderParameter(binary.fragmentShader, this.gpgpu.gl.COMPILE_STATUS) === false) {
              logShaderSourceAndInfoLog(binary.source, this.gpgpu.gl.getShaderInfoLog(binary.fragmentShader));
              throw new Error("Failed to compile fragment shader.");
            }
            throw new Error("Failed to link vertex and fragment shaders.");
          }
          return true;
        };
        MathBackendWebGL2.prototype.getUniformLocations = function() {
          var e_4, _b;
          try {
            for (var _c = __values(Object.values(this.binaryCache)), _d = _c.next(); !_d.done; _d = _c.next()) {
              var binary = _d.value;
              this.gpgpu.buildVao(binary.webGLProgram);
              var _e = getUniformLocations(this.gpgpu, binary.program, binary.webGLProgram), variablesLocations = _e.variablesLocations, customUniformLocations = _e.customUniformLocations, infLoc = _e.infLoc, nanLoc = _e.nanLoc, outShapeLocation = _e.outShapeLocation, outShapeStridesLocation = _e.outShapeStridesLocation, outTexShapeLocation = _e.outTexShapeLocation;
              binary.variablesLocations = variablesLocations;
              binary.customUniformLocations = customUniformLocations;
              binary.infLoc = infLoc;
              binary.nanLoc = nanLoc;
              binary.outShapeLocation = outShapeLocation;
              binary.outShapeStridesLocation = outShapeStridesLocation;
              binary.outTexShapeLocation = outTexShapeLocation;
            }
          } catch (e_4_1) {
            e_4 = { error: e_4_1 };
          } finally {
            try {
              if (_d && !_d.done && (_b = _c.return))
                _b.call(_c);
            } finally {
              if (e_4)
                throw e_4.error;
            }
          }
        };
        MathBackendWebGL2.prototype.createTensorFromGPUData = function(values, shape, dtype) {
          values.channels = values.channels || "RGBA";
          var texture = values.texture, height = values.height, width = values.width, channels = values.channels;
          var backend = tf.engine().backend;
          if (!backend.gpgpu.gl.isTexture(texture)) {
            throw new Error("The texture is invalid. Also, please make sure the texture and the TFJS WebGL backend are using the same canvas. If you want to use your own custom canvas, you have to create and use the custom TFJS WebGL backend created from the canvas through 'new tf.MathBackendWebGL(customCanvas)'.");
          }
          var dataId = backend.writeTexture(texture, shape, dtype, height, width, channels);
          return tf.engine().makeTensorFromDataId(dataId, shape, dtype, backend);
        };
        return MathBackendWebGL2;
      }(tf.KernelBackend)
    );
    MathBackendWebGL.nextDataId = 0;
    function float32ToTypedArray(a, dtype) {
      if (dtype === "float32" || dtype === "complex64") {
        return a;
      } else if (dtype === "int32" || dtype === "bool") {
        var result = dtype === "int32" ? new Int32Array(a.length) : new Uint8Array(a.length);
        for (var i = 0; i < result.length; ++i) {
          result[i] = Math.round(a[i]);
        }
        return result;
      } else {
        throw new Error("Unknown dtype ".concat(dtype));
      }
    }
    var version = "4.15.0";
    function forceHalfFloat() {
      tf.env().set("WEBGL_FORCE_F16_TEXTURES", true);
    }
    if (tf.device_util.isBrowser()) {
      tf.registerBackend(
        "webgl",
        function() {
          return new MathBackendWebGL();
        },
        2
        /* priority */
      );
    }
    var webgl = { forceHalfFloat };
    var CHECK_NAN_SNIPPET = "\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n";
    var BinaryOpProgram = (
      /** @class */
      function() {
        function BinaryOpProgram2(op, aShape, bShape) {
          this.variableNames = ["A", "B"];
          this.outputShape = tf.backend_util.assertAndGetBroadcastShape(aShape, bShape);
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          this.userCode = "\n      float binaryOperation(float a, float b) {\n        ".concat(op, "\n      }\n\n      void main() {\n        float a = getAAtOutCoords();\n        float b = getBAtOutCoords();\n        setOutput(binaryOperation(a, b));\n      }\n    ");
        }
        return BinaryOpProgram2;
      }()
    );
    var CHECK_NAN_SNIPPET_PACKED = "\n  result.r = isNaN.r ? NAN : result.r;\n  result.g = isNaN.g ? NAN : result.g;\n  result.b = isNaN.b ? NAN : result.b;\n  result.a = isNaN.a ? NAN : result.a;\n";
    var BinaryOpPackedProgram = (
      /** @class */
      function() {
        function BinaryOpPackedProgram2(op, aShape, bShape, checkOutOfBounds) {
          if (checkOutOfBounds === void 0) {
            checkOutOfBounds = false;
          }
          this.variableNames = ["A", "B"];
          this.supportsBroadcasting = true;
          this.packedInputs = true;
          this.packedOutput = true;
          this.outputShape = tf.backend_util.assertAndGetBroadcastShape(aShape, bShape);
          var rank = this.outputShape.length;
          this.enableShapeUniforms = useShapeUniforms(rank);
          var checkOutOfBoundsString = "";
          if (checkOutOfBounds) {
            if (rank === 0 || tf.util.sizeFromShape(this.outputShape) === 1) {
              checkOutOfBoundsString = "\n          result.y = 0.;\n          result.z = 0.;\n          result.w = 0.;\n        ";
            } else {
              var dtype = getCoordsDataType(rank);
              checkOutOfBoundsString = "\n          ".concat(dtype, " coords = getOutputCoords();\n        ");
              if (rank === 1) {
                if (this.enableShapeUniforms) {
                  checkOutOfBoundsString += "\n            result.y = (coords + 1) >= outShape ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          ";
                } else {
                  checkOutOfBoundsString += "\n            result.y = (coords + 1) >= ".concat(this.outputShape[0], " ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          ");
                }
              } else {
                var channels = getChannels("coords", rank);
                if (this.enableShapeUniforms) {
                  checkOutOfBoundsString += "\n            bool nextRowOutOfBounds =\n              (".concat(channels[rank - 2], " + 1) >= outShape[").concat(rank, " - 2];\n            bool nextColOutOfBounds =\n              (").concat(channels[rank - 1], " + 1) >= outShape[").concat(rank, " - 1];\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          ");
                } else {
                  checkOutOfBoundsString += "\n            bool nextRowOutOfBounds =\n              (".concat(channels[rank - 2], " + 1) >= ").concat(this.outputShape[rank - 2], ";\n            bool nextColOutOfBounds =\n              (").concat(channels[rank - 1], " + 1) >= ").concat(this.outputShape[rank - 1], ";\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          ");
                }
              }
            }
          }
          this.userCode = "\n      vec4 binaryOperation(vec4 a, vec4 b) {\n        ".concat(op, "\n      }\n\n      void main() {\n        vec4 a = getAAtOutCoords();\n        vec4 b = getBAtOutCoords();\n\n        vec4 result = binaryOperation(a, b);\n        ").concat(checkOutOfBoundsString, "\n\n        setOutput(result);\n      }\n    ");
        }
        return BinaryOpPackedProgram2;
      }()
    );
    function identity(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x;
      backend.incRef(x.dataId);
      return { dataId: x.dataId, shape: x.shape, dtype: x.dtype };
    }
    var identityConfig = {
      kernelName: tf.Identity,
      backendName: "webgl",
      kernelFunc: identity
    };
    function complex(args) {
      var inputs = args.inputs, backend = args.backend;
      var real2 = inputs.real, imag2 = inputs.imag;
      var complexInfo = backend.makeTensorInfo(real2.shape, "complex64");
      var complex2 = backend.texData.get(complexInfo.dataId);
      var realTensorInfo = identity({ inputs: { x: real2 }, backend });
      var imagTensorInfo = identity({ inputs: { x: imag2 }, backend });
      complex2.complexTensorInfos = { real: realTensorInfo, imag: imagTensorInfo };
      return complexInfo;
    }
    var complexConfig = {
      kernelName: tf.Complex,
      backendName: "webgl",
      kernelFunc: complex
    };
    var LEAKYRELU = "return (a < 0.) ? b * a : a;";
    var LEAKYRELU_PACKED = "\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";
    function leakyRelu(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var alpha = attrs.alpha;
      var $alpha = backend.makeTensorInfo([], "float32", tf.util.createScalarValue(alpha, "float32"));
      var program = tf.env().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(LEAKYRELU_PACKED, x.shape, $alpha.shape) : new BinaryOpProgram(LEAKYRELU, x.shape, $alpha.shape);
      var result = backend.runWebGLProgram(program, [x, $alpha], "float32");
      backend.disposeIntermediateTensorInfo($alpha);
      return result;
    }
    var leakyReluConfig = {
      kernelName: tf.LeakyRelu,
      backendName: "webgl",
      kernelFunc: leakyRelu
    };
    var PRELU = "return (a < 0.) ? b * a : a;";
    var PRELU_PACKED = "\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";
    function prelu(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x, alpha = inputs.alpha;
      var program = tf.env().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(PRELU_PACKED, x.shape, alpha.shape) : new BinaryOpProgram(PRELU, x.shape, alpha.shape);
      return backend.runWebGLProgram(program, [x, alpha], "float32");
    }
    var preluConfig = {
      kernelName: tf.Prelu,
      backendName: "webgl",
      kernelFunc: prelu
    };
    var CHECK_NAN_SNIPPET_UNARY = "if (isnan(x)) return x;";
    function unaryKernelFunc(_a2) {
      var opSnippet = _a2.opSnippet, packedOpSnippet = _a2.packedOpSnippet, cpuKernelImpl = _a2.cpuKernelImpl, dtype = _a2.dtype;
      return function(_a3) {
        var inputs = _a3.inputs, backend = _a3.backend;
        var x = inputs.x;
        var webglBackend = backend;
        var $dtype = dtype || x.dtype;
        if (webglBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {
          var xData = webglBackend.texData.get(x.dataId);
          var outValues = cpuKernelImpl(xData.values, $dtype);
          return webglBackend.makeTensorInfo(x.shape, $dtype, outValues);
        }
        var shouldUsePackedProgram = tf.env().getBool("WEBGL_PACK_UNARY_OPERATIONS") && packedOpSnippet != null;
        var program;
        if (shouldUsePackedProgram) {
          program = new UnaryOpPackedProgram(x.shape, packedOpSnippet);
        } else {
          program = new UnaryOpProgram(x.shape, opSnippet);
        }
        return webglBackend.runWebGLProgram(program, [x], $dtype);
      };
    }
    function binaryKernelFunc(_a2) {
      var opSnippet = _a2.opSnippet, packedOpSnippet = _a2.packedOpSnippet, _b = _a2.checkOutOfBounds, checkOutOfBounds = _b === void 0 ? false : _b, _c = _a2.supportsComplex, supportsComplex = _c === void 0 ? false : _c, cpuKernelImpl = _a2.cpuKernelImpl, dtype = _a2.dtype;
      return function(_a3) {
        var inputs = _a3.inputs, backend = _a3.backend;
        var a = inputs.a, b = inputs.b;
        var webglBackend = backend;
        if (supportsComplex && a.dtype === "complex64") {
          var aData = webglBackend.texData.get(a.dataId);
          var bData = webglBackend.texData.get(b.dataId);
          var _b2 = __read([
            [aData.complexTensorInfos.real, bData.complexTensorInfos.real],
            [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]
          ].map(function(complexParts) {
            var _a4 = __read(complexParts, 2), aPart = _a4[0], bPart = _a4[1];
            var aHandle = {
              dataId: aPart.dataId,
              dtype: aPart.dtype,
              shape: a.shape
            };
            var bHandle = {
              dataId: bPart.dataId,
              dtype: bPart.dtype,
              shape: b.shape
            };
            var program2 = new BinaryOpProgram(opSnippet, a.shape, b.shape);
            return webglBackend.runWebGLProgram(program2, [aHandle, bHandle], tf.upcastType(aPart.dtype, bPart.dtype));
          }), 2), real2 = _b2[0], imag2 = _b2[1];
          var complexOutput = complex({ inputs: { real: real2, imag: imag2 }, backend: webglBackend });
          webglBackend.disposeIntermediateTensorInfo(real2);
          webglBackend.disposeIntermediateTensorInfo(imag2);
          return complexOutput;
        }
        var $dtype = dtype || tf.upcastType(a.dtype, b.dtype);
        if ((a.dtype === "string" || b.dtype === "string" || webglBackend.shouldExecuteOnCPU([a, b])) && cpuKernelImpl != null) {
          var aVals = webglBackend.texData.get(a.dataId).values;
          var bVals = webglBackend.texData.get(b.dataId).values;
          var decodedAVals = a.dtype === "string" ? (
            // tslint:disable-next-line: no-any
            tf.backend_util.fromUint8ToStringArray(aVals)
          ) : aVals;
          var decodedBVals = a.dtype === "string" ? (
            // tslint:disable-next-line: no-any
            tf.backend_util.fromUint8ToStringArray(bVals)
          ) : bVals;
          var _c2 = __read(cpuKernelImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype), 2), outValues = _c2[0], outShape = _c2[1];
          var out = webglBackend.makeTensorInfo(outShape, $dtype);
          var outData = webglBackend.texData.get(out.dataId);
          outData.values = outValues;
          return out;
        }
        var shouldUsePackedProgram = tf.env().getBool("WEBGL_PACK_BINARY_OPERATIONS") && packedOpSnippet != null;
        var program;
        if (shouldUsePackedProgram) {
          program = new BinaryOpPackedProgram(packedOpSnippet, a.shape, b.shape, checkOutOfBounds);
        } else {
          program = new BinaryOpProgram(opSnippet, a.shape, b.shape);
        }
        return webglBackend.runWebGLProgram(program, [a, b], $dtype);
      };
    }
    function mapActivationToShaderProgram(activation, packed) {
      if (packed === void 0) {
        packed = false;
      }
      if (activation === "linear") {
        if (packed) {
          return LINEAR;
        }
        return LINEAR$1;
      } else if (activation === "relu") {
        if (packed) {
          return RELU$1;
        }
        return RELU$2;
      } else if (activation === "elu") {
        if (packed) {
          return ELU$1;
        }
        return ELU$2;
      } else if (activation === "relu6") {
        if (packed) {
          return RELU6$1;
        }
        return RELU6$2;
      } else if (activation === "prelu") {
        if (packed) {
          return PRELU_PACKED;
        }
        return PRELU;
      } else if (activation === "leakyrelu") {
        if (packed) {
          return LEAKYRELU_PACKED;
        }
        return LEAKYRELU;
      } else if (activation === "sigmoid") {
        if (packed) {
          return SIGMOID$1;
        }
        return SIGMOID$2;
      }
      throw new Error("Activation ".concat(activation, " has not been implemented for the WebGL backend."));
    }
    var MatMulPackedProgram = (
      /** @class */
      function() {
        function MatMulPackedProgram2(aShape, bShape, outputShape, transposeA, transposeB, addBias, activation, hasPreluActivation, hasLeakyreluActivation) {
          if (transposeA === void 0) {
            transposeA = false;
          }
          if (transposeB === void 0) {
            transposeB = false;
          }
          if (addBias === void 0) {
            addBias = false;
          }
          if (activation === void 0) {
            activation = null;
          }
          if (hasPreluActivation === void 0) {
            hasPreluActivation = false;
          }
          if (hasLeakyreluActivation === void 0) {
            hasLeakyreluActivation = false;
          }
          this.variableNames = ["matrixA", "matrixB"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.outputShape = outputShape;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          var sharedDim = transposeA ? aShape[1] : aShape[2];
          var sharedDimensionPacked = Math.ceil(sharedDim / 2);
          var aSample = transposeA ? "i * 2, rc.y" : "rc.y, i * 2";
          var bSample = transposeB ? "rc.z, i * 2" : "i * 2, rc.z";
          var aSwizzle = transposeA ? ["a.xxyy", "a.zzww"] : ["a.xxzz", "a.yyww"];
          var bSwizzle = transposeB ? ["b.xzxz", "b.ywyw"] : ["b.xyxy", "b.zwzw"];
          var activationSnippet = "", applyActivationSnippet = "";
          if (activation) {
            if (hasPreluActivation) {
              activationSnippet = "vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ".concat(activation, "\n        }");
            } else if (hasLeakyreluActivation) {
              activationSnippet = "vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ".concat(activation, "\n        }");
            } else {
              activationSnippet = "vec4 activation(vec4 x) {\n          ".concat(activation, "\n        }");
            }
            applyActivationSnippet = "result = activation(result);";
          }
          var addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
          if (addBias) {
            this.variableNames.push("bias");
          }
          if (hasPreluActivation) {
            this.variableNames.push("preluActivationWeights");
          }
          if (hasLeakyreluActivation) {
            this.variableNames.push("leakyreluAlpha");
          }
          var batchASnippet = "rc.x";
          var batchBSnippet = "rc.x";
          if (aShape[0] < bShape[0]) {
            batchASnippet = "imod(rc.x, ".concat(aShape[0], ")");
          } else if (bShape[0] < aShape[0]) {
            batchBSnippet = "imod(rc.x, ".concat(bShape[0], ")");
          }
          this.userCode = "\n      ".concat(activationSnippet, "\n      // Don't use uniform for sharedDimensionPacked for performance.\n      const float sharedDimension = ").concat(sharedDimensionPacked, ".0;\n\n      vec4 dot2x2ARowBCol(ivec3 rc) {\n        vec4 result = vec4(0);\n        int batchA = ").concat(batchASnippet, ";\n        int batchB = ").concat(batchBSnippet, ";\n        for (int i = 0; i < ").concat(sharedDimensionPacked, "; i++) {\n          vec4 a = getMatrixA(batchA, ").concat(aSample, ");\n          vec4 b = getMatrixB(batchB, ").concat(bSample, ");\n\n          // These swizzled products need to be separately added.\n          // See: https://github.com/tensorflow/tfjs/issues/1735\n          result += (").concat(aSwizzle[0], " * ").concat(bSwizzle[0], ");\n          result += (").concat(aSwizzle[1], " * ").concat(bSwizzle[1], ");\n        }\n        return result;\n      }\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n        vec4 result = dot2x2ARowBCol(rc);\n\n        ").concat(addBiasSnippet, "\n\n        ").concat(applyActivationSnippet, "\n\n        setOutput(result);\n      }\n    ");
        }
        return MatMulPackedProgram2;
      }()
    );
    var COMPLEX_MULTIPLY = {
      REAL: "return areal * breal - aimag * bimag;",
      IMAG: "return areal * bimag + aimag * breal;"
    };
    var BinaryOpComplexProgram = (
      /** @class */
      function() {
        function BinaryOpComplexProgram2(op, aShape, bShape) {
          this.variableNames = ["AReal", "AImag", "BReal", "BImag"];
          this.outputShape = tf.backend_util.assertAndGetBroadcastShape(aShape, bShape);
          this.userCode = "\n      float binaryOpComplex(\n          float areal, float aimag, float breal, float bimag) {\n        ".concat(op, "\n      }\n\n      void main() {\n        float areal = getARealAtOutCoords();\n        float aimag = getAImagAtOutCoords();\n        float breal = getBRealAtOutCoords();\n        float bimag = getBImagAtOutCoords();\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\n      }\n    ");
        }
        return BinaryOpComplexProgram2;
      }()
    );
    var MUL = "return a * b;";
    function multiply(args) {
      var inputs = args.inputs, backend = args.backend;
      var a = inputs.a, b = inputs.b;
      var dtype = tf.backend_util.upcastType(a.dtype, b.dtype);
      if (a.dtype === "complex64") {
        var aData = backend.texData.get(a.dataId);
        var bData = backend.texData.get(b.dataId);
        var realProgram = new BinaryOpComplexProgram(COMPLEX_MULTIPLY.REAL, a.shape, b.shape);
        var imagProgram = new BinaryOpComplexProgram(COMPLEX_MULTIPLY.IMAG, a.shape, b.shape);
        var inputs_1 = [
          {
            dataId: aData.complexTensorInfos.real.dataId,
            dtype: aData.complexTensorInfos.real.dtype,
            shape: a.shape
          },
          {
            dataId: aData.complexTensorInfos.imag.dataId,
            dtype: aData.complexTensorInfos.imag.dtype,
            shape: a.shape
          },
          {
            dataId: bData.complexTensorInfos.real.dataId,
            dtype: bData.complexTensorInfos.real.dtype,
            shape: b.shape
          },
          {
            dataId: bData.complexTensorInfos.imag.dataId,
            dtype: bData.complexTensorInfos.imag.dtype,
            shape: b.shape
          }
        ];
        var realPart = backend.runWebGLProgram(realProgram, inputs_1, "float32");
        var imagPart = backend.runWebGLProgram(imagProgram, inputs_1, "float32");
        var complexOutput = complex({ inputs: { real: realPart, imag: imagPart }, backend });
        backend.disposeIntermediateTensorInfo(realPart);
        backend.disposeIntermediateTensorInfo(imagPart);
        return complexOutput;
      }
      if (backend.shouldExecuteOnCPU([a, b])) {
        var aData = backend.texData.get(a.dataId);
        var bData = backend.texData.get(b.dataId);
        var _a2 = __read(multiplyImplCPU(a.shape, b.shape, aData.values, bData.values, dtype), 2), outValues = _a2[0], outShape = _a2[1];
        var out = backend.makeTensorInfo(outShape, dtype);
        var outData = backend.texData.get(out.dataId);
        outData.values = outValues;
        return out;
      }
      var program;
      if (tf.env().getBool("WEBGL_PACK_BINARY_OPERATIONS")) {
        program = new BinaryOpPackedProgram(MUL, a.shape, b.shape);
      } else {
        program = new BinaryOpProgram(MUL, a.shape, b.shape);
      }
      return backend.runWebGLProgram(program, [a, b], dtype);
    }
    var multiplyConfig = {
      kernelName: tf.Multiply,
      backendName: "webgl",
      kernelFunc: multiply
    };
    function packedReshape(input, afterShape, backend) {
      var input3DShape = __spreadArray([getBatchDim(input.shape)], __read(getRowsCols(input.shape)), false);
      var input3D = {
        dtype: input.dtype,
        shape: input3DShape,
        dataId: input.dataId
      };
      var afterShapeAs3D = __spreadArray([getBatchDim(afterShape)], __read(getRowsCols(afterShape)), false);
      var program = new ReshapePackedProgram(afterShapeAs3D, input3DShape);
      var preventEagerUnpackingOfOutput = true;
      var customValues = [input3DShape];
      var output = backend.runWebGLProgram(program, [input3D], input.dtype, customValues, preventEagerUnpackingOfOutput);
      return { dataId: output.dataId, shape: afterShape, dtype: output.dtype };
    }
    function reshape(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var shape = attrs.shape;
      var webglBackend = backend;
      var xSize = tf.util.sizeFromShape(x.shape);
      var $shape = tf.util.inferFromImplicitShape(shape, xSize);
      var $xSize = tf.util.sizeFromShape($shape);
      tf.util.assert(xSize === $xSize, function() {
        return "The new shape (".concat($shape, ") has ").concat($xSize, " elements and the old ") + "shape (".concat(x.shape, ") has ").concat(xSize, " elements. The new shape and old ") + "shape must have the same number of elements.";
      });
      var xTexData = webglBackend.texData.get(x.dataId);
      if (xTexData.isPacked && !isReshapeFree(x.shape, $shape) && !(xTexData.texture !== null && isReshapeFree(xTexData.shape, $shape))) {
        return packedReshape(x, $shape, webglBackend);
      }
      webglBackend.incRef(x.dataId);
      return { dataId: x.dataId, shape: $shape, dtype: x.dtype };
    }
    var reshapeConfig = {
      kernelName: tf.Reshape,
      backendName: "webgl",
      kernelFunc: reshape
    };
    var MeanProgram = (
      /** @class */
      function() {
        function MeanProgram2(reduceInfo, divisor) {
          this.variableNames = ["x"];
          var windowSize = reduceInfo.windowSize, batchSize = reduceInfo.batchSize, inSize = reduceInfo.inSize, outSize = reduceInfo.outSize;
          this.outputShape = [batchSize, outSize];
          var windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;
          var windowSizeVec4Remainder = windowSize % 4;
          var updateSnippet = "sumValue += dot(values, ones);";
          if (divisor != null) {
            var denominator = 1 / divisor;
            updateSnippet = "sumValue += dot(values * ".concat(tf.util.isInt(denominator) ? denominator.toPrecision(2) : denominator, ", ones);");
          }
          var checkOutOfBounds = "";
          if (inSize % windowSize > 0) {
            checkOutOfBounds = "\n        if (inIdx < 0 || inIdx >= ".concat(inSize, ") {\n          return 0.0;\n        }\n      ");
          }
          this.userCode = "\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ".concat(checkOutOfBounds, "\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ").concat(windowSize, ";\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ").concat(windowSizeNearestVec4, "; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ").concat(updateSnippet, "\n        }\n\n        int inIdx = inOffset + ").concat(windowSizeNearestVec4, ";\n        if (").concat(windowSizeVec4Remainder === 1, ") {\n          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);\n\n          ").concat(updateSnippet, "\n        } else if (").concat(windowSizeVec4Remainder === 2, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1), 0.0, 0.0);\n\n          ").concat(updateSnippet, "\n        } else if (").concat(windowSizeVec4Remainder === 3, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2), 0.0);\n\n          ").concat(updateSnippet, "\n        }\n        setOutput(sumValue);\n      }\n    ");
        }
        return MeanProgram2;
      }()
    );
    var ReduceProgram = (
      /** @class */
      function() {
        function ReduceProgram2(reduceInfo, reduceType) {
          this.variableNames = ["x"];
          var windowSize = reduceInfo.windowSize, batchSize = reduceInfo.batchSize, inSize = reduceInfo.inSize, outSize = reduceInfo.outSize;
          this.outputShape = [batchSize, outSize];
          var initializationValue = "0.0";
          var compareOp = "";
          if (reduceType === "prod") {
            initializationValue = "1.0";
          } else if (reduceType === "min") {
            initializationValue = "1.0 / 1e-20";
            compareOp = "min";
          } else if (reduceType === "max") {
            initializationValue = "-1.0 / 1e-20";
            compareOp = "max";
          }
          var returnValue = "".concat(reduceType, "(").concat(reduceType, "(").concat(reduceType, "(") + "minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])";
          if (reduceType === "sum") {
            returnValue = "sumValue";
          } else if (reduceType === "prod") {
            returnValue = "prodValue";
          } else if (reduceType === "all") {
            returnValue = "allValue";
          } else if (reduceType === "any") {
            returnValue = "anyValue";
          }
          var windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;
          var windowSizeVec4Remainder = windowSize % 4;
          var updateSnippet = "\n      if (".concat(reduceType === "sum", ") {\n        sumValue += dot(values, ones);\n      } else if (").concat(reduceType === "prod", ") {\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\n        prodValue *= tmp[0] * tmp[1];\n      } else {\n        minMaxValue = ").concat(compareOp, "(values, minMaxValue);\n        if (").concat(reduceType === "min", " || ").concat(reduceType === "max", ") {\n          minMaxValue = ").concat(compareOp, "(values, minMaxValue);\n          bvec4 isNaN = isnan(values);\n          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {\n            minMaxValue = vec4(NAN);\n          }\n        }\n      }\n    ");
          var vecType = "vec4";
          if (reduceType === "all") {
            initializationValue = "1.0";
            updateSnippet = "\n        bool reducedAllValue = all(values);\n        float floatedReducedAllValue = float(reducedAllValue);\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\n      ";
            vecType = "bvec4";
          } else if (reduceType === "any") {
            initializationValue = "0.0";
            updateSnippet = "\n        bool reducedAnyValue = any(values);\n        float floatedReducedAnyValue = float(reducedAnyValue);\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\n      ";
            vecType = "bvec4";
          }
          var checkOutOfBounds = "";
          if (inSize % windowSize > 0) {
            checkOutOfBounds = "\n        if (inIdx < 0 || inIdx >= ".concat(inSize, ") {\n          return initializationValue;\n        }\n      ");
          }
          this.userCode = "\n      const float initializationValue = ".concat(initializationValue, ";\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ").concat(checkOutOfBounds, "\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ").concat(windowSize, ";\n\n        vec4 minMaxValue = vec4(").concat(initializationValue, ");\n        float prodValue = 1.0;\n        float sumValue = 0.0;\n        float allValue = 1.0;\n        float anyValue = 0.0;\n\n        for (int i = 0; i < ").concat(windowSizeNearestVec4, "; i += 4) {\n          int inIdx = inOffset + i;\n          ").concat(vecType, " values = ").concat(vecType, "(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ").concat(updateSnippet, "\n        }\n\n        int inIdx = inOffset + ").concat(windowSizeNearestVec4, ";\n        if (").concat(windowSizeVec4Remainder === 1, ") {\n          ").concat(vecType, " values = ").concat(vecType, "(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          ").concat(updateSnippet, "\n        } else if (").concat(windowSizeVec4Remainder === 2, ") {\n          ").concat(vecType, " values = ").concat(vecType, "(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          ").concat(updateSnippet, "\n        } else if (").concat(windowSizeVec4Remainder === 3, ") {\n          ").concat(vecType, " values = ").concat(vecType, "(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          ").concat(updateSnippet, "\n        }\n        setOutput(").concat(returnValue, ");\n      }\n    ");
        }
        return ReduceProgram2;
      }()
    );
    function getReductionStages(inShape) {
      var stages = [];
      while (stages.length === 0 || stages[stages.length - 1].outSize !== 1) {
        var outSize = stages.length ? stages[stages.length - 1].outSize : inShape[1];
        var windowSize = tf.backend_util.computeOptimalWindowSize(outSize);
        stages.push({
          inSize: outSize,
          windowSize,
          outSize: Math.ceil(outSize / windowSize)
        });
      }
      return stages;
    }
    function reduce(x, dtype, reductionType, backend) {
      var reductionStages = getReductionStages(x.shape);
      var result = x;
      for (var i = 0; i < reductionStages.length; i++) {
        var _a2 = reductionStages[i], inSize = _a2.inSize, windowSize = _a2.windowSize, outSize = _a2.outSize;
        var program = void 0;
        var previousResult = void 0;
        if (reductionType === "mean") {
          program = i === 0 ? new MeanProgram({ windowSize, inSize, batchSize: x.shape[0], outSize }, inSize) : new MeanProgram({ windowSize, inSize, batchSize: x.shape[0], outSize });
        } else {
          program = new ReduceProgram({ windowSize, inSize, batchSize: x.shape[0], outSize }, reductionType);
        }
        previousResult = result;
        result = backend.runWebGLProgram(program, [result], dtype);
        if (previousResult.dataId !== x.dataId) {
          backend.disposeIntermediateTensorInfo(previousResult);
        }
      }
      return result;
    }
    var TransposeProgram = (
      /** @class */
      function() {
        function TransposeProgram2(aShape, newDim) {
          this.variableNames = ["A"];
          var outputShape = new Array(aShape.length);
          for (var i = 0; i < outputShape.length; i++) {
            outputShape[i] = aShape[newDim[i]];
          }
          this.outputShape = outputShape;
          this.rank = outputShape.length;
          var dtype = getCoordsDataType(this.rank);
          var switched = getSwitchedCoords(newDim);
          this.userCode = "\n    void main() {\n      ".concat(dtype, " resRC = getOutputCoords();\n      setOutput(getA(").concat(switched, "));\n    }\n    ");
        }
        return TransposeProgram2;
      }()
    );
    function getSwitchedCoords(newDim) {
      var rank = newDim.length;
      if (rank > 6) {
        throw Error("Transpose for rank ".concat(rank, " is not yet supported"));
      }
      var originalOrder = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u", "resRC.v"];
      var switchedCoords = new Array(rank);
      for (var i = 0; i < newDim.length; i++) {
        switchedCoords[newDim[i]] = originalOrder[i];
      }
      return switchedCoords.join();
    }
    var TransposePackedProgram = (
      /** @class */
      function() {
        function TransposePackedProgram2(aShape, newDim) {
          this.variableNames = ["A"];
          this.packedInputs = true;
          this.packedOutput = true;
          var outputShape = new Array(aShape.length);
          for (var i = 0; i < outputShape.length; i++) {
            outputShape[i] = aShape[newDim[i]];
          }
          this.outputShape = outputShape;
          this.rank = outputShape.length;
          if (this.rank > 6) {
            throw Error("Packed transpose for rank ".concat(this.rank, " is not yet supported."));
          }
          var dtype = getCoordsDataType(this.rank);
          var outputOrder = getVecChannels("rc", this.rank);
          var switchedOrder = new Array(this.rank);
          for (var i = 0; i < newDim.length; i++) {
            switchedOrder[newDim[i]] = outputOrder[i];
          }
          var innerDims = "vec2(".concat(switchedOrder.slice(-2).join(), ")");
          var nextColumn = "++".concat(outputOrder[this.rank - 1], " < ").concat(outputShape[this.rank - 1]);
          var getc = "getChannel(getA(".concat(switchedOrder.join(), "), ").concat(innerDims, ")");
          this.userCode = "\n    void main() {\n      ".concat(dtype, " rc = getOutputCoords();\n      vec4 result = vec4(0.);\n      result[0] = ").concat(getc, ";\n      if(").concat(nextColumn, ") {\n        result[1] = ").concat(getc, ";\n      }\n      --").concat(outputOrder[this.rank - 1], ";\n      if(++").concat(outputOrder[this.rank - 2], " < ").concat(outputShape[this.rank - 2], ") {\n        result[2] = ").concat(getc, ";\n        if(").concat(nextColumn, ") {\n          result[3] = ").concat(getc, ";\n        }\n      }\n      setOutput(result);\n    }\n    ");
        }
        return TransposePackedProgram2;
      }()
    );
    function transposeImpl(x, perm, backend) {
      var program = tf.env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new TransposePackedProgram(x.shape, perm) : new TransposeProgram(x.shape, perm);
      return backend.runWebGLProgram(program, [x], x.dtype);
    }
    function sumImpl(x, axis, keepDims, backend) {
      var reductionIndices = axis;
      var xRank = x.shape.length;
      var origAxes = tf.util.parseAxisParam(reductionIndices, x.shape);
      var axes = origAxes;
      var permutedAxes = tf.backend_util.getAxesPermutation(axes, xRank);
      var sumInputIsTransposed = permutedAxes != null;
      var sumInput = x;
      if (sumInputIsTransposed) {
        sumInput = transposeImpl(x, permutedAxes, backend);
        axes = tf.backend_util.getInnerMostAxes(axes.length, xRank);
      }
      tf.backend_util.assertAxesAreInnerMostDims("sum", axes, xRank);
      var _a2 = __read(tf.backend_util.computeOutAndReduceShapes(sumInput.shape, axes), 2), sumOutShape = _a2[0], reduceShape = _a2[1];
      var outShape = sumOutShape;
      if (keepDims) {
        outShape = tf.backend_util.expandShapeToKeepDim(sumOutShape, origAxes);
      }
      var inSize = tf.util.sizeFromShape(reduceShape);
      var xSize = tf.util.sizeFromShape(x.shape);
      var batchSize = xSize / inSize;
      var reshapedInput = reshape({ inputs: { x: sumInput }, attrs: { shape: [batchSize, inSize] }, backend });
      var outType = tf.sumOutType(x.dtype);
      var reduced = reduce(reshapedInput, outType, "sum", backend);
      var out = reshape({ inputs: { x: reduced }, attrs: { shape: outShape }, backend });
      backend.disposeIntermediateTensorInfo(reshapedInput);
      backend.disposeIntermediateTensorInfo(reduced);
      if (sumInputIsTransposed) {
        backend.disposeIntermediateTensorInfo(sumInput);
      }
      return out;
    }
    function sum(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      return sumImpl(x, axis, keepDims, backend);
    }
    var sumConfig = {
      kernelName: tf.Sum,
      backendName: "webgl",
      kernelFunc: sum
    };
    function transpose(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var perm = attrs.perm;
      var webglBackend = backend;
      var xRank = x.shape.length;
      var newShape = new Array(xRank);
      for (var i = 0; i < newShape.length; i++) {
        newShape[i] = x.shape[perm[i]];
      }
      var out;
      if (webglBackend.shouldExecuteOnCPU([x])) {
        var xTexData = webglBackend.texData.get(x.dataId);
        var values = xTexData.values;
        var outValues = transposeImplCPU(values, x.shape, x.dtype, perm, newShape);
        out = webglBackend.makeTensorInfo(newShape, x.dtype);
        var outData = webglBackend.texData.get(out.dataId);
        outData.values = outValues;
      } else {
        out = transposeImpl(x, perm, webglBackend);
      }
      return out;
    }
    var transposeConfig = {
      kernelName: tf.Transpose,
      backendName: "webgl",
      kernelFunc: transpose
    };
    var MATMUL_SHARED_DIM_THRESHOLD = 1e3;
    function batchMatMulImpl(_a2) {
      var e_12, _b;
      var a = _a2.a, b = _a2.b, transposeA = _a2.transposeA, transposeB = _a2.transposeB, backend = _a2.backend, _c = _a2.bias, bias = _c === void 0 ? null : _c, _d = _a2.preluActivationWeights, preluActivationWeights = _d === void 0 ? null : _d, _e = _a2.leakyreluAlpha, leakyreluAlpha = _e === void 0 ? 0 : _e, _f = _a2.activation, activation = _f === void 0 ? null : _f;
      var aRank = a.shape.length;
      var bRank = b.shape.length;
      var innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];
      var innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];
      var outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];
      var outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];
      var outerDimsA = a.shape.slice(0, -2);
      var outerDimsB = b.shape.slice(0, -2);
      var batchDimA = tf.util.sizeFromShape(outerDimsA);
      var batchDimB = tf.util.sizeFromShape(outerDimsB);
      var outShapeOuterDims = tf.broadcast_util.assertAndGetBroadcastShape(a.shape.slice(0, -2), b.shape.slice(0, -2));
      var outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
      tf.util.assert(innerShapeA === innerShapeB, function() {
        return "Error in matMul: inner shapes (".concat(innerShapeA, ") and (") + "".concat(innerShapeB, ") of Tensors with shapes ").concat(a.shape, " and ") + "".concat(b.shape, " and transposeA=").concat(transposeA) + " and transposeB=".concat(transposeB, " must match.");
      });
      var a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];
      var b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB];
      var a3d = reshape({ inputs: { x: a }, backend, attrs: { shape: a3dShape } });
      var b3d = reshape({ inputs: { x: b }, backend, attrs: { shape: b3dShape } });
      var intermediates = [a3d, b3d];
      var batchDim = Math.max(batchDimA, batchDimB);
      var sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];
      var hasBias = bias != null;
      var hasPreluActivationWeights = preluActivationWeights != null;
      var hasLeakyreluAlpha = activation === "leakyrelu";
      var fusedActivation = activation != null ? mapActivationToShaderProgram(activation, true) : null;
      var containsFusedOps = hasBias || hasPreluActivationWeights || hasLeakyreluAlpha || fusedActivation != null;
      var out;
      if ((outerShapeA === 1 || outerShapeB === 1) && sharedDim > MATMUL_SHARED_DIM_THRESHOLD && containsFusedOps === false) {
        var aVec = a3d;
        var bVec = b3d;
        if (transposeA) {
          aVec = transpose({ inputs: { x: a3d }, backend, attrs: { perm: [0, 2, 1] } });
          intermediates.push(aVec);
        }
        if (transposeB) {
          bVec = transpose({ inputs: { x: b3d }, backend, attrs: { perm: [0, 2, 1] } });
          intermediates.push(bVec);
        }
        var shouldReshapeA = outerShapeB !== 1;
        var shouldReshapeB = outerShapeB === 1;
        var aVec3d = aVec;
        if (shouldReshapeA) {
          aVec3d = reshape({
            inputs: { x: aVec },
            backend,
            attrs: { shape: [batchDim, sharedDim, 1] }
          });
          intermediates.push(aVec3d);
        }
        var axis = outerShapeB === 1 ? 2 : 1;
        var bVec3d = bVec;
        if (shouldReshapeB) {
          bVec3d = reshape({
            inputs: { x: bVec },
            backend,
            attrs: { shape: [batchDim, 1, sharedDim] }
          });
          intermediates.push(bVec3d);
        }
        var product = multiply({ inputs: { a: aVec3d, b: bVec3d }, backend });
        out = sum({ inputs: { x: product }, backend, attrs: { axis, keepDims: true } });
        intermediates.push(product);
      } else {
        var dtype = tf.upcastType(a.dtype, b.dtype);
        var program = new MatMulPackedProgram(a3dShape, b3dShape, [batchDim, outerShapeA, outerShapeB], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
        var inputs = [a3d, b3d];
        if (bias != null) {
          inputs.push(bias);
        }
        if (hasPreluActivationWeights) {
          inputs.push(preluActivationWeights);
        }
        if (hasLeakyreluAlpha) {
          var $leakyreluAlpha = backend.makeTensorInfo([], "float32", tf.util.createScalarValue(leakyreluAlpha, "float32"));
          inputs.push($leakyreluAlpha);
          intermediates.push($leakyreluAlpha);
        }
        out = backend.runWebGLProgram(program, inputs, dtype);
      }
      var outReshaped = reshape({ inputs: { x: out }, backend, attrs: { shape: outShape } });
      intermediates.push(out);
      try {
        for (var intermediates_1 = __values(intermediates), intermediates_1_1 = intermediates_1.next(); !intermediates_1_1.done; intermediates_1_1 = intermediates_1.next()) {
          var i = intermediates_1_1.value;
          backend.disposeIntermediateTensorInfo(i);
        }
      } catch (e_1_1) {
        e_12 = { error: e_1_1 };
      } finally {
        try {
          if (intermediates_1_1 && !intermediates_1_1.done && (_b = intermediates_1.return))
            _b.call(intermediates_1);
        } finally {
          if (e_12)
            throw e_12.error;
        }
      }
      return outReshaped;
    }
    function _fusedMatMul(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var a = inputs.a, b = inputs.b, bias = inputs.bias, preluActivationWeights = inputs.preluActivationWeights;
      var transposeA = attrs.transposeA, transposeB = attrs.transposeB, activation = attrs.activation, leakyreluAlpha = attrs.leakyreluAlpha;
      return batchMatMulImpl({
        a,
        b,
        transposeA,
        transposeB,
        backend,
        bias,
        preluActivationWeights,
        leakyreluAlpha,
        activation
      });
    }
    var _fusedMatMulConfig = {
      kernelName: tf._FusedMatMul,
      backendName: "webgl",
      kernelFunc: _fusedMatMul
    };
    var ABS = "return abs(x);";
    function abs(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x;
      if (backend.shouldExecuteOnCPU([x]) && x.dtype !== "complex64") {
        var xData = backend.texData.get(x.dataId);
        var outValues = simpleAbsImplCPU(xData.values);
        return backend.makeTensorInfo(x.shape, x.dtype, outValues);
      }
      var program;
      if (tf.env().getBool("WEBGL_PACK_UNARY_OPERATIONS")) {
        program = new UnaryOpPackedProgram(x.shape, ABS);
      } else {
        program = new UnaryOpProgram(x.shape, ABS);
      }
      return backend.runWebGLProgram(program, [x], x.dtype);
    }
    var absConfig = {
      kernelName: tf.Abs,
      backendName: "webgl",
      kernelFunc: abs
    };
    var ACOS = CHECK_NAN_SNIPPET$1 + "\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return acos(x);\n";
    var acos = unaryKernelFunc({ opSnippet: ACOS });
    var acosConfig = {
      kernelName: tf.Acos,
      backendName: "webgl",
      kernelFunc: acos
    };
    var ACOSH = CHECK_NAN_SNIPPET$1 + "\n  if (x < 1.0) return NAN;\nreturn log(x + sqrt(x * x - 1.0));";
    var acosh = unaryKernelFunc({ opSnippet: ACOSH });
    var acoshConfig = {
      kernelName: tf.Acosh,
      backendName: "webgl",
      kernelFunc: acosh
    };
    var ADD = "return a + b;";
    var addKernelFunc = binaryKernelFunc({
      opSnippet: ADD,
      packedOpSnippet: ADD,
      supportsComplex: true,
      cpuKernelImpl: addImplCPU
    });
    var addConfig = {
      kernelName: tf.Add,
      backendName: "webgl",
      kernelFunc: addKernelFunc
    };
    var AddNProgram = (
      /** @class */
      function() {
        function AddNProgram2(outputShape, shapes) {
          this.outputShape = [];
          this.outputShape = outputShape;
          this.variableNames = shapes.map(function(_, i) {
            return "T".concat(i);
          });
          var snippets = [];
          this.variableNames.forEach(function(variable) {
            snippets.push("float v".concat(variable, " = get").concat(variable, "AtOutCoords();"));
          });
          var operation = this.variableNames.map(function(variable) {
            return "v".concat(variable);
          }).join(" + ");
          this.userCode = "\n      void main() {\n        ".concat(snippets.join("\n        "), "\n\n        float result = ").concat(operation, ";\n        setOutput(result);\n      }\n    ");
        }
        return AddNProgram2;
      }()
    );
    var AddNPackedProgram = (
      /** @class */
      function() {
        function AddNPackedProgram2(outputShape, shapes) {
          this.outputShape = [];
          this.packedInputs = true;
          this.packedOutput = true;
          this.outputShape = outputShape;
          this.variableNames = shapes.map(function(_, i) {
            return "T".concat(i);
          });
          var snippets = [];
          this.variableNames.forEach(function(variable) {
            snippets.push("vec4 v".concat(variable, " = get").concat(variable, "AtOutCoords();"));
          });
          var operation = this.variableNames.map(function(variable) {
            return "v".concat(variable);
          }).join(" + ");
          this.userCode = "\n      void main() {\n        ".concat(snippets.join("\n        "), "\n\n        vec4 result = ").concat(operation, ";\n        setOutput(result);\n      }\n    ");
        }
        return AddNPackedProgram2;
      }()
    );
    function addN(args) {
      var inputs = args.inputs, backend = args.backend;
      var tensors = inputs;
      if (tensors.length === 1) {
        return identity({ inputs: { x: tensors[0] }, backend });
      }
      if (tensors.length > tf.env().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER")) {
        var midIndex = Math.floor(tensors.length / 2);
        var leftSide = addN({ inputs: tensors.slice(0, midIndex), backend });
        var rightSide = addN({ inputs: tensors.slice(midIndex), backend });
        return addN({ inputs: [leftSide, rightSide], backend });
      }
      var dtype = tensors.map(function(t) {
        return t.dtype;
      }).reduce(function(d1, d2) {
        return tf.upcastType(d1, d2);
      });
      var shapes = tensors.map(function(t) {
        return t.shape;
      });
      var usePackedOp = tf.env().getBool("WEBGL_PACK");
      var program = usePackedOp ? new AddNPackedProgram(tensors[0].shape, shapes) : new AddNProgram(tensors[0].shape, shapes);
      return backend.runWebGLProgram(program, tensors, dtype);
    }
    var addNConfig = {
      kernelName: tf.AddN,
      backendName: "webgl",
      kernelFunc: addN
    };
    function all(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      var xRank = x.shape.length;
      var origAxes = tf.util.parseAxisParam(axis, x.shape);
      var axes = origAxes;
      var permutedAxes = tf.backend_util.getAxesPermutation(axes, xRank);
      var permutedX = x;
      if (permutedAxes != null) {
        permutedX = transpose({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
        axes = tf.backend_util.getInnerMostAxes(axes.length, xRank);
      }
      tf.backend_util.assertAxesAreInnerMostDims("all", axes, xRank);
      var _a2 = __read(tf.backend_util.computeOutAndReduceShapes(permutedX.shape, axes), 2), outShape = _a2[0], reduceShape = _a2[1];
      var inSize = tf.util.sizeFromShape(reduceShape);
      var a2D = reshape({ inputs: { x: permutedX }, backend, attrs: { shape: [-1, inSize] } });
      var reduced = reduce(a2D, a2D.dtype, "all", backend);
      var res;
      if (keepDims) {
        var newShape = tf.backend_util.expandShapeToKeepDim(outShape, origAxes);
        res = reshape({ inputs: { x: reduced }, backend, attrs: { shape: newShape } });
      } else {
        res = reshape({ inputs: { x: reduced }, backend, attrs: { shape: outShape } });
      }
      backend.disposeIntermediateTensorInfo(a2D);
      backend.disposeIntermediateTensorInfo(reduced);
      if (permutedAxes != null) {
        backend.disposeIntermediateTensorInfo(permutedX);
      }
      return res;
    }
    var allConfig = {
      kernelName: tf.All,
      backendName: "webgl",
      kernelFunc: all
    };
    function any(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      var xRank = x.shape.length;
      var origAxes = tf.util.parseAxisParam(axis, x.shape);
      var axes = origAxes;
      var permutedAxes = tf.backend_util.getAxesPermutation(axes, xRank);
      var permutedX = x;
      if (permutedAxes != null) {
        permutedX = transpose({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
        axes = tf.backend_util.getInnerMostAxes(axes.length, xRank);
      }
      tf.backend_util.assertAxesAreInnerMostDims("any", axes, xRank);
      var _a2 = __read(tf.backend_util.computeOutAndReduceShapes(permutedX.shape, axes), 2), outShape = _a2[0], reduceShape = _a2[1];
      var inSize = tf.util.sizeFromShape(reduceShape);
      var a2D = reshape({ inputs: { x: permutedX }, backend, attrs: { shape: [-1, inSize] } });
      var reduced = reduce(a2D, a2D.dtype, "any", backend);
      var res;
      if (keepDims) {
        var newShape = tf.backend_util.expandShapeToKeepDim(outShape, origAxes);
        res = reshape({ inputs: { x: reduced }, backend, attrs: { shape: newShape } });
      } else {
        res = reshape({ inputs: { x: reduced }, backend, attrs: { shape: outShape } });
      }
      backend.disposeIntermediateTensorInfo(a2D);
      backend.disposeIntermediateTensorInfo(reduced);
      if (permutedAxes != null) {
        backend.disposeIntermediateTensorInfo(permutedX);
      }
      return res;
    }
    var anyConfig = {
      kernelName: tf.Any,
      backendName: "webgl",
      kernelFunc: any
    };
    var ArgMinMaxProgram = (
      /** @class */
      function() {
        function ArgMinMaxProgram2(reduceInfo, op, firstPass) {
          this.variableNames = ["A"];
          var windowSize = reduceInfo.windowSize, batchSize = reduceInfo.batchSize, outSize = reduceInfo.outSize;
          if (!firstPass) {
            this.variableNames.push("bestIndicesA");
          }
          this.outputShape = [batchSize, outSize];
          var compOp = op === "max" ? ">" : "<";
          var indexSnippet = firstPass ? "inOffset + i;" : "round(getBestIndicesA(batch, inOffset + i));";
          this.userCode = "\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ".concat(windowSize, ";\n\n        int bestIndex = inOffset;\n        float bestValue = getA(batch, bestIndex);\n\n        for (int i = 0; i < ").concat(windowSize, "; i++) {\n          int inIdx = ").concat(indexSnippet, ";\n          float candidate = getA(batch, inIdx);\n          if (candidate ").concat(compOp, " bestValue) {\n            bestValue = candidate;\n            bestIndex = inIdx;\n          }\n        }\n        setOutput(float(bestIndex));\n      }\n    ");
        }
        return ArgMinMaxProgram2;
      }()
    );
    var ArgMinMaxPackedProgram = (
      /** @class */
      function() {
        function ArgMinMaxPackedProgram2(shape, windowSize, op, firstPass) {
          this.variableNames = ["A"];
          this.packedInputs = true;
          this.packedOutput = true;
          tf.util.assert(shape.length > 2, function() {
            return "Packed arg".concat(op.charAt(0).toUpperCase() + op.slice(1), " supports only inputs with rank above 2.");
          });
          var inSize = shape[shape.length - 1];
          var outSize = Math.ceil(inSize / windowSize);
          this.outputShape = shape.slice(0, -1);
          if (outSize > 1) {
            this.outputShape.push(outSize);
          }
          if (!firstPass) {
            this.variableNames.push("bestIndicesA");
          }
          var outShape = this.outputShape;
          var rank = outShape.length;
          var dtype = getCoordsDataType(rank);
          var coords2 = getChannels("coords", rank);
          var sourceLocSetup;
          var sourceRank;
          if (outSize === 1) {
            sourceRank = rank + 1;
            var sourceLocDType = getCoordsDataType(sourceRank);
            sourceLocSetup = "\n        ".concat(sourceLocDType, " sourceLocR = ").concat(sourceLocDType, "(").concat(coords2.join(), ", 0);\n        ++").concat(coords2[rank - 1], ";\n        ").concat(sourceLocDType, " sourceLocG = ").concat(sourceLocDType, "(").concat(coords2.join(), ", 0);\n        ++").concat(coords2[rank - 2], ";\n        ").concat(sourceLocDType, " sourceLocA = ").concat(sourceLocDType, "(").concat(coords2.join(), ", 0);\n        --").concat(coords2[rank - 1], ";\n        ").concat(sourceLocDType, " sourceLocB = ").concat(sourceLocDType, "(").concat(coords2.join(), ", 0);\n        --").concat(coords2[rank - 2], ";");
          } else {
            sourceRank = rank;
            sourceLocSetup = "\n        ".concat(dtype, " sourceLocR = coords;\n        ++").concat(coords2[rank - 1], ";\n        ").concat(dtype, " sourceLocG = coords;\n        ++").concat(coords2[rank - 2], ";\n        ").concat(dtype, " sourceLocA = coords;\n        --").concat(coords2[rank - 1], ";\n        ").concat(dtype, " sourceLocB = coords;\n        --").concat(coords2[rank - 2], ";");
          }
          var channels = ["x", "y", "z", "w", "u", "v"].slice(0, sourceRank);
          var inChannel = "." + channels[sourceRank - 1];
          var intChannels = channels.map(function(x) {
            return "int " + x;
          });
          var srcRCoords = getChannels("sourceLocR", sourceRank - 1).concat("inIdx.r");
          var srcGCoords = getChannels("sourceLocG", sourceRank - 1).concat("inIdx.g");
          var srcBCoords = getChannels("sourceLocB", sourceRank - 1).concat("inIdx.b");
          var srcACoords = getChannels("sourceLocA", sourceRank - 1).concat("inIdx.a");
          var compOp = op === "max" ? "greaterThan" : "lessThan";
          var fetchCandidateIdx = firstPass ? "" : "\n          inIdx = round(vec4(getBestIndicesAChannel(".concat(srcRCoords.join(), "),\n                             getBestIndicesAChannel(").concat(srcGCoords.join(), "),\n                             getBestIndicesAChannel(").concat(srcBCoords.join(), "),\n                             getBestIndicesAChannel(").concat(srcACoords.join(), ")));");
          var fetchValue = "vec4(\n            getAChannel(".concat(srcRCoords.join(), "),\n            hasNextCol ? getAChannel(").concat(srcGCoords.join(), ") : 0.,\n            hasNextRow ? getAChannel(").concat(srcBCoords.join(), ") : 0.,\n            hasNextRow && hasNextCol ? getAChannel(").concat(srcACoords.join(), ") : 0.)");
          var getBestIndicesAChannelSnippet = firstPass ? "" : "\n      float getBestIndicesAChannel(".concat(intChannels.join(), ") {\n        return getChannel(getBestIndicesA(").concat(channels.join(), "),\n                                          vec2(").concat(channels.slice(-2).join(), "));\n      }");
          this.userCode = "\n      float getAChannel(".concat(intChannels.join(), ") {\n        return getChannel(getA(").concat(channels.join(), "),\n                               vec2(").concat(channels.slice(-2).join(), "));\n      }\n      ").concat(getBestIndicesAChannelSnippet, "\n      void main() {\n        ").concat(dtype, " coords = getOutputCoords();\n        bool hasNextCol = ").concat(coords2[rank - 1], " < ").concat(outShape[rank - 1] - 1, ";\n        bool hasNextRow = ").concat(coords2[rank - 2], " < ").concat(outShape[rank - 2] - 1, ";\n        ").concat(sourceLocSetup, "\n        ivec4 srcIdx = ivec4(sourceLocR").concat(inChannel, ", sourceLocG").concat(inChannel, ",\n          sourceLocB").concat(inChannel, ", sourceLocA").concat(inChannel, ") * ").concat(windowSize, ";\n        ivec4 inIdx = srcIdx;\n        vec4 bestIndex = vec4(inIdx);\n        vec4 bestValue = ").concat(fetchValue, ";\n\n        for (int i = 0; i < ").concat(windowSize, "; i++) {\n          inIdx = srcIdx;\n          ").concat(fetchCandidateIdx, "\n          vec4 candidate = ").concat(fetchValue, ";\n          bvec4 nan = isnan(candidate);\n          bvec4 replace = bvec4(\n            vec4(").concat(compOp, "(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\n\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\n                           replace.y  ? candidate.y : bestValue.y,\n                           replace.z  ? candidate.z : bestValue.z,\n                           replace.w  ? candidate.w : bestValue.w);\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\n          srcIdx++;\n        }\n        setOutput(bestIndex);\n      }\n    ");
        }
        return ArgMinMaxPackedProgram2;
      }()
    );
    function argReduce(backend, x, reduceType, bestIndicesA) {
      if (bestIndicesA === void 0) {
        bestIndicesA = null;
      }
      var batchSize = x.shape[0];
      var inSize = x.shape[1];
      if (bestIndicesA != null) {
        batchSize = bestIndicesA.shape[0];
        inSize = bestIndicesA.shape[1];
      }
      var windowSize = tf.backend_util.computeOptimalWindowSize(inSize);
      var reduceInfo = { windowSize, inSize, batchSize, outSize: Math.ceil(inSize / windowSize) };
      var program = new ArgMinMaxProgram(reduceInfo, reduceType, bestIndicesA == null);
      var inputs = [x];
      if (bestIndicesA != null) {
        inputs.push(bestIndicesA);
      }
      var output = backend.runWebGLProgram(program, inputs, "int32");
      if (output.shape[1] === 1) {
        return output;
      }
      var result = argReduce(backend, x, reduceType, output);
      backend.disposeIntermediateTensorInfo(output);
      return result;
    }
    function argReducePacked(backend, x, reduceType, bestIndicesA) {
      if (bestIndicesA === void 0) {
        bestIndicesA = null;
      }
      var inShape = bestIndicesA != null ? bestIndicesA.shape : x.shape;
      var inSize = inShape[inShape.length - 1];
      var windowSize = tf.backend_util.computeOptimalWindowSize(inSize);
      var program = new ArgMinMaxPackedProgram(inShape, windowSize, reduceType, bestIndicesA == null);
      var inputs = bestIndicesA == null ? [x] : [x, bestIndicesA];
      var output = backend.runWebGLProgram(program, inputs, "int32");
      if (output.shape.length === x.shape.length) {
        var result = argReducePacked(backend, x, reduceType, output);
        backend.disposeIntermediateTensorInfo(output);
        return result;
      }
      return output;
    }
    function argMinMaxReduce(backend, x, axis, reduceType) {
      var axes = [axis];
      tf.backend_util.assertAxesAreInnerMostDims("arg" + reduceType.charAt(0).toUpperCase() + reduceType.slice(1), axes, x.shape.length);
      if (!tf.env().getBool("WEBGL_PACK_REDUCE") || x.shape.length <= 2) {
        var intermediateTensorInfos = [];
        var xtexData = backend.texData.get(x.dataId);
        var xIsPacked = xtexData !== null && xtexData.isPacked;
        var xUnPacked = x;
        if (xIsPacked) {
          xUnPacked = backend.unpackTensor(x);
          intermediateTensorInfos.push(xUnPacked);
        }
        var _a2 = __read(tf.backend_util.computeOutAndReduceShapes(xUnPacked.shape, axes), 2), outShape = _a2[0], reduceShape = _a2[1];
        var inSize = tf.util.sizeFromShape(reduceShape);
        var a2D = reshape({ inputs: { x: xUnPacked }, backend, attrs: { shape: [-1, inSize] } });
        intermediateTensorInfos.push(a2D);
        var reduced = argReduce(backend, a2D, reduceType);
        intermediateTensorInfos.push(reduced);
        var reshaped = reshape({ inputs: { x: reduced }, backend, attrs: { shape: outShape } });
        intermediateTensorInfos.forEach(function(t) {
          return backend.disposeIntermediateTensorInfo(t);
        });
        return reshaped;
      }
      return argReducePacked(backend, x, reduceType);
    }
    function argMax(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis;
      var axes = tf.util.parseAxisParam(axis, x.shape);
      var permutedAxes = tf.backend_util.getAxesPermutation(axes, x.shape.length);
      var $x = x;
      var intermediateTensorInfos = [];
      if (permutedAxes != null) {
        $x = transpose({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
        intermediateTensorInfos.push($x);
        axes = tf.backend_util.getInnerMostAxes(axes.length, $x.shape.length);
      }
      tf.backend_util.assertAxesAreInnerMostDims("argMax", [axes[0]], $x.shape.length);
      var out = argMinMaxReduce(backend, $x, axes[0], "max");
      intermediateTensorInfos.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return out;
    }
    var argMaxConfig = {
      kernelName: tf.ArgMax,
      backendName: "webgl",
      kernelFunc: argMax
    };
    function argMin(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis;
      var axes = tf.util.parseAxisParam(axis, x.shape);
      var permutedAxes = tf.backend_util.getAxesPermutation(axes, x.shape.length);
      var $x = x;
      var intermediateTensorInfos = [];
      if (permutedAxes != null) {
        $x = transpose({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
        intermediateTensorInfos.push($x);
        axes = tf.backend_util.getInnerMostAxes(axes.length, $x.shape.length);
      }
      tf.backend_util.assertAxesAreInnerMostDims("argMin", [axes[0]], $x.shape.length);
      var out = argMinMaxReduce(backend, $x, axes[0], "min");
      intermediateTensorInfos.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return out;
    }
    var argMinConfig = {
      kernelName: tf.ArgMin,
      backendName: "webgl",
      kernelFunc: argMin
    };
    var ASIN = CHECK_NAN_SNIPPET$1 + "\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return asin(x);\n";
    var asin = unaryKernelFunc({ opSnippet: ASIN });
    var asinConfig = {
      kernelName: tf.Asin,
      backendName: "webgl",
      kernelFunc: asin
    };
    var ASINH = CHECK_NAN_SNIPPET$1 + "return log(x + sqrt(x * x + 1.0));";
    var asinh = unaryKernelFunc({ opSnippet: ASINH });
    var asinhConfig = {
      kernelName: tf.Asinh,
      backendName: "webgl",
      kernelFunc: asinh
    };
    var ATAN = CHECK_NAN_SNIPPET$1 + "\n  return atan(x);\n";
    var atan = unaryKernelFunc({ opSnippet: ATAN });
    var atanConfig = {
      kernelName: tf.Atan,
      backendName: "webgl",
      kernelFunc: atan
    };
    var ATAN2 = CHECK_NAN_SNIPPET + "\n  return atan(a, b);\n";
    var ATAN2_PACKED = "\n  vec4 result = atan(a, b);\n  bvec4 isNaNA = isnan(a);\n  bvec4 isNaNB = isnan(b);\n  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);\n  " + CHECK_NAN_SNIPPET_PACKED + "\n  return result;\n";
    var atan2 = binaryKernelFunc({ opSnippet: ATAN2, packedOpSnippet: ATAN2_PACKED });
    var atan2Config = {
      kernelName: tf.Atan2,
      backendName: "webgl",
      kernelFunc: atan2
    };
    var ATANH = CHECK_NAN_SNIPPET$1 + "\n  if ((x < -1.0) || (x > 1.0)) return NAN;\nreturn (log(1.0 + x) - log(1.0 - x)) / 2.0;";
    var atanh = unaryKernelFunc({ opSnippet: ATANH });
    var atanhConfig = {
      kernelName: tf.Atanh,
      backendName: "webgl",
      kernelFunc: atanh
    };
    var Pool2DProgram = (
      /** @class */
      function() {
        function Pool2DProgram2(convInfo, poolType, computePositions, flattenPositions, includeBatchInIndex) {
          if (flattenPositions === void 0) {
            flattenPositions = false;
          }
          if (includeBatchInIndex === void 0) {
            includeBatchInIndex = false;
          }
          this.variableNames = ["x"];
          if (poolType === "avg" && computePositions) {
            throw new Error("Cannot compute positions for average pool.");
          }
          var filterWidth = convInfo.filterWidth;
          var strideHeight = convInfo.strideHeight;
          var strideWidth = convInfo.strideWidth;
          var dilationHeight = convInfo.dilationHeight;
          var dilationWidth = convInfo.dilationWidth;
          var effectiveFilterHeight = convInfo.effectiveFilterHeight;
          var effectiveFilterWidth = convInfo.effectiveFilterWidth;
          var padTop = convInfo.padInfo.top;
          var padLeft = convInfo.padInfo.left;
          this.outputShape = convInfo.outShape;
          var isAvgPool = poolType === "avg";
          var batchFlattenPositionStr = "((batch  * ".concat(convInfo.inHeight, " + xR) * ").concat(convInfo.inWidth, " + xC) * ").concat(convInfo.inChannels, " + d");
          var flattenPositionStr = "(xR * ".concat(convInfo.inWidth, " + xC) * ").concat(convInfo.inChannels, " + d");
          var initializationValue = "0.0";
          if (!isAvgPool) {
            initializationValue = "-1.0 / 1e-20";
          }
          if (computePositions) {
            var compareOp_1 = ">=";
            this.userCode = "\n        const ivec2 strides = ivec2(".concat(strideHeight, ", ").concat(strideWidth, ");\n        const ivec2 pads = ivec2(").concat(padTop, ", ").concat(padLeft, ");\n\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int batch = coords[0];\n          int d = coords[3];\n\n          ivec2 xRCCorner = coords.yz * strides - pads;\n          int xRCorner = xRCCorner.x;\n          int xCCorner = xRCCorner.y;\n\n          // max/min x(?, ?, d) to get y(yR, yC, d).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n          float avgValue = 0.0;\n\n          for (int wR = 0; wR < ").concat(effectiveFilterHeight, ";\n              wR += ").concat(dilationHeight, ") {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ").concat(convInfo.inHeight, ") {\n              continue;\n            }\n\n            for (int wC = 0; wC < ").concat(effectiveFilterWidth, ";\n                wC += ").concat(dilationWidth, ") {\n              int xC = xCCorner + wC;\n\n              if (xC < 0 || xC >= ").concat(convInfo.inWidth, ") {\n                continue;\n              }\n\n              float value = getX(batch, xR, xC, d);\n\n              // If a min / max value has already been found, use it. If not,\n              // use the current value.\n              float currMinMaxValue = mix(\n                  value, minMaxValue, minMaxValueFound);\n              if (value ").concat(compareOp_1, " currMinMaxValue) {\n                minMaxValue = value;\n                minMaxValueFound = 1.0;\n                minMaxPosition = ").concat(flattenPositions ? includeBatchInIndex ? batchFlattenPositionStr : flattenPositionStr : "wR * ".concat(effectiveFilterWidth, " + wC"), ";\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      ");
            return;
          }
          var compareOp = "max";
          var returnValue = "".concat(poolType, "(").concat(poolType, "(").concat(poolType, "(") + "minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])";
          if (poolType === "avg") {
            returnValue = "avgValue / max(count, 1.0)";
          }
          var filterWidthNearestVec4 = Math.floor(filterWidth / 4) * 4;
          var filterWidthVec4Remainder = filterWidth % 4;
          var updateSnippet = "\n      if (".concat(isAvgPool, ") {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = ").concat(compareOp, "(values, minMaxValue);\n      }\n    ");
          this.userCode = "\n      const ivec2 strides = ivec2(".concat(strideHeight, ", ").concat(strideWidth, ");\n      const ivec2 pads = ivec2(").concat(padTop, ", ").concat(padLeft, ");\n      const float initializationValue = ").concat(initializationValue, ";\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xR, int xC, int d) {\n        if (xC < 0 || xC >= ").concat(convInfo.inWidth, ") {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xR, xC, d);\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d = coords[3];\n\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // max/min x(?, ?, d) to get y(yR, yC, d).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(").concat(initializationValue, ");\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wR = 0; wR < ").concat(effectiveFilterHeight, ";\n            wR += ").concat(dilationHeight, ") {\n          int xR = xRCorner + wR;\n\n          if (xR < 0 || xR >= ").concat(convInfo.inHeight, ") {\n            continue;\n          }\n\n          for (int wC = 0; wC < ").concat(filterWidthNearestVec4, "; wC += 4) {\n            int xC = xCCorner + wC * ").concat(dilationWidth, ";\n\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ").concat(dilationWidth, ", d),\n              getValue(batch, xR, xC + 2 * ").concat(dilationWidth, ", d),\n              getValue(batch, xR, xC + 3 * ").concat(dilationWidth, ", d)\n            );\n\n            ").concat(updateSnippet, "\n          }\n\n          int xC = xCCorner + ").concat(filterWidthNearestVec4, ";\n          if (").concat(filterWidthVec4Remainder === 1, ") {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              initializationValue,\n              initializationValue,\n              initializationValue\n            );\n\n            ").concat(updateSnippet, "\n          } else if (").concat(filterWidthVec4Remainder === 2, ") {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ").concat(dilationWidth, ", d),\n              initializationValue,\n              initializationValue\n            );\n\n            ").concat(updateSnippet, "\n          } else if (").concat(filterWidthVec4Remainder === 3, ") {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ").concat(dilationWidth, ", d),\n              getValue(batch, xR, xC + 2 * ").concat(dilationWidth, ", d),\n              initializationValue\n            );\n\n            ").concat(updateSnippet, "\n          }\n        }\n        setOutput(").concat(returnValue, ");\n      }\n    ");
        }
        return Pool2DProgram2;
      }()
    );
    var Pool3DProgram = (
      /** @class */
      function() {
        function Pool3DProgram2(convInfo, poolType, computePositions, flattenPositions, includeBatchInIndex) {
          if (flattenPositions === void 0) {
            flattenPositions = false;
          }
          if (includeBatchInIndex === void 0) {
            includeBatchInIndex = false;
          }
          this.variableNames = ["x"];
          if (poolType === "avg" && computePositions) {
            throw new Error("Cannot compute positions for average pool.");
          }
          var filterWidth = convInfo.filterWidth;
          var strideDepth = convInfo.strideDepth;
          var strideHeight = convInfo.strideHeight;
          var strideWidth = convInfo.strideWidth;
          var dilationDepth = convInfo.dilationDepth;
          var dilationHeight = convInfo.dilationHeight;
          var dilationWidth = convInfo.dilationWidth;
          var effectiveFilterDepth = convInfo.effectiveFilterDepth;
          var effectiveFilterHeight = convInfo.effectiveFilterHeight;
          var effectiveFilterWidth = convInfo.effectiveFilterWidth;
          var padFront = convInfo.padInfo.front;
          var padTop = convInfo.padInfo.top;
          var padLeft = convInfo.padInfo.left;
          this.outputShape = convInfo.outShape;
          var isAvgPool = poolType === "avg";
          var initializationValue = "0.0";
          if (!isAvgPool) {
            initializationValue = "-1.0 / 1e-20";
          }
          if (computePositions) {
            var compareOp_2 = ">=";
            this.userCode = "\n        const ivec3 strides =\n            ivec3(".concat(strideDepth, ", ").concat(strideHeight, ", ").concat(strideWidth, ");\n        const ivec3 pads = ivec3(").concat(padFront, ", ").concat(padTop, ", ").concat(padLeft, ");\n\n        void main() {\n          ivec5 coords = getOutputCoords();\n          int batch = coords.x;\n          int ch = coords.u;\n\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n          int xDCorner = xCorner.x;\n          int xRCorner = xCorner.y;\n          int xCCorner = xCorner.z;\n\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n\n          for (int wD = 0; wD < ").concat(effectiveFilterDepth, ";\n              wD += ").concat(dilationDepth, ") {\n            int xD = xDCorner + wD;\n\n            if (xD < 0 || xD >= ").concat(convInfo.inDepth, ") {\n              continue;\n            }\n\n            for (int wR = 0; wR < ").concat(effectiveFilterHeight, ";\n                wR += ").concat(dilationHeight, ") {\n              int xR = xRCorner + wR;\n\n              if (xR < 0 || xR >= ").concat(convInfo.inHeight, ") {\n                continue;\n              }\n\n              for (int wC = 0; wC < ").concat(effectiveFilterWidth, ";\n                  wC += ").concat(dilationWidth, ") {\n                int xC = xCCorner + wC;\n\n                if (xC < 0 || xC >= ").concat(convInfo.inWidth, ") {\n                  continue;\n                }\n\n                float value = getX(batch, xD, xR, xC, ch);\n\n                // If a min / max value has already been found, use it. If not,\n                // use the current value.\n                float currMinMaxValue = mix(\n                    value, minMaxValue, minMaxValueFound);\n                if (value ").concat(compareOp_2, " currMinMaxValue) {\n                  minMaxValue = value;\n                  minMaxValueFound = 1.0;\n                  minMaxPosition = ").concat(flattenPositions ? includeBatchInIndex ? "(((batch * ".concat(convInfo.inDepth, " + xD) * ").concat(convInfo.inHeight, " + xR) * ").concat(convInfo.inWidth, " + xC) * ").concat(convInfo.inChannels, " + ch") : "((xD * ".concat(convInfo.inHeight, " + xR) * ").concat(convInfo.inWidth, " + xC) * ").concat(convInfo.inChannels, " + ch") : "wD * ".concat(effectiveFilterHeight, " * ").concat(effectiveFilterWidth, " +\n                      wR * ").concat(effectiveFilterWidth, " + wC"), ";\n                }\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      ");
            return;
          }
          var compareOp = "max";
          var returnValue = "".concat(poolType, "(").concat(poolType, "(").concat(poolType, "(") + "minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])";
          if (poolType === "avg") {
            returnValue = "avgValue / max(count, 1.0)";
          }
          var filterWidthNearestVec4 = Math.floor(filterWidth / 4) * 4;
          var filterWidthVec4Remainder = filterWidth % 4;
          var updateSnippet = "\n      if (".concat(isAvgPool, ") {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = ").concat(compareOp, "(values, minMaxValue);\n      }\n    ");
          this.userCode = "\n      const ivec3 strides =\n        ivec3(".concat(strideDepth, ", ").concat(strideHeight, ", ").concat(strideWidth, ");\n      const ivec3 pads = ivec3(").concat(padFront, ", ").concat(padTop, ", ").concat(padLeft, ");\n      const float initializationValue = ").concat(initializationValue, ";\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\n        if (xC < 0 || xC >= ").concat(convInfo.inWidth, ") {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xD, xR, xC, ch);\n      }\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xDCorner = xCorner.x;\n        int xRCorner = xCorner.y;\n        int xCCorner = xCorner.z;\n\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(").concat(initializationValue, ");\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wD = 0; wD < ").concat(effectiveFilterDepth, ";\n            wD += ").concat(dilationDepth, ") {\n          int xD = xDCorner + wD;\n\n          if (xD < 0 || xD >= ").concat(convInfo.inDepth, ") {\n            continue;\n          }\n\n          for (int wR = 0; wR < ").concat(effectiveFilterHeight, ";\n            wR += ").concat(dilationHeight, ") {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ").concat(convInfo.inHeight, ") {\n              continue;\n            }\n\n            for (int wC = 0; wC < ").concat(filterWidthNearestVec4, "; wC += 4) {\n              int xC = xCCorner + wC * ").concat(dilationWidth, ";\n\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ").concat(dilationWidth, ", ch),\n                getValue(batch, xD, xR, xC + 2 * ").concat(dilationWidth, ", ch),\n                getValue(batch, xD, xR, xC + 3 * ").concat(dilationWidth, ", ch)\n              );\n\n              ").concat(updateSnippet, "\n            }\n\n            int xC = xCCorner + ").concat(filterWidthNearestVec4, ";\n            if (").concat(filterWidthVec4Remainder === 1, ") {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                initializationValue,\n                initializationValue,\n                initializationValue\n              );\n\n              ").concat(updateSnippet, "\n            } else if (").concat(filterWidthVec4Remainder === 2, ") {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ").concat(dilationWidth, ", ch),\n                initializationValue,\n                initializationValue\n              );\n\n              ").concat(updateSnippet, "\n            } else if (").concat(filterWidthVec4Remainder === 3, ") {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ").concat(dilationWidth, ", ch),\n                getValue(batch, xD, xR, xC + 2 * ").concat(dilationWidth, ", ch),\n                initializationValue\n              );\n\n              ").concat(updateSnippet, "\n            }\n          }\n        }\n        setOutput(").concat(returnValue, ");\n      }\n    ");
        }
        return Pool3DProgram2;
      }()
    );
    function avgPool(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      assertNotComplex(x, "avgPool");
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      var dilations = 1;
      tf.util.assert(tf.backend_util.eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in avgPool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var convInfo = tf.backend_util.computePool2DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode);
      if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && tf.util.arraysEqual(convInfo.inShape, convInfo.outShape)) {
        return identity({ inputs: { x }, backend });
      }
      var avgPoolProgram = new Pool2DProgram(convInfo, "avg", false);
      return backend.runWebGLProgram(avgPoolProgram, [x], "float32");
    }
    var avgPoolConfig = {
      kernelName: tf.AvgPool,
      backendName: "webgl",
      kernelFunc: avgPool
    };
    function avgPool3D(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode, dataFormat = attrs.dataFormat;
      var dilations = [1, 1, 1];
      var convInfo = tf.backend_util.computePool3DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode, dataFormat);
      var avgPoolProgram = new Pool3DProgram(convInfo, "avg", false);
      return backend.runWebGLProgram(avgPoolProgram, [x], "float32");
    }
    var avgPool3DConfig = {
      kernelName: tf.AvgPool3D,
      backendName: "webgl",
      kernelFunc: avgPool3D
    };
    var AvgPool2DBackpropProgram = (
      /** @class */
      function() {
        function AvgPool2DBackpropProgram2(convInfo) {
          this.variableNames = ["dy"];
          this.outputShape = convInfo.inShape;
          var filterHeight = convInfo.filterHeight;
          var filterWidth = convInfo.filterWidth;
          var strideHeight = convInfo.strideHeight;
          var strideWidth = convInfo.strideWidth;
          var dilationHeight = convInfo.dilationHeight;
          var dilationWidth = convInfo.dilationWidth;
          var effectiveFilterHeight = convInfo.effectiveFilterHeight;
          var effectiveFilterWidth = convInfo.effectiveFilterWidth;
          var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
          var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
          var avgMultiplier = 1 / (filterHeight * filterWidth);
          this.userCode = "\n      const ivec2 pads = ivec2(".concat(padTop, ", ").concat(padLeft, ");\n      const float avgMultiplier = float(").concat(avgMultiplier, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ").concat(effectiveFilterHeight, ";\n            wR += ").concat(dilationHeight, ") {\n          float dyR = float(dyRCorner + wR) / ").concat(strideHeight, ".0;\n\n          if (dyR < 0.0 || dyR >= ").concat(convInfo.outHeight, ".0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ").concat(effectiveFilterWidth, ";\n            wC+= ").concat(dilationWidth, ") {\n            float dyC = float(dyCCorner + wC) / ").concat(strideWidth, ".0;\n\n            if (dyC < 0.0 || dyC >= ").concat(convInfo.outWidth, ".0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n\n            dotProd += dyValue * avgMultiplier;\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
        }
        return AvgPool2DBackpropProgram2;
      }()
    );
    var AvgPool3DBackpropProgram = (
      /** @class */
      function() {
        function AvgPool3DBackpropProgram2(convInfo) {
          this.variableNames = ["dy"];
          this.outputShape = convInfo.inShape;
          var filterDepth = convInfo.filterDepth;
          var filterHeight = convInfo.filterHeight;
          var filterWidth = convInfo.filterWidth;
          var strideDepth = convInfo.strideDepth;
          var strideHeight = convInfo.strideHeight;
          var strideWidth = convInfo.strideWidth;
          var dilationDepth = convInfo.dilationDepth;
          var dilationHeight = convInfo.dilationHeight;
          var dilationWidth = convInfo.dilationWidth;
          var effectiveFilterDepth = convInfo.effectiveFilterDepth;
          var effectiveFilterHeight = convInfo.effectiveFilterHeight;
          var effectiveFilterWidth = convInfo.effectiveFilterWidth;
          var padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
          var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
          var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
          var avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);
          this.userCode = "\n      const ivec3 pads = ivec3(".concat(padFront, ", ").concat(padTop, ", ").concat(padLeft, ");\n      const float avgMultiplier = float(").concat(avgMultiplier, ");\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ").concat(effectiveFilterDepth, ";\n            wD += ").concat(dilationDepth, ") {\n          float dyD = float(dyDCorner + wD) / ").concat(strideDepth, ".0;\n\n          if (dyD < 0.0 || dyD >= ").concat(convInfo.outDepth, ".0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ").concat(effectiveFilterHeight, ";\n              wR += ").concat(dilationHeight, ") {\n            float dyR = float(dyRCorner + wR) / ").concat(strideHeight, ".0;\n\n            if (dyR < 0.0 || dyR >= ").concat(convInfo.outHeight, ".0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ").concat(effectiveFilterWidth, ";\n                wC += ").concat(dilationWidth, ") {\n              float dyC = float(dyCCorner + wC) / ").concat(strideWidth, ".0;\n\n              if (dyC < 0.0 || dyC >= ").concat(convInfo.outWidth, ".0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n\n              dotProd += dyValue * avgMultiplier;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
        }
        return AvgPool3DBackpropProgram2;
      }()
    );
    function avgPool3DGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, input = inputs.input;
      var x = input;
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      var dilations = [1, 1, 1];
      var convInfo = tf.backend_util.computePool3DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode);
      var avgPoolBackpropProgram = new AvgPool3DBackpropProgram(convInfo);
      return backend.runWebGLProgram(avgPoolBackpropProgram, [dy], x.dtype);
    }
    var avgPool3DGradConfig = {
      kernelName: tf.AvgPool3DGrad,
      backendName: "webgl",
      kernelFunc: avgPool3DGrad
    };
    function avgPoolGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, input = inputs.input;
      var x = input;
      assertNotComplex([dy, input], "avgPoolGrad");
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad;
      var convInfo = tf.backend_util.computePool2DInfo(x.shape, filterSize, strides, 1, pad);
      var avgPoolBackpropProgram = new AvgPool2DBackpropProgram(convInfo);
      return backend.runWebGLProgram(avgPoolBackpropProgram, [dy], x.dtype);
    }
    var avgPoolGradConfig = {
      kernelName: tf.AvgPoolGrad,
      backendName: "webgl",
      kernelFunc: avgPoolGrad
    };
    function batchMatMul(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var a = inputs.a, b = inputs.b;
      var transposeA = attrs.transposeA, transposeB = attrs.transposeB;
      return batchMatMulImpl({ a, b, transposeA, transposeB, backend });
    }
    var batchMatMulConfig = {
      kernelName: tf.BatchMatMul,
      backendName: "webgl",
      kernelFunc: batchMatMul
    };
    var BatchNormProgram = (
      /** @class */
      function() {
        function BatchNormProgram2(xShape, meanShape, varianceShape, offsetShape, scaleShape, varianceEpsilon) {
          this.outputShape = [];
          this.variableNames = ["x", "mean", "variance"];
          tf.backend_util.assertAndGetBroadcastShape(xShape, meanShape);
          tf.backend_util.assertAndGetBroadcastShape(xShape, varianceShape);
          var offsetSnippet = "0.0";
          if (offsetShape != null) {
            tf.backend_util.assertAndGetBroadcastShape(xShape, offsetShape);
            this.variableNames.push("offset");
            offsetSnippet = "getOffsetAtOutCoords()";
          }
          var scaleSnippet = "1.0";
          if (scaleShape != null) {
            tf.backend_util.assertAndGetBroadcastShape(xShape, scaleShape);
            this.variableNames.push("scale");
            scaleSnippet = "getScaleAtOutCoords()";
          }
          this.outputShape = xShape;
          this.userCode = "\n      void main() {\n        float x = getXAtOutCoords();\n        float mean = getMeanAtOutCoords();\n        float variance = getVarianceAtOutCoords();\n        float offset = ".concat(offsetSnippet, ";\n        float scale = ").concat(scaleSnippet, ";\n        float inv = scale * inversesqrt(variance + float(").concat(varianceEpsilon, "));\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\n      }\n    ");
        }
        return BatchNormProgram2;
      }()
    );
    var BatchNormPackedProgram = (
      /** @class */
      function() {
        function BatchNormPackedProgram2(xShape, meanShape, varianceShape, offsetShape, scaleShape, varianceEpsilon) {
          this.packedInputs = true;
          this.packedOutput = true;
          this.variableNames = ["x", "mean", "variance"];
          tf.backend_util.assertAndGetBroadcastShape(xShape, meanShape);
          tf.backend_util.assertAndGetBroadcastShape(xShape, varianceShape);
          var offsetSnippet = "vec4(0.0)";
          if (offsetShape != null) {
            tf.backend_util.assertAndGetBroadcastShape(xShape, offsetShape);
            this.variableNames.push("offset");
            offsetSnippet = "getOffsetAtOutCoords()";
          }
          var scaleSnippet = "vec4(1.0)";
          if (scaleShape != null) {
            tf.backend_util.assertAndGetBroadcastShape(xShape, scaleShape);
            this.variableNames.push("scale");
            scaleSnippet = "getScaleAtOutCoords()";
          }
          this.outputShape = xShape;
          this.userCode = "\n      void main() {\n        vec4 offset = ".concat(offsetSnippet, ";\n        vec4 scale = ").concat(scaleSnippet, ";\n\n        vec4 x = getXAtOutCoords();\n        vec4 mean = getMeanAtOutCoords();\n        vec4 variance = getVarianceAtOutCoords();\n\n        vec4 inv = scale * inversesqrt(variance + vec4(").concat(varianceEpsilon, "));\n\n        setOutput((x - mean) * inv + offset);\n      }\n    ");
        }
        return BatchNormPackedProgram2;
      }()
    );
    var batchNorm = function(_a2) {
      var inputs = _a2.inputs, backend = _a2.backend, attrs = _a2.attrs;
      var x = inputs.x, mean = inputs.mean, variance = inputs.variance, offset = inputs.offset, scale = inputs.scale;
      tf.util.assert(mean.shape.length === variance.shape.length, function() {
        return "Batch normalization gradient requires mean and variance to have equal ranks.";
      });
      tf.util.assert(offset == null || mean.shape.length === offset.shape.length, function() {
        return "Batch normalization gradient requires mean and offset to have equal ranks.";
      });
      tf.util.assert(scale == null || mean.shape.length === scale.shape.length, function() {
        return "Batch normalization gradient requires mean and scale to have equal ranks.";
      });
      var varianceEpsilon = attrs.varianceEpsilon;
      if (varianceEpsilon == null) {
        varianceEpsilon = 1e-3;
      }
      var finalInputs = [x, mean, variance];
      var offsetShape = null;
      if (offset != null) {
        offsetShape = offset.shape;
        finalInputs.push(offset);
      }
      var scaleShape = null;
      if (scale != null) {
        scaleShape = scale.shape;
        finalInputs.push(scale);
      }
      var program = tf.env().getBool("WEBGL_PACK_NORMALIZATION") ? new BatchNormPackedProgram(x.shape, mean.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon) : new BatchNormProgram(x.shape, mean.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon);
      var output = backend.runWebGLProgram(program, finalInputs, finalInputs[0].dtype);
      return output;
    };
    var batchNormConfig = {
      kernelName: tf.FusedBatchNorm,
      backendName: "webgl",
      kernelFunc: batchNorm
    };
    var SliceProgram = (
      /** @class */
      function() {
        function SliceProgram2(destSize) {
          this.variableNames = ["source"];
          this.outputShape = destSize;
          this.rank = destSize.length;
          var dtype = getCoordsDataType(this.rank);
          this.customUniforms = [{ name: "start", arrayIndex: this.rank, type: "int" }];
          var sourceCoords = getCoords$1(this.rank);
          var body;
          var coordSum = destSize.map(function(_, i) {
            return "sourceLoc.".concat(coords[i], " = start[").concat(i, "] + coords.").concat(coords[i], ";");
          });
          body = "\n        ".concat(dtype, " sourceLoc;\n        ").concat(dtype, " coords = getOutputCoords();\n        ").concat(coordSum.join("\n"), "\n      ");
          this.userCode = "\n      void main() {\n        ".concat(body, "\n        setOutput(getSource(").concat(sourceCoords, "));\n      }\n    ");
        }
        return SliceProgram2;
      }()
    );
    var coords = ["x", "y", "z", "w", "u", "v"];
    function getCoords$1(rank) {
      if (rank === 1) {
        return "sourceLoc";
      } else if (rank <= 6) {
        return coords.slice(0, rank).map(function(x) {
          return "sourceLoc." + x;
        }).join(",");
      } else {
        throw Error("Slicing for rank ".concat(rank, " is not yet supported"));
      }
    }
    var SlicePackedProgram = (
      /** @class */
      function() {
        function SlicePackedProgram2(destSize) {
          this.variableNames = ["source"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.outputShape = destSize;
          this.rank = destSize.length;
          this.customUniforms = [{ name: "start", arrayIndex: this.rank, type: "int" }];
          var dtype = getCoordsDataType(this.rank);
          var coords2 = getChannels("coords", this.rank);
          var sourceLoc = getChannels("sourceLoc", this.rank);
          var innerDims = this.rank === 1 ? "sourceLoc" : "vec2(".concat(sourceLoc.slice(-2).join(), ")");
          var getChannel = "getChannel(getSource(".concat(sourceLoc.join(), "), ").concat(innerDims, ")");
          var upperRow = "\n      result.x = ".concat(getChannel, ";\n      if (++").concat(coords2[this.rank - 1], " < ").concat(destSize[this.rank - 1], ") {\n        ++").concat(sourceLoc[this.rank - 1], ";\n        result.y = ").concat(getChannel, ";\n        --").concat(sourceLoc[this.rank - 1], ";\n      }\n    ");
          var lowerRow = this.rank === 1 ? "" : "\n      --".concat(coords2[this.rank - 1], ";\n      if (++").concat(coords2[this.rank - 2], " < ").concat(destSize[this.rank - 2], ") {\n        ++").concat(sourceLoc[this.rank - 2], ";\n        result.z = ").concat(getChannel, ";\n        if (++").concat(coords2[this.rank - 1], " < ").concat(destSize[this.rank - 1], ") {\n          ++").concat(sourceLoc[this.rank - 1], ";\n          result.w = ").concat(getChannel, ";\n        }\n      }\n    ");
          var sourceLocSetup = this.rank <= 4 ? "sourceLoc = coords +\n            ".concat(dtype, "(").concat(destSize.map(function(_, i) {
            return "start[".concat(i, "]");
          }).join(), ");") : destSize.map(function(_, i) {
            return "".concat(sourceLoc[i], " = ").concat(coords2[i], " + start[").concat(i, "];");
          }).join("\n");
          this.userCode = "\n      void main() {\n        ".concat(dtype, " coords = getOutputCoords();\n        ").concat(dtype, " sourceLoc;\n        ").concat(sourceLocSetup, "\n        vec4 result = vec4(0.);\n        ").concat(upperRow, "\n        ").concat(lowerRow, "\n        setOutput(result);\n      }\n    ");
        }
        return SlicePackedProgram2;
      }()
    );
    function shallowSlice(x, begin, size, backend) {
      var xTexData = backend.texData.get(x.dataId);
      var t = backend.makeTensorInfo(size, x.dtype);
      var newTexData = backend.texData.get(t.dataId);
      Object.assign(newTexData, xTexData);
      newTexData.refCount = 1;
      newTexData.shape = size;
      newTexData.dtype = x.dtype;
      var flatOffset = tf.slice_util.computeFlatOffset(begin, tf.util.computeStrides(x.shape));
      if (xTexData.slice) {
        flatOffset += xTexData.slice.flatOffset;
      }
      newTexData.slice = {
        flatOffset,
        // Point to the original dataId, which is used to do ref counting.
        origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId
      };
      var refCount = backend.dataRefCount.get(newTexData.slice.origDataId) || 1;
      backend.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);
      return t;
    }
    function slice(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var begin = attrs.begin, size = attrs.size;
      var _a2 = __read(tf.slice_util.parseSliceParams(x, begin, size), 2), $begin = _a2[0], $size = _a2[1];
      tf.slice_util.assertParamsValid(x, $begin, $size);
      if (tf.util.sizeFromShape($size) === 0) {
        return backend.makeTensorInfo($size, x.dtype, []);
      }
      if (backend.shouldExecuteOnCPU([x]) || x.dtype === "string") {
        var xTexData = backend.texData.get(x.dataId);
        var outValues = sliceImplCPU(xTexData.values, $begin, $size, x.shape, x.dtype);
        return backend.makeTensorInfo($size, x.dtype, outValues);
      }
      var isPacked = backend.texData.get(x.dataId).isPacked;
      var isContinous = tf.slice_util.isSliceContinous(x.shape, $begin, $size);
      if (isPacked || !isContinous) {
        var program = tf.env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new SlicePackedProgram($size) : new SliceProgram($size);
        var customValues = [$begin];
        return backend.runWebGLProgram(program, [x], x.dtype, customValues);
      }
      backend.uploadToGPU(x.dataId);
      return shallowSlice(x, $begin, $size, backend);
    }
    var sliceConfig = {
      kernelName: tf.Slice,
      backendName: "webgl",
      kernelFunc: slice
    };
    var batchToSpaceND = function(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var blockShape = attrs.blockShape, crops = attrs.crops;
      tf.util.assert(x.shape.length <= 4, function() {
        return "batchToSpaceND for rank > 4 with a WebGL backend not implemented yet";
      });
      var prod2 = blockShape.reduce(function(a, b) {
        return a * b;
      });
      var reshaped = tf.backend_util.getReshaped(x.shape, blockShape, prod2);
      var permuted = tf.backend_util.getPermuted(reshaped.length, blockShape.length);
      var reshapedPermuted = tf.backend_util.getReshapedPermuted(x.shape, blockShape, prod2);
      var sliceBeginCoords = tf.backend_util.getSliceBeginCoords(crops, blockShape.length);
      var sliceSize = tf.backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);
      var toDispose = [];
      var reshapedIntermediate = reshape({ inputs: { x }, backend, attrs: { shape: reshaped } });
      var transposedIntermediate = transpose({ inputs: { x: reshapedIntermediate }, backend, attrs: { perm: permuted } });
      var reshapedIntermediate2 = reshape({
        inputs: { x: transposedIntermediate },
        backend,
        attrs: { shape: reshapedPermuted }
      });
      var sliced = slice({
        inputs: { x: reshapedIntermediate2 },
        backend,
        attrs: { begin: sliceBeginCoords, size: sliceSize }
      });
      toDispose.push(reshapedIntermediate);
      toDispose.push(transposedIntermediate);
      toDispose.push(reshapedIntermediate2);
      toDispose.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return sliced;
    };
    var batchToSpaceNDConfig = {
      kernelName: tf.BatchToSpaceND,
      backendName: "webgl",
      kernelFunc: batchToSpaceND
    };
    function bincount(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, weights = inputs.weights;
      var size = attrs.size;
      var xVals = backend.readSync(x.dataId);
      var weightsVals = backend.readSync(weights.dataId);
      var outVals = bincountImplCPU(xVals, weightsVals, weights.dtype, weights.shape, size);
      return backend.makeTensorInfo([size], weights.dtype, outVals);
    }
    var bincountConfig = {
      kernelName: tf.Bincount,
      backendName: "webgl",
      kernelFunc: bincount
    };
    var BITWISEAND = "\n  int r = int(a.r) & int(b.r);\n  int g = int(a.g) & int(b.g);\n  int rb = int(a.b) & int(b.b);\n  int ra = int(a.a) & int(b.a);\n  return vec4(r, g, rb, ra);\n";
    var BITWISEAND_UNPACKED = "\n  return float(int(a.r) & int(b.r));\n";
    function bitwiseAnd(args) {
      var inputs = args.inputs, backend = args.backend;
      var a = inputs.a, b = inputs.b;
      var shouldUsePackedProgram = tf.env().getBool("WEBGL_PACK_BINARY_OPERATIONS");
      var versionNumber = tf.env().getNumber("WEBGL_VERSION");
      if (backend.shouldExecuteOnCPU([a, b]) || versionNumber === 1) {
        var aVals = backend.texData.get(a.dataId).values;
        var bVals = backend.texData.get(b.dataId).values;
        var _a2 = __read(bitwiseAndImplCPU(a.shape, b.shape, aVals, bVals, a.dtype), 2), outValues = _a2[0], outShape = _a2[1];
        var out = backend.makeTensorInfo(outShape, a.dtype);
        var outData = backend.texData.get(out.dataId);
        outData.values = outValues;
        return out;
      }
      var program;
      if (shouldUsePackedProgram) {
        program = new BinaryOpPackedProgram(BITWISEAND, a.shape, b.shape, false);
      } else {
        program = new BinaryOpProgram(BITWISEAND_UNPACKED, a.shape, b.shape);
      }
      return backend.runWebGLProgram(program, [a, b], a.dtype);
    }
    var bitwiseAndConfig = {
      kernelName: tf.BitwiseAnd,
      backendName: "webgl",
      kernelFunc: bitwiseAnd
    };
    function broadcastArgs(args) {
      var inputs = args.inputs, backend = args.backend;
      var s0 = inputs.s0, s1 = inputs.s1;
      var s0Vals = backend.readSync(s0.dataId);
      var s1Vals = backend.readSync(s1.dataId);
      var broadcastShape = tf.backend_util.assertAndGetBroadcastShape(Array.from(s0Vals), Array.from(s1Vals));
      return backend.makeTensorInfo([broadcastShape.length], "int32", Int32Array.from(broadcastShape));
    }
    var broadcastArgsConfig = {
      kernelName: tf.BroadcastArgs,
      backendName: "webgl",
      kernelFunc: broadcastArgs
    };
    var NOT_EQUAL = "return float(a != b);";
    var notEqual = binaryKernelFunc({ opSnippet: NOT_EQUAL, cpuKernelImpl: notEqualImplCPU, dtype: "bool" });
    var notEqualConfig = {
      kernelName: tf.NotEqual,
      backendName: "webgl",
      kernelFunc: notEqual
    };
    function real(args) {
      var inputs = args.inputs, backend = args.backend;
      var input = inputs.input;
      var inputData = backend.texData.get(input.dataId);
      return identity({ inputs: { x: inputData.complexTensorInfos.real }, backend });
    }
    var realConfig = {
      kernelName: tf.Real,
      backendName: "webgl",
      kernelFunc: real
    };
    var TO_INT = "return float(int(x));";
    function int(input, backend) {
      var program = new UnaryOpProgram(input.shape, TO_INT);
      var output = backend.runWebGLProgram(program, [input], "int32");
      return { dataId: output.dataId, shape: output.shape, dtype: output.dtype };
    }
    function cast(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var dtype = attrs.dtype;
      if (dtype === "complex64") {
        if (x.dtype === "complex64") {
          return identity({ inputs: { x }, backend });
        }
        var zerosTensor = tf__namespace.zeros(x.shape);
        var floatX = cast({ inputs: { x }, backend, attrs: { dtype: "float32" } });
        var result = complex({ inputs: { real: floatX, imag: zerosTensor }, backend });
        zerosTensor.dispose();
        backend.disposeIntermediateTensorInfo(floatX);
        return result;
      }
      if (x.dtype === "complex64") {
        var realPart = real({ inputs: { input: x }, backend });
        var result = cast({ inputs: { x: realPart }, backend, attrs: { dtype } });
        backend.disposeIntermediateTensorInfo(realPart);
        return result;
      }
      if (!tf.util.hasEncodingLoss(x.dtype, dtype)) {
        var result = identity({ inputs: { x }, backend });
        return { dataId: result.dataId, shape: result.shape, dtype };
      }
      if (backend.shouldExecuteOnCPU([x])) {
        var values = backend.texData.get(x.dataId).values;
        var _a2 = __read(castImplCPU(values, x.shape, x.dtype, dtype), 3), resultShape = _a2[0], resultType = _a2[1], resultData = _a2[2];
        return backend.makeTensorInfo(resultShape, resultType, resultData);
      }
      if (dtype === "int32") {
        return int(x, backend);
      }
      if (dtype === "bool") {
        var zerosTensorInfo = backend.makeTensorInfo([], "bool", tf.util.getTypedArrayFromDType("bool", 1));
        var binaryInputs = { a: x, b: zerosTensorInfo };
        var result = notEqual({ inputs: binaryInputs, backend });
        backend.disposeIntermediateTensorInfo(zerosTensorInfo);
        return result;
      }
      throw new Error("Error in Cast: failed to cast ".concat(x.dtype, " to ").concat(dtype));
    }
    var castConfig = {
      kernelName: tf.Cast,
      backendName: "webgl",
      kernelFunc: cast
    };
    var CEIL = "return ceil(x);";
    var ceil = unaryKernelFunc({ opSnippet: CEIL, packedOpSnippet: CEIL, cpuKernelImpl: ceilImplCPU });
    var ceilConfig = {
      kernelName: tf.Ceil,
      backendName: "webgl",
      kernelFunc: ceil
    };
    var ClipProgram = (
      /** @class */
      function() {
        function ClipProgram2(aShape) {
          this.variableNames = ["A"];
          this.customUniforms = [
            { name: "minVal", type: "float" },
            { name: "maxVal", type: "float" }
          ];
          this.outputShape = aShape;
          this.userCode = "\n\n      void main() {\n        float value = getAAtOutCoords();\n        if (isnan(value)) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, minVal, maxVal));\n      }\n    ";
        }
        return ClipProgram2;
      }()
    );
    var ClipPackedProgram = (
      /** @class */
      function() {
        function ClipPackedProgram2(aShape) {
          this.variableNames = ["A"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.customUniforms = [
            { name: "minVal", type: "float" },
            { name: "maxVal", type: "float" }
          ];
          this.outputShape = aShape;
          this.userCode = "\n      void main() {\n        vec4 value = getAAtOutCoords();\n\n        if (any(isnan(value))) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\n      }\n    ";
        }
        return ClipPackedProgram2;
      }()
    );
    function clipByValue(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var clipValueMin = attrs.clipValueMin, clipValueMax = attrs.clipValueMax;
      var program;
      if (tf.env().getBool("WEBGL_PACK_CLIP")) {
        program = new ClipPackedProgram(x.shape);
      } else {
        program = new ClipProgram(x.shape);
      }
      var customValues = [[clipValueMin], [clipValueMax]];
      return backend.runWebGLProgram(program, [x], x.dtype, customValues);
    }
    var clipByValueConfig = {
      kernelName: tf.ClipByValue,
      backendName: "webgl",
      kernelFunc: clipByValue
    };
    var ComplexAbsProgram = (
      /** @class */
      function() {
        function ComplexAbsProgram2(shape) {
          this.variableNames = ["real", "imag"];
          this.outputShape = shape;
          this.userCode = "\n      void main() {\n        float re = abs(getRealAtOutCoords());\n        float im = abs(getImagAtOutCoords());\n        float mx = max(re, im);\n\n        // sadly the length function in glsl is not underflow-safe\n        // (at least not on Intel GPUs). So the safe solution is\n        // to ensure underflow-safety in all cases.\n        setOutput(\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\n        );\n      }\n    ";
        }
        return ComplexAbsProgram2;
      }()
    );
    function makeComplexComponentTensorInfo(complexTensor, complexPart) {
      return {
        dataId: complexPart.dataId,
        dtype: complexPart.dtype,
        shape: complexTensor.shape
      };
    }
    function complexAbs(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x;
      var xData = backend.texData.get(x.dataId);
      var program = new ComplexAbsProgram(x.shape);
      var programInputs = [
        makeComplexComponentTensorInfo(x, xData.complexTensorInfos.real),
        makeComplexComponentTensorInfo(x, xData.complexTensorInfos.imag)
      ];
      return backend.runWebGLProgram(program, programInputs, programInputs[0].dtype);
    }
    var complexAbsConfig = {
      kernelName: tf.ComplexAbs,
      backendName: "webgl",
      kernelFunc: complexAbs
    };
    var ConcatProgram = (
      /** @class */
      function() {
        function ConcatProgram2(shapes) {
          this.outputShape = [];
          this.outputShape = tf.backend_util.computeOutShape(
            shapes,
            1
            /* axis */
          );
          this.variableNames = shapes.map(function(_, i2) {
            return "T".concat(i2);
          });
          var offsets = new Array(shapes.length - 1);
          offsets[0] = shapes[0][1];
          for (var i = 1; i < offsets.length; i++) {
            offsets[i] = offsets[i - 1] + shapes[i][1];
          }
          var snippets = ["if (yC < ".concat(offsets[0], ") setOutput(getT0(yR, yC));")];
          for (var i = 1; i < offsets.length; i++) {
            var shift = offsets[i - 1];
            snippets.push("else if (yC < ".concat(offsets[i], ") ") + "setOutput(getT".concat(i, "(yR, yC-").concat(shift, "));"));
          }
          var lastIndex = offsets.length;
          var lastShift = offsets[offsets.length - 1];
          snippets.push("else setOutput(getT".concat(lastIndex, "(yR, yC-").concat(lastShift, "));"));
          this.userCode = "\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int yR = coords.x;\n        int yC = coords.y;\n\n        ".concat(snippets.join("\n        "), "\n      }\n    ");
        }
        return ConcatProgram2;
      }()
    );
    var ConcatPackedProgram = (
      /** @class */
      function() {
        function ConcatPackedProgram2(shapes, axis) {
          this.packedInputs = true;
          this.packedOutput = true;
          this.outputShape = [];
          this.outputShape = tf.backend_util.computeOutShape(shapes, axis);
          var shape = this.outputShape;
          var rank = shape.length;
          var dtype = getCoordsDataType(rank);
          var coords2 = getChannels("coords", rank);
          var channels = ["x", "y", "z", "w", "u", "v"].slice(0, rank);
          this.variableNames = shapes.map(function(_, i2) {
            return "T".concat(i2);
          });
          var offsets = new Array(shapes.length - 1);
          offsets[0] = shapes[0][axis];
          for (var i = 1; i < offsets.length; i++) {
            offsets[i] = offsets[i - 1] + shapes[i][axis];
          }
          var channel = channels[axis];
          var lastChannels = channels.slice(-2);
          var allChannels = channels.join();
          var getValueSnippet = "if (".concat(channel, " < ").concat(offsets[0], ") {\n        return getChannel(\n            getT0(").concat(allChannels, "), vec2(").concat(lastChannels.join(), "));\n        }");
          for (var i = 1; i < offsets.length; i++) {
            var shift_1 = offsets[i - 1];
            getValueSnippet += "\n        if (".concat(channel, " < ").concat(offsets[i], "  && ").concat(channel, " >= ").concat(offsets[i - 1], ") {\n          return getChannel(\n            getT").concat(i, "(").concat(shiftedChannels(channels, channel, shift_1), "),\n            vec2(").concat(shiftedChannels(lastChannels, channel, shift_1), "));\n        }");
          }
          var lastIndex = offsets.length;
          var shift = offsets[offsets.length - 1];
          getValueSnippet += "\n        return getChannel(\n          getT".concat(lastIndex, "(").concat(shiftedChannels(channels, channel, shift), "),\n          vec2(").concat(shiftedChannels(lastChannels, channel, shift), "));");
          this.userCode = "\n      float getValue(".concat(channels.map(function(x) {
            return "int " + x;
          }), ") {\n        ").concat(getValueSnippet, "\n      }\n\n      void main() {\n        ").concat(dtype, " coords = getOutputCoords();\n        vec4 result = vec4(getValue(").concat(coords2, "), 0., 0., 0.);\n\n        ").concat(coords2[rank - 1], " = ").concat(coords2[rank - 1], " + 1;\n        if (").concat(coords2[rank - 1], " < ").concat(shape[rank - 1], ") {\n          result.g = getValue(").concat(coords2, ");\n        }\n\n        ").concat(coords2[rank - 2], " = ").concat(coords2[rank - 2], " + 1;\n        if (").concat(coords2[rank - 2], " < ").concat(shape[rank - 2], ") {\n          result.a = getValue(").concat(coords2, ");\n        }\n\n        ").concat(coords2[rank - 1], " = ").concat(coords2[rank - 1], " - 1;\n        if (").concat(coords2[rank - 2], " < ").concat(shape[rank - 2], " &&\n            ").concat(coords2[rank - 1], " < ").concat(shape[rank - 1], ") {\n          result.b = getValue(").concat(coords2, ");\n        }\n        setOutput(result);\n      }\n    ");
        }
        return ConcatPackedProgram2;
      }()
    );
    function shiftedChannels(channels, channel, shift) {
      var channelIdx = channels.indexOf(channel);
      var res = channels.map(function(c, idx) {
        if (idx === channelIdx) {
          return "".concat(c, " - ").concat(shift);
        } else {
          return c;
        }
      });
      return res.join();
    }
    function imag(args) {
      var inputs = args.inputs, backend = args.backend;
      var input = inputs.input;
      var inputData = backend.texData.get(input.dataId);
      return identity({ inputs: { x: inputData.complexTensorInfos.imag }, backend });
    }
    var imagConfig = {
      kernelName: tf.Imag,
      backendName: "webgl",
      kernelFunc: imag
    };
    function concatImpl(inputs, axis, backend) {
      var e_12, _a2;
      var dtype = inputs[0].dtype;
      if (dtype === "complex64") {
        var reals = inputs.map(function(t) {
          return real({ inputs: { input: t }, backend });
        });
        var imags = inputs.map(function(t) {
          return imag({ inputs: { input: t }, backend });
        });
        var realConcated = concatImpl(reals, axis, backend);
        var imagConcated = concatImpl(imags, axis, backend);
        var result_1 = complex({ inputs: { real: realConcated, imag: imagConcated }, backend });
        reals.forEach(function(r) {
          return backend.disposeIntermediateTensorInfo(r);
        });
        imags.forEach(function(i2) {
          return backend.disposeIntermediateTensorInfo(i2);
        });
        backend.disposeIntermediateTensorInfo(realConcated);
        backend.disposeIntermediateTensorInfo(imagConcated);
        return result_1;
      }
      var runOnCpu = backend.shouldExecuteOnCPU(inputs);
      if (dtype === "string") {
        runOnCpu = true;
      }
      if (runOnCpu) {
        var tensors2D_1 = inputs.map(function(t) {
          var innerSize = tf.util.sizeFromShape(t.shape.slice(axis));
          var shape = [-1, innerSize];
          return reshape({ inputs: { x: t }, backend, attrs: { shape } });
        });
        var inputsValShapes = tensors2D_1.map(function(t) {
          return { vals: backend.readSync(t.dataId), shape: t.shape };
        });
        var outShape_1 = tf.backend_util.computeOutShape(
          tensors2D_1.map(function(t) {
            return t.shape;
          }),
          1
          /* axis */
        );
        var simplyConcat = tensors2D_1[0].shape[0] === 1;
        var outVals = concatImplCPU(inputsValShapes, outShape_1, dtype, simplyConcat);
        var finalOutShape = tf.backend_util.computeOutShape(inputs.map(function(t) {
          return t.shape;
        }), axis);
        var outInfo = backend.makeTensorInfo(finalOutShape, dtype, outVals);
        tensors2D_1.forEach(function(t) {
          return backend.disposeIntermediateTensorInfo(t);
        });
        return outInfo;
      }
      var $inputs = inputs.filter(function(t) {
        return tf.util.sizeFromShape(t.shape) > 0;
      });
      var shouldPack = tf.env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") && $inputs[0].shape.length > 1;
      if ($inputs.length === 1) {
        var program_1 = shouldPack ? new UnaryOpProgram(inputs[0].shape, CLONE) : new UnaryOpPackedProgram(inputs[0].shape, CLONE);
        return backend.runWebGLProgram(program_1, inputs, dtype);
      }
      var maxTexturesInShader = tf.env().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER");
      if ($inputs.length > maxTexturesInShader) {
        var reducedInputs = [];
        for (var i = 0; i < $inputs.length; i += maxTexturesInShader) {
          var subArray = $inputs.slice(i, i + maxTexturesInShader);
          reducedInputs.push(concatImpl(subArray, axis, backend));
        }
        var result_2 = concatImpl(reducedInputs, axis, backend);
        try {
          for (var reducedInputs_1 = __values(reducedInputs), reducedInputs_1_1 = reducedInputs_1.next(); !reducedInputs_1_1.done; reducedInputs_1_1 = reducedInputs_1.next()) {
            var i = reducedInputs_1_1.value;
            backend.disposeIntermediateTensorInfo(i);
          }
        } catch (e_1_1) {
          e_12 = { error: e_1_1 };
        } finally {
          try {
            if (reducedInputs_1_1 && !reducedInputs_1_1.done && (_a2 = reducedInputs_1.return))
              _a2.call(reducedInputs_1);
          } finally {
            if (e_12)
              throw e_12.error;
          }
        }
        return result_2;
      }
      if (shouldPack) {
        var program_2 = new ConcatPackedProgram($inputs.map(function(t) {
          return t.shape;
        }), axis);
        return backend.runWebGLProgram(program_2, $inputs, dtype);
      }
      var _b = computeTensors2D($inputs, axis, backend), tensors2D = _b.tensors2D, outShape = _b.outShape;
      var program = new ConcatProgram(tensors2D.map(function(t) {
        return t.shape;
      }));
      var result = backend.runWebGLProgram(program, tensors2D, dtype);
      tensors2D.forEach(function(r) {
        return backend.disposeIntermediateTensorInfo(r);
      });
      var reshapedResult = reshape({ inputs: { x: result }, attrs: { shape: outShape }, backend });
      backend.disposeIntermediateTensorInfo(result);
      return reshapedResult;
    }
    function computeTensors2D(inputs, axis, backend) {
      var outShape = tf.backend_util.computeOutShape(inputs.map(function(t) {
        return t.shape;
      }), axis);
      var tensors2D = inputs.map(function(x) {
        return reshape({
          inputs: { x },
          attrs: { shape: [-1, tf.util.sizeFromShape(x.shape.slice(axis))] },
          backend
        });
      });
      return { tensors2D, outShape };
    }
    function concat(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var axis = attrs.axis;
      var $axis = tf.util.parseAxisParam(axis, inputs[0].shape)[0];
      var shapes = inputs.map(function(t) {
        return t.shape;
      });
      tf.backend_util.assertParamsConsistent(shapes, $axis);
      var outShape = tf.backend_util.computeOutShape(inputs.map(function(t) {
        return t.shape;
      }), $axis);
      if (tf.util.sizeFromShape(outShape) === 0) {
        return backend.makeTensorInfo(outShape, inputs[0].dtype, []);
      }
      var $inputs = inputs.filter(function(t) {
        return tf.util.sizeFromShape(t.shape) > 0;
      });
      if ($inputs.length === 1) {
        return identity({ inputs: { x: $inputs[0] }, backend });
      }
      return concatImpl($inputs, $axis, backend);
    }
    var concatConfig = {
      kernelName: tf.Concat,
      backendName: "webgl",
      kernelFunc: concat
    };
    var Conv2DProgram = (
      /** @class */
      function() {
        function Conv2DProgram2(convInfo, addBias, activation, hasPreluActivationWeights, hasLeakyreluAlpha) {
          if (addBias === void 0) {
            addBias = false;
          }
          if (activation === void 0) {
            activation = null;
          }
          if (hasPreluActivationWeights === void 0) {
            hasPreluActivationWeights = false;
          }
          if (hasLeakyreluAlpha === void 0) {
            hasLeakyreluAlpha = false;
          }
          this.variableNames = ["x", "W"];
          this.outputShape = convInfo.outShape;
          var padTop = convInfo.padInfo.top;
          var padLeft = convInfo.padInfo.left;
          var strideHeight = convInfo.strideHeight;
          var strideWidth = convInfo.strideWidth;
          var dilationHeight = convInfo.dilationHeight;
          var dilationWidth = convInfo.dilationWidth;
          var filterHeight = convInfo.filterHeight;
          var filterWidth = convInfo.filterWidth;
          var inputDepthNearestVec4 = Math.floor(convInfo.inChannels / 4) * 4;
          var inputDepthVec4Remainder = convInfo.inChannels % 4;
          var isChannelsLast = convInfo.dataFormat === "channelsLast";
          var rowDim = isChannelsLast ? 1 : 2;
          var colDim = isChannelsLast ? 2 : 3;
          var channelDim = isChannelsLast ? 3 : 1;
          var activationSnippet = "", applyActivationSnippet = "";
          if (activation) {
            if (hasPreluActivationWeights) {
              activationSnippet = "float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ".concat(activation, "\n        }");
            } else if (hasLeakyreluAlpha) {
              activationSnippet = "float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ".concat(activation, "\n        }");
            } else {
              activationSnippet = "\n          float activation(float x) {\n            ".concat(activation, "\n          }\n        ");
            }
            applyActivationSnippet = "result = activation(result);";
          }
          var addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
          if (addBias) {
            this.variableNames.push("bias");
          }
          if (hasPreluActivationWeights) {
            this.variableNames.push("preluActivationWeights");
          }
          if (hasLeakyreluAlpha) {
            this.variableNames.push("leakyreluAlpha");
          }
          this.userCode = "\n      ".concat(activationSnippet, "\n\n      const ivec2 strides = ivec2(").concat(strideHeight, ", ").concat(strideWidth, ");\n      const ivec2 pads = ivec2(").concat(padTop, ", ").concat(padLeft, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d2 = coords[").concat(channelDim, "];\n\n        ivec2 xRCCorner =\n            ivec2(coords[").concat(rowDim, "], coords[").concat(colDim, "]) * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ").concat(filterHeight, "; wR++) {\n          int xR = xRCorner + wR * ").concat(dilationHeight, ";\n\n          if (xR < 0 || xR >= ").concat(convInfo.inHeight, ") {\n            continue;\n          }\n\n          for (int wC = 0; wC < ").concat(filterWidth, "; wC++) {\n            int xC = xCCorner + wC * ").concat(dilationWidth, ";\n\n            if (xC < 0 || xC >= ").concat(convInfo.inWidth, ") {\n              continue;\n            }\n\n            for (int d1 = 0; d1 < ").concat(inputDepthNearestVec4, "; d1 += 4) {\n              vec4 wValues = vec4(\n                getW(wR, wC, d1, d2),\n                getW(wR, wC, d1 + 1, d2),\n                getW(wR, wC, d1 + 2, d2),\n                getW(wR, wC, d1 + 3, d2)\n              );\n\n              if (").concat(isChannelsLast, ") {\n                vec4 xValues = vec4(\n                  getX(batch, xR, xC, d1),\n                  getX(batch, xR, xC, d1 + 1),\n                  getX(batch, xR, xC, d1 + 2),\n                  getX(batch, xR, xC, d1 + 3)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec4 xValues = vec4(\n                  getX(batch, d1, xR, xC),\n                  getX(batch, d1 + 1, xR, xC),\n                  getX(batch, d1 + 2, xR, xC),\n                  getX(batch, d1 + 3, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n\n            if (").concat(inputDepthVec4Remainder === 1, ") {\n\n              if (").concat(isChannelsLast, ") {\n                dotProd +=\n                    getX(batch, xR, xC, ").concat(inputDepthNearestVec4, ") *\n                    getW(wR, wC, ").concat(inputDepthNearestVec4, ", d2);\n              } else {\n                dotProd +=\n                    getX(batch, ").concat(inputDepthNearestVec4, ", xR, xC) *\n                    getW(wR, wC, ").concat(inputDepthNearestVec4, ", d2);\n              }\n\n            } else if (").concat(inputDepthVec4Remainder === 2, ") {\n              vec2 wValues = vec2(\n                getW(wR, wC, ").concat(inputDepthNearestVec4, ", d2),\n                getW(wR, wC, ").concat(inputDepthNearestVec4, " + 1, d2)\n              );\n\n              if (").concat(isChannelsLast, ") {\n                vec2 xValues = vec2(\n                  getX(batch, xR, xC, ").concat(inputDepthNearestVec4, "),\n                  getX(batch, xR, xC, ").concat(inputDepthNearestVec4, " + 1)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec2 xValues = vec2(\n                  getX(batch, ").concat(inputDepthNearestVec4, ", xR, xC),\n                  getX(batch, ").concat(inputDepthNearestVec4, " + 1, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            } else if (").concat(inputDepthVec4Remainder === 3, ") {\n              vec3 wValues = vec3(\n                getW(wR, wC, ").concat(inputDepthNearestVec4, ", d2),\n                getW(wR, wC, ").concat(inputDepthNearestVec4, " + 1, d2),\n                getW(wR, wC, ").concat(inputDepthNearestVec4, " + 2, d2)\n              );\n\n              if (").concat(isChannelsLast, ") {\n                vec3 xValues = vec3(\n                  getX(batch, xR, xC, ").concat(inputDepthNearestVec4, "),\n                  getX(batch, xR, xC, ").concat(inputDepthNearestVec4, " + 1),\n                  getX(batch, xR, xC, ").concat(inputDepthNearestVec4, " + 2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec3 xValues = vec3(\n                  getX(batch, ").concat(inputDepthNearestVec4, ", xR, xC),\n                  getX(batch, ").concat(inputDepthNearestVec4, " + 1, xR, xC),\n                  getX(batch, ").concat(inputDepthNearestVec4, " + 2, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            }\n          }\n        }\n\n        float result = dotProd;\n        ").concat(addBiasSnippet, "\n        ").concat(applyActivationSnippet, "\n        setOutput(result);\n      }\n    ");
        }
        return Conv2DProgram2;
      }()
    );
    var Conv3DProgram = (
      /** @class */
      function() {
        function Conv3DProgram2(convInfo) {
          this.variableNames = ["x", "W"];
          this.outputShape = convInfo.outShape;
          var padFront = convInfo.padInfo.front;
          var padTop = convInfo.padInfo.top;
          var padLeft = convInfo.padInfo.left;
          var strideDepth = convInfo.strideDepth;
          var strideHeight = convInfo.strideHeight;
          var strideWidth = convInfo.strideWidth;
          var dilationDepth = convInfo.dilationDepth;
          var dilationHeight = convInfo.dilationHeight;
          var dilationWidth = convInfo.dilationWidth;
          var filterDepth = convInfo.filterDepth;
          var filterHeight = convInfo.filterHeight;
          var filterWidth = convInfo.filterWidth;
          var inputDepthNearestVec4 = Math.floor(convInfo.inChannels / 4) * 4;
          var inputDepthVec4Remainder = convInfo.inChannels % 4;
          this.userCode = "\n      const ivec3 strides = ivec3(".concat(strideDepth, ", ").concat(strideHeight, ", ").concat(strideWidth, ");\n      const ivec3 pads = ivec3(").concat(padFront, ", ").concat(padTop, ", ").concat(padLeft, ");\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d2 = coords.u;\n\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xFCorner = xFRCCorner.x;\n        int xRCorner = xFRCCorner.y;\n        int xCCorner = xFRCCorner.z;\n\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\n        // values in that axis.\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ").concat(filterDepth, "; wF++) {\n          int xF = xFCorner + wF * ").concat(dilationDepth, ";\n\n          if (xF < 0 || xF >= ").concat(convInfo.inDepth, ") {\n            continue;\n          }\n\n          for (int wR = 0; wR < ").concat(filterHeight, "; wR++) {\n            int xR = xRCorner + wR * ").concat(dilationHeight, ";\n\n            if (xR < 0 || xR >= ").concat(convInfo.inHeight, ") {\n              continue;\n            }\n\n            for (int wC = 0; wC < ").concat(filterWidth, "; wC++) {\n              int xC = xCCorner + wC * ").concat(dilationWidth, ";\n\n              if (xC < 0 || xC >= ").concat(convInfo.inWidth, ") {\n                continue;\n              }\n\n              for (int d1 = 0; d1 < ").concat(inputDepthNearestVec4, "; d1 += 4) {\n                vec4 xValues = vec4(\n                  getX(batch, xF, xR, xC, d1),\n                  getX(batch, xF, xR, xC, d1 + 1),\n                  getX(batch, xF, xR, xC, d1 + 2),\n                  getX(batch, xF, xR, xC, d1 + 3)\n                );\n                vec4 wValues = vec4(\n                  getW(wF, wR, wC, d1, d2),\n                  getW(wF, wR, wC, d1 + 1, d2),\n                  getW(wF, wR, wC, d1 + 2, d2),\n                  getW(wF, wR, wC, d1 + 3, d2)\n                );\n\n                dotProd += dot(xValues, wValues);\n              }\n\n              if (").concat(inputDepthVec4Remainder === 1, ") {\n                dotProd +=\n                  getX(batch, xF, xR, xC, ").concat(inputDepthNearestVec4, ") *\n                  getW(wF, wR, wC, ").concat(inputDepthNearestVec4, ", d2);\n              } else if (").concat(inputDepthVec4Remainder === 2, ") {\n                vec2 xValues = vec2(\n                  getX(batch, xF, xR, xC, ").concat(inputDepthNearestVec4, "),\n                  getX(batch, xF, xR, xC, ").concat(inputDepthNearestVec4, " + 1)\n                );\n                vec2 wValues = vec2(\n                  getW(wF, wR, wC, ").concat(inputDepthNearestVec4, ", d2),\n                  getW(wF, wR, wC, ").concat(inputDepthNearestVec4, " + 1, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else if (").concat(inputDepthVec4Remainder === 3, ") {\n                vec3 xValues = vec3(\n                  getX(batch, xF, xR, xC, ").concat(inputDepthNearestVec4, "),\n                  getX(batch, xF, xR, xC, ").concat(inputDepthNearestVec4, " + 1),\n                  getX(batch, xF, xR, xC, ").concat(inputDepthNearestVec4, " + 2)\n                );\n                vec3 wValues = vec3(\n                  getW(wF, wR, wC, ").concat(inputDepthNearestVec4, ", d2),\n                  getW(wF, wR, wC, ").concat(inputDepthNearestVec4, " + 1, d2),\n                  getW(wF, wR, wC, ").concat(inputDepthNearestVec4, " + 2, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
        }
        return Conv3DProgram2;
      }()
    );
    var Conv2DPackedProgram = (
      /** @class */
      function() {
        function Conv2DPackedProgram2(convInfo, addBias, activation, hasPreluActivation, hasLeakyReluAlpha) {
          if (addBias === void 0) {
            addBias = false;
          }
          if (activation === void 0) {
            activation = null;
          }
          if (hasPreluActivation === void 0) {
            hasPreluActivation = false;
          }
          if (hasLeakyReluAlpha === void 0) {
            hasLeakyReluAlpha = false;
          }
          this.variableNames = ["x", "W"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.customUniforms = [
            { name: "pads", type: "ivec2" },
            { name: "strides", type: "ivec2" },
            { name: "dilations", type: "ivec2" },
            { name: "inDims", type: "ivec2" }
          ];
          this.outputShape = convInfo.outShape;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          var padLeft = convInfo.padInfo.left;
          var strideWidth = convInfo.strideWidth;
          var dilationWidth = convInfo.dilationWidth;
          var filterHeight = convInfo.filterHeight;
          var filterWidth = convInfo.filterWidth;
          var texelsAcross = filterWidth;
          var mainLoop = "\n       int xR; int xC; int xCOffset;\n       vec4 wTexel; vec4 previous; vec4 final;";
          for (var c = 0; c < filterWidth; c++) {
            mainLoop += "\n           vec4 xTexelC".concat(c * 2, ";\n           int xTexelC").concat(c * 2, "Ready;\n           vec4 xTexelC").concat(c * 2 + 1, ";\n           int xTexelC").concat(c * 2 + 1, "Ready;\n           vec4 xC").concat(c, ";");
          }
          mainLoop += "\n     for (int r = 0; r < ".concat(filterHeight, "; r++) {\n      for (int d1 = 0; d1 < ").concat(convInfo.inChannels, "; d1 += 2) {\n       ");
          for (var c = 0; c < filterWidth; c++) {
            mainLoop += "\n           xTexelC".concat(c * 2, " = vec4(0.0);\n           xTexelC").concat(c * 2, "Ready = 0;\n           xTexelC").concat(c * 2 + 1, " = vec4(0.0);\n           xTexelC").concat(c * 2 + 1, "Ready = 0;\n           xC").concat(c, " = vec4(0.0);");
          }
          mainLoop += "\n         xR = xRCorner + r * dilations[0];\n         if (xR >=0 && xR < inDims[0]) {\n       ";
          for (var texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {
            var colIndex = texelC * 2;
            mainLoop += "\n           xC = xCCorner + ".concat(colIndex * dilationWidth, ";\n           ");
            if (strideWidth === 1) {
              if (colIndex < filterWidth) {
                if (padLeft % 2 === 1) {
                  mainLoop += "\n                 xCOffset = xC + 1;\n                 if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC".concat(colIndex, "Ready == 0) {\n                   xTexelC").concat(colIndex, " = getX(batch, xR, xCOffset, d1);\n\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC").concat(colIndex, ".zw = vec2(0.0);\n                   }\n                   xTexelC").concat(colIndex, "Ready = 1;\n                 }\n               ");
                  if (dilationWidth === 1 && colIndex > 0) {
                    mainLoop += "\n                 xC".concat(colIndex, " = vec4(xTexelC").concat(colIndex - 2, ".zw, xTexelC").concat(colIndex, ".xy);\n                 ");
                  } else {
                    mainLoop += "\n                   xCOffset = xC + 1 - 2;\n\n                   if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                     previous = getX(batch, xR, xCOffset, d1);\n\n                     // Need to manually clear unused channels in case\n                     // we're reading from recycled texture.\n                     if (xCOffset + 1 >= inDims[1]) {\n                       previous.zw = vec2(0.0);\n                     }\n\n                     xC".concat(colIndex, " = vec4(previous.zw, xTexelC").concat(colIndex, ".xy);\n                   } else {\n                     xC").concat(colIndex, " = vec4(0.0, 0.0, xTexelC").concat(colIndex, ".xy);\n                   }\n                   ");
                  }
                } else {
                  mainLoop += "\n                 if (xC >= 0 && xC < inDims[1] && xTexelC".concat(colIndex, "Ready == 0) {\n                   xTexelC").concat(colIndex, " = getX(batch, xR, xC, d1);\n                   if (xC + 1 >= inDims[1]) {\n                     xTexelC").concat(colIndex, ".zw = vec2(0.0);\n                   }\n                   xTexelC").concat(colIndex, "Ready = 1;\n                 }\n\n                 xC").concat(colIndex, " = xTexelC").concat(colIndex, ";\n                 ");
                }
                if (colIndex + 1 < filterWidth) {
                  var nextTexelOffset = padLeft % 2 === 0 ? tf.util.nearestLargerEven(dilationWidth) : dilationWidth;
                  if (dilationWidth % 2 === 0 && padLeft % 2 === 1 || dilationWidth % 2 !== 0 && padLeft % 2 !== 1) {
                    mainLoop += "\n                   xCOffset = xC + imod(pads[1], 2) + ".concat(nextTexelOffset, ";\n\n                   if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC").concat(colIndex + 1, "Ready == 0) {\n                     xTexelC").concat(colIndex + 1, " = getX(batch, xR, xCOffset, d1);\n\n                     // Need to manually clear unused channels in case\n                     // we're reading from recycled texture.\n                     if (xCOffset + 1 >= inDims[1]) {\n                       xTexelC").concat(colIndex + 1, ".zw = vec2(0.0);\n                     }\n                     xTexelC").concat(colIndex + 1, "Ready = 1;\n                   }\n                   ");
                    if (dilationWidth > 1) {
                      mainLoop += "\n                     xCOffset -= 2;\n                     if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                      previous = getX(batch, xR, xCOffset, d1);\n                      xC".concat(colIndex + 1, " = vec4(previous.zw, xTexelC").concat(colIndex + 1, ".xy);\n                     } else {\n                      xC").concat(colIndex + 1, " = vec4(0.0, 0.0, xTexelC").concat(colIndex + 1, ".xy);\n                     }\n                     ");
                    } else {
                      mainLoop += "\n                     xC".concat(colIndex + 1, " = vec4(xTexelC").concat(colIndex, ".zw, xTexelC").concat(colIndex + 1, ".xy);\n                     ");
                    }
                  } else {
                    if (nextTexelOffset === 1) {
                      mainLoop += "\n                     xC".concat(colIndex + 1, " = xTexelC").concat(colIndex, ";\n                     ");
                    } else {
                      mainLoop += "\n                     xCOffset = xC + ".concat(nextTexelOffset, ";\n\n                     if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC").concat(colIndex + 1, "Ready == 0) {\n                       xTexelC").concat(colIndex + 1, " = getX(batch, xR, xCOffset, d1);\n                       if (xCOffset + 1 >= inDims[1]) {\n                         xTexelC").concat(colIndex + 1, ".zw = vec2(0.0);\n                       }\n                       xTexelC").concat(colIndex + 1, "Ready = 1;\n                     }\n\n                     xC").concat(colIndex + 1, " = xTexelC").concat(colIndex + 1, ";\n                     ");
                    }
                  }
                }
              }
            } else {
              if (colIndex < filterWidth) {
                if (padLeft % 2 === 1) {
                  mainLoop += "\n                 xCOffset = xC + 1 - strides[1];\n                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC".concat(colIndex, "Ready == 0) {\n                   xTexelC").concat(colIndex, " = getX(batch, xR, xCOffset, d1);\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC").concat(colIndex, ".zw = vec2(0.0);\n                   }\n                   xTexelC").concat(colIndex, "Ready = 1;\n                 }\n\n                 if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC").concat(colIndex + 1, "Ready == 0) {\n                   xTexelC").concat(colIndex + 1, " = getX(batch, xR, xC + 1, d1);\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xC + 2 >= inDims[1]) {\n                     xTexelC").concat(colIndex + 1, ".zw = vec2(0.0);\n                   }\n                   xTexelC").concat(colIndex + 1, "Ready = 1;\n                 }\n\n                 xC").concat(colIndex, " = vec4(xTexelC").concat(colIndex, ".zw, xTexelC").concat(colIndex + 1, ".zw);\n               ");
                  if (colIndex + 1 < filterWidth) {
                    mainLoop += "\n                   final = vec4(0.0);\n                   xCOffset = xC + 1 + strides[1];\n                   if(xCOffset >= 0 && xCOffset < inDims[1]) {\n                     final = getX(batch, xR, xCOffset, d1);\n                   }\n                   xC".concat(colIndex + 1, " = vec4(xTexelC").concat(colIndex + 1, ".xy, final.xy);\n                 ");
                  }
                } else {
                  mainLoop += "\n                 if(xC >= 0 && xC < inDims[1] && xTexelC".concat(colIndex, "Ready == 0) {\n                   xTexelC").concat(colIndex, " = getX(batch, xR, xC, d1);\n                   if (xC + 1 >= inDims[1]) {\n                     xTexelC").concat(colIndex, ".zw = vec2(0.0);\n                   }\n                   xTexelC").concat(colIndex, "Ready = 1;\n                 }\n\n                 xCOffset = xC + strides[1];\n                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC").concat(colIndex + 1, "Ready == 0) {\n                   xTexelC").concat(colIndex + 1, " = getX(batch, xR, xCOffset, d1);\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC").concat(colIndex + 1, ".zw = vec2(0.);\n                   }\n                   xTexelC").concat(colIndex + 1, "Ready = 1;\n                 }\n\n                 xC").concat(colIndex, " = vec4(\n                   xTexelC").concat(colIndex, ".xy, xTexelC").concat(colIndex + 1, ".xy);\n               ");
                  if (colIndex + 1 < filterWidth) {
                    mainLoop += "\n                   xC".concat(colIndex + 1, " = vec4(xTexelC").concat(colIndex, ".zw, xTexelC").concat(colIndex + 1, ".zw);\n                 ");
                  }
                }
              }
            }
            if (colIndex < filterWidth) {
              mainLoop += "\n             wTexel = getW(r, ".concat(colIndex, ", d1, d2);\n             dotProd += xC").concat(colIndex, ".xxzz * vec4(wTexel.xy, wTexel.xy);\n             if(d1 + 1 < ").concat(convInfo.inChannels, ") {\n               dotProd += xC").concat(colIndex, ".yyww * vec4(wTexel.zw, wTexel.zw);\n             }\n           ");
              if (colIndex + 1 < filterWidth) {
                mainLoop += "\n               wTexel = getW(r, ".concat(colIndex + 1, ", d1, d2);\n               dotProd += xC").concat(colIndex + 1, ".xxzz * vec4(wTexel.xy, wTexel.xy);\n               if(d1 + 1 < ").concat(convInfo.inChannels, ") {\n                 dotProd += xC").concat(colIndex + 1, ".yyww * vec4(wTexel.zw, wTexel.zw);\n               }\n             ");
              }
            }
          }
          mainLoop += "\n     }\n   ";
          mainLoop += "\n     }\n   ";
          mainLoop += "\n     }\n   ";
          var activationSnippet = "", applyActivationSnippet = "";
          if (activation) {
            if (hasPreluActivation) {
              activationSnippet = "vec4 activation(vec4 a) {\n           vec4 b = getPreluActivationWeightsAtOutCoords();\n           ".concat(activation, "\n         }");
            } else if (hasLeakyReluAlpha) {
              activationSnippet = "vec4 activation(vec4 a) {\n           vec4 b = getLeakyreluAlphaAtOutCoords();\n           ".concat(activation, "\n         }");
            } else {
              activationSnippet = "vec4 activation(vec4 x) {\n           ".concat(activation, "\n         }");
            }
            applyActivationSnippet = "result = activation(result);";
          }
          var addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
          if (addBias) {
            this.variableNames.push("bias");
          }
          if (hasPreluActivation) {
            this.variableNames.push("preluActivationWeights");
          }
          if (hasLeakyReluAlpha) {
            this.variableNames.push("leakyreluAlpha");
          }
          this.userCode = "\n       ".concat(activationSnippet, "\n\n       void main() {\n         ivec4 coords = getOutputCoords();\n         int batch = coords.x;\n         ivec2 xRCCorner = coords.yz * strides - pads;\n         int d2 = coords.w;\n         int xRCorner = xRCCorner.x;\n         int xCCorner = xRCCorner.y;\n\n         //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n         vec4 dotProd = vec4(0.000000000000001);\n\n         ").concat(mainLoop, "\n\n         vec4 result = dotProd - vec4(0.000000000000001);\n         ").concat(addBiasSnippet, "\n         ").concat(applyActivationSnippet, "\n         setOutput(result);\n       }\n     ");
        }
        return Conv2DPackedProgram2;
      }()
    );
    var Im2ColPackedProgram = (
      /** @class */
      function() {
        function Im2ColPackedProgram2(outputShape, convInfo) {
          this.variableNames = ["A"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.customUniforms = [
            { name: "inputShape", type: "ivec4" },
            { name: "pad", type: "ivec2" },
            { name: "stride", type: "ivec2" },
            { name: "dilation", type: "ivec2" },
            { name: "inChannels", type: "int" },
            { name: "itemsPerBlockRow", type: "int" },
            { name: "outWidth", type: "int" }
          ];
          this.outputShape = outputShape;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          var dataFormat = convInfo.dataFormat;
          var glsl = getGlslDifferences();
          var isChannelsLast = dataFormat === "channelsLast";
          var rowDim = isChannelsLast ? 1 : 2;
          var colDim = isChannelsLast ? 2 : 3;
          var boundsCheckingSnippet = this.enableShapeUniforms ? "if(blockIndex < outShape[2] && pos < outShape[1]) {" : "if(blockIndex < ".concat(outputShape[2], " && pos < ").concat(outputShape[1], ") {");
          var unrolled = "";
          for (var row = 0; row <= 1; row++) {
            for (var col = 0; col <= 1; col++) {
              unrolled += "\n          blockIndex = rc.z + ".concat(col, ";\n          pos = rc.y + ").concat(row, ";\n\n          ").concat(boundsCheckingSnippet, "\n            offsetY = int(blockIndex / outWidth) * stride[0] - pad[0];\n            d0 = offsetY + dilation[0] * (pos / itemsPerBlockRow);\n\n            if(d0 < inputShape[").concat(rowDim, "] && d0 >= 0) {\n              // Use custom imod instead mod. On Intel GPU, mod may generate\n              // unexpected value.\n              // https://github.com/tensorflow/tfjs/issues/5447\n              offsetX = imod(blockIndex, outWidth) * stride[1] - pad[1];\n              d1 = offsetX + dilation[1] * (imod(pos, itemsPerBlockRow) /\n                  inChannels);\n\n              if(d1 < inputShape[").concat(colDim, "] && d1 >= 0) {\n\n                ch = imod(pos, inChannels);\n\n                if (").concat(isChannelsLast, ") {\n                  innerDims = vec2(d1, ch);\n                  result[").concat(row * 2 + col, "] = getChannel(\n                    getA(rc.x, d0, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                } else {\n                  innerDims = vec2(d0, d1);\n                  result[").concat(row * 2 + col, "] = getChannel(\n                    getA(rc.x, ch, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                }\n              }\n            }\n          }\n        ");
            }
          }
          this.userCode = "\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0);\n\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\n        vec2 innerDims;\n\n        ".concat(unrolled, "\n\n        ").concat(glsl.output, " = result;\n      }\n    ");
        }
        return Im2ColPackedProgram2;
      }()
    );
    function getShapeForBatchMatMul(shape, isChannelsLast) {
      var length = shape.length;
      if (length >= 3) {
        return isChannelsLast ? __spreadArray(__spreadArray([], __read(
          shape.slice(0, -3)
          /* batch */
        ), false), [
          shape[length - 3] * shape[length - 2],
          shape[length - 1]
          /* channel */
        ], false) : __spreadArray(__spreadArray([], __read(
          shape.slice(0, -3)
          /* batch */
        ), false), [
          shape[length - 3],
          shape[length - 2] * shape[length - 1]
          /* height * width */
        ], false);
      } else if (!isChannelsLast && length === 1 && shape[0] > 1) {
        return [shape[0], 1];
      } else {
        return null;
      }
    }
    function conv2dByMatMul(_a2) {
      var e_12, _b;
      var x = _a2.x, filter = _a2.filter, convInfo = _a2.convInfo, backend = _a2.backend, _c = _a2.bias, bias = _c === void 0 ? null : _c, _d = _a2.preluActivationWeights, preluActivationWeights = _d === void 0 ? null : _d, _e = _a2.leakyreluAlpha, leakyreluAlpha = _e === void 0 ? 0 : _e, _f = _a2.activation, activation = _f === void 0 ? null : _f;
      var xShape = x.shape;
      var xTexData = backend.texData.get(x.dataId);
      var sharedMatMulDim = convInfo.inChannels;
      var outerShapeX = xShape[0] * xShape[1] * xShape[2];
      var outerShapeFilter = convInfo.outChannels;
      var isChannelsLast = convInfo.dataFormat === "channelsLast";
      var transposeA = false;
      var transposeB = false;
      var out;
      var intermediates = [];
      if (preluActivationWeights != null) {
        var targetShape = getShapeForBatchMatMul(preluActivationWeights.shape, isChannelsLast);
        if (targetShape != null) {
          preluActivationWeights = reshape({
            inputs: { x: preluActivationWeights },
            backend,
            attrs: { shape: targetShape }
          });
          intermediates.push(preluActivationWeights);
        }
      }
      if (bias != null) {
        var targetShape = getShapeForBatchMatMul(bias.shape, isChannelsLast);
        if (targetShape != null) {
          bias = reshape({ inputs: { x: bias }, backend, attrs: { shape: targetShape } });
          intermediates.push(bias);
        }
      }
      var batchMatMulWillBeUnpacked = (outerShapeX === 1 || outerShapeFilter === 1) && sharedMatMulDim > MATMUL_SHARED_DIM_THRESHOLD;
      var canOptimize = !batchMatMulWillBeUnpacked && xTexData.isPacked && isChannelsLast && xTexData.texture != null && xShape[2] % 2 !== 0 && tf.util.arraysEqual(xTexData.shape.slice(-3), xShape.slice(-3));
      if (canOptimize) {
        var targetShape = xShape[0] * xShape[1] * (xShape[2] + 1);
        var xReshaped_1 = {
          dataId: x.dataId,
          shape: [1, targetShape, convInfo.inChannels],
          dtype: x.dtype
        };
        var originalXTexDataShape = xTexData.shape;
        xTexData.shape = xTexData.shape.slice();
        xTexData.shape[xTexData.shape.length - 2]++;
        tf.util.assert(isReshapeFree(xTexData.shape, xReshaped_1.shape), function() {
          return "packed reshape ".concat(xTexData.shape, " to ").concat(xReshaped_1.shape, " isn't free");
        });
        var filterReshaped = reshape({
          inputs: { x: filter },
          backend,
          attrs: { shape: [1, convInfo.inChannels, convInfo.outChannels] }
        });
        intermediates.push(filterReshaped);
        var pointwiseConv = batchMatMulImpl({
          a: xReshaped_1,
          b: filterReshaped,
          backend,
          transposeA,
          transposeB,
          bias,
          activation,
          preluActivationWeights,
          leakyreluAlpha
        });
        var pointwiseConvTexData = backend.texData.get(pointwiseConv.dataId);
        tf.util.assert(pointwiseConvTexData.isPacked, function() {
          return "batchMatMul result is expected to be packed";
        });
        xTexData.shape = originalXTexDataShape;
        pointwiseConvTexData.shape = convInfo.outShape;
        out = identity({ inputs: { x: pointwiseConv }, backend });
        out.shape = convInfo.outShape;
        intermediates.push(pointwiseConv);
      } else {
        var numCols = convInfo.outHeight * convInfo.outWidth;
        var xReshaped = reshape({
          inputs: { x },
          backend,
          attrs: {
            shape: isChannelsLast ? [convInfo.batchSize, numCols, convInfo.inChannels] : [convInfo.batchSize, convInfo.inChannels, numCols]
          }
        });
        var filterReshaped = reshape({
          inputs: { x: filter },
          backend,
          attrs: { shape: [1, convInfo.inChannels, convInfo.outChannels] }
        });
        var result = batchMatMulImpl({
          a: isChannelsLast ? xReshaped : filterReshaped,
          b: isChannelsLast ? filterReshaped : xReshaped,
          transposeA: !isChannelsLast,
          transposeB,
          backend,
          bias,
          activation,
          preluActivationWeights,
          leakyreluAlpha
        });
        out = reshape({ inputs: { x: result }, backend, attrs: { shape: convInfo.outShape } });
        intermediates.push(xReshaped);
        intermediates.push(filterReshaped);
        intermediates.push(result);
      }
      try {
        for (var intermediates_1 = __values(intermediates), intermediates_1_1 = intermediates_1.next(); !intermediates_1_1.done; intermediates_1_1 = intermediates_1.next()) {
          var i = intermediates_1_1.value;
          backend.disposeIntermediateTensorInfo(i);
        }
      } catch (e_1_1) {
        e_12 = { error: e_1_1 };
      } finally {
        try {
          if (intermediates_1_1 && !intermediates_1_1.done && (_b = intermediates_1.return))
            _b.call(intermediates_1);
        } finally {
          if (e_12)
            throw e_12.error;
        }
      }
      return out;
    }
    function conv2dWithIm2Row(_a2) {
      var e_2, _b;
      var x = _a2.x, filter = _a2.filter, convInfo = _a2.convInfo, backend = _a2.backend, _c = _a2.bias, bias = _c === void 0 ? null : _c, _d = _a2.preluActivationWeights, preluActivationWeights = _d === void 0 ? null : _d, _e = _a2.leakyreluAlpha, leakyreluAlpha = _e === void 0 ? 0 : _e, _f = _a2.activation, activation = _f === void 0 ? null : _f;
      var filterWidth = convInfo.filterWidth, filterHeight = convInfo.filterHeight, inChannels = convInfo.inChannels, outWidth = convInfo.outWidth, outHeight = convInfo.outHeight, dataFormat = convInfo.dataFormat;
      var isChannelsLast = dataFormat === "channelsLast";
      var sharedDim = filterWidth * filterHeight * inChannels;
      var numCols = outHeight * outWidth;
      var x2ColShape = [convInfo.batchSize, sharedDim, numCols];
      var transposeA = true;
      var transposeB = false;
      var intermediates = [];
      if (preluActivationWeights != null) {
        var targetShape = getShapeForBatchMatMul(preluActivationWeights.shape, isChannelsLast);
        if (targetShape != null) {
          preluActivationWeights = reshape({
            inputs: { x: preluActivationWeights },
            backend,
            attrs: { shape: targetShape }
          });
          intermediates.push(preluActivationWeights);
        }
      }
      if (bias != null) {
        var targetShape = getShapeForBatchMatMul(bias.shape, isChannelsLast);
        if (targetShape != null) {
          bias = reshape({ inputs: { x: bias }, backend, attrs: { shape: targetShape } });
          intermediates.push(bias);
        }
      }
      var w2Row = reshape({
        inputs: { x: filter },
        backend,
        attrs: { shape: [1, sharedDim, tf.util.sizeFromShape(filter.shape) / sharedDim] }
      });
      intermediates.push(w2Row);
      var im2ColProgram = new Im2ColPackedProgram(x2ColShape, convInfo);
      var customValues = [
        x.shape,
        [convInfo.padInfo.top, convInfo.padInfo.left],
        [convInfo.strideHeight, convInfo.strideWidth],
        [convInfo.dilationHeight, convInfo.dilationWidth],
        [convInfo.inChannels],
        [convInfo.filterWidth * convInfo.inChannels],
        [convInfo.outWidth]
      ];
      var im2Col = backend.runWebGLProgram(im2ColProgram, [x], "float32", customValues);
      var im2ColReshaped = reshape({ inputs: { x: im2Col }, backend, attrs: { shape: x2ColShape } });
      intermediates.push(im2Col);
      intermediates.push(im2ColReshaped);
      var hasBias = bias != null;
      var hasPreluActivationWeights = preluActivationWeights != null;
      var hasLeakyreluAlpha = activation === "leakyrelu";
      var fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;
      var matmulProgram = new MatMulPackedProgram(isChannelsLast ? im2ColReshaped.shape : w2Row.shape, isChannelsLast ? w2Row.shape : im2ColReshaped.shape, isChannelsLast ? [convInfo.batchSize, numCols, convInfo.outChannels] : [convInfo.batchSize, convInfo.outChannels, numCols], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
      var inputs = isChannelsLast ? [im2ColReshaped, w2Row] : [w2Row, im2ColReshaped];
      if (bias) {
        inputs.push(bias);
      }
      if (hasPreluActivationWeights) {
        inputs.push(preluActivationWeights);
      }
      if (hasLeakyreluAlpha) {
        var $leakyreluAlpha = backend.makeTensorInfo([], "float32", tf.util.createScalarValue(leakyreluAlpha, "float32"));
        inputs.push($leakyreluAlpha);
        intermediates.push($leakyreluAlpha);
      }
      var product = backend.runWebGLProgram(matmulProgram, inputs, "float32");
      var out = reshape({ inputs: { x: product }, backend, attrs: { shape: convInfo.outShape } });
      intermediates.push(product);
      try {
        for (var intermediates_2 = __values(intermediates), intermediates_2_1 = intermediates_2.next(); !intermediates_2_1.done; intermediates_2_1 = intermediates_2.next()) {
          var i = intermediates_2_1.value;
          backend.disposeIntermediateTensorInfo(i);
        }
      } catch (e_2_1) {
        e_2 = { error: e_2_1 };
      } finally {
        try {
          if (intermediates_2_1 && !intermediates_2_1.done && (_b = intermediates_2.return))
            _b.call(intermediates_2);
        } finally {
          if (e_2)
            throw e_2.error;
        }
      }
      return out;
    }
    function conv2d(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter;
      var strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dilations = attrs.dilations, dimRoundingMode = attrs.dimRoundingMode;
      var $dataFormat = tf.backend_util.convertConv2DDataFormat(dataFormat);
      var convInfo = tf.backend_util.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad, dimRoundingMode, false, $dataFormat);
      var out;
      if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === "SAME" || convInfo.padInfo.type === "VALID")) {
        out = conv2dByMatMul({ x, filter, convInfo, backend });
      } else if (convInfo.strideWidth <= 2 && $dataFormat === "channelsLast" && tf.env().getBool("WEBGL_EXP_CONV")) {
        var program = new Conv2DPackedProgram(convInfo);
        var customValues = [
          [convInfo.padInfo.top, convInfo.padInfo.left],
          [convInfo.strideHeight, convInfo.strideWidth],
          [convInfo.dilationHeight, convInfo.dilationWidth],
          [convInfo.inHeight, convInfo.inWidth]
        ];
        out = backend.runWebGLProgram(program, [x, filter], "float32", customValues);
      } else if (tf.env().getBool("WEBGL_CONV_IM2COL")) {
        out = conv2dWithIm2Row({ x, filter, convInfo, backend });
      } else {
        var program = new Conv2DProgram(convInfo);
        out = backend.runWebGLProgram(program, [x, filter], "float32");
      }
      var outReshaped = reshape({ inputs: { x: out }, backend, attrs: { shape: convInfo.outShape } });
      backend.disposeIntermediateTensorInfo(out);
      return outReshaped;
    }
    var conv2DConfig = {
      kernelName: tf.Conv2D,
      backendName: "webgl",
      kernelFunc: conv2d
    };
    var Conv2DDerFilterProgram = (
      /** @class */
      function() {
        function Conv2DDerFilterProgram2(convInfo) {
          this.variableNames = ["x", "dy"];
          this.outputShape = convInfo.filterShape;
          var strideHeight = convInfo.strideHeight;
          var strideWidth = convInfo.strideWidth;
          var padTop = convInfo.padInfo.top;
          var padLeft = convInfo.padInfo.left;
          var isChannelsLast = convInfo.dataFormat === "channelsLast";
          this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int d2 = coords.w;\n\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ".concat(convInfo.batchSize, "; b++) {\n          for (int yR = 0; yR < ").concat(convInfo.outHeight, "; yR++) {\n            int xR = wR + yR * ").concat(strideHeight, " - ").concat(padTop, ";\n\n            if (xR < 0 || xR >= ").concat(convInfo.inHeight, ") {\n              continue;\n            }\n\n            for (int yC = 0; yC < ").concat(convInfo.outWidth, "; yC++) {\n              int xC = wC + yC * ").concat(strideWidth, " - ").concat(padLeft, ";\n\n              if (xC < 0 || xC >= ").concat(convInfo.inWidth, ") {\n                continue;\n              }\n\n              ").concat(isChannelsLast ? "float dyValue = getDy(b, yR, yC, d2);\n              float xValue = getX(b, xR, xC, d1);\n              dotProd += (xValue * dyValue);" : "float dyValue = getDy(b, d2, yR, yC);\n              float xValue = getX(b, d1, xR, xC);\n              dotProd += (xValue * dyValue);", "\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
        }
        return Conv2DDerFilterProgram2;
      }()
    );
    var Conv2DDerInputProgram = (
      /** @class */
      function() {
        function Conv2DDerInputProgram2(convInfo) {
          this.variableNames = ["dy", "W"];
          this.outputShape = convInfo.inShape;
          var filterHeight = convInfo.filterHeight;
          var filterWidth = convInfo.filterWidth;
          var strideHeight = convInfo.strideHeight;
          var strideWidth = convInfo.strideWidth;
          var isChannelsLast = convInfo.dataFormat === "channelsLast";
          var padTop = filterHeight - 1 - convInfo.padInfo.top;
          var padLeft = filterWidth - 1 - convInfo.padInfo.left;
          var rowDim = isChannelsLast ? 1 : 2;
          var colDim = isChannelsLast ? 2 : 3;
          var channelDim = isChannelsLast ? 3 : 1;
          this.userCode = "\n      const ivec2 pads = ivec2(".concat(padTop, ", ").concat(padLeft, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[").concat(channelDim, "];\n\n        ivec2 dyCorner = ivec2(coords[").concat(rowDim, "], coords[").concat(colDim, "]) - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ").concat(filterHeight, "; wR++) {\n          float dyR = float(dyRCorner + wR) / ").concat(strideHeight, ".0;\n\n          if (dyR < 0.0 || dyR >= ").concat(convInfo.outHeight, ".0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ").concat(filterHeight, " - 1 - wR;\n\n          for (int wC = 0; wC < ").concat(filterWidth, "; wC++) {\n            float dyC = float(dyCCorner + wC) / ").concat(strideWidth, ".0;\n\n            if (dyC < 0.0 || dyC >= ").concat(convInfo.outWidth, ".0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ").concat(filterWidth, " - 1 - wC;\n\n            for (int d2 = 0; d2 < ").concat(convInfo.outChannels, "; d2++) {\n\n              if (").concat(isChannelsLast, ") {\n                float xValue = getDy(batch, idyR, idyC, d2);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              } else {\n                float xValue = getDy(batch, d2, idyR, idyC);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
        }
        return Conv2DDerInputProgram2;
      }()
    );
    var Conv3DDerFilterProgram = (
      /** @class */
      function() {
        function Conv3DDerFilterProgram2(convInfo) {
          this.variableNames = ["x", "dy"];
          this.outputShape = convInfo.filterShape;
          var strideDepth = convInfo.strideDepth;
          var strideHeight = convInfo.strideHeight;
          var strideWidth = convInfo.strideWidth;
          var padFront = convInfo.padInfo.front;
          var padTop = convInfo.padInfo.top;
          var padLeft = convInfo.padInfo.left;
          this.userCode = "\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int wF = coords.x;\n        int wR = coords.y;\n        int wC = coords.z;\n        int d1 = coords.w;\n        int d2 = coords.u;\n\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ".concat(convInfo.batchSize, "; b++) {\n          for (int yF = 0; yF < ").concat(convInfo.outDepth, "; yF++) {\n            int xF = wF + yF * ").concat(strideDepth, " - ").concat(padFront, ";\n\n            if (xF < 0 || xF >= ").concat(convInfo.inDepth, ") {\n              continue;\n            }\n\n            for (int yR = 0; yR < ").concat(convInfo.outHeight, "; yR++) {\n              int xR = wR + yR * ").concat(strideHeight, " - ").concat(padTop, ";\n\n              if (xR < 0 || xR >= ").concat(convInfo.inHeight, ") {\n                continue;\n              }\n\n              for (int yC = 0; yC < ").concat(convInfo.outWidth, "; yC++) {\n                int xC = wC + yC * ").concat(strideWidth, " - ").concat(padLeft, ";\n\n                if (xC < 0 || xC >= ").concat(convInfo.inWidth, ") {\n                  continue;\n                }\n\n                float dyValue = getDy(b, yF, yR, yC, d2);\n                float xValue = getX(b, xF, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
        }
        return Conv3DDerFilterProgram2;
      }()
    );
    var Conv3DDerInputProgram = (
      /** @class */
      function() {
        function Conv3DDerInputProgram2(convInfo) {
          this.variableNames = ["dy", "W"];
          this.outputShape = convInfo.inShape;
          var filterDepth = convInfo.filterDepth;
          var filterHeight = convInfo.filterHeight;
          var filterWidth = convInfo.filterWidth;
          var strideDepth = convInfo.strideDepth;
          var strideHeight = convInfo.strideHeight;
          var strideWidth = convInfo.strideWidth;
          var padFront = filterDepth - 1 - convInfo.padInfo.front;
          var padTop = filterHeight - 1 - convInfo.padInfo.top;
          var padLeft = filterWidth - 1 - convInfo.padInfo.left;
          this.userCode = "\n      const ivec3 pads = ivec3(".concat(padFront, ", ").concat(padTop, ", ").concat(padLeft, ");\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.u;\n\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyFCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ").concat(filterDepth, "; wF++) {\n          float dyF = float(dyFCorner + wF) / ").concat(strideDepth, ".0;\n\n          if (dyF < 0.0 || dyF >= ").concat(convInfo.outDepth, ".0 || fract(dyF) > 0.0) {\n            continue;\n          }\n          int idyF = int(dyF);\n\n          int wFPerm = ").concat(filterDepth, " - 1 - wF;\n\n          for (int wR = 0; wR < ").concat(filterHeight, "; wR++) {\n            float dyR = float(dyRCorner + wR) / ").concat(strideHeight, ".0;\n\n            if (dyR < 0.0 || dyR >= ").concat(convInfo.outHeight, ".0 ||\n              fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            int wRPerm = ").concat(filterHeight, " - 1 - wR;\n\n            for (int wC = 0; wC < ").concat(filterWidth, "; wC++) {\n              float dyC = float(dyCCorner + wC) / ").concat(strideWidth, ".0;\n\n              if (dyC < 0.0 || dyC >= ").concat(convInfo.outWidth, ".0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              int wCPerm = ").concat(filterWidth, " - 1 - wC;\n\n              for (int d2 = 0; d2 < ").concat(convInfo.outChannels, "; d2++) {\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
        }
        return Conv3DDerInputProgram2;
      }()
    );
    function conv2DBackpropFilter(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, dy = inputs.dy;
      var strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dimRoundingMode = attrs.dimRoundingMode, filterShape = attrs.filterShape;
      var $dataFormat = tf.backend_util.convertConv2DDataFormat(dataFormat);
      var convInfo = tf.backend_util.computeConv2DInfo(x.shape, filterShape, strides, 1, pad, dimRoundingMode, false, $dataFormat);
      var program = new Conv2DDerFilterProgram(convInfo);
      return backend.runWebGLProgram(program, [x, dy], "float32");
    }
    var conv2DBackpropFilterConfig = {
      kernelName: tf.Conv2DBackpropFilter,
      backendName: "webgl",
      kernelFunc: conv2DBackpropFilter
    };
    var Conv2DDerInputPackedProgram = (
      /** @class */
      function() {
        function Conv2DDerInputPackedProgram2(convInfo) {
          this.variableNames = ["dy", "W"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.customUniforms = [
            { name: "strides", type: "vec2" }
          ];
          this.outputShape = convInfo.inShape;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          var filterHeight = convInfo.filterHeight;
          var filterWidth = convInfo.filterWidth;
          var padTop = filterHeight - 1 - convInfo.padInfo.top;
          var padLeft = filterWidth - 1 - convInfo.padInfo.left;
          this.userCode = "\n      const ivec2 pads = ivec2(".concat(padTop, ", ").concat(padLeft, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[3];\n\n        ivec2 dyCorner = ivec2(coords[1], coords[2]) - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        vec4 result = vec4(0.);\n        for (int wR = 0; wR < ").concat(filterHeight, "; wR++) {\n          float dyR = float(dyRCorner + wR) / strides[0];\n          if (dyR < 0.0 || dyR >= ").concat(convInfo.outHeight, ".0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n          int wRPerm = ").concat(filterHeight, " - 1 - wR;\n\n          for (int wC = 0; wC < ").concat(filterWidth, "; wC++) {\n            int wCPerm = ").concat(filterWidth, " - 1 - wC;\n\n            float dyC = float(dyCCorner + wC) / strides[1];\n            bool idyCVal = (dyC >= 0.0) && (dyC < ").concat(convInfo.outWidth, ".0)\n              && (fract(dyC) == 0.0);\n            int idyC = int(dyC);\n\n            float dyC2 = float(dyCCorner + wC + 1) / strides[1];\n            bool idyCVal2 = (dyC2 >= 0.0) && (dyC2 < ").concat(convInfo.outWidth, ".0)\n              && (fract(dyC2) == 0.0);\n            int idyC2 = int(dyC2);\n\n            if (idyCVal && idyCVal2) {\n              for (int d2 = 0; d2 < ").concat(convInfo.outChannels, "; d2 += 2) {\n                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);\n                vec4 dySample = getDy(batch, idyR, idyC, d2);\n                vec4 dySample2 = (idyC / 2 == idyC2 / 2) ?\n                  dySample : getDy(batch, idyR, idyC2, d2);\n\n                vec2 dyValue = mod(float(idyC), 2.) == 0. ?\n                  dySample.xy : dySample.zw;\n                result.xy += vec2(dot(dyValue, wValue.xy),\n                  dot(dyValue, wValue.zw));\n\n                dyValue = mod(float(idyC2), 2.) == 0. ?\n                  dySample2.xy : dySample2.zw;\n                result.zw += vec2(dot(dyValue, wValue.xy),\n                  dot(dyValue, wValue.zw));\n              }\n            } else if (idyCVal) {\n              for (int d2 = 0; d2 < ").concat(convInfo.outChannels, "; d2 += 2) {\n                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);\n                vec4 dySample = getDy(batch, idyR, idyC, d2);\n                vec2 dyValue = mod(float(idyC), 2.) == 0. ?\n                  dySample.xy : dySample.zw;\n                result.xy += vec2(dot(dyValue, wValue.xy),\n                  dot(dyValue, wValue.zw));\n              }\n            } else if (idyCVal2) {\n              for (int d2 = 0; d2 < ").concat(convInfo.outChannels, "; d2 += 2) {\n                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);\n                vec4 dySample = getDy(batch, idyR, idyC2, d2);\n                vec2 dyValue = mod(float(idyC2), 2.) == 0. ?\n                  dySample.xy : dySample.zw;\n                result.zw += vec2(dot(dyValue, wValue.xy),\n                  dot(dyValue, wValue.zw));\n              }\n            }\n          }\n        }\n        setOutput(result);\n      }\n    ");
        }
        return Conv2DDerInputPackedProgram2;
      }()
    );
    function conv2DBackpropInput(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, filter = inputs.filter;
      var inputShape = attrs.inputShape, strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dimRoundingMode = attrs.dimRoundingMode;
      var $dataFormat = tf.backend_util.convertConv2DDataFormat(dataFormat);
      var convInfo = tf.backend_util.computeConv2DInfo(inputShape, filter.shape, strides, 1, pad, dimRoundingMode, false, $dataFormat);
      if (tf.env().getBool("WEBGL_PACK_CONV2DTRANSPOSE") && $dataFormat === "channelsLast") {
        var customValues = [
          [convInfo.strideHeight, convInfo.strideWidth]
        ];
        var program = new Conv2DDerInputPackedProgram(convInfo);
        return backend.runWebGLProgram(program, [dy, filter], "float32", customValues);
      } else {
        var program = new Conv2DDerInputProgram(convInfo);
        return backend.runWebGLProgram(program, [dy, filter], "float32");
      }
    }
    var conv2DBackpropInputConfig = {
      kernelName: tf.Conv2DBackpropInput,
      backendName: "webgl",
      kernelFunc: conv2DBackpropInput
    };
    function conv3D(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter;
      var strides = attrs.strides, pad = attrs.pad, dilations = attrs.dilations;
      var convInfo = tf.backend_util.computeConv3DInfo(x.shape, filter.shape, strides, dilations, pad);
      var program = new Conv3DProgram(convInfo);
      return backend.runWebGLProgram(program, [x, filter], "float32");
    }
    var conv3DConfig = {
      kernelName: tf.Conv3D,
      backendName: "webgl",
      kernelFunc: conv3D
    };
    function conv3DBackpropFilterV2(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, dy = inputs.dy;
      var strides = attrs.strides, pad = attrs.pad, filterShape = attrs.filterShape;
      var convInfo = tf.backend_util.computeConv3DInfo(x.shape, filterShape, strides, 1, pad);
      var program = new Conv3DDerFilterProgram(convInfo);
      return backend.runWebGLProgram(program, [x, dy], "float32");
    }
    var conv3DBackpropFilterV2Config = {
      kernelName: tf.Conv3DBackpropFilterV2,
      backendName: "webgl",
      kernelFunc: conv3DBackpropFilterV2
    };
    function conv3DBackpropInput(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, filter = inputs.filter;
      var pad = attrs.pad, strides = attrs.strides, inputShape = attrs.inputShape;
      var convInfo = tf.backend_util.computeConv3DInfo(inputShape, filter.shape, strides, 1, pad);
      var program = new Conv3DDerInputProgram(convInfo);
      return backend.runWebGLProgram(program, [dy, filter], "float32");
    }
    var conv3DBackpropInputConfig = {
      kernelName: tf.Conv3DBackpropInputV2,
      backendName: "webgl",
      kernelFunc: conv3DBackpropInput
    };
    var COS = CHECK_NAN_SNIPPET_UNARY + "\n  return cos(x);\n";
    var COS_PACKED = "\n  vec4 result = cos(x);\n  bvec4 isNaN = isnan(x);\n  ".concat(CHECK_NAN_SNIPPET_PACKED, "\n  return result;\n");
    var cos = unaryKernelFunc({ opSnippet: COS, packedOpSnippet: COS_PACKED });
    var cosConfig = {
      kernelName: tf.Cos,
      backendName: "webgl",
      kernelFunc: cos
    };
    var COSH = "\n  float e2x = exp(-x);\n  return (e2x + 1.0 / e2x) / 2.0;\n";
    var cosh = unaryKernelFunc({ opSnippet: COSH });
    var coshConfig = {
      kernelName: tf.Cosh,
      backendName: "webgl",
      kernelFunc: cosh
    };
    var CropAndResizeProgram = (
      /** @class */
      function() {
        function CropAndResizeProgram2(imageShape, boxShape, cropSize, method, extrapolationValue) {
          this.variableNames = ["Image", "Boxes", "BoxInd"];
          this.outputShape = [];
          var _a2 = __read(imageShape, 4), batch = _a2[0], imageHeight = _a2[1], imageWidth = _a2[2], depth = _a2[3];
          var _b = __read(boxShape, 1), numBoxes = _b[0];
          var _c = __read(cropSize, 2), cropHeight = _c[0], cropWidth = _c[1];
          this.outputShape = [numBoxes, cropHeight, cropWidth, depth];
          var methodId = method === "bilinear" ? 1 : 0;
          var _d = __read(["".concat(imageHeight - 1, ".0"), "".concat(imageWidth - 1, ".0")], 2), inputHeightFloat = _d[0], inputWidthFloat = _d[1];
          var _e = __read(cropHeight > 1 ? [
            "".concat((imageHeight - 1) / (cropHeight - 1)),
            "(y2-y1) * height_ratio",
            "y1*".concat(inputHeightFloat, " + float(y)*(height_scale)")
          ] : [
            "0.0",
            "0.0",
            "0.5 * (y1+y2) * ".concat(inputHeightFloat)
          ], 3), heightRatio = _e[0], heightScale = _e[1], inY = _e[2];
          var _f = __read(cropWidth > 1 ? [
            "".concat((imageWidth - 1) / (cropWidth - 1)),
            "(x2-x1) * width_ratio",
            "x1*".concat(inputWidthFloat, " + float(x)*(width_scale)")
          ] : [
            "0.0",
            "0.0",
            "0.5 * (x1+x2) * ".concat(inputWidthFloat)
          ], 3), widthRatio = _f[0], widthScale = _f[1], inX = _f[2];
          this.userCode = "\n      const float height_ratio = float(".concat(heightRatio, ");\n      const float width_ratio = float(").concat(widthRatio, ");\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int y = coords[1];\n        int x = coords[2];\n        int d = coords[3];\n\n        // get box vals\n        float y1 = getBoxes(b,0);\n        float x1 = getBoxes(b,1);\n        float y2 = getBoxes(b,2);\n        float x2 = getBoxes(b,3);\n\n        // get image in batch index\n        int bInd = round(getBoxInd(b));\n        if(bInd < 0 || bInd >= ").concat(batch, ") {\n          return;\n        }\n\n        float height_scale = ").concat(heightScale, ";\n        float width_scale = ").concat(widthScale, ";\n\n        float in_y = ").concat(inY, ";\n        if( in_y < 0.0 || in_y > ").concat(inputHeightFloat, " ) {\n          setOutput(float(").concat(extrapolationValue, "));\n          return;\n        }\n        float in_x = ").concat(inX, ";\n        if( in_x < 0.0 || in_x > ").concat(inputWidthFloat, " ) {\n          setOutput(float(").concat(extrapolationValue, "));\n          return;\n        }\n\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\n        if(").concat(methodId, " == 1) {\n          // Compute the four integer indices.\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\n\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\n\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\n\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\n          float newValue = top + (bottom - top) * fracCR.y;\n          setOutput(newValue);\n        } else {\n          // Compute the coordinators of nearest neighbor point.\n          ivec2 sourceNearestCR = ivec2(floor(\n            sourceFracIndexCR + vec2(0.5,0.5)));\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\n          setOutput(newValue);\n        }\n      }\n    ");
        }
        return CropAndResizeProgram2;
      }()
    );
    var cropAndResize = function(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var image = inputs.image, boxes = inputs.boxes, boxInd = inputs.boxInd;
      var cropSize = attrs.cropSize, method = attrs.method, extrapolationValue = attrs.extrapolationValue;
      var program = new CropAndResizeProgram(image.shape, boxes.shape, cropSize, method, extrapolationValue);
      return backend.runWebGLProgram(program, [image, boxes, boxInd], "float32");
    };
    var cropAndResizeConfig = {
      kernelName: tf.CropAndResize,
      backendName: "webgl",
      kernelFunc: cropAndResize
    };
    var CumOpType;
    (function(CumOpType2) {
      CumOpType2["Prod"] = "*";
      CumOpType2["Sum"] = "+";
    })(CumOpType || (CumOpType = {}));
    var CumProgram = (
      /** @class */
      function() {
        function CumProgram2(op, outputShape, exclusive, reverse2) {
          this.op = op;
          this.outputShape = outputShape;
          this.variableNames = ["x"];
          this.customUniforms = [{ name: "index", type: "float" }];
          var rank = this.outputShape.length;
          var initVal = this.op === CumOpType.Prod ? "1.0" : "0.0";
          var val = exclusive ? initVal : "getX(".concat(getCoords(rank, "coords", this.op), ")");
          var length = this.outputShape[this.outputShape.length - 1];
          var condition = "";
          var idxString = "";
          if (exclusive) {
            condition = reverse2 ? "end != ".concat(length - 1) : "end != 0";
            idxString = reverse2 ? "end + 1" : "end - 1";
          } else {
            condition = reverse2 ? "end + pow2 < ".concat(length) : "end >= pow2";
            idxString = reverse2 ? "end + pow2" : "end - pow2";
          }
          this.userCode = "\n      void main() {\n        ".concat(getCoordsDataType(rank), " coords = getOutputCoords();\n        int end = ").concat(getFinalCoord(rank, "coords", this.op), ";\n        float val = ").concat(val, ";\n        int pow2 = int(pow(2.0, index));\n        if (").concat(condition, ") {\n          int idx = ").concat(idxString, ";\n          ").concat(getFinalCoord(rank, "coords", this.op), " = idx;\n          val ").concat(this.op, "= getX(").concat(getCoords(rank, "coords", this.op), ");\n        }\n        setOutput(val);\n      }\n    ");
        }
        return CumProgram2;
      }()
    );
    function getCoords(rank, name, op) {
      if (rank === 1) {
        return "".concat(name);
      } else if (rank === 2) {
        return "".concat(name, ".x, ").concat(name, ".y");
      } else if (rank === 3) {
        return "".concat(name, ".x, ").concat(name, ".y, ").concat(name, ".z");
      } else if (rank === 4) {
        return "".concat(name, ".x, ").concat(name, ".y, ").concat(name, ".z, ").concat(name, ".w");
      } else {
        throw new Error("Cumulative ".concat(op, " for rank ").concat(rank, " is not yet supported"));
      }
    }
    function getFinalCoord(rank, name, op) {
      if (rank === 1) {
        return "".concat(name);
      } else if (rank === 2) {
        return "".concat(name, ".y");
      } else if (rank === 3) {
        return "".concat(name, ".z");
      } else if (rank === 4) {
        return "".concat(name, ".w");
      } else {
        throw new Error("Cumulative ".concat(op, " for rank ").concat(rank, " is not yet supported"));
      }
    }
    function cumImpl(op, x, backend, axis, exclusive, reverse2) {
      var xRank = x.shape.length;
      var permutation = tf.backend_util.getAxesPermutation([axis], xRank);
      var permutedX = x;
      if (permutation != null) {
        permutedX = transpose({ inputs: { x }, backend, attrs: { perm: permutation } });
      }
      var permutedAxis = tf.backend_util.getInnerMostAxes(1, xRank)[0];
      if (permutedAxis !== xRank - 1) {
        throw new Error("WebGL cumprod shader expects an inner-most axis=".concat(x.shape.length - 1, " ") + "but got axis=".concat(axis));
      }
      var size = permutedX.shape[permutedAxis];
      var result = identity({ inputs: { x: permutedX }, backend });
      for (var i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {
        var program = new CumProgram(op, permutedX.shape, false, reverse2);
        var customValues = [[i]];
        var prevResult = result;
        result = backend.runWebGLProgram(program, [result], result.dtype, customValues);
        backend.disposeIntermediateTensorInfo(prevResult);
      }
      if (exclusive) {
        var program = new CumProgram(op, permutedX.shape, exclusive, reverse2);
        var prevResult = result;
        result = backend.runWebGLProgram(program, [result], result.dtype);
        backend.disposeIntermediateTensorInfo(prevResult);
      }
      if (permutation != null) {
        var reversePermutation = tf.backend_util.getUndoAxesPermutation(permutation);
        var reverseTransposedResult = transpose({ inputs: { x: result }, backend, attrs: { perm: reversePermutation } });
        backend.disposeIntermediateTensorInfo(result);
        backend.disposeIntermediateTensorInfo(permutedX);
        return reverseTransposedResult;
      }
      return result;
    }
    function cumprod(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, exclusive = attrs.exclusive, reverse2 = attrs.reverse;
      return cumImpl(CumOpType.Prod, x, backend, axis, exclusive, reverse2);
    }
    var cumprodConfig = {
      kernelName: tf.Cumprod,
      backendName: "webgl",
      kernelFunc: cumprod
    };
    function cumsum(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, exclusive = attrs.exclusive, reverse2 = attrs.reverse;
      return cumImpl(CumOpType.Sum, x, backend, axis, exclusive, reverse2);
    }
    var cumsumConfig = {
      kernelName: tf.Cumsum,
      backendName: "webgl",
      kernelFunc: cumsum
    };
    function denseBincount(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, weights = inputs.weights;
      var size = attrs.size, binaryOutput = attrs.binaryOutput;
      if (x.shape.length === 1) {
        var xVals = backend.readSync(x.dataId);
        var weightsVals = backend.readSync(weights.dataId);
        var outVals = bincountImplCPU(xVals, weightsVals, weights.dtype, weights.shape, size);
        return backend.makeTensorInfo([size], weights.dtype, outVals);
      } else if (x.shape.length === 2) {
        var xBuf = backend.bufferSync(x);
        var weightsBuf = backend.bufferSync(weights);
        var outBuf = bincountReduceImplCPU(xBuf, weightsBuf, size, binaryOutput);
        return backend.makeTensorInfo(outBuf.shape, weights.dtype, outBuf.values);
      }
      throw new Error("Error in denseBincount: input must be at most rank 2, but got rank" + "".concat(x.shape.length, "."));
    }
    var denseBincountConfig = {
      kernelName: tf.DenseBincount,
      backendName: "webgl",
      kernelFunc: denseBincount
    };
    var DepthToSpaceProgram = (
      /** @class */
      function() {
        function DepthToSpaceProgram2(outputShape, blockSize, dataFormat) {
          this.variableNames = ["x"];
          this.outputShape = [];
          this.outputShape = outputShape;
          this.blockSize = blockSize;
          this.dataFormat = dataFormat;
          this.userCode = "\n    void main() {\n      ivec4 coords = getOutputCoords();\n      int b = coords[0];\n      int h = ".concat(this.getHeightCoordString(), ";\n      int w = ").concat(this.getWidthCoordString(), ";\n      int d = ").concat(this.getDepthCoordString(), ";\n\n      int in_h = h / ").concat(blockSize, ";\n      int offset_h = imod(h, ").concat(blockSize, ");\n      int in_w = w / ").concat(blockSize, ";\n      int offset_w = imod(w, ").concat(blockSize, ");\n      int offset_d = (offset_h * ").concat(blockSize, " + offset_w) *\n        ").concat(this.getOutputDepthSize(), ";\n      int in_d = d + offset_d;\n\n      float result = ").concat(this.getInputSamplingString(), ";\n      setOutput(result);\n    }\n  ");
        }
        DepthToSpaceProgram2.prototype.getHeightCoordString = function() {
          if (this.dataFormat === "NHWC") {
            return "coords[1]";
          } else {
            return "coords[2]";
          }
        };
        DepthToSpaceProgram2.prototype.getWidthCoordString = function() {
          if (this.dataFormat === "NHWC") {
            return "coords[2]";
          } else {
            return "coords[3]";
          }
        };
        DepthToSpaceProgram2.prototype.getDepthCoordString = function() {
          if (this.dataFormat === "NHWC") {
            return "coords[3]";
          } else {
            return "coords[1]";
          }
        };
        DepthToSpaceProgram2.prototype.getOutputDepthSize = function() {
          if (this.dataFormat === "NHWC") {
            return this.outputShape[3];
          } else {
            return this.outputShape[1];
          }
        };
        DepthToSpaceProgram2.prototype.getInputSamplingString = function() {
          if (this.dataFormat === "NHWC") {
            return "getX(b, in_h, in_w, in_d)";
          } else {
            return "getX(b, in_d, in_h, in_w)";
          }
        };
        return DepthToSpaceProgram2;
      }()
    );
    function depthToSpace(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var blockSize = attrs.blockSize, dataFormat = attrs.dataFormat;
      var batchSize = x.shape[0];
      var inputHeight = dataFormat === "NHWC" ? x.shape[1] : x.shape[2];
      var inputWidth = dataFormat === "NHWC" ? x.shape[2] : x.shape[3];
      var inputDepth = dataFormat === "NHWC" ? x.shape[3] : x.shape[1];
      var outputHeight = inputHeight * blockSize;
      var outputWidth = inputWidth * blockSize;
      var outputDepth = inputDepth / (blockSize * blockSize);
      var outputShape = dataFormat === "NHWC" ? [batchSize, outputHeight, outputWidth, outputDepth] : [batchSize, outputDepth, outputHeight, outputWidth];
      var program = new DepthToSpaceProgram(outputShape, blockSize, dataFormat);
      return backend.runWebGLProgram(program, [x], x.dtype);
    }
    var depthToSpaceConfig = {
      kernelName: tf.DepthToSpace,
      backendName: "webgl",
      kernelFunc: depthToSpace
    };
    var DepthwiseConv2DProgram = (
      /** @class */
      function() {
        function DepthwiseConv2DProgram2(convInfo, addBias, activation, hasPreluActivation, hasLeakyReluAlpha) {
          if (addBias === void 0) {
            addBias = false;
          }
          if (activation === void 0) {
            activation = null;
          }
          if (hasPreluActivation === void 0) {
            hasPreluActivation = false;
          }
          if (hasLeakyReluAlpha === void 0) {
            hasLeakyReluAlpha = false;
          }
          this.variableNames = ["x", "W"];
          this.customUniforms = [
            { name: "pads", type: "ivec2" },
            { name: "strides", type: "ivec2" },
            { name: "dilations", type: "ivec2" },
            { name: "inDims", type: "ivec2" }
          ];
          this.outputShape = convInfo.outShape;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          var filterHeight = convInfo.filterHeight;
          var filterWidth = convInfo.filterWidth;
          var channelMul = convInfo.outChannels / convInfo.inChannels;
          var activationSnippet = "", applyActivationSnippet = "";
          if (activation) {
            if (hasPreluActivation) {
              activationSnippet = "float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ".concat(activation, "\n        }");
            } else if (hasLeakyReluAlpha) {
              activationSnippet = "float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ".concat(activation, "\n        }");
            } else {
              activationSnippet = "\n          float activation(float x) {\n            ".concat(activation, "\n          }\n        ");
            }
            applyActivationSnippet = "result = activation(result);";
          }
          var addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
          if (addBias) {
            this.variableNames.push("bias");
          }
          if (hasPreluActivation) {
            this.variableNames.push("preluActivationWeights");
          }
          if (hasLeakyReluAlpha) {
            this.variableNames.push("leakyreluAlpha");
          }
          this.userCode = "\n      ".concat(activationSnippet, "\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ").concat(channelMul, ";\n        int q = d2 - d1 * ").concat(channelMul, ";\n\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\n        for (int wR = 0; wR < ").concat(filterHeight, "; wR++) {\n          int xR = xRCorner + wR * dilations[0];\n\n          if (xR < 0 || xR >= inDims[0]) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ").concat(filterWidth, "; wC++) {\n            int xC = xCCorner + wC * dilations[1];\n\n            if (xC < 0 || xC >= inDims[1]) {\n              continue;\n            }\n\n            float xVal = getX(batch, xR, xC, d1);\n            float wVal = getW(wR, wC, d1, q);\n            dotProd += xVal * wVal;\n          }\n        }\n\n        float result = dotProd;\n        ").concat(addBiasSnippet, "\n        ").concat(applyActivationSnippet, "\n        setOutput(result);\n      }\n    ");
        }
        return DepthwiseConv2DProgram2;
      }()
    );
    var DepthwiseConvPacked2DProgram = (
      /** @class */
      function() {
        function DepthwiseConvPacked2DProgram2(convInfo, addBias, activation, hasPreluActivation, hasLeakyReluAlpha) {
          if (addBias === void 0) {
            addBias = false;
          }
          if (activation === void 0) {
            activation = null;
          }
          if (hasPreluActivation === void 0) {
            hasPreluActivation = false;
          }
          if (hasLeakyReluAlpha === void 0) {
            hasLeakyReluAlpha = false;
          }
          this.variableNames = ["x", "W"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.customUniforms = [
            { name: "pads", type: "ivec2" },
            { name: "strides", type: "ivec2" },
            { name: "dilations", type: "ivec2" },
            { name: "inDims", type: "ivec2" }
          ];
          this.outputShape = convInfo.outShape;
          this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
          var channelMul = convInfo.outChannels / convInfo.inChannels;
          var padLeft = convInfo.padInfo.left;
          var strideWidth = convInfo.strideWidth;
          var dilationWidth = convInfo.dilationWidth;
          var filterHeight = convInfo.filterHeight;
          var filterWidth = convInfo.filterWidth;
          var texelsAcross = filterWidth;
          var mainLoop = "\n      int xR; int xC; int xCOffset;\n      vec4 wTexel; vec4 previous; vec4 final;";
          for (var c = 0; c < filterWidth; c++) {
            mainLoop += "\n          vec4 xTexelC".concat(c * 2, ";\n          int xTexelC").concat(c * 2, "Ready;\n          vec4 xTexelC").concat(c * 2 + 1, ";\n          int xTexelC").concat(c * 2 + 1, "Ready;\n          vec4 xC").concat(c, ";");
          }
          mainLoop += "\n    for (int r = 0; r < ".concat(filterHeight, "; r++) {\n      ");
          for (var c = 0; c < filterWidth; c++) {
            mainLoop += "\n          xTexelC".concat(c * 2, " = vec4(0.0);\n          xTexelC").concat(c * 2, "Ready = 0;\n          xTexelC").concat(c * 2 + 1, " = vec4(0.0);\n          xTexelC").concat(c * 2 + 1, "Ready = 0;\n          xC").concat(c, " = vec4(0.0);");
          }
          mainLoop += "\n        xR = xRCorner + r * dilations[0];\n        if (xR >=0 && xR < inDims[0]) {\n      ";
          for (var texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {
            var colIndex = texelC * 2;
            mainLoop += "\n          xC = xCCorner + ".concat(colIndex * dilationWidth, ";\n          ");
            if (strideWidth === 1) {
              if (colIndex < filterWidth) {
                if (padLeft % 2 === 1) {
                  mainLoop += "\n                xCOffset = xC + 1;\n                if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC".concat(colIndex, "Ready == 0) {\n                  xTexelC").concat(colIndex, " = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC").concat(colIndex, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(colIndex, "Ready = 1;\n                }\n              ");
                  if (dilationWidth === 1 && colIndex > 0) {
                    mainLoop += "\n                xC".concat(colIndex, " = vec4(xTexelC").concat(colIndex - 2, ".zw, xTexelC").concat(colIndex, ".xy);\n                ");
                  } else {
                    mainLoop += "\n                  xCOffset = xC + 1 - 2;\n\n                  if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                    previous = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= inDims[1]) {\n                      previous.zw = vec2(0.0);\n                    }\n\n                    xC".concat(colIndex, " = vec4(previous.zw, xTexelC").concat(colIndex, ".xy);\n                  } else {\n                    xC").concat(colIndex, " = vec4(0.0, 0.0, xTexelC").concat(colIndex, ".xy);\n                  }\n                  ");
                  }
                } else {
                  mainLoop += "\n                if (xC >= 0 && xC < inDims[1] && xTexelC".concat(colIndex, "Ready == 0) {\n                  xTexelC").concat(colIndex, " = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= inDims[1]) {\n                    xTexelC").concat(colIndex, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(colIndex, "Ready = 1;\n                }\n\n                xC").concat(colIndex, " = xTexelC").concat(colIndex, ";\n                ");
                }
                if (colIndex + 1 < filterWidth) {
                  var nextTexelOffset = padLeft % 2 === 0 ? tf.util.nearestLargerEven(dilationWidth) : dilationWidth;
                  if (dilationWidth % 2 === 0 && padLeft % 2 === 1 || dilationWidth % 2 !== 0 && padLeft % 2 !== 1) {
                    mainLoop += "\n                  xCOffset = xC + imod(pads[1], 2) + ".concat(nextTexelOffset, ";\n\n                  if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC").concat(colIndex + 1, "Ready == 0) {\n                    xTexelC").concat(colIndex + 1, " = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= inDims[1]) {\n                      xTexelC").concat(colIndex + 1, ".zw = vec2(0.0);\n                    }\n                    xTexelC").concat(colIndex + 1, "Ready = 1;\n                  }\n                  ");
                    if (dilationWidth > 1) {
                      mainLoop += "\n                    xCOffset -= 2;\n                    if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                     previous = getX(batch, xR, xCOffset, d1);\n                     xC".concat(colIndex + 1, " = vec4(previous.zw, xTexelC").concat(colIndex + 1, ".xy);\n                    } else {\n                     xC").concat(colIndex + 1, " = vec4(0.0, 0.0, xTexelC").concat(colIndex + 1, ".xy);\n                    }\n                    ");
                    } else {
                      mainLoop += "\n                    xC".concat(colIndex + 1, " = vec4(xTexelC").concat(colIndex, ".zw, xTexelC").concat(colIndex + 1, ".xy);\n                    ");
                    }
                  } else {
                    if (nextTexelOffset === 1) {
                      mainLoop += "\n                    xC".concat(colIndex + 1, " = xTexelC").concat(colIndex, ";\n                    ");
                    } else {
                      mainLoop += "\n                    xCOffset = xC + ".concat(nextTexelOffset, ";\n\n                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC").concat(colIndex + 1, "Ready == 0) {\n                      xTexelC").concat(colIndex + 1, " = getX(batch, xR, xCOffset, d1);\n                      if (xCOffset + 1 >= inDims[1]) {\n                        xTexelC").concat(colIndex + 1, ".zw = vec2(0.0);\n                      }\n                      xTexelC").concat(colIndex + 1, "Ready = 1;\n                    }\n\n                    xC").concat(colIndex + 1, " = xTexelC").concat(colIndex + 1, ";\n                    ");
                    }
                  }
                }
              }
            } else {
              if (colIndex < filterWidth) {
                if (padLeft % 2 === 1) {
                  mainLoop += "\n                xCOffset = xC + 1 - strides[1];\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC".concat(colIndex, "Ready == 0) {\n                  xTexelC").concat(colIndex, " = getX(batch, xR, xCOffset, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC").concat(colIndex, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(colIndex, "Ready = 1;\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC").concat(colIndex + 1, "Ready == 0) {\n                  xTexelC").concat(colIndex + 1, " = getX(batch, xR, xC + 1, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xC + 2 >= inDims[1]) {\n                    xTexelC").concat(colIndex + 1, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(colIndex + 1, "Ready = 1;\n                }\n\n                xC").concat(colIndex, " = vec4(xTexelC").concat(colIndex, ".zw, xTexelC").concat(colIndex + 1, ".zw);\n              ");
                  if (colIndex + 1 < filterWidth) {
                    mainLoop += "\n                  final = vec4(0.0);\n                  xCOffset = xC + 1 + strides[1];\n                  if(xCOffset >= 0 && xCOffset < inDims[1]) {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xC".concat(colIndex + 1, " = vec4(xTexelC").concat(colIndex + 1, ".xy, final.xy);\n                ");
                  }
                } else {
                  mainLoop += "\n                if(xC >= 0 && xC < inDims[1] && xTexelC".concat(colIndex, "Ready == 0) {\n                  xTexelC").concat(colIndex, " = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= inDims[1]) {\n                    xTexelC").concat(colIndex, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(colIndex, "Ready = 1;\n                }\n\n                xCOffset = xC + strides[1];\n                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC").concat(colIndex + 1, "Ready == 0) {\n                  xTexelC").concat(colIndex + 1, " = getX(batch, xR, xCOffset, d1);\n                  if (xCOffset + 1 >= inDims[1]) {\n                    xTexelC").concat(colIndex + 1, ".zw = vec2(0.);\n                  }\n                  xTexelC").concat(colIndex + 1, "Ready = 1;\n                }\n\n                xC").concat(colIndex, " = vec4(\n                  xTexelC").concat(colIndex, ".xy, xTexelC").concat(colIndex + 1, ".xy);\n              ");
                  if (colIndex + 1 < filterWidth) {
                    mainLoop += "\n                  xC".concat(colIndex + 1, " = vec4(xTexelC").concat(colIndex, ".zw, xTexelC").concat(colIndex + 1, ".zw);\n                ");
                  }
                }
              }
            }
            if (colIndex < filterWidth) {
              mainLoop += "\n            wTexel = getW(r, ".concat(colIndex, ", d1, q);\n            dotProd += xC").concat(colIndex, " * vec4(wTexel.xz, wTexel.xz);\n          ");
              if (colIndex + 1 < filterWidth) {
                mainLoop += "\n              wTexel = getW(r, ".concat(colIndex + 1, ", d1, q);\n              dotProd += xC").concat(colIndex + 1, " * vec4(wTexel.xz, wTexel.xz);\n            ");
              }
            }
          }
          mainLoop += "\n    }\n  ";
          mainLoop += "\n      }\n    ";
          var activationSnippet = "", applyActivationSnippet = "";
          if (activation) {
            if (hasPreluActivation) {
              activationSnippet = "vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ".concat(activation, "\n        }");
            } else if (hasLeakyReluAlpha) {
              activationSnippet = "vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ".concat(activation, "\n        }");
            } else {
              activationSnippet = "vec4 activation(vec4 x) {\n          ".concat(activation, "\n        }");
            }
            applyActivationSnippet = "result = activation(result);";
          }
          var addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
          if (addBias) {
            this.variableNames.push("bias");
          }
          if (hasPreluActivation) {
            this.variableNames.push("preluActivationWeights");
          }
          if (hasLeakyReluAlpha) {
            this.variableNames.push("leakyreluAlpha");
          }
          this.userCode = "\n      ".concat(activationSnippet, "\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ").concat(channelMul, ";\n        int q = d2 - d1 * ").concat(channelMul, ";\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n        vec4 dotProd = vec4(0.000000000000001);\n\n        ").concat(mainLoop, "\n\n        vec4 result = dotProd - vec4(0.000000000000001);\n        ").concat(addBiasSnippet, "\n        ").concat(applyActivationSnippet, "\n        setOutput(result);\n      }\n    ");
        }
        return DepthwiseConvPacked2DProgram2;
      }()
    );
    function depthwiseConv2dNative(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter;
      var strides = attrs.strides, pad = attrs.pad, dilations = attrs.dilations, dimRoundingMode = attrs.dimRoundingMode;
      var $dilations = dilations;
      if ($dilations == null) {
        $dilations = [1, 1];
      }
      tf.util.assert(tf.backend_util.eitherStridesOrDilationsAreOne(strides, $dilations), function() {
        return "Error in depthwiseConv2d: Either strides or dilations must be " + "1. Got strides ".concat(strides, " and dilations '").concat($dilations, "'");
      });
      var convInfo = tf.backend_util.computeConv2DInfo(
        x.shape,
        filter.shape,
        strides,
        $dilations,
        pad,
        dimRoundingMode,
        true
        /* depthwise */
      );
      var program;
      if (tf.env().getBool("WEBGL_PACK_DEPTHWISECONV") && convInfo.strideWidth <= 2 && convInfo.outChannels / convInfo.inChannels === 1) {
        program = new DepthwiseConvPacked2DProgram(convInfo);
      } else {
        program = new DepthwiseConv2DProgram(convInfo);
      }
      var customValues = [
        [convInfo.padInfo.top, convInfo.padInfo.left],
        [convInfo.strideHeight, convInfo.strideWidth],
        [convInfo.dilationHeight, convInfo.dilationWidth],
        [convInfo.inHeight, convInfo.inWidth]
      ];
      return backend.runWebGLProgram(program, [x, filter], "float32", customValues);
    }
    var depthwiseConv2dNativeConfig = {
      kernelName: tf.DepthwiseConv2dNative,
      backendName: "webgl",
      kernelFunc: depthwiseConv2dNative
    };
    var DepthwiseConv2DDerFilterProgram = (
      /** @class */
      function() {
        function DepthwiseConv2DDerFilterProgram2(convInfo) {
          this.variableNames = ["x", "dy"];
          this.outputShape = convInfo.filterShape;
          var strideHeight = convInfo.strideHeight;
          var strideWidth = convInfo.strideWidth;
          var padTop = convInfo.padInfo.top;
          var padLeft = convInfo.padInfo.left;
          var channelMul = convInfo.outChannels / convInfo.inChannels;
          this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int dm = coords.w;\n        int d2 = d1 * ".concat(channelMul, " + dm;\n\n        float dotProd = 0.0;\n\n        // TO DO: Vec4 over the batch size\n        for (int b = 0; b < ").concat(convInfo.batchSize, "; b++) {\n          for (int yR = 0; yR < ").concat(convInfo.outHeight, "; yR++) {\n            int xR = wR + yR * ").concat(strideHeight, " - ").concat(padTop, ";\n\n            if (xR < 0 || xR >= ").concat(convInfo.inHeight, ") {\n              continue;\n            }\n\n            for (int yC = 0; yC < ").concat(convInfo.outWidth, "; yC++) {\n              int xC = wC + yC * ").concat(strideWidth, " - ").concat(padLeft, ";\n\n              if (xC < 0 || xC >= ").concat(convInfo.inWidth, ") {\n                continue;\n              }\n\n              float dyValue = getDy(b, yR, yC, d2);\n              float xValue = getX(b, xR, xC, d1);\n              dotProd += (xValue * dyValue);\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
        }
        return DepthwiseConv2DDerFilterProgram2;
      }()
    );
    var DepthwiseConv2DDerInputProgram = (
      /** @class */
      function() {
        function DepthwiseConv2DDerInputProgram2(convInfo) {
          this.variableNames = ["dy", "W"];
          this.outputShape = convInfo.inShape;
          var filterHeight = convInfo.filterHeight;
          var filterWidth = convInfo.filterWidth;
          var strideHeight = convInfo.strideHeight;
          var strideWidth = convInfo.strideWidth;
          var padTop = filterHeight - 1 - convInfo.padInfo.top;
          var padLeft = filterWidth - 1 - convInfo.padInfo.left;
          var channelMul = convInfo.outChannels / convInfo.inChannels;
          this.userCode = "\n      const ivec2 pads = ivec2(".concat(padTop, ", ").concat(padLeft, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[3];\n        ivec2 dyCorner = coords.yz - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        float dotProd = 0.0;\n\n        for (int wR = 0; wR < ").concat(filterHeight, "; wR++) {\n          float dyR = float(dyRCorner + wR) / ").concat(strideHeight, ".0;\n\n          if (dyR < 0.0 || dyR >= ").concat(convInfo.outHeight, ".0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ").concat(filterHeight, " - 1 - wR;\n\n          for (int wC = 0; wC < ").concat(filterWidth, "; wC++) {\n            float dyC = float(dyCCorner + wC) / ").concat(strideWidth, ".0;\n\n            if (dyC < 0.0 || dyC >= ").concat(convInfo.outWidth, ".0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ").concat(filterWidth, " - 1 - wC;\n\n            // TO DO: Vec4 over the channelMul\n            for (int dm = 0; dm < ").concat(channelMul, "; dm++) {\n              int d2 = d1 * ").concat(channelMul, " + dm;\n              float xValue = getDy(batch, idyR, idyC, d2);\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\n              dotProd += xValue * wValue;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
        }
        return DepthwiseConv2DDerInputProgram2;
      }()
    );
    function depthwiseConv2dNativeBackpropFilter(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, dy = inputs.dy;
      var strides = attrs.strides, dilations = attrs.dilations, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode, filterShape = attrs.filterShape;
      var convInfo = tf.backend_util.computeConv2DInfo(
        x.shape,
        filterShape,
        strides,
        dilations,
        pad,
        dimRoundingMode,
        true
        /* depthwise */
      );
      var program = new DepthwiseConv2DDerFilterProgram(convInfo);
      return backend.runWebGLProgram(program, [x, dy], "float32");
    }
    var depthwiseConv2dNativeBackpropFilterConfig = {
      kernelName: tf.DepthwiseConv2dNativeBackpropFilter,
      backendName: "webgl",
      kernelFunc: depthwiseConv2dNativeBackpropFilter
    };
    function depthwiseConv2dNativeBackpropInput(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, filter = inputs.filter;
      var strides = attrs.strides, dilations = attrs.dilations, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode, inputShape = attrs.inputShape;
      var convInfo = tf.backend_util.computeConv2DInfo(
        inputShape,
        filter.shape,
        strides,
        dilations,
        pad,
        dimRoundingMode,
        true
        /* depthwise */
      );
      var program = new DepthwiseConv2DDerInputProgram(convInfo);
      return backend.runWebGLProgram(program, [dy, filter], "float32");
    }
    var depthwiseConv2dNativeBackpropInputConfig = {
      kernelName: tf.DepthwiseConv2dNativeBackpropInput,
      backendName: "webgl",
      kernelFunc: depthwiseConv2dNativeBackpropInput
    };
    var DiagProgram = (
      /** @class */
      function() {
        function DiagProgram2(size) {
          this.variableNames = ["X"];
          this.outputShape = [size, size];
          this.userCode = "\n      void main() {\n          ivec2 coords = getOutputCoords();\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\n          setOutput(val);\n      }\n    ";
        }
        return DiagProgram2;
      }()
    );
    function diag(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x;
      var outShape = __spreadArray(__spreadArray([], __read(x.shape), false), __read(x.shape), false);
      var xSize = tf.util.sizeFromShape(x.shape);
      var flat = reshape({ inputs: { x }, backend, attrs: { shape: [xSize] } });
      var program = new DiagProgram(xSize);
      var res = backend.runWebGLProgram(program, [flat], flat.dtype);
      var out = reshape({ inputs: { x: res }, backend, attrs: { shape: outShape } });
      backend.disposeIntermediateTensorInfo(flat);
      backend.disposeIntermediateTensorInfo(res);
      return out;
    }
    var diagConfig = {
      kernelName: tf.Diag,
      backendName: "webgl",
      kernelFunc: diag
    };
    var Dilation2DProgram = (
      /** @class */
      function() {
        function Dilation2DProgram2(convInfo) {
          this.variableNames = ["x", "W"];
          this.outputShape = convInfo.outShape;
          var inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, padInfo = convInfo.padInfo, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, dilationHeight = convInfo.dilationHeight, dilationWidth = convInfo.dilationWidth;
          var padTop = padInfo.top, padLeft = padInfo.left;
          this.userCode = "\n      const ivec2 strides = ivec2(".concat(strideHeight, ", ").concat(strideWidth, ");\n      const ivec2 pads = ivec2(").concat(padTop, ", ").concat(padLeft, ");\n      const float neg_infinity = -3.4e38;\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.w;\n        ivec2 outTopLeftCorner =\n            coords.yz * strides - pads;\n        int hBeg = outTopLeftCorner.x;\n        int wBeg = outTopLeftCorner.y;\n\n        float curVal = neg_infinity;\n        for (int h = 0; h < ").concat(filterHeight, "; h++) {\n          int hIn = hBeg + h * ").concat(dilationHeight, ";\n\n          if (hIn >= 0 && hIn < ").concat(inHeight, ") {\n            for (int w = 0; w < ").concat(filterWidth, "; w++) {\n              int wIn = wBeg + w * ").concat(dilationWidth, ";\n\n              if (wIn >= 0 && wIn < ").concat(inWidth, ") {\n                float xVal = getX(batch, hIn, wIn, d1);\n                float wVal = getW(h, w, d1);\n\n                float val = xVal + wVal;\n                if (val > curVal) {\n                  curVal = val;\n                }\n              }\n            }\n          }\n        }\n\n        float result = curVal;\n        setOutput(result);\n      }\n    ");
        }
        return Dilation2DProgram2;
      }()
    );
    function dilation2D(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter;
      var strides = attrs.strides, pad = attrs.pad, dilations = attrs.dilations;
      var convInfo = tf.backend_util.computeDilation2DInfo(x.shape, filter.shape, strides, pad, "NHWC", dilations);
      var out;
      var program = new Dilation2DProgram(convInfo);
      out = backend.runWebGLProgram(program, [x, filter], "float32");
      var outReshaped = reshape({ inputs: { x: out }, backend, attrs: { shape: convInfo.outShape } });
      backend.disposeIntermediateTensorInfo(out);
      return outReshaped;
    }
    var dilation2DConfig = {
      kernelName: tf.Dilation2D,
      backendName: "webgl",
      kernelFunc: dilation2D
    };
    function einsum(args) {
      var e_12, _a2, e_2, _b;
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var equation = attrs.equation;
      var tensors = inputs;
      var _c = tf.backend_util.decodeEinsumEquation(equation, tensors.length), allDims = _c.allDims, summedDims = _c.summedDims, idDims = _c.idDims;
      tf.backend_util.checkEinsumDimSizes(allDims.length, idDims, tensors);
      var _d = tf.backend_util.getEinsumComputePath(summedDims, idDims), path = _d.path, steps = _d.steps;
      var nSteps = steps.length;
      var out = null;
      var numDimsRemaining = allDims.length;
      var tensorsToDispose = [];
      for (var i = 0; i < nSteps; ++i) {
        try {
          for (var _e = (e_12 = void 0, __values(steps[i])), _f = _e.next(); !_f.done; _f = _e.next()) {
            var idTerm = _f.value;
            var _g = tf.backend_util.getEinsumPermutation(numDimsRemaining, idDims[idTerm]), perm = _g.permutationIndices, dimsToExpand = _g.expandDims;
            var x = void 0;
            if (tf.backend_util.isIdentityPermutation(perm)) {
              x = tensors[idTerm];
            } else {
              x = transpose({ inputs: { x: tensors[idTerm] }, backend, attrs: { perm } });
              tensorsToDispose.push(x);
            }
            var targetShape = x.shape.slice();
            for (var k = 0; k < dimsToExpand.length; ++k) {
              targetShape.splice(dimsToExpand[k], 0, 1);
            }
            if (!tf.util.arraysEqual(x.shape, targetShape)) {
              x = reshape({ inputs: { x }, backend, attrs: { shape: targetShape } });
              tensorsToDispose.push(x);
            }
            if (out === null) {
              out = x;
            } else {
              out = multiply({ inputs: { a: x, b: out }, backend });
              tensorsToDispose.push(out);
            }
          }
        } catch (e_1_1) {
          e_12 = { error: e_1_1 };
        } finally {
          try {
            if (_f && !_f.done && (_a2 = _e.return))
              _a2.call(_e);
          } finally {
            if (e_12)
              throw e_12.error;
          }
        }
        if (i < nSteps - 1) {
          if (path[i] >= 0) {
            out = sum({
              inputs: { x: out },
              backend,
              attrs: {
                axis: path[i] - (allDims.length - numDimsRemaining),
                keepDims: false
              }
            });
            tensorsToDispose.push(out);
          }
          numDimsRemaining--;
        }
      }
      try {
        for (var tensorsToDispose_1 = __values(tensorsToDispose), tensorsToDispose_1_1 = tensorsToDispose_1.next(); !tensorsToDispose_1_1.done; tensorsToDispose_1_1 = tensorsToDispose_1.next()) {
          var tensorInfo = tensorsToDispose_1_1.value;
          if (tensorInfo === out) {
            continue;
          }
          backend.disposeIntermediateTensorInfo(tensorInfo);
        }
      } catch (e_2_1) {
        e_2 = { error: e_2_1 };
      } finally {
        try {
          if (tensorsToDispose_1_1 && !tensorsToDispose_1_1.done && (_b = tensorsToDispose_1.return))
            _b.call(tensorsToDispose_1);
        } finally {
          if (e_2)
            throw e_2.error;
        }
      }
      return out;
    }
    var einsumConfig = {
      kernelName: tf.Einsum,
      backendName: "webgl",
      kernelFunc: einsum
    };
    var ELU = "return (x >= 0.0) ? x : (exp(x) - 1.0);";
    var ELU_PACKED = "\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n";
    var elu = unaryKernelFunc({ opSnippet: ELU, packedOpSnippet: ELU_PACKED });
    var eluConfig = {
      kernelName: tf.Elu,
      backendName: "webgl",
      kernelFunc: elu
    };
    var ELU_DER = "return (b >= 0.0) ? a : a * (b + 1.0);";
    var ELU_DER_PACKED = "\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\n";
    var eluGrad = function(args) {
      var inputs = args.inputs, backend = args.backend;
      var dy = inputs.dy, y = inputs.y;
      var program = tf.env().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(ELU_DER_PACKED, dy.shape, y.shape) : new BinaryOpProgram(ELU_DER, dy.shape, y.shape);
      return backend.runWebGLProgram(program, [dy, y], dy.dtype);
    };
    var eluGradConfig = {
      kernelName: tf.EluGrad,
      backendName: "webgl",
      kernelFunc: eluGrad
    };
    var PACKED_EQUAL = "\n  return vec4(equal(a, b));\n";
    var EQUAL = "return float(a == b);";
    var equal = binaryKernelFunc({
      opSnippet: EQUAL,
      packedOpSnippet: PACKED_EQUAL,
      dtype: "bool",
      cpuKernelImpl: equalImplCPU
    });
    var equalConfig = {
      kernelName: tf.Equal,
      backendName: "webgl",
      kernelFunc: equal
    };
    var ERF = '\n  // Error function is calculated approximately with elementary function.\n  // See "Handbook of Mathematical Functions with Formulas,\n  // Graphs, and Mathematical Tables", Abramowitz and Stegun.\n  float p = '.concat(tf.backend_util.ERF_P, ";\n  float a1 = ").concat(tf.backend_util.ERF_A1, ";\n  float a2 = ").concat(tf.backend_util.ERF_A2, ";\n  float a3 = ").concat(tf.backend_util.ERF_A3, ";\n  float a4 = ").concat(tf.backend_util.ERF_A4, ";\n  float a5 = ").concat(tf.backend_util.ERF_A5, ";\n\n  float sign = sign(x);\n  x = abs(x);\n  float t = 1.0 / (1.0 + p * x);\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\n");
    var erf = unaryKernelFunc({ opSnippet: ERF });
    var erfConfig = {
      kernelName: tf.Erf,
      backendName: "webgl",
      kernelFunc: erf
    };
    var EXP = CHECK_NAN_SNIPPET_UNARY + "\n  return exp(x);\n";
    var EXP_PACKED = "\n  vec4 result = exp(x);\n  bvec4 isNaN = isnan(x);\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n";
    var exp = unaryKernelFunc({
      opSnippet: EXP,
      packedOpSnippet: EXP_PACKED,
      cpuKernelImpl: expImplCPU,
      dtype: "float32"
    });
    var expConfig = {
      kernelName: tf.Exp,
      backendName: "webgl",
      kernelFunc: exp
    };
    function expandDims(args) {
      var inputs = args.inputs, attrs = args.attrs, backend = args.backend;
      var dim = attrs.dim;
      var input = inputs.input;
      var inputRank = input.shape.length;
      var newShape = input.shape.slice();
      var $dim = dim;
      if (dim < 0) {
        tf.util.assert(-(inputRank + 1) <= dim, function() {
          return "Axis must be in the interval [".concat(-(inputRank + 1), ", ").concat(inputRank, "]");
        });
        $dim = inputRank + dim + 1;
      }
      newShape.splice($dim, 0, 1);
      return reshape({ inputs: { x: input }, backend, attrs: { shape: newShape } });
    }
    var expandDimsConfig = {
      kernelName: tf.ExpandDims,
      backendName: "webgl",
      kernelFunc: expandDims
    };
    var EXPM1 = "return exp(x) - 1.0;";
    var expm1 = unaryKernelFunc({ opSnippet: EXPM1, packedOpSnippet: EXPM1, cpuKernelImpl: expm1ImplCPU });
    var expm1Config = {
      kernelName: tf.Expm1,
      backendName: "webgl",
      kernelFunc: expm1
    };
    var FFTProgram = (
      /** @class */
      function() {
        function FFTProgram2(component, inputShape, inverse) {
          this.variableNames = ["real", "imag"];
          var innerDim = inputShape[1];
          this.outputShape = inputShape;
          var exponentMultiplierSnippet = inverse ? "2.0 * ".concat(Math.PI) : "-2.0 * ".concat(Math.PI);
          var resultDenominator = inverse ? "".concat(innerDim, ".0") : "1.0";
          var opString;
          if (component === "real") {
            opString = "return real * expR - imag * expI;";
          } else if (component === "imag") {
            opString = "return real * expI + imag * expR;";
          } else {
            throw new Error('FFT component must be either "real" or "imag", got '.concat(component, "."));
          }
          this.userCode = "\n      const float exponentMultiplier = ".concat(exponentMultiplierSnippet, ";\n\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\n        ").concat(opString, "\n      }\n\n      float mulMatDFT(int batch, int index) {\n        float indexRatio = float(index) / float(").concat(innerDim, ");\n        float exponentMultiplierTimesIndexRatio =\n            exponentMultiplier * indexRatio;\n\n        float result = 0.0;\n\n        for (int i = 0; i < ").concat(innerDim, "; i++) {\n          // x = (-2|2 * PI / N) * index * i;\n          float x = exponentMultiplierTimesIndexRatio * float(i);\n          float expR = cos(x);\n          float expI = sin(x);\n          float real = getReal(batch, i);\n          float imag = getImag(batch, i);\n\n          result +=\n              unaryOpComplex(real, expR, imag, expI) / ").concat(resultDenominator, ";\n        }\n\n        return result;\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        setOutput(mulMatDFT(coords[0], coords[1]));\n      }\n    ");
        }
        return FFTProgram2;
      }()
    );
    function fftImpl(x, inverse, backend) {
      var xData = backend.texData.get(x.dataId);
      var inputSize = tf.util.sizeFromShape(x.shape);
      var innerDimensionSize = x.shape[x.shape.length - 1];
      var batch = inputSize / innerDimensionSize;
      var input2D = reshape({ inputs: { x }, backend, attrs: { shape: [batch, innerDimensionSize] } });
      var xShape = input2D.shape;
      var realProgram = new FFTProgram("real", xShape, inverse);
      var imagProgram = new FFTProgram("imag", xShape, inverse);
      var inputs = [
        {
          dataId: xData.complexTensorInfos.real.dataId,
          dtype: xData.complexTensorInfos.real.dtype,
          shape: xShape
        },
        {
          dataId: xData.complexTensorInfos.imag.dataId,
          dtype: xData.complexTensorInfos.imag.dtype,
          shape: xShape
        }
      ];
      var realPart = backend.runWebGLProgram(realProgram, inputs, "float32");
      var imagPart = backend.runWebGLProgram(imagProgram, inputs, "float32");
      var complexOutput = complex({ inputs: { real: realPart, imag: imagPart }, backend });
      backend.disposeIntermediateTensorInfo(realPart);
      backend.disposeIntermediateTensorInfo(imagPart);
      var complexOutputReshaped = reshape({ inputs: { x: complexOutput }, backend, attrs: { shape: x.shape } });
      backend.disposeIntermediateTensorInfo(input2D);
      backend.disposeIntermediateTensorInfo(complexOutput);
      return complexOutputReshaped;
    }
    function fft(args) {
      var inputs = args.inputs, backend = args.backend;
      var input = inputs.input;
      return fftImpl(input, false, backend);
    }
    var fftConfig = {
      kernelName: tf.FFT,
      backendName: "webgl",
      kernelFunc: fft
    };
    var FillProgram = (
      /** @class */
      function() {
        function FillProgram2(shape, value) {
          this.outputShape = [];
          this.customUniforms = [{ name: "value", type: "float" }];
          this.variableNames = ["x"];
          this.outputShape = shape;
          this.userCode = "\n      void main() {\n        // Input can be obtained from uniform value.\n        setOutput(value);\n      }\n    ";
        }
        return FillProgram2;
      }()
    );
    function fill(args) {
      var backend = args.backend, attrs = args.attrs;
      var shape = attrs.shape, value = attrs.value;
      var dtype = attrs.dtype;
      dtype = dtype || tf.util.inferDtype(value);
      if (dtype === "string") {
        var values = tf.util.getArrayFromDType(dtype, tf.util.sizeFromShape(shape));
        values.fill(value);
        return backend.makeTensorInfo(shape, dtype, values);
      } else {
        var program = new FillProgram(shape, value);
        var customValues = [[value]];
        return backend.runWebGLProgram(program, [], dtype, customValues);
      }
    }
    var fillConfig = {
      kernelName: tf.Fill,
      backendName: "webgl",
      kernelFunc: fill
    };
    var FlipLeftRightProgram = (
      /** @class */
      function() {
        function FlipLeftRightProgram2(imageShape) {
          this.variableNames = ["Image"];
          this.outputShape = [];
          var imageWidth = imageShape[2];
          this.outputShape = imageShape;
          this.userCode = "\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n\n          int coordX = ".concat(imageWidth, " - x - 1;\n          float outputValue;\n          if(coordX >= 0 && coordX < ").concat(imageWidth, ") {\n            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);\n          } else {\n            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    ");
        }
        return FlipLeftRightProgram2;
      }()
    );
    var flipLeftRightConfig = {
      kernelName: tf.FlipLeftRight,
      backendName: "webgl",
      kernelFunc: function(_a2) {
        var inputs = _a2.inputs, backend = _a2.backend;
        var image = inputs.image;
        var webglBackend = backend;
        var program = new FlipLeftRightProgram(image.shape);
        var output = webglBackend.runWebGLProgram(program, [image], image.dtype);
        return output;
      }
    };
    var FLOOR = "return floor(x);";
    var floor = unaryKernelFunc({ opSnippet: FLOOR, packedOpSnippet: FLOOR, cpuKernelImpl: floorImplCPU });
    var floorConfig = {
      kernelName: tf.Floor,
      backendName: "webgl",
      kernelFunc: floor
    };
    var INT_DIV = "\n  float s = sign(a) * sign(b);\n  int ia = round(a);\n  int ib = round(b);\n  if (ib != 0) {\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n    return float(idiv(ia, ib, s));\n  } else {\n    return NAN;\n  }\n";
    var INT_DIV_PACKED = "\n  ivec4 ia = round(a);\n  ivec4 ib = round(b);\n  bvec4 cond = notEqual(ib, ivec4(0));\n  ivec4 result = ivec4(0);\n  vec4 s = sign(a) * sign(b);\n\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n  if (cond[0]) {\n    result[0] = idiv(ia[0], ib[0], s[0]);\n  }\n  if (cond[1]) {\n    result[1] = idiv(ia[1], ib[1], s[1]);\n  }\n  if (cond[2]) {\n    result[2] = idiv(ia[2], ib[2], s[2]);\n  }\n  if (cond[3]) {\n    result[3] = idiv(ia[3], ib[3], s[3]);\n  }\n  return vec4(result);\n";
    var floorDiv = binaryKernelFunc({ opSnippet: INT_DIV, packedOpSnippet: INT_DIV_PACKED, dtype: "int32" });
    var floorDivConfig = {
      kernelName: tf.FloorDiv,
      backendName: "webgl",
      kernelFunc: floorDiv
    };
    var FromPixelsProgram = (
      /** @class */
      function() {
        function FromPixelsProgram2(outputShape) {
          this.variableNames = ["A"];
          var glsl = getGlslDifferences();
          var _a2 = __read(outputShape, 2), height = _a2[0], width = _a2[1];
          this.outputShape = outputShape;
          this.userCode = "\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(".concat(width, ".0, ").concat(height, ".0);\n\n        vec4 values = ").concat(glsl.texture2D, "(A, uv);\n        float value;\n        if (depth == 0) {\n          value = values.r;\n        } else if (depth == 1) {\n          value = values.g;\n        } else if (depth == 2) {\n          value = values.b;\n        } else if (depth == 3) {\n          value = values.a;\n        }\n\n        setOutput(floor(value * 255.0 + 0.5));\n      }\n    ");
        }
        return FromPixelsProgram2;
      }()
    );
    var FromPixelsPackedProgram = (
      /** @class */
      function() {
        function FromPixelsPackedProgram2(outputShape) {
          this.variableNames = ["A"];
          this.packedInputs = false;
          this.packedOutput = true;
          var glsl = getGlslDifferences();
          var _a2 = __read(outputShape, 2), height = _a2[0], width = _a2[1];
          this.outputShape = outputShape;
          this.userCode = "\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n\n        vec4 result = vec4(0.);\n\n        for(int row=0; row<=1; row++) {\n          for(int col=0; col<=1; col++) {\n            texC = coords[1] + row;\n            depth = coords[2] + col;\n\n            vec2 uv = (vec2(texC, texR) + halfCR) /\n                       vec2(".concat(width, ".0, ").concat(height, ".0);\n            vec4 values = ").concat(glsl.texture2D, "(A, uv);\n            float value;\n            if (depth == 0) {\n              value = values.r;\n            } else if (depth == 1) {\n              value = values.g;\n            } else if (depth == 2) {\n              value = values.b;\n            } else if (depth == 3) {\n              value = values.a;\n            }\n\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\n          }\n        }\n\n        ").concat(glsl.output, " = result;\n      }\n    ");
        }
        return FromPixelsPackedProgram2;
      }()
    );
    var fromPixelsConfig = {
      kernelName: tf.FromPixels,
      backendName: "webgl",
      kernelFunc: fromPixels
    };
    var fromPixels2DContext;
    var willReadFrequently = tf.env().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");
    function fromPixels(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var pixels = inputs.pixels;
      var numChannels = attrs.numChannels;
      var isVideo = typeof HTMLVideoElement !== "undefined" && pixels instanceof HTMLVideoElement;
      var isImage = typeof HTMLImageElement !== "undefined" && pixels instanceof HTMLImageElement;
      var _a2 = __read(isVideo ? [
        pixels.videoWidth,
        pixels.videoHeight
      ] : [pixels.width, pixels.height], 2), width = _a2[0], height = _a2[1];
      var texShape = [height, width];
      var outShape = [height, width, numChannels];
      if (isImage || isVideo) {
        var newWillReadFrequently = tf.env().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");
        if (fromPixels2DContext == null || newWillReadFrequently !== willReadFrequently) {
          willReadFrequently = newWillReadFrequently;
          fromPixels2DContext = document.createElement("canvas").getContext("2d", { willReadFrequently });
        }
        fromPixels2DContext.canvas.width = width;
        fromPixels2DContext.canvas.height = height;
        fromPixels2DContext.drawImage(pixels, 0, 0, width, height);
        pixels = fromPixels2DContext.canvas;
      }
      var tempPixelHandle = backend.makeTensorInfo(texShape, "int32");
      backend.texData.get(tempPixelHandle.dataId).usage = TextureUsage.PIXELS;
      backend.gpgpu.uploadPixelDataToTexture(backend.getTexture(tempPixelHandle.dataId), pixels);
      var program = tf.env().getBool("WEBGL_PACK") ? new FromPixelsPackedProgram(outShape) : new FromPixelsProgram(outShape);
      var res = backend.runWebGLProgram(program, [tempPixelHandle], "int32");
      backend.disposeData(tempPixelHandle.dataId);
      return res;
    }
    function fusedConv2d(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter, bias = inputs.bias, preluActivationWeights = inputs.preluActivationWeights;
      var strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dilations = attrs.dilations, dimRoundingMode = attrs.dimRoundingMode, activation = attrs.activation, leakyreluAlpha = attrs.leakyreluAlpha;
      var $dataFormat = tf.backend_util.convertConv2DDataFormat(dataFormat);
      var convInfo = tf.backend_util.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad, dimRoundingMode, false, $dataFormat);
      var out;
      var intermediates = [];
      var hasBias = bias != null;
      var hasPreluActivationWeights = preluActivationWeights != null;
      var hasLeakyreluAlpha = activation === "leakyrelu";
      var prepareInputs = function() {
        var inputs2 = [x, filter];
        var alignInputWithDataFormat = function(input, dataFormat2) {
          if (dataFormat2 === "NCHW" && input.shape.length === 1 && input.shape[0] !== 1) {
            var alignedInput = reshape({
              inputs: { x: input },
              backend,
              attrs: { shape: [input.shape[0], 1, 1] }
            });
            intermediates.push(alignedInput);
            return alignedInput;
          }
          return input;
        };
        if (hasBias) {
          inputs2.push(alignInputWithDataFormat(bias, dataFormat));
        }
        if (hasPreluActivationWeights) {
          inputs2.push(alignInputWithDataFormat(preluActivationWeights, dataFormat));
        }
        if (hasLeakyreluAlpha) {
          var $leakyreluAlpha = backend.makeTensorInfo([], "float32", tf.util.createScalarValue(leakyreluAlpha, "float32"));
          inputs2.push($leakyreluAlpha);
          intermediates.push($leakyreluAlpha);
        }
        return inputs2;
      };
      if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === "SAME" || convInfo.padInfo.type === "VALID")) {
        out = conv2dByMatMul({
          x,
          filter,
          convInfo,
          backend,
          bias,
          activation,
          preluActivationWeights,
          leakyreluAlpha
        });
      } else if (convInfo.strideWidth <= 2 && $dataFormat === "channelsLast" && tf.env().getBool("WEBGL_EXP_CONV")) {
        var fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;
        var program = new Conv2DPackedProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
        var customValues = [
          [convInfo.padInfo.top, convInfo.padInfo.left],
          [convInfo.strideHeight, convInfo.strideWidth],
          [convInfo.dilationHeight, convInfo.dilationWidth],
          [convInfo.inHeight, convInfo.inWidth]
        ];
        var inputs_1 = prepareInputs();
        out = backend.runWebGLProgram(program, inputs_1, "float32", customValues);
      } else if (tf.env().getBool("WEBGL_CONV_IM2COL")) {
        out = conv2dWithIm2Row({
          x,
          filter,
          convInfo,
          backend,
          bias,
          activation,
          preluActivationWeights,
          leakyreluAlpha
        });
      } else {
        var fusedActivation = activation ? mapActivationToShaderProgram(activation, false) : null;
        var program = new Conv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
        var inputs_2 = prepareInputs();
        out = backend.runWebGLProgram(program, inputs_2, "float32");
      }
      var outReshaped = reshape({ inputs: { x: out }, backend, attrs: { shape: convInfo.outShape } });
      intermediates.push(out);
      intermediates.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return outReshaped;
    }
    var fusedConv2DConfig = {
      kernelName: tf.FusedConv2D,
      backendName: "webgl",
      kernelFunc: fusedConv2d
    };
    function fusedDepthwiseConv2D(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter, bias = inputs.bias, preluActivationWeights = inputs.preluActivationWeights;
      var strides = attrs.strides, pad = attrs.pad, dilations = attrs.dilations, dimRoundingMode = attrs.dimRoundingMode, activation = attrs.activation, leakyreluAlpha = attrs.leakyreluAlpha;
      var intermediates = [];
      var $dilations = dilations;
      if ($dilations == null) {
        $dilations = [1, 1];
      }
      tf.util.assert(tf.backend_util.eitherStridesOrDilationsAreOne(strides, $dilations), function() {
        return "Error in depthwiseConv2d: Either strides or dilations must be " + "1. Got strides ".concat(strides, " and dilations '").concat($dilations, "'");
      });
      var convInfo = tf.backend_util.computeConv2DInfo(
        x.shape,
        filter.shape,
        strides,
        $dilations,
        pad,
        dimRoundingMode,
        true
        /* depthwise */
      );
      var shouldPackDepthwiseConv = tf.env().getBool("WEBGL_PACK_DEPTHWISECONV") && convInfo.strideWidth <= 2 && convInfo.outChannels / convInfo.inChannels === 1;
      var fusedActivation = activation ? mapActivationToShaderProgram(activation, shouldPackDepthwiseConv) : null;
      var programInputs = [x, filter];
      var hasBias = bias != null;
      var hasPreluActivationWeights = preluActivationWeights != null;
      var hasLeakyreluAlpha = activation === "leakyrelu";
      if (hasBias) {
        programInputs.push(bias);
      }
      if (hasPreluActivationWeights) {
        programInputs.push(preluActivationWeights);
      }
      if (hasLeakyreluAlpha) {
        var $leakyreluAlpha = backend.makeTensorInfo([], "float32", tf.util.createScalarValue(leakyreluAlpha, "float32"));
        programInputs.push($leakyreluAlpha);
        intermediates.push($leakyreluAlpha);
      }
      var program;
      if (shouldPackDepthwiseConv) {
        program = new DepthwiseConvPacked2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
      } else {
        program = new DepthwiseConv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
      }
      var customValues = [
        [convInfo.padInfo.top, convInfo.padInfo.left],
        [convInfo.strideHeight, convInfo.strideWidth],
        [convInfo.dilationHeight, convInfo.dilationWidth],
        [convInfo.inHeight, convInfo.inWidth]
      ];
      var result = backend.runWebGLProgram(program, programInputs, "float32", customValues);
      intermediates.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return result;
    }
    var fusedDepthwiseConv2DConfig = {
      kernelName: tf.FusedDepthwiseConv2D,
      backendName: "webgl",
      kernelFunc: fusedDepthwiseConv2D
    };
    var GatherNDProgram = (
      /** @class */
      function() {
        function GatherNDProgram2(sliceDim, strides, shape, paramsShape) {
          this.sliceDim = sliceDim;
          this.strides = strides;
          this.paramsShape = paramsShape;
          this.variableNames = ["x", "indices"];
          this.outputShape = shape;
          var dtype = getCoordsDataType(shape.length);
          var mainLoop = "\n    int index;";
          for (var j = 0; j < this.sliceDim; j++) {
            mainLoop += "\n          index = round(getIndices(coords[0], ".concat(j, "));\n          out_of_bounds = out_of_bounds || index < 0;\n          out_of_bounds = out_of_bounds || index >= ").concat(this.paramsShape[j], ";\n          flattenIndex += index * ").concat(this.strides[j], ";");
          }
          this.userCode = "\n         void main() {\n          ".concat(dtype, " coords = getOutputCoords();\n          int flattenIndex = 0;\n          bool out_of_bounds = false;\n\n          ").concat(mainLoop, "\n\n          setOutput(out_of_bounds ? 0.0 : getX(flattenIndex, coords[1]));\n        }\n      ");
        }
        return GatherNDProgram2;
      }()
    );
    function gatherNd(args) {
      var inputs = args.inputs, backend = args.backend;
      var params = inputs.params, indices = inputs.indices;
      var indicesShape = indices.shape;
      var sliceRank = indicesShape[indicesShape.length - 1];
      var paramsSize = tf.util.sizeFromShape(params.shape);
      var _a2 = __read(tf.backend_util.prepareAndValidate(params, indices), 4), resultShape = _a2[0], numSlices = _a2[1], sliceSize = _a2[2], strides = _a2[3];
      var flattenIndices = reshape({ inputs: { x: indices }, backend, attrs: { shape: [numSlices, sliceRank] } });
      var flattenX = reshape({
        inputs: { x: params },
        backend,
        attrs: { shape: [tf.util.sizeFromShape(params.shape) / sliceSize, sliceSize] }
      });
      if (backend.shouldExecuteOnCPU([params, indices]) || params.dtype === "string") {
        var indicesData = backend.readSync(indices.dataId);
        var paramsBuf = backend.bufferSync(params);
        var outValue = gatherNdImplCPU(indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize, strides, params.shape, paramsSize);
        return backend.makeTensorInfo(resultShape, params.dtype, outValue.values);
      }
      var program = new GatherNDProgram(sliceRank, strides, [numSlices, sliceSize], params.shape);
      var res = backend.runWebGLProgram(program, [flattenX, flattenIndices], flattenX.dtype);
      var reshaped = reshape({ inputs: { x: res }, backend, attrs: { shape: resultShape } });
      backend.disposeIntermediateTensorInfo(flattenIndices);
      backend.disposeIntermediateTensorInfo(flattenX);
      backend.disposeIntermediateTensorInfo(res);
      return reshaped;
    }
    var gatherNdConfig = {
      kernelName: tf.GatherNd,
      backendName: "webgl",
      kernelFunc: gatherNd
    };
    var GatherProgram = (
      /** @class */
      function() {
        function GatherProgram2(aShape, outputShape) {
          this.variableNames = ["A", "indices"];
          this.outputShape = outputShape;
          this.rank = outputShape.length;
          var dtype = getCoordsDataType(this.rank);
          var sourceCoords = getSourceCoords$1(aShape);
          this.userCode = "\n      void main() {\n        ".concat(dtype, " resRC = getOutputCoords();\n        int index = int(getIndices(resRC.x, resRC.z));\n        float inBounds = (index >= 0) && (index < ").concat(aShape[2], ") ? 1.0 : 0.0;\n        setOutput(inBounds * getA(").concat(sourceCoords, "));\n      }\n    ");
        }
        return GatherProgram2;
      }()
    );
    function getSourceCoords$1(aShape, axis) {
      var currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"];
      var sourceCoords = [];
      for (var i = 0; i < aShape.length; i++) {
        if (i === 2) {
          sourceCoords.push("index");
        } else {
          sourceCoords.push("".concat(currentCoords[i]));
        }
      }
      return sourceCoords.join();
    }
    function gatherV2(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, indices = inputs.indices;
      var axis = attrs.axis, batchDims = attrs.batchDims;
      var parsedAxis = tf.util.parseAxisParam(axis, x.shape)[0];
      if (tf.env().get("DEBUG")) {
        var indicesVals = backend.readSync(indices.dataId);
        var axisDim_1 = x.shape[parsedAxis];
        var _loop_1 = function(i2) {
          var index = indicesVals[i2];
          tf.util.assert(index <= axisDim_1 - 1 && index >= 0, function() {
            return "GatherV2: the index value ".concat(index, " is not in [0, ").concat(axisDim_1 - 1, "]");
          });
        };
        for (var i = 0; i < indicesVals.length; ++i) {
          _loop_1(i);
        }
      }
      var shapeInfo = tf.backend_util.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, batchDims);
      var indicesSize = tf.util.sizeFromShape(indices.shape);
      var toDispose = [];
      var flattenX = reshape({
        inputs: { x },
        backend,
        attrs: {
          shape: [
            shapeInfo.batchSize,
            shapeInfo.outerSize,
            shapeInfo.dimSize,
            shapeInfo.sliceSize
          ]
        }
      });
      var flattenIndex = reshape({
        inputs: { x: indices },
        backend,
        attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] }
      });
      toDispose.push(flattenX);
      toDispose.push(flattenIndex);
      var flattenOutputShape = [
        shapeInfo.batchSize,
        shapeInfo.outerSize,
        indicesSize / shapeInfo.batchSize,
        shapeInfo.sliceSize
      ];
      if (backend.shouldExecuteOnCPU([x, indices]) || x.dtype === "string") {
        var indicesBuf = backend.bufferSync(flattenIndex);
        var xBuf = backend.bufferSync(flattenX);
        var outBuf = gatherV2ImplCPU(xBuf, indicesBuf, flattenOutputShape);
        toDispose.forEach(function(t) {
          return backend.disposeIntermediateTensorInfo(t);
        });
        return backend.makeTensorInfo(shapeInfo.outputShape, outBuf.dtype, outBuf.values);
      }
      var program = new GatherProgram(flattenX.shape, flattenOutputShape);
      var res = backend.runWebGLProgram(program, [flattenX, flattenIndex], flattenX.dtype);
      toDispose.push(res);
      var reshaped = reshape({ inputs: { x: res }, backend, attrs: { shape: shapeInfo.outputShape } });
      toDispose.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return reshaped;
    }
    var gatherV2Config = {
      kernelName: tf.GatherV2,
      backendName: "webgl",
      kernelFunc: gatherV2
    };
    var GREATER = "return float(a > b);";
    var GREATER_PACKED = "\n  return vec4(greaterThan(a, b));\n";
    var greater = binaryKernelFunc({
      opSnippet: GREATER,
      packedOpSnippet: GREATER_PACKED,
      cpuKernelImpl: greaterImplCPU,
      dtype: "bool"
    });
    var greaterConfig = {
      kernelName: tf.Greater,
      backendName: "webgl",
      kernelFunc: greater
    };
    var GREATER_EQUAL = "return float(a >= b);";
    var GREATER_EQUAL_PACKED = "\n  return vec4(greaterThanEqual(a, b));\n";
    var greaterEqual = binaryKernelFunc({
      opSnippet: GREATER_EQUAL,
      packedOpSnippet: GREATER_EQUAL_PACKED,
      dtype: "bool",
      cpuKernelImpl: greaterEqualImplCPU
    });
    var greaterEqualConfig = {
      kernelName: tf.GreaterEqual,
      backendName: "webgl",
      kernelFunc: greaterEqual
    };
    function ifft(args) {
      var inputs = args.inputs, backend = args.backend;
      var input = inputs.input;
      return fftImpl(input, true, backend);
    }
    var ifftConfig = {
      kernelName: tf.IFFT,
      backendName: "webgl",
      kernelFunc: ifft
    };
    var IS_FINITE = "return float(!isnan(x) && !isinf(x));";
    var isFinite2 = unaryKernelFunc({ opSnippet: IS_FINITE, dtype: "bool" });
    var isFiniteConfig = {
      kernelName: tf.IsFinite,
      backendName: "webgl",
      kernelFunc: isFinite2
    };
    var IS_INF = "return float(isinf(x));";
    var isInf = unaryKernelFunc({ opSnippet: IS_INF, dtype: "bool" });
    var isInfConfig = {
      kernelName: tf.IsInf,
      backendName: "webgl",
      kernelFunc: isInf
    };
    var IS_NAN = "return float(isnan(x));";
    var isNaN2 = unaryKernelFunc({ opSnippet: IS_NAN, dtype: "bool" });
    var isNaNConfig = {
      kernelName: tf.IsNan,
      backendName: "webgl",
      kernelFunc: isNaN2
    };
    var LESS = "return float(a < b);";
    var LESS_PACKED = "\n  return vec4(lessThan(a, b));\n";
    var less = binaryKernelFunc({
      opSnippet: LESS,
      packedOpSnippet: LESS_PACKED,
      cpuKernelImpl: lessImplCPU,
      dtype: "bool"
    });
    var lessConfig = {
      kernelName: tf.Less,
      backendName: "webgl",
      kernelFunc: less
    };
    var LESS_EQUAL = "return float(a <= b);";
    var LESS_EQUAL_PACKED = "\n  return vec4(lessThanEqual(a, b));\n";
    var lessEqual = binaryKernelFunc({
      opSnippet: LESS_EQUAL,
      packedOpSnippet: LESS_EQUAL_PACKED,
      cpuKernelImpl: lessEqualImplCPU,
      dtype: "bool"
    });
    var lessEqualConfig = {
      kernelName: tf.LessEqual,
      backendName: "webgl",
      kernelFunc: lessEqual
    };
    function linSpace(args) {
      var backend = args.backend, attrs = args.attrs;
      var start = attrs.start, stop = attrs.stop, num = attrs.num;
      var outVals = linSpaceImplCPU(start, stop, num);
      return backend.makeTensorInfo([outVals.length], "float32", outVals);
    }
    var linSpaceConfig = {
      kernelName: tf.LinSpace,
      backendName: "webgl",
      kernelFunc: linSpace
    };
    var LOG = CHECK_NAN_SNIPPET_UNARY + "\n  return x < 0.0 ? 0./0. : log(x);\n";
    var LOG_PACKED = "\n  vec4 result = log(x);\n  bvec4 isNaN = isnan(x);\n  result.r = isNaN.r ? x.r : (x.r < 0.0 ? 0./0. : result.r);\n  result.g = isNaN.g ? x.g : (x.g < 0.0 ? 0./0. : result.g);\n  result.b = isNaN.b ? x.b : (x.b < 0.0 ? 0./0. : result.b);\n  result.a = isNaN.a ? x.a : (x.a < 0.0 ? 0./0. : result.a);\n  return result;\n";
    var log = unaryKernelFunc({ opSnippet: LOG, packedOpSnippet: LOG_PACKED, cpuKernelImpl: logImplCPU });
    var logConfig = {
      kernelName: tf.Log,
      backendName: "webgl",
      kernelFunc: log
    };
    var LOG1P = CHECK_NAN_SNIPPET_UNARY + "\n  return log(1.0 + x);\n";
    var log1p = unaryKernelFunc({ opSnippet: LOG1P });
    var log1pConfig = {
      kernelName: tf.Log1p,
      backendName: "webgl",
      kernelFunc: log1p
    };
    var LOGICAL_AND = "return float(a >= 1.0 && b >= 1.0);";
    var LOGICAL_AND_PACKED = "\n  return vec4(\n    vec4(greaterThanEqual(a, vec4(1.0))) *\n    vec4(greaterThanEqual(b, vec4(1.0))));\n";
    var logicalAnd = binaryKernelFunc({
      opSnippet: LOGICAL_AND,
      packedOpSnippet: LOGICAL_AND_PACKED,
      dtype: "bool"
    });
    var logicalAndConfig = {
      kernelName: tf.LogicalAnd,
      backendName: "webgl",
      kernelFunc: logicalAnd
    };
    var LOGICAL_NOT = "return float(!(x >= 1.0));";
    var logicalNot = unaryKernelFunc({ opSnippet: LOGICAL_NOT });
    var logicalNotConfig = {
      kernelName: tf.LogicalNot,
      backendName: "webgl",
      kernelFunc: logicalNot
    };
    var LOGICAL_OR = "return float(a >= 1.0 || b >= 1.0);";
    var LOGICAL_OR_PACKED = "\n  return min(\n    vec4(greaterThanEqual(a, vec4(1.0))) +\n    vec4(greaterThanEqual(b, vec4(1.0))),\n    vec4(1.0));\n";
    var logicalOr = binaryKernelFunc({ opSnippet: LOGICAL_OR, packedOpSnippet: LOGICAL_OR_PACKED, dtype: "bool" });
    var logicalOrConfig = {
      kernelName: tf.LogicalOr,
      backendName: "webgl",
      kernelFunc: logicalOr
    };
    var LRNProgram = (
      /** @class */
      function() {
        function LRNProgram2(xShape, radius, bias, alpha, beta) {
          this.variableNames = ["x"];
          this.outputShape = [];
          var rad = radius;
          var maxD = xShape[3] - 1;
          this.outputShape = xShape;
          var powOperator;
          var basis = "float(".concat(bias, ") + float(").concat(alpha, ") * sum");
          if (beta === 0.5) {
            powOperator = "inversesqrt(".concat(basis, ")");
          } else if (beta === 1) {
            powOperator = "1.0/(".concat(basis, ")");
          } else {
            powOperator = "exp(log(".concat(basis, ") * float(-").concat(beta, "));");
          }
          this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n        int d = coords[3];\n        float x = getX(b, r, c, d);\n        float sum = 0.0;\n        for (int j = -".concat(rad, "; j <= ").concat(rad, "; j++) {\n          int idx = d + j;\n          if (idx >= 0 && idx <=  ").concat(maxD, ") {\n            float z = getX(b, r, c, idx);\n            sum += z * z;\n          }\n        }\n        float val = x * ").concat(powOperator, ";\n        setOutput(val);\n      }\n    ");
        }
        return LRNProgram2;
      }()
    );
    var LRNPackedProgram = (
      /** @class */
      function() {
        function LRNPackedProgram2(xShape, radius, bias, alpha, beta) {
          this.variableNames = ["x"];
          this.outputShape = [];
          this.packedInputs = true;
          this.packedOutput = true;
          var rad = radius;
          var maxD = xShape[3] - 1;
          this.outputShape = xShape;
          var powOperator;
          var basis = "float(".concat(bias, ") + float(").concat(alpha, ") * sum");
          if (beta === 0.5) {
            powOperator = "inversesqrt(".concat(basis, ")");
          } else if (beta === 1) {
            powOperator = "1.0/(".concat(basis, ")");
          } else {
            powOperator = "exp(log(".concat(basis, ") * float(-").concat(beta, "));");
          }
          this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords.x;\n        int r = coords.y;\n        int c = coords.z;\n        int d = coords.w;\n\n        bool hasNextCol = d < ".concat(this.outputShape[3], ";\n        bool hasNextRow = c < ").concat(this.outputShape[2], ";\n\n        vec4 sum = vec4(0.);\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\n\n        vec4 xAtOutputCoords = vec4(\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\n          hasNextCol ?\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\n          hasNextRow ?\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\n        );\n\n        int firstChannel = d - ").concat(rad, ";\n        vec2 cache = vec2(0.);\n        if(firstChannel >= 0){\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\n            if(hasNextRow){\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\n            }\n        }\n\n        ivec2 depth = ivec2(d, d + 1);\n        for (int j = - ").concat(rad, "; j <= ").concat(rad, "; j++) {\n          ivec2 idx = depth + j;\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(").concat(maxD, "));\n\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\n\n          if(depthInRange || depthPlusOneInRange){\n            vec4 z = vec4(0.);\n            vec4 xFragAtCurrentDepth;\n            z.xz = cache.xy;\n            if(depthPlusOneInRange && hasNextCol){\n              xFragAtCurrentDepth = idx.y != d ?\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\n              if(hasNextRow){\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\n              }\n            }\n            cache.xy = z.yw;\n            sum += z * z;\n          }\n        }\n        vec4 result = xAtOutputCoords * ").concat(powOperator, ";\n        setOutput(result);\n      }\n    ");
        }
        return LRNPackedProgram2;
      }()
    );
    var lrn = function(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var depthRadius = attrs.depthRadius, bias = attrs.bias, alpha = attrs.alpha, beta = attrs.beta;
      var program = tf.env().getBool("WEBGL_PACK_NORMALIZATION") ? new LRNPackedProgram(x.shape, depthRadius, bias, alpha, beta) : new LRNProgram(x.shape, depthRadius, bias, alpha, beta);
      return backend.runWebGLProgram(program, [x], x.dtype);
    };
    var LRNConfig = {
      kernelName: tf.LRN,
      backendName: "webgl",
      kernelFunc: lrn
    };
    var LRNGradProgram = (
      /** @class */
      function() {
        function LRNGradProgram2(inputShape, depthRadius, bias, alpha, beta) {
          this.variableNames = ["inputImage", "outputImage", "dy"];
          this.outputShape = [];
          this.outputShape = inputShape;
          this.depth = inputShape[3];
          this.depthRadius = depthRadius;
          this.bias = bias;
          this.alpha = alpha;
          this.beta = beta;
          this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n\n        float result = 0.0;\n        for (int d = 0; d < ".concat(this.depth, "; ++d) {\n          int depthBegin = int(max(0.0, float(d - ").concat(depthRadius, ")));\n          int depthEnd = int(min(float(").concat(this.depth, "),\n              float(d + ").concat(depthRadius, " + 1)));\n\n          const int MIN_DEPTH_BEGIN = 0;\n          const int MAX_DEPTH_END = ").concat(this.depth, ";\n\n          float norm = 0.0;\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd) {\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\n            }\n            else {\n              break;\n            }\n          }\n\n          norm = float(").concat(alpha, ") * norm + float(").concat(bias, ");\n\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd){\n              float dyi = -2.0 * float(").concat(alpha, ")\n                * float(").concat(beta, ")\n                * getInputImage(b, r, c, k) * getOutputImage(b, r, c, d)\n                / norm;\n              if (k == d) {\n                dyi += pow(norm, -1.0 * ").concat(beta, ");\n              }\n              if (k == coords[3]) {\n                dyi *= getDy(b, r, c, d);\n                result += dyi;\n              }\n            }\n            else {\n              break;\n            }\n          }\n      }\n      setOutput(result);\n      }\n    ");
        }
        return LRNGradProgram2;
      }()
    );
    var lrnGrad = function(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, y = inputs.y, dy = inputs.dy;
      var depthRadius = attrs.depthRadius, bias = attrs.bias, alpha = attrs.alpha, beta = attrs.beta;
      var program = new LRNGradProgram(x.shape, depthRadius, bias, alpha, beta);
      return backend.runWebGLProgram(program, [x, y, dy], x.dtype);
    };
    var LRNGradConfig = {
      kernelName: tf.LRNGrad,
      backendName: "webgl",
      kernelFunc: lrnGrad
    };
    function maxImpl(x, reduceShape, outShape, backend) {
      var inSize = tf.util.sizeFromShape(reduceShape);
      var xSize = tf.util.sizeFromShape(x.shape);
      var batchSize = xSize / inSize;
      var reshapedInput = reshape({ inputs: { x }, attrs: { shape: [batchSize, inSize] }, backend });
      var reduced = reduce(reshapedInput, x.dtype, "max", backend);
      var reshapedOutput = reshape({ inputs: { x: reduced }, attrs: { shape: outShape }, backend });
      backend.disposeIntermediateTensorInfo(reshapedInput);
      backend.disposeIntermediateTensorInfo(reduced);
      return reshapedOutput;
    }
    function max(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var reductionIndices = attrs.reductionIndices, keepDims = attrs.keepDims;
      var xRank = x.shape.length;
      var origAxes = tf.util.parseAxisParam(reductionIndices, x.shape);
      var axes = origAxes;
      var permutedAxes = tf.backend_util.getAxesPermutation(axes, xRank);
      var maxInputIsTransposed = permutedAxes != null;
      var shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);
      var maxInput = x;
      if (maxInputIsTransposed) {
        if (shouldExecuteOnCPU) {
          var xTexData = backend.texData.get(maxInput.dataId);
          var values = xTexData.values;
          var newShape = new Array(xRank);
          for (var i = 0; i < newShape.length; i++) {
            newShape[i] = x.shape[permutedAxes[i]];
          }
          var maxInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);
          maxInput = backend.makeTensorInfo(newShape, x.dtype);
          var maxInputData = backend.texData.get(maxInput.dataId);
          maxInputData.values = maxInputValues;
        } else {
          maxInput = transposeImpl(x, permutedAxes, backend);
        }
        axes = tf.backend_util.getInnerMostAxes(axes.length, xRank);
      }
      tf.backend_util.assertAxesAreInnerMostDims("max", axes, xRank);
      var _a2 = __read(tf.backend_util.computeOutAndReduceShapes(maxInput.shape, axes), 2), maxOutShape = _a2[0], reduceShape = _a2[1];
      var outShape = maxOutShape;
      if (keepDims) {
        outShape = tf.backend_util.expandShapeToKeepDim(maxOutShape, origAxes);
      }
      var out;
      if (shouldExecuteOnCPU) {
        var xTexData = backend.texData.get(maxInput.dataId);
        var values = xTexData.values;
        var outValues = maxImplCPU(values, tf.util.sizeFromShape(reduceShape), outShape, x.dtype);
        out = backend.makeTensorInfo(outShape, x.dtype);
        var outData = backend.texData.get(out.dataId);
        outData.values = outValues;
      } else {
        out = maxImpl(maxInput, reduceShape, outShape, backend);
      }
      if (maxInputIsTransposed) {
        backend.disposeIntermediateTensorInfo(maxInput);
      }
      return out;
    }
    var maxConfig = {
      kernelName: tf.Max,
      backendName: "webgl",
      kernelFunc: max
    };
    var MAXIMUM = CHECK_NAN_SNIPPET + "\n  return max(a, b);\n";
    var MAXIMUM_PACKED = "\n  vec4 result = vec4(max(a, b));\n  bvec4 isNaNA = isnan(a);\n  bvec4 isNaNB = isnan(b);\n  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);\n  " + CHECK_NAN_SNIPPET_PACKED + "\n  return result;\n";
    var maximum = binaryKernelFunc({
      opSnippet: MAXIMUM,
      packedOpSnippet: MAXIMUM_PACKED,
      cpuKernelImpl: maximumImplCPU
    });
    var maximumConfig = {
      kernelName: tf.Maximum,
      backendName: "webgl",
      kernelFunc: maximum
    };
    function maxPool(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      assertNotComplex(x, "maxPool");
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      var dilations = 1;
      tf.util.assert(tf.backend_util.eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in maxPool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var convInfo = tf.backend_util.computePool2DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode);
      if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && tf.util.arraysEqual(convInfo.inShape, convInfo.outShape)) {
        return identity({ inputs: { x }, backend });
      }
      var maxPoolProgram = new Pool2DProgram(convInfo, "max", false);
      return backend.runWebGLProgram(maxPoolProgram, [x], x.dtype);
    }
    var maxPoolConfig = {
      kernelName: tf.MaxPool,
      backendName: "webgl",
      kernelFunc: maxPool
    };
    function maxPool3d(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dataFormat = attrs.dataFormat, dimRoundingMode = attrs.dimRoundingMode;
      var dilations = [1, 1, 1];
      var convInfo = tf.backend_util.computePool3DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode, dataFormat);
      var maxPoolProgram = new Pool3DProgram(convInfo, "max", false);
      return backend.runWebGLProgram(maxPoolProgram, [x], x.dtype);
    }
    var maxPool3DConfig = {
      kernelName: tf.MaxPool3D,
      backendName: "webgl",
      kernelFunc: maxPool3d
    };
    var MaxPool2DBackpropProgram = (
      /** @class */
      function() {
        function MaxPool2DBackpropProgram2(convInfo) {
          this.variableNames = ["dy", "maxPos"];
          this.outputShape = convInfo.inShape;
          var strideHeight = convInfo.strideHeight;
          var strideWidth = convInfo.strideWidth;
          var dilationHeight = convInfo.dilationHeight;
          var effectiveFilterHeight = convInfo.effectiveFilterHeight;
          var effectiveFilterWidth = convInfo.effectiveFilterWidth;
          var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
          var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
          var lastIndex = effectiveFilterHeight * effectiveFilterWidth - 1;
          this.userCode = "\n      const ivec2 pads = ivec2(".concat(padTop, ", ").concat(padLeft, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ").concat(effectiveFilterHeight, ";\n          wR += ").concat(dilationHeight, ") {\n          float dyR = float(dyRCorner + wR) / ").concat(strideHeight, ".0;\n\n          if (dyR < 0.0 || dyR >= ").concat(convInfo.outHeight, ".0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ").concat(effectiveFilterWidth, "; wC++) {\n            float dyC = float(dyCCorner + wC) / ").concat(strideWidth, ".0;\n\n            if (dyC < 0.0 || dyC >= ").concat(convInfo.outWidth, ".0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n            int maxPosValue = ").concat(lastIndex, " - int(getMaxPos(b, idyR, idyC, d));\n\n            // Get the current value, check it against the value from the\n            // position matrix.\n            int curPosValue = wR * ").concat(effectiveFilterWidth, " + wC;\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n            dotProd += dyValue * mask;\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
        }
        return MaxPool2DBackpropProgram2;
      }()
    );
    var MaxPool3DBackpropProgram = (
      /** @class */
      function() {
        function MaxPool3DBackpropProgram2(convInfo) {
          this.variableNames = ["dy", "maxPos"];
          this.outputShape = convInfo.inShape;
          var strideDepth = convInfo.strideDepth;
          var strideHeight = convInfo.strideHeight;
          var strideWidth = convInfo.strideWidth;
          var dilationDepth = convInfo.dilationDepth;
          var dilationHeight = convInfo.dilationHeight;
          var dilationWidth = convInfo.dilationWidth;
          var effectiveFilterDepth = convInfo.effectiveFilterDepth;
          var effectiveFilterHeight = convInfo.effectiveFilterHeight;
          var effectiveFilterWidth = convInfo.effectiveFilterWidth;
          var padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
          var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
          var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
          var lastIndex = effectiveFilterDepth * effectiveFilterHeight * effectiveFilterWidth - 1;
          this.userCode = "\n      const ivec3 pads = ivec3(".concat(padFront, ", ").concat(padTop, ", ").concat(padLeft, ");\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ").concat(effectiveFilterDepth, ";\n           wD += ").concat(dilationDepth, ") {\n          float dyD = float(dyDCorner + wD) / ").concat(strideDepth, ".0;\n\n          if (dyD < 0.0 || dyD >= ").concat(convInfo.outDepth, ".0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ").concat(effectiveFilterHeight, ";\n              wR += ").concat(dilationHeight, ") {\n            float dyR = float(dyRCorner + wR) / ").concat(strideHeight, ".0;\n\n            if (dyR < 0.0 || dyR >= ").concat(convInfo.outHeight, ".0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ").concat(effectiveFilterWidth, ";\n                wC += ").concat(dilationWidth, ") {\n              float dyC = float(dyCCorner + wC) / ").concat(strideWidth, ".0;\n\n              if (dyC < 0.0 || dyC >= ").concat(convInfo.outWidth, ".0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              int maxPosValue = ").concat(lastIndex, " -\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\n\n              // Get the current value, check it against the value from the\n              // position matrix.\n              int curPosValue =\n                  wD * ").concat(effectiveFilterHeight, " * ").concat(effectiveFilterWidth, " +\n                  wR * ").concat(effectiveFilterWidth, " + wC;\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n              dotProd += dyValue * mask;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
        }
        return MaxPool3DBackpropProgram2;
      }()
    );
    function maxPool3DGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, input = inputs.input;
      var x = input;
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      var dilations = [1, 1, 1];
      var convInfo = tf.backend_util.computePool3DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode);
      var maxPool3dPositionsProgram = new Pool3DProgram(
        convInfo,
        "max",
        true
        /* get positions */
      );
      var maxPool3dPositions = backend.runWebGLProgram(maxPool3dPositionsProgram, [x], x.dtype);
      var maxPoolBackpropProgram = new MaxPool3DBackpropProgram(convInfo);
      var result = backend.runWebGLProgram(maxPoolBackpropProgram, [dy, maxPool3dPositions], x.dtype);
      backend.disposeIntermediateTensorInfo(maxPool3dPositions);
      return result;
    }
    var maxPool3DGradConfig = {
      kernelName: tf.MaxPool3DGrad,
      backendName: "webgl",
      kernelFunc: maxPool3DGrad
    };
    function maxPoolGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, input = inputs.input, output = inputs.output;
      var x = input;
      assertNotComplex([input, output], "maxPoolGrad");
      var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      var convInfo = tf.backend_util.computePool2DInfo(x.shape, filterSize, strides, 1, pad, dimRoundingMode);
      var getPositions = true;
      var maxPoolPositionsProgram = new Pool2DProgram(convInfo, "max", getPositions);
      var maxPoolPositions = backend.runWebGLProgram(maxPoolPositionsProgram, [x], x.dtype);
      var maxPoolBackPropProgram = new MaxPool2DBackpropProgram(convInfo);
      var result = backend.runWebGLProgram(maxPoolBackPropProgram, [dy, maxPoolPositions], x.dtype);
      backend.disposeIntermediateTensorInfo(maxPoolPositions);
      return result;
    }
    var maxPoolGradConfig = {
      kernelName: tf.MaxPoolGrad,
      backendName: "webgl",
      kernelFunc: maxPoolGrad
    };
    function maxPoolWithArgmaxImpl(x, includeBatchInIndex, convInfo, backend) {
      var program = new Pool2DProgram(convInfo, "max", false);
      var poolOutput = backend.runWebGLProgram(program, [x], "float32");
      program = new Pool2DProgram(convInfo, "max", true, true, includeBatchInIndex);
      var indexOutput = backend.runWebGLProgram(program, [x], "float32");
      return [poolOutput, indexOutput];
    }
    var maxPoolWithArgmaxConfig = {
      kernelName: tf.MaxPoolWithArgmax,
      backendName: "webgl",
      kernelFunc: function(_a2) {
        var inputs = _a2.inputs, attrs = _a2.attrs, backend = _a2.backend;
        var x = inputs.x;
        var filterSize = attrs.filterSize, strides = attrs.strides, pad = attrs.pad, includeBatchInIndex = attrs.includeBatchInIndex;
        var webglBackend = backend;
        tf.util.assert(x.shape.length === 4, function() {
          return "Error in maxPool: input must be rank 4 but got rank ".concat(x.shape.length, ".");
        });
        var dilations = [1, 1];
        tf.util.assert(tf.backend_util.eitherStridesOrDilationsAreOne(strides, dilations), function() {
          return "Error in maxPool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
        });
        var convInfo = tf.backend_util.computePool2DInfo(x.shape, filterSize, strides, dilations, pad);
        var _b = __read(maxPoolWithArgmaxImpl(x, includeBatchInIndex, convInfo, webglBackend), 2), result = _b[0], indexes = _b[1];
        return [result, indexes];
      }
    };
    function meanImpl(x, reduceShape, outShape, backend) {
      var inSize = tf.util.sizeFromShape(reduceShape);
      var xSize = tf.util.sizeFromShape(x.shape);
      var batchSize = xSize / inSize;
      var reshapedInput = reshape({ inputs: { x }, attrs: { shape: [batchSize, inSize] }, backend });
      var reduced = reduce(reshapedInput, "float32", "mean", backend);
      var reshapedOutput = reshape({ inputs: { x: reduced }, attrs: { shape: outShape }, backend });
      backend.disposeIntermediateTensorInfo(reshapedInput);
      backend.disposeIntermediateTensorInfo(reduced);
      return reshapedOutput;
    }
    var meanConfig = {
      kernelName: tf.Mean,
      backendName: "webgl",
      kernelFunc: function(_a2) {
        var e_12, _b;
        var inputs = _a2.inputs, attrs = _a2.attrs, backend = _a2.backend;
        var x = inputs.x;
        var keepDims = attrs.keepDims, axis = attrs.axis;
        var webglBackend = backend;
        var xRank = x.shape.length;
        var origAxes = tf.util.parseAxisParam(axis, x.shape);
        var axes = origAxes;
        var permutedAxes = tf.backend_util.getAxesPermutation(axes, xRank);
        var meanInputIsTransposed = permutedAxes != null;
        var shouldExecuteOnCPU = webglBackend.shouldExecuteOnCPU([x]);
        var intermediates = [];
        var meanInput = x;
        if (meanInputIsTransposed) {
          if (shouldExecuteOnCPU) {
            var xTexData = webglBackend.texData.get(meanInput.dataId);
            var values = xTexData.values;
            var newShape = new Array(xRank);
            for (var i = 0; i < newShape.length; i++) {
              newShape[i] = x.shape[permutedAxes[i]];
            }
            var meanInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);
            meanInput = webglBackend.makeTensorInfo(newShape, x.dtype);
            var meanInputData = webglBackend.texData.get(meanInput.dataId);
            meanInputData.values = meanInputValues;
          } else {
            meanInput = transposeImpl(x, permutedAxes, webglBackend);
          }
          intermediates.push(meanInput);
          axes = tf.backend_util.getInnerMostAxes(axes.length, xRank);
        }
        tf.backend_util.assertAxesAreInnerMostDims("sum", axes, xRank);
        var _c = __read(tf.backend_util.computeOutAndReduceShapes(meanInput.shape, axes), 2), meanOutShape = _c[0], reduceShape = _c[1];
        var outShape = meanOutShape;
        if (keepDims) {
          outShape = tf.backend_util.expandShapeToKeepDim(meanOutShape, origAxes);
        }
        var out = meanImpl(meanInput, reduceShape, outShape, webglBackend);
        try {
          for (var intermediates_1 = __values(intermediates), intermediates_1_1 = intermediates_1.next(); !intermediates_1_1.done; intermediates_1_1 = intermediates_1.next()) {
            var i = intermediates_1_1.value;
            webglBackend.disposeIntermediateTensorInfo(i);
          }
        } catch (e_1_1) {
          e_12 = { error: e_1_1 };
        } finally {
          try {
            if (intermediates_1_1 && !intermediates_1_1.done && (_b = intermediates_1.return))
              _b.call(intermediates_1);
          } finally {
            if (e_12)
              throw e_12.error;
          }
        }
        return out;
      }
    };
    function min(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      var xRank = x.shape.length;
      var origAxes = tf.util.parseAxisParam(axis, x.shape);
      var axes = origAxes;
      var permutedAxes = tf.backend_util.getAxesPermutation(axes, xRank);
      var permutedX = x;
      if (permutedAxes != null) {
        permutedX = transpose({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
        axes = tf.backend_util.getInnerMostAxes(axes.length, x.shape.length);
      }
      tf.backend_util.assertAxesAreInnerMostDims("min", axes, xRank);
      var _a2 = __read(tf.backend_util.computeOutAndReduceShapes(permutedX.shape, axes), 2), outShape = _a2[0], reduceShape = _a2[1];
      var inSize = tf.util.sizeFromShape(reduceShape);
      var a2D = reshape({ inputs: { x: permutedX }, backend, attrs: { shape: [-1, inSize] } });
      var reduced = reduce(a2D, a2D.dtype, "min", backend);
      var res;
      if (keepDims) {
        var newShape = tf.backend_util.expandShapeToKeepDim(outShape, origAxes);
        res = reshape({ inputs: { x: reduced }, backend, attrs: { shape: newShape } });
      } else {
        res = reshape({ inputs: { x: reduced }, backend, attrs: { shape: outShape } });
      }
      backend.disposeIntermediateTensorInfo(a2D);
      backend.disposeIntermediateTensorInfo(reduced);
      if (permutedAxes != null) {
        backend.disposeIntermediateTensorInfo(permutedX);
      }
      return res;
    }
    var minConfig = {
      kernelName: tf.Min,
      backendName: "webgl",
      kernelFunc: min
    };
    var MINIMUM = CHECK_NAN_SNIPPET + "\n  return min(a, b);\n";
    var MINIMUM_PACKED = "\n  vec4 result = vec4(min(a, b));\n  bvec4 isNaNA = isnan(a);\n  bvec4 isNaNB = isnan(b);\n  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);\n  " + CHECK_NAN_SNIPPET_PACKED + "\n  return result;\n";
    var minimum = binaryKernelFunc({
      opSnippet: MINIMUM,
      packedOpSnippet: MINIMUM_PACKED,
      cpuKernelImpl: minimumImplCPU
    });
    var minimumConfig = {
      kernelName: tf.Minimum,
      backendName: "webgl",
      kernelFunc: minimum
    };
    var MirrorPadProgram = (
      /** @class */
      function() {
        function MirrorPadProgram2(xShape, paddings, mode) {
          this.variableNames = ["x"];
          this.outputShape = paddings.map(
            function(p, i) {
              return p[0] + xShape[i] + p[1];
            }
            /* afterPad */
          );
          var rank = xShape.length;
          var dtype = getCoordsDataType(rank);
          var start = paddings.map(function(p) {
            return p[0];
          }).join(",");
          var end = paddings.map(function(p, i) {
            return p[0] + xShape[i];
          }).join(",");
          var unpackedCoords = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, rank);
          var offset = mode === "reflect" ? 0 : 1;
          if (rank === 1) {
            this.userCode = "\n        int start = ".concat(start, ";\n        int end = ").concat(end, ";\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start) {\n            outC = start * 2 - outC - ").concat(offset, ";\n          } else if(outC >= end) {\n            outC = (end - 1) * 2 - outC + ").concat(offset, ";\n          }\n          setOutput(getX(outC - start));\n        }\n      ");
            return;
          }
          this.userCode = "\n      ".concat(dtype, " start = ").concat(dtype, "(").concat(start, ");\n      ").concat(dtype, " end = ").concat(dtype, "(").concat(end, ");\n\n      void main() {\n        ").concat(dtype, " outC = getOutputCoords();\n        for (int i = 0; i < ").concat(rank, "; i++) {\n          if (outC[i] < start[i]) {\n            outC[i] = start[i] * 2 - outC[i] - ").concat(offset, ";\n          } else if(outC[i] >= end[i]) {\n            outC[i] = (end[i] - 1) * 2 - outC[i] + ").concat(offset, ";\n          }\n        }\n        ").concat(dtype, " coords = outC - start;\n        setOutput(getX(").concat(unpackedCoords, "));\n      }\n    ");
        }
        return MirrorPadProgram2;
      }()
    );
    var MirrorPadPackedProgram = (
      /** @class */
      function() {
        function MirrorPadPackedProgram2(xShape, paddings, mode) {
          this.variableNames = ["x"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.outputShape = paddings.map(
            function(p, i) {
              return p[0] + xShape[i] + p[1];
            }
            /* afterPad */
          );
          var rank = xShape.length;
          var dtype = getCoordsDataType(rank);
          var start = paddings.map(function(p) {
            return p[0];
          }).join(",");
          var end = paddings.map(function(p, i) {
            return p[0] + xShape[i];
          }).join(",");
          var coords2 = getChannels("rc", rank);
          var source = getChannels("source", rank);
          var cLimit = "".concat(coords2[rank - 1], " < ").concat(this.outputShape[rank - 1]);
          var innerDims = rank === 1 ? "source" : "vec2(".concat(source.slice(-2).join(), ")");
          var offset = mode === "reflect" ? 0 : 1;
          var mainLoop = "";
          if (rank === 1) {
            var padSetup = "\n        ".concat(dtype, " source = rc;\n        if (source < start) {\n          source = start * 2 - source - ").concat(offset, ";\n        } else if (source >= end) {\n          source = (end - 1) * 2 - source + ").concat(offset, ";\n        }\n        source -= start;\n      ");
            mainLoop = "\n        ".concat(dtype, " rc = outputLoc;\n        ").concat(padSetup, "\n        result[0] = getChannel(getX(").concat(source.join(), "), ").concat(innerDims, ");\n        ").concat(coords2[rank - 1], " += 1;\n        if(").concat(cLimit, ") {\n          ").concat(padSetup, "\n          result[1] = getChannel(getX(").concat(source.join(), "), ").concat(innerDims, ");\n        }\n      ");
          } else {
            var padSetup = "\n        ".concat(dtype, " source = rc;\n        ").concat(dtype, " lt = ").concat(dtype, "(lessThan(source, start));\n        ").concat(dtype, " gte = ").concat(dtype, "(greaterThanEqual(source, end));\n        ").concat(dtype, " orig = 1 - (lt + gte);\n        source = orig * source +\n                lt * (start * 2 - source - ").concat(offset, ") +\n                gte * ((end - 1) * 2 - source + ").concat(offset, ");\n        source -= start;\n      ");
            mainLoop = "\n        ".concat(dtype, " rc = outputLoc;\n        ").concat(padSetup, "\n        result[0] = getChannel(getX(").concat(source.join(), "), ").concat(innerDims, ");\n        ").concat(coords2[rank - 1], " += 1;\n        if(").concat(cLimit, ") {\n          ").concat(padSetup, "\n          result[1] = getChannel(getX(").concat(source.join(), "), ").concat(innerDims, ");\n        }\n        rc = outputLoc;\n        ").concat(coords2[rank - 2], " += 1;\n        if(").concat(coords2[rank - 2], " < ").concat(this.outputShape[rank - 2], ") {\n          ").concat(padSetup, "\n          result[2] = getChannel(getX(").concat(source.join(), "), ").concat(innerDims, ");\n          ").concat(coords2[rank - 1], " += 1;\n          if(").concat(cLimit, ") {\n            ").concat(padSetup, "\n            result[3] = getChannel(getX(").concat(source.join(), "), ").concat(innerDims, ");\n          }\n        }\n      ");
          }
          this.userCode = "\n      const ".concat(dtype, " start = ").concat(dtype, "(").concat(start, ");\n      const ").concat(dtype, " end = ").concat(dtype, "(").concat(end, ");\n\n      void main() {\n        ").concat(dtype, " outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ").concat(mainLoop, "\n        setOutput(result);\n      }\n    ");
        }
        return MirrorPadPackedProgram2;
      }()
    );
    var mirrorPadKernelFunc = function(_a2) {
      var inputs = _a2.inputs, backend = _a2.backend, attrs = _a2.attrs;
      var x = inputs.x;
      var paddings = attrs.paddings, mode = attrs.mode;
      var program = tf.env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new MirrorPadPackedProgram(x.shape, paddings, mode) : new MirrorPadProgram(x.shape, paddings, mode);
      var output = backend.runWebGLProgram(program, [x], x.dtype);
      return output;
    };
    var mirrorPadConfig = {
      kernelName: tf.MirrorPad,
      backendName: "webgl",
      kernelFunc: mirrorPadKernelFunc
    };
    var MOD = "if (b == 0.0) return NAN;\n  return mod(a, b);";
    var MOD_PACKED = "\n  vec4 result = mod(a, b);\n  bvec4 isNaN = equal(b, vec4(0.0));\n  " + CHECK_NAN_SNIPPET_PACKED + "\n  return result;\n";
    var mod = binaryKernelFunc({
      opSnippet: MOD,
      packedOpSnippet: MOD_PACKED
    });
    var modConfig = {
      kernelName: tf.Mod,
      backendName: "webgl",
      kernelFunc: mod
    };
    var MultinomialProgram = (
      /** @class */
      function() {
        function MultinomialProgram2(batchSize, numOutcomes, numSamples) {
          this.variableNames = ["probs"];
          this.customUniforms = [{ name: "seed", type: "float" }];
          this.outputShape = [batchSize, numSamples];
          this.userCode = "\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n\n        float r = random(seed);\n        float cdf = 0.0;\n\n        for (int i = 0; i < ".concat(numOutcomes - 1, "; i++) {\n          cdf += getProbs(batch, i);\n\n          if (r < cdf) {\n            setOutput(float(i));\n            return;\n          }\n        }\n\n        // If no other event happened, last event happened.\n        setOutput(float(").concat(numOutcomes - 1, "));\n      }\n    ");
        }
        return MultinomialProgram2;
      }()
    );
    var DIV = "\nif (a == b) {\n  return 1.0;\n};\nreturn a / b;";
    var DIV_PACKED = "\n  // vec4 one = vec4(equal(a, b));\n  // return one + (vec4(1.0) - one) * a / b;\n  vec4 result = a / b;\n  if(a.x == b.x) {\n    result.x = 1.;\n  }\n  if(a.y == b.y) {\n    result.y = 1.;\n  }\n  if(a.z == b.z) {\n    result.z = 1.;\n  }\n  if(a.w == b.w) {\n    result.w = 1.;\n  }\n\n  return result;\n";
    var realDiv = binaryKernelFunc({ opSnippet: DIV, packedOpSnippet: DIV_PACKED, checkOutOfBounds: true });
    var realDivConfig = {
      kernelName: tf.RealDiv,
      backendName: "webgl",
      kernelFunc: realDiv
    };
    var SUB = "return a - b;";
    var sub = binaryKernelFunc({
      opSnippet: SUB,
      packedOpSnippet: SUB,
      supportsComplex: true,
      cpuKernelImpl: subImplCPU
    });
    var subConfig = {
      kernelName: tf.Sub,
      backendName: "webgl",
      kernelFunc: sub
    };
    function softmax(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var logits = inputs.logits;
      var dim = attrs.dim;
      var axes = tf.util.parseAxisParam([dim], logits.shape);
      var maxLogit = max({
        inputs: { x: logits },
        backend,
        attrs: { reductionIndices: axes, keepDims: false }
      });
      var expandedShape = tf.backend_util.expandShapeToKeepDim(maxLogit.shape, axes);
      var maxLogitsReshaped = reshape({ inputs: { x: maxLogit }, backend, attrs: { shape: expandedShape } });
      var a = sub({ inputs: { a: logits, b: maxLogitsReshaped }, backend });
      var b = exp({ inputs: { x: a }, backend });
      var sumExp = sum({ inputs: { x: b }, backend, attrs: { axis: axes, keepDims: false } });
      var sumExpReshaped = reshape({ inputs: { x: sumExp }, backend, attrs: { shape: expandedShape } });
      var res = realDiv({ inputs: { a: b, b: sumExpReshaped }, backend });
      backend.disposeIntermediateTensorInfo(maxLogit);
      backend.disposeIntermediateTensorInfo(maxLogitsReshaped);
      backend.disposeIntermediateTensorInfo(a);
      backend.disposeIntermediateTensorInfo(b);
      backend.disposeIntermediateTensorInfo(sumExp);
      backend.disposeIntermediateTensorInfo(sumExpReshaped);
      return res;
    }
    var softmaxConfig = {
      kernelName: tf.Softmax,
      backendName: "webgl",
      kernelFunc: softmax
    };
    function multinomial(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var logits = inputs.logits;
      var numSamples = attrs.numSamples, seed = attrs.seed, normalized = attrs.normalized;
      var probs = normalized ? logits : softmax({ inputs: { logits }, backend, attrs: { dim: logits.shape.length - 1 } });
      var batchSize = probs.shape[0];
      var numOutcomes = probs.shape[1];
      var program = new MultinomialProgram(batchSize, numOutcomes, numSamples);
      var customValues = [[seed]];
      var res = backend.runWebGLProgram(program, [probs], "int32", customValues);
      if (!normalized) {
        backend.disposeIntermediateTensorInfo(probs);
      }
      return res;
    }
    var multinomialConfig = {
      kernelName: tf.Multinomial,
      backendName: "webgl",
      kernelFunc: multinomial
    };
    var NEG = CHECK_NAN_SNIPPET$1 + "\n  return -x;\n";
    var NEG_PACKED = "\n  vec4 result = -x;\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n";
    function neg(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x;
      if (backend.shouldExecuteOnCPU([x])) {
        var xData = backend.texData.get(x.dataId);
        var _a2 = __read(negImplCPU(xData.values, x.shape, x.dtype), 2), outValues = _a2[0], newShape = _a2[1];
        return backend.makeTensorInfo(newShape, x.dtype, outValues);
      }
      var program;
      if (tf.env().getBool("WEBGL_PACK_UNARY_OPERATIONS")) {
        program = new UnaryOpPackedProgram(x.shape, NEG_PACKED);
      } else {
        program = new UnaryOpProgram(x.shape, NEG);
      }
      return backend.runWebGLProgram(program, [x], x.dtype);
    }
    var negConfig = {
      kernelName: tf.Neg,
      backendName: "webgl",
      kernelFunc: neg
    };
    var nonMaxSuppressionV3Impl = tf.kernel_impls.nonMaxSuppressionV3Impl;
    function nonMaxSuppressionV3(args) {
      tf.backend_util.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var boxes = inputs.boxes, scores = inputs.scores;
      var maxOutputSize = attrs.maxOutputSize, iouThreshold = attrs.iouThreshold, scoreThreshold = attrs.scoreThreshold;
      var boxesVals = backend.readSync(boxes.dataId);
      var scoresVals = backend.readSync(scores.dataId);
      var selectedIndices = nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold).selectedIndices;
      return backend.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices));
    }
    var nonMaxSuppressionV3Config = {
      kernelName: tf.NonMaxSuppressionV3,
      backendName: "webgl",
      kernelFunc: nonMaxSuppressionV3
    };
    var nonMaxSuppressionV4Impl = tf.kernel_impls.nonMaxSuppressionV4Impl;
    function nonMaxSuppressionV4(args) {
      tf.backend_util.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var boxes = inputs.boxes, scores = inputs.scores;
      var maxOutputSize = attrs.maxOutputSize, iouThreshold = attrs.iouThreshold, scoreThreshold = attrs.scoreThreshold, padToMaxOutputSize = attrs.padToMaxOutputSize;
      var boxesVals = backend.readSync(boxes.dataId);
      var scoresVals = backend.readSync(scores.dataId);
      var _a2 = nonMaxSuppressionV4Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize), selectedIndices = _a2.selectedIndices, validOutputs = _a2.validOutputs;
      return [
        backend.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
        backend.makeTensorInfo([], "int32", new Int32Array([validOutputs]))
      ];
    }
    var nonMaxSuppressionV4Config = {
      kernelName: tf.NonMaxSuppressionV4,
      backendName: "webgl",
      kernelFunc: nonMaxSuppressionV4
    };
    var nonMaxSuppressionV5Impl = tf.kernel_impls.nonMaxSuppressionV5Impl;
    function nonMaxSuppressionV5(args) {
      tf.backend_util.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var boxes = inputs.boxes, scores = inputs.scores;
      var maxOutputSize = attrs.maxOutputSize, iouThreshold = attrs.iouThreshold, scoreThreshold = attrs.scoreThreshold, softNmsSigma = attrs.softNmsSigma;
      var boxesVals = backend.readSync(boxes.dataId);
      var scoresVals = backend.readSync(scores.dataId);
      var maxOutputSizeVal = maxOutputSize;
      var iouThresholdVal = iouThreshold;
      var scoreThresholdVal = scoreThreshold;
      var softNmsSigmaVal = softNmsSigma;
      var _a2 = nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal), selectedIndices = _a2.selectedIndices, selectedScores = _a2.selectedScores;
      return [
        backend.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
        backend.makeTensorInfo([selectedScores.length], "float32", new Float32Array(selectedScores))
      ];
    }
    var nonMaxSuppressionV5Config = {
      kernelName: tf.NonMaxSuppressionV5,
      backendName: "webgl",
      kernelFunc: nonMaxSuppressionV5
    };
    var OneHotProgram = (
      /** @class */
      function() {
        function OneHotProgram2(numIndices, depth, onValue, offValue) {
          this.variableNames = ["indices"];
          this.outputShape = [numIndices, depth];
          this.userCode = "\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int index = round(getIndices(coords.x));\n        setOutput(mix(float(".concat(offValue, "), float(").concat(onValue, "),\n                      float(index == coords.y)));\n      }\n    ");
        }
        return OneHotProgram2;
      }()
    );
    var oneHot = function(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var indices = inputs.indices;
      var dtype = attrs.dtype, depth = attrs.depth, onValue = attrs.onValue, offValue = attrs.offValue;
      var indicesSize = tf.util.sizeFromShape(indices.shape);
      var program = new OneHotProgram(indicesSize, depth, onValue, offValue);
      var reshaped = reshape({ inputs: { x: indices }, backend, attrs: { shape: [indicesSize] } });
      var result = backend.runWebGLProgram(program, [reshaped], dtype);
      backend.disposeIntermediateTensorInfo(reshaped);
      var outShape = __spreadArray(__spreadArray([], __read(indices.shape), false), [depth], false);
      var out = reshape({ inputs: { x: result }, backend, attrs: { shape: outShape } });
      backend.disposeIntermediateTensorInfo(result);
      return out;
    };
    var oneHotConfig = {
      kernelName: tf.OneHot,
      backendName: "webgl",
      kernelFunc: oneHot
    };
    function zerosLike(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x;
      if (x.dtype === "complex64") {
        var realPart = real({ inputs: { input: x }, backend });
        var r = zerosLike({ inputs: { x: realPart }, backend });
        var imagPart = imag({ inputs: { input: x }, backend });
        var i = zerosLike({ inputs: { x: imagPart }, backend });
        var result = complex({ inputs: { real: r, imag: i }, backend });
        backend.disposeIntermediateTensorInfo(realPart);
        backend.disposeIntermediateTensorInfo(r);
        backend.disposeIntermediateTensorInfo(imagPart);
        backend.disposeIntermediateTensorInfo(i);
        return result;
      } else {
        return fill({
          attrs: {
            shape: x.shape,
            dtype: x.dtype,
            value: x.dtype === "string" ? "" : 0
          },
          backend
        });
      }
    }
    var zerosLikeConfig = {
      kernelName: tf.ZerosLike,
      backendName: "webgl",
      kernelFunc: zerosLike
    };
    function onesLike(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x;
      if (x.dtype === "string") {
        throw new Error("onesLike is not supported under string dtype");
      } else if (x.dtype === "complex64") {
        var realPart = real({ inputs: { input: x }, backend });
        var r = onesLike({ inputs: { x: realPart }, backend });
        var imagPart = imag({ inputs: { input: x }, backend });
        var i = zerosLike({ inputs: { x: imagPart }, backend });
        var result = complex({ inputs: { real: r, imag: i }, backend });
        backend.disposeIntermediateTensorInfo(realPart);
        backend.disposeIntermediateTensorInfo(r);
        backend.disposeIntermediateTensorInfo(imagPart);
        backend.disposeIntermediateTensorInfo(i);
        return result;
      } else {
        return fill({ attrs: { shape: x.shape, dtype: x.dtype, value: 1 }, backend });
      }
    }
    var onesLikeConfig = {
      kernelName: tf.OnesLike,
      backendName: "webgl",
      kernelFunc: onesLike
    };
    function pack(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var axis = attrs.axis;
      if (inputs.length === 1) {
        return expandDims({ inputs: { input: inputs[0] }, backend, attrs: { dim: axis } });
      }
      var shape = inputs[0].shape;
      var dtype = inputs[0].dtype;
      inputs.forEach(function(t) {
        tf.util.assertShapesMatch(shape, t.shape, "All tensors passed to stack must have matching shapes");
        tf.util.assert(dtype === t.dtype, function() {
          return "All tensors passed to stack must have matching dtypes";
        });
      });
      var intermediateTensorInfos = [];
      var expandedTensors = inputs.map(function(t) {
        var expandedT = expandDims({ inputs: { input: t }, backend, attrs: { dim: axis } });
        intermediateTensorInfos.push(expandedT);
        return expandedT;
      });
      var result = concat({ inputs: expandedTensors, backend, attrs: { axis } });
      intermediateTensorInfos.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return result;
    }
    var packConfig = {
      kernelName: tf.Pack,
      backendName: "webgl",
      kernelFunc: pack
    };
    var PadProgram = (
      /** @class */
      function() {
        function PadProgram2(xShape, paddings, constantValue) {
          this.variableNames = ["x"];
          this.customUniforms = [{ name: "value", type: "float" }];
          this.outputShape = paddings.map(
            function(p, i) {
              return p[0] + xShape[i] + p[1];
            }
            /* afterPad */
          );
          var rank = xShape.length;
          var type = getCoordsDataType(rank);
          var start = paddings.map(function(p) {
            return p[0];
          }).join(",");
          var end = paddings.map(function(p, i) {
            return p[0] + xShape[i];
          }).join(",");
          var unpackedCoords = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, rank);
          if (rank === 1) {
            this.userCode = "\n        int start = ".concat(start, ";\n        int end = ").concat(end, ";\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start || outC >= end) {\n            setOutput(value);\n          } else {\n            setOutput(getX(outC - start));\n          }\n        }\n      ");
            return;
          }
          this.userCode = "\n      ".concat(type, " start = ").concat(type, "(").concat(start, ");\n      ").concat(type, " end = ").concat(type, "(").concat(end, ");\n\n      void main() {\n        ").concat(type, " outC = getOutputCoords();\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\n          setOutput(value);\n        } else {\n          ").concat(type, " coords = outC - start;\n          setOutput(getX(").concat(unpackedCoords, "));\n        }\n      }\n    ");
        }
        return PadProgram2;
      }()
    );
    var PadPackedProgram = (
      /** @class */
      function() {
        function PadPackedProgram2(xShape, paddings, constantValue) {
          this.variableNames = ["x"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.customUniforms = [{ name: "value", type: "float" }];
          this.outputShape = paddings.map(
            function(p, i2) {
              return p[0] + xShape[i2] + p[1];
            }
            /* afterPad */
          );
          var rank = xShape.length;
          var dtype = getCoordsDataType(rank);
          var start = paddings.map(function(p) {
            return p[0];
          }).join(",");
          var end = paddings.map(function(p, i2) {
            return p[0] + xShape[i2];
          }).join(",");
          var coords2 = getChannels("rc", rank);
          var source = getChannels("source", rank);
          var cLimit = "".concat(coords2[rank - 1], " < ").concat(this.outputShape[rank - 1]);
          var innerDims = rank === 1 ? "source" : "vec2(".concat(source.slice(-2).join(), ")");
          var componentSetup = [
            "".concat(dtype, " rc = outputLoc;"),
            "".concat(coords2[rank - 1], " += 1;\n       if(").concat(cLimit, ") {\n      "),
            rank === 1 ? "" : "}\n       rc = outputLoc;\n       ".concat(coords2[rank - 2], " += 1;\n       if(").concat(coords2[rank - 2], " < ").concat(this.outputShape[rank - 2], ") {"),
            rank === 1 ? "" : "  ".concat(coords2[rank - 1], " += 1;\n         if(").concat(cLimit, ") {")
          ];
          var paddingArea = rank === 1 ? "rc < start || rc >= end" : "any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";
          var mainLoop = "";
          for (var i = 0, j = rank === 1 ? 2 : 4; i < j; i++) {
            mainLoop += "\n        ".concat(componentSetup[i], "\n        if (").concat(paddingArea, ") {\n          result[").concat(i, "] = float(value);\n        } else {\n          ").concat(dtype, " source = rc - start;\n          result[").concat(i, "] = getChannel(getX(").concat(source.join(), "), ").concat(innerDims, ");\n        }\n      ");
          }
          mainLoop += rank === 1 ? "} " : "}}";
          this.userCode = "\n      const ".concat(dtype, " start = ").concat(dtype, "(").concat(start, ");\n      const ").concat(dtype, " end = ").concat(dtype, "(").concat(end, ");\n\n      void main() {\n        ").concat(dtype, " outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ").concat(mainLoop, "\n        setOutput(result);\n      }\n    ");
        }
        return PadPackedProgram2;
      }()
    );
    var padV2 = function(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var paddings = attrs.paddings, constantValue = attrs.constantValue;
      if (tf.util.sizeFromShape(x.shape) === 0) {
        var outputShape = paddings.map(
          function(p, i) {
            return p[0] + x.shape[i] + p[1];
          }
          /* afterPad */
        );
        return fill({
          backend,
          attrs: { shape: outputShape, value: constantValue, dtype: x.dtype }
        });
      }
      var program = tf.env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new PadPackedProgram(x.shape, paddings, constantValue) : new PadProgram(x.shape, paddings, constantValue);
      var customValues = [[constantValue]];
      return backend.runWebGLProgram(program, [x], x.dtype, customValues);
    };
    var padV2Config = {
      kernelName: tf.PadV2,
      backendName: "webgl",
      kernelFunc: padV2
    };
    var POW = "\n  if(a < 0.0 && floor(b) < b){\n    return NAN;\n  }\n  if (b == 0.0) {\n    return 1.0;\n  }\n  return (round(mod(b, 2.0)) != 1) ?\n      pow(abs(a), b) : sign(a) * pow(abs(a), b);\n";
    var POW_PACKED = "\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\n  vec4 result = multiplier * pow(abs(a), b);\n\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\n  bvec4 isExpZero = equal(b, vec4(0.0));\n  result.r = isExpZero.r ? 1.0 : result.r;\n  result.g = isExpZero.g ? 1.0 : result.g;\n  result.b = isExpZero.b ? 1.0 : result.b;\n  result.a = isExpZero.a ? 1.0 : result.a;\n\n  bvec4 isNaN1 = lessThan(a, vec4(0.0));\n  bvec4 isNaN2 = lessThan(floor(b), b);\n  bvec4 isNaN = bvec4(isNaN1.x && isNaN2.x, isNaN1.y && isNaN2.y, isNaN1.z && isNaN2.z, isNaN1.w && isNaN2.w);\n  " + CHECK_NAN_SNIPPET_PACKED + "\n  return result;\n";
    var pow = binaryKernelFunc({ opSnippet: POW, packedOpSnippet: POW_PACKED });
    var powConfig = {
      kernelName: tf.Pow,
      backendName: "webgl",
      kernelFunc: pow
    };
    function prod(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      var xRank = x.shape.length;
      var toDispose = [];
      var origAxes = tf.util.parseAxisParam(axis, x.shape);
      var axes = origAxes;
      var permutedAxes = tf.backend_util.getAxesPermutation(axes, xRank);
      var permutedX = x;
      if (permutedAxes != null) {
        permutedX = transpose({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
        axes = tf.backend_util.getInnerMostAxes(axes.length, xRank);
        toDispose.push(permutedX);
      }
      tf.backend_util.assertAxesAreInnerMostDims("prod", axes, xRank);
      var res;
      if (backend.shouldExecuteOnCPU([permutedX])) {
        var xVals = backend.texData.get(permutedX.dataId).values;
        var _a2 = prodImplCPU(permutedX.shape, permutedX.dtype, xVals, axes), outVals = _a2.outVals, outShape = _a2.outShape, outDtype = _a2.outDtype;
        res = backend.makeTensorInfo(outShape, outDtype, outVals);
      } else {
        var _b = __read(tf.backend_util.computeOutAndReduceShapes(permutedX.shape, axes), 2), outShape = _b[0], reduceShape = _b[1];
        var inSize = tf.util.sizeFromShape(reduceShape);
        var a2D = reshape({ inputs: { x: permutedX }, backend, attrs: { shape: [-1, inSize] } });
        var outputDType = tf.sumOutType(x.dtype);
        var reduced = reduce(a2D, outputDType, "prod", backend);
        res = reshape({ inputs: { x: reduced }, backend, attrs: { shape: outShape } });
        toDispose.push(a2D);
        toDispose.push(reduced);
      }
      if (keepDims) {
        toDispose.push(res);
        var newShape = tf.backend_util.expandShapeToKeepDim(res.shape, origAxes);
        res = reshape({ inputs: { x: res }, backend, attrs: { shape: newShape } });
      }
      toDispose.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return res;
    }
    var prodConfig = {
      kernelName: tf.Prod,
      backendName: "webgl",
      kernelFunc: prod
    };
    function raggedGather(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var paramsNestedSplits = inputs.paramsNestedSplits, paramsDenseValues = inputs.paramsDenseValues, indices = inputs.indices;
      attrs.outputRaggedRank;
      var $paramsNestedSplits = paramsNestedSplits.map(function(t) {
        return backend.readSync(t.dataId);
      });
      var $paramsNestedSplitsShapes = paramsNestedSplits.map(function(t) {
        return t.shape;
      });
      var $paramsDenseValues = backend.readSync(paramsDenseValues.dataId);
      var $indices = backend.readSync(indices.dataId);
      var _a2 = __read(raggedGatherImplCPU($paramsNestedSplits, $paramsNestedSplitsShapes, $paramsDenseValues, paramsDenseValues.shape, paramsDenseValues.dtype, $indices, indices.shape), 3), outputNestedSplits = _a2[0], outputDenseValues = _a2[1], outputDenseValuesShape = _a2[2];
      var outputNestedSplitsTensors = outputNestedSplits.map(function(splits) {
        return backend.makeTensorInfo([splits.length], "int32", splits);
      });
      var outputDenseValuesTensor = backend.makeTensorInfo(outputDenseValuesShape, paramsDenseValues.dtype, outputDenseValues);
      return outputNestedSplitsTensors.concat([outputDenseValuesTensor]);
    }
    var raggedGatherConfig = {
      kernelName: tf.RaggedGather,
      backendName: "webgl",
      kernelFunc: raggedGather
    };
    function raggedRange(args) {
      var inputs = args.inputs, backend = args.backend;
      var starts = inputs.starts, limits = inputs.limits, deltas = inputs.deltas;
      var $starts = backend.readSync(starts.dataId);
      var $limits = backend.readSync(limits.dataId);
      var $deltas = backend.readSync(deltas.dataId);
      var _a2 = __read(raggedRangeImplCPU($starts, starts.shape, starts.dtype, $limits, limits.shape, $deltas, deltas.shape), 2), rtNestedSplitsData = _a2[0], rtDenseValuesData = _a2[1];
      var rtNestedSplits = backend.makeTensorInfo([rtNestedSplitsData.length], "int32", rtNestedSplitsData);
      var rtDenseValues = backend.makeTensorInfo([rtDenseValuesData.length], starts.dtype, rtDenseValuesData);
      return [rtNestedSplits, rtDenseValues];
    }
    var raggedRangeConfig = {
      kernelName: tf.RaggedRange,
      backendName: "webgl",
      kernelFunc: raggedRange
    };
    function raggedTensorToTensor(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var shape = inputs.shape, values = inputs.values, defaultValue = inputs.defaultValue, rowPartitionTensors = inputs.rowPartitionTensors;
      var rowPartitionTypes = attrs.rowPartitionTypes;
      var $shape = backend.readSync(shape.dataId);
      var $values = backend.readSync(values.dataId);
      var $defaultValue = backend.readSync(defaultValue.dataId);
      var $rowPartitionValues = rowPartitionTensors.map(function(t) {
        return backend.readSync(t.dataId);
      });
      var rowPartitionValuesShapes = rowPartitionTensors.map(function(t) {
        return t.shape;
      });
      var _a2 = __read(raggedTensorToTensorImplCPU($shape, shape.shape, $values, values.shape, values.dtype, $defaultValue, defaultValue.shape, $rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes), 2), outputShape = _a2[0], output = _a2[1];
      return backend.makeTensorInfo(outputShape, values.dtype, output);
    }
    var raggedTensorToTensorConfig = {
      kernelName: tf.RaggedTensorToTensor,
      backendName: "webgl",
      kernelFunc: raggedTensorToTensor
    };
    var range = function(args) {
      var backend = args.backend, attrs = args.attrs;
      var start = attrs.start, stop = attrs.stop, step2 = attrs.step, dtype = attrs.dtype;
      var values = rangeImplCPU(start, stop, step2, dtype);
      return backend.makeTensorInfo([values.length], dtype, values);
    };
    var rangeConfig = {
      kernelName: tf.Range,
      backendName: "webgl",
      kernelFunc: range
    };
    var RECIPROCAL = "return 1.0 / x;";
    var reciprocal = unaryKernelFunc({ opSnippet: RECIPROCAL });
    var reciprocalConfig = {
      kernelName: tf.Reciprocal,
      backendName: "webgl",
      kernelFunc: reciprocal
    };
    var RELU = CHECK_NAN_SNIPPET$1 + "\n  return (x < 0.0) ? 0.0 : x;\n";
    var RELU_PACKED = "\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n";
    var relu = unaryKernelFunc({ opSnippet: RELU, packedOpSnippet: RELU_PACKED });
    var reluConfig = {
      kernelName: tf.Relu,
      backendName: "webgl",
      kernelFunc: relu
    };
    var RELU6 = CHECK_NAN_SNIPPET$1 + "\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n";
    var RELU6_PACKED = "\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n";
    var relu6 = unaryKernelFunc({ opSnippet: RELU6, packedOpSnippet: RELU6_PACKED });
    var relu6Config = {
      kernelName: tf.Relu6,
      backendName: "webgl",
      kernelFunc: relu6
    };
    var ResizeBilinearProgram = (
      /** @class */
      function() {
        function ResizeBilinearProgram2(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
          this.variableNames = ["A"];
          this.outputShape = [];
          var _a2 = __read(inputShape, 4), batch = _a2[0], oldHeight = _a2[1], oldWidth = _a2[2], depth = _a2[3];
          this.outputShape = [batch, newHeight, newWidth, depth];
          var effectiveInSize = [
            alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
            alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
          ];
          var effectiveOutSize = [
            alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
            alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
          ];
          var sourceFracIndexRC;
          if (halfPixelCenters) {
            sourceFracIndexRC = "(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)";
          } else {
            sourceFracIndexRC = "vec2(yRC) * effectiveInputOverOutputRatioRC";
          }
          this.userCode = "\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ".concat(effectiveInSize[0] / effectiveOutSize[0], ",\n          ").concat(effectiveInSize[1] / effectiveOutSize[1], ");\n      const vec2 inputShapeRC = vec2(").concat(oldHeight, ".0, ").concat(oldWidth, ".0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ").concat(sourceFracIndexRC, ";\n\n        // Compute the four integer indices.\n        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));\n        ivec2 sourceCeilRC = ivec2(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\n\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\n\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\n        float newValue = top + (bottom - top) * fracRC.x;\n\n        setOutput(newValue);\n      }\n    ");
        }
        return ResizeBilinearProgram2;
      }()
    );
    var ResizeBilinearPackedProgram = (
      /** @class */
      function() {
        function ResizeBilinearPackedProgram2(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
          this.variableNames = ["A"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.outputShape = [];
          var _a2 = __read(inputShape, 4), batch = _a2[0], oldHeight = _a2[1], oldWidth = _a2[2], depth = _a2[3];
          this.outputShape = [batch, newHeight, newWidth, depth];
          var effectiveInSize = [
            alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
            alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
          ];
          var effectiveOutSize = [
            alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
            alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
          ];
          var sourceFracIndexRC;
          if (halfPixelCenters) {
            sourceFracIndexRC = "(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)";
          } else {
            sourceFracIndexRC = "vec3(yRC) * effectiveInputOverOutputRatioRC";
          }
          this.userCode = "\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ".concat(effectiveInSize[0] / effectiveOutSize[0], ",\n          ").concat(effectiveInSize[1] / effectiveOutSize[1], ",\n          ").concat(effectiveInSize[1] / effectiveOutSize[1], ");\n      const vec3 inputShapeRC = vec3(").concat(oldHeight, ".0, ").concat(oldWidth, ".0,\n                                     ").concat(oldWidth, ".0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ").concat(sourceFracIndexRC, ";\n\n        // Compute the four integer indices.\n        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));\n        ivec3 sourceCeilRC = ivec3(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ").concat(depth - 1, ";\n        bool hasNextRow = coords.z < ").concat(newWidth - 1, ";\n\n        // In parallel, construct four corners for all four components in\n        // packed 2x2 cell.\n        vec4 topLeft = vec4(\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 bottomLeft = vec4(\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 topRight = vec4(\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec4 bottomRight = vec4(\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\n\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\n        vec4 newValue = mix(top, bottom, fracRC.x);\n\n        setOutput(newValue);\n      }\n    ");
        }
        return ResizeBilinearPackedProgram2;
      }()
    );
    function resizeBilinear(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var images = inputs.images;
      var alignCorners = attrs.alignCorners, halfPixelCenters = attrs.halfPixelCenters, size = attrs.size;
      var _a2 = __read(size, 2), newHeight = _a2[0], newWidth = _a2[1];
      var program = tf.env().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new ResizeBilinearPackedProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters) : new ResizeBilinearProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters);
      return backend.runWebGLProgram(program, [images], "float32");
    }
    var resizeBilinearConfig = {
      kernelName: tf.ResizeBilinear,
      backendName: "webgl",
      kernelFunc: resizeBilinear
    };
    var ResizeBilinearBackpropProgram = (
      /** @class */
      function() {
        function ResizeBilinearBackpropProgram2(dyShape, inputShape, alignCorners) {
          this.variableNames = ["dy"];
          this.outputShape = [];
          this.outputShape = inputShape;
          var _a2 = __read(inputShape, 3), xHeight = _a2[1], xWidth = _a2[2];
          var _b = __read(dyShape, 3), yHeight = _b[1], yWidth = _b[2];
          var effectiveXSize = [
            alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
            alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
          ];
          var effectiveYSize = [
            alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
            alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
          ];
          var heightScale = effectiveXSize[0] / effectiveYSize[0];
          var widthScale = effectiveXSize[1] / effectiveYSize[1];
          var invHeightScale = 1 / heightScale;
          var invWidthScale = 1 / widthScale;
          var winHeight = Math.ceil(invHeightScale) * 2 + 2;
          var winWidth = Math.ceil(invWidthScale) * 2 + 2;
          this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(".concat(heightScale, ");\n        const float widthScale = float(").concat(widthScale, ");\n\n        const float invHeightScale = float(").concat(invHeightScale, ");\n        const float invWidthScale = float(").concat(invWidthScale, ");\n\n        const int winHeight = int(").concat(winHeight, ");\n        const int winWidth = int(").concat(winWidth, ");\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(startRLerp - float(winHeight / 2));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(startCLerp - float(winWidth / 2));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ").concat(yHeight, ") {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ").concat(yWidth, ") {\n              continue;\n            }\n\n            float dxR = float(dyR) * heightScale;\n            int topDxRIndex = int(floor(dxR));\n            int bottomDxRIndex = int(min(ceil(dxR), ").concat(xHeight - 1, ".0));\n            float dxRLerp = dxR - float(topDxRIndex);\n            float inverseDxRLerp = 1.0 - dxRLerp;\n\n            float dxC = float(dyC) * widthScale;\n            int leftDxCIndex = int(floor(dxC));\n            int rightDxCIndex = int(min(ceil(dxC), ").concat(xWidth - 1, ".0));\n            float dxCLerp = dxC - float(leftDxCIndex);\n            float inverseDxCLerp = 1.0 - dxCLerp;\n\n            if (r == topDxRIndex && c == leftDxCIndex) {\n              // topLeft\n              accumulator +=\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\n            }\n\n            if (r == topDxRIndex && c == rightDxCIndex) {\n              // topRight\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\n              // bottomLeft\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\n              // bottomRight\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    ");
        }
        return ResizeBilinearBackpropProgram2;
      }()
    );
    function resizeBilinearGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var images = inputs.images, dy = inputs.dy;
      var alignCorners = attrs.alignCorners;
      var program = new ResizeBilinearBackpropProgram(dy.shape, images.shape, alignCorners);
      return backend.runWebGLProgram(program, [dy], dy.dtype);
    }
    var resizeBilinearGradConfig = {
      kernelName: tf.ResizeBilinearGrad,
      backendName: "webgl",
      kernelFunc: resizeBilinearGrad
    };
    var ResizeNearestNeighborProgram = (
      /** @class */
      function() {
        function ResizeNearestNeighborProgram2(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
          this.variableNames = ["A"];
          this.outputShape = [];
          var _a2 = __read(inputShape, 4), batch = _a2[0], oldHeight = _a2[1], oldWidth = _a2[2], depth = _a2[3];
          this.outputShape = [batch, newHeight, newWidth, depth];
          var effectiveInSize = [
            alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
            alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
          ];
          var effectiveOutSize = [
            alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
            alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
          ];
          var roundBase = alignCorners ? "0.5" : "0.0";
          var sourceFracIndexRC;
          if (halfPixelCenters) {
            sourceFracIndexRC = "max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))";
          } else {
            sourceFracIndexRC = "vec2(yRC) * effectiveInputOverOutputRatioRC";
          }
          this.userCode = "\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ".concat(effectiveInSize[0] / effectiveOutSize[0], ",\n          ").concat(effectiveInSize[1] / effectiveOutSize[1], ");\n      const vec2 inputShapeRC = vec2(").concat(oldHeight, ".0, ").concat(oldWidth, ".0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ").concat(sourceFracIndexRC, ";\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec2 sourceNearestRC = ivec2(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ").concat(roundBase, ")));\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\n\n        setOutput(newValue);\n      }\n    ");
        }
        return ResizeNearestNeighborProgram2;
      }()
    );
    var ResizeNearestNeighborPackedProgram = (
      /** @class */
      function() {
        function ResizeNearestNeighborPackedProgram2(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
          this.variableNames = ["A"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.outputShape = [];
          var _a2 = __read(inputShape, 4), batch = _a2[0], oldHeight = _a2[1], oldWidth = _a2[2], depth = _a2[3];
          this.outputShape = [batch, newHeight, newWidth, depth];
          var effectiveInSize = [
            alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
            alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
          ];
          var effectiveOutSize = [
            alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
            alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
          ];
          var roundBase = alignCorners ? "0.5" : "0.0";
          var sourceFracIndexRC;
          if (halfPixelCenters) {
            sourceFracIndexRC = "max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))";
          } else {
            sourceFracIndexRC = "vec3(yRC) * effectiveInputOverOutputRatioRC";
          }
          this.userCode = "\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ".concat(effectiveInSize[0] / effectiveOutSize[0], ",\n          ").concat(effectiveInSize[1] / effectiveOutSize[1], ",\n          ").concat(effectiveInSize[1] / effectiveOutSize[1], ");\n      const vec3 inputShapeRC = vec3(").concat(oldHeight, ".0, ").concat(oldWidth, ".0,\n                                     ").concat(oldWidth, ".0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ").concat(sourceFracIndexRC, ";\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec3 sourceNearestRC = ivec3(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ").concat(roundBase, ")));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ").concat(depth - 1, ";\n        bool hasNextRow = coords.z < ").concat(newWidth - 1, ";\n\n        vec4 newValue = vec4(\n          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),\n          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);\n\n        setOutput(newValue);\n      }\n    ");
        }
        return ResizeNearestNeighborPackedProgram2;
      }()
    );
    function resizeNearestNeighbor(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var images = inputs.images;
      var alignCorners = attrs.alignCorners, halfPixelCenters = attrs.halfPixelCenters, size = attrs.size;
      var _a2 = __read(size, 2), newHeight = _a2[0], newWidth = _a2[1];
      var program = tf.env().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new ResizeNearestNeighborPackedProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters) : new ResizeNearestNeighborProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters);
      return backend.runWebGLProgram(program, [images], images.dtype);
    }
    var resizeNearestNeighborConfig = {
      kernelName: tf.ResizeNearestNeighbor,
      backendName: "webgl",
      kernelFunc: resizeNearestNeighbor
    };
    var ResizeNearestNeigborBackpropProgram = (
      /** @class */
      function() {
        function ResizeNearestNeigborBackpropProgram2(dyShape, inputShape, alignCorners) {
          this.variableNames = ["dy"];
          this.outputShape = [];
          this.outputShape = inputShape;
          var _a2 = __read(inputShape, 3), xHeight = _a2[1], xWidth = _a2[2];
          var _b = __read(dyShape, 3), yHeight = _b[1], yWidth = _b[2];
          var effectiveXSize = [
            alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
            alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
          ];
          var effectiveYSize = [
            alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
            alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
          ];
          var heightScale = effectiveXSize[0] / effectiveYSize[0];
          var widthScale = effectiveXSize[1] / effectiveYSize[1];
          var invHeightScale = 1 / heightScale;
          var invWidthScale = 1 / widthScale;
          var winHeight = Math.ceil(invHeightScale) * 2 + 2;
          var winWidth = Math.ceil(invWidthScale) * 2 + 2;
          this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(".concat(heightScale, ");\n        const float widthScale = float(").concat(widthScale, ");\n\n        const float invHeightScale = float(").concat(invHeightScale, ");\n        const float invWidthScale = float(").concat(invWidthScale, ");\n\n        const int winHeight = int(").concat(winHeight, ");\n        const int winWidth = int(").concat(winWidth, ");\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ").concat(yHeight, ") {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ").concat(yWidth, ") {\n              continue;\n            }\n\n            float sourceFracRow =\n              float(").concat(effectiveXSize[0], ") *\n                (float(dyR) / float(").concat(effectiveYSize[0], "));\n\n            float sourceFracCol =\n                float(").concat(effectiveXSize[1], ") *\n                  (float(dyC) / float(").concat(effectiveYSize[1], "));\n\n            int sourceNearestRow = int(min(\n                float(int(").concat(xHeight, ") - 1),\n                ").concat(alignCorners, " ? float(round(sourceFracRow)) :\n                                  float(floor(sourceFracRow))));\n\n            int sourceNearestCol = int(min(\n                float(int(").concat(xWidth, ") - 1),\n                ").concat(alignCorners, " ? float(round(sourceFracCol)) :\n                                  float(floor(sourceFracCol))));\n\n            if (r == sourceNearestRow && c == sourceNearestCol) {\n              accumulator += getDy(b, dyR, dyC, d);\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    ");
        }
        return ResizeNearestNeigborBackpropProgram2;
      }()
    );
    function resizeNearestNeighborGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var images = inputs.images, dy = inputs.dy;
      var alignCorners = attrs.alignCorners;
      var program = new ResizeNearestNeigborBackpropProgram(dy.shape, images.shape, alignCorners);
      return backend.runWebGLProgram(program, [dy], dy.dtype);
    }
    var resizeNearestNeighborGradConfig = {
      kernelName: tf.ResizeNearestNeighborGrad,
      backendName: "webgl",
      kernelFunc: resizeNearestNeighborGrad
    };
    var ReverseProgram = (
      /** @class */
      function() {
        function ReverseProgram2(xShape, axis) {
          this.variableNames = ["x"];
          var rank = xShape.length;
          if (rank > 4) {
            throw new Error("WebGL backend: Reverse of rank-".concat(rank, " tensor is not yet supported"));
          }
          this.outputShape = xShape;
          if (rank === 1) {
            this.userCode = "\n        void main() {\n          int coord = getOutputCoords();\n          setOutput(getX(".concat(xShape[0], " - coord - 1));\n        }\n      ");
            return;
          }
          var getInCoord = function(i) {
            if (axis.indexOf(i) !== -1 && xShape[i] !== 1) {
              return "".concat(xShape[i], " - coords[").concat(i, "] - 1");
            }
            return "coords[".concat(i, "]");
          };
          var inCoords = xShape.map(function(_, i) {
            return getInCoord(i);
          }).join(",");
          var type = getCoordsDataType(rank);
          this.userCode = "\n      void main() {\n        ".concat(type, " coords = getOutputCoords();\n        setOutput(getX(").concat(inCoords, "));\n      }\n    ");
        }
        return ReverseProgram2;
      }()
    );
    var ReversePackedProgram = (
      /** @class */
      function() {
        function ReversePackedProgram2(xShape, axis) {
          this.variableNames = ["x"];
          this.packedInputs = true;
          this.packedOutput = true;
          var rank = xShape.length;
          if (rank > 4) {
            throw new Error("WebGL backend: Reverse of rank-".concat(rank, " tensor is not yet supported"));
          }
          this.outputShape = xShape;
          var channels = getChannels("rc", rank);
          var nextColumn = "".concat(channels[rank - 1], " + 1 < ").concat(this.outputShape[rank - 1]);
          var nextRow = "".concat(channels[rank - 2], " + 1 < ").concat(this.outputShape[rank - 2]);
          var type = getCoordsDataType(rank);
          if (rank === 1) {
            this.userCode = "\n        void main(){\n          int rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = getChannel(getX(".concat(xShape[0], " - rc - 1),\n            ").concat(xShape[0], " - rc - 1);\n          if(").concat(nextColumn, "){\n              result.g = getChannel(getX(").concat(xShape[0], " - (rc  + 1) - 1),\n                ").concat(xShape[0], " - (rc  + 1) - 1);\n          }\n          setOutput(result);\n        }\n      ");
          } else {
            this.userCode = "\n        void main() {\n          ".concat(type, " rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = ").concat(getR(channels.slice()), ";\n          if(").concat(nextColumn, "){\n            result.g = ").concat(getG(channels.slice()), ";\n          }\n          if(").concat(nextRow, ") {\n            result.b = ").concat(getB(channels.slice()), ";\n            if(").concat(nextColumn, ") {\n              result.a = ").concat(getA(channels.slice()), ";\n            }\n          }\n          setOutput(result);\n        }\n    ");
          }
          function getR(channels2) {
            return getChannel(channels2);
          }
          function getG(channels2) {
            channels2[rank - 1] = "(" + channels2[rank - 1] + " + 1)";
            return getChannel(channels2);
          }
          function getB(channels2) {
            channels2[rank - 2] = "(" + channels2[rank - 2] + " + 1)";
            return getChannel(channels2);
          }
          function getA(channels2) {
            channels2[rank - 1] = "(" + channels2[rank - 1] + " + 1)";
            channels2[rank - 2] = "(" + channels2[rank - 2] + " + 1)";
            return getChannel(channels2);
          }
          function getChannel(channels2) {
            var inCoordsArray = xShape.map(function(_, i) {
              return getInCoord(i, channels2);
            });
            var inCoords = inCoordsArray.join(",");
            var innerDims = inCoordsArray.slice(-2).join(",");
            return "getChannel(getX(".concat(inCoords, "), vec2(").concat(innerDims, "))");
          }
          function getInCoord(i, channels1) {
            if (axis.indexOf(i) !== -1 && xShape[i] !== 1) {
              return "".concat(xShape[i], " - ").concat(channels1[i], " - 1");
            } else {
              return "".concat(channels1[i]);
            }
          }
        }
        return ReversePackedProgram2;
      }()
    );
    function reverse(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var dims = attrs.dims;
      var xRank = x.shape.length;
      var $dims = tf.util.parseAxisParam(dims, x.shape);
      if (xRank === 0) {
        return identity({ inputs: { x }, backend });
      }
      var program = tf.env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new ReversePackedProgram(x.shape, $dims) : new ReverseProgram(x.shape, $dims);
      return backend.runWebGLProgram(program, [x], x.dtype);
    }
    var reverseConfig = {
      kernelName: tf.Reverse,
      backendName: "webgl",
      kernelFunc: reverse
    };
    var RotateProgram = (
      /** @class */
      function() {
        function RotateProgram2(imageShape, fillValue) {
          this.variableNames = ["Image"];
          this.outputShape = [];
          this.customUniforms = [{ name: "params", type: "vec4" }];
          var imageHeight = imageShape[1];
          var imageWidth = imageShape[2];
          this.outputShape = imageShape;
          var fillSnippet = "";
          if (typeof fillValue === "number") {
            fillSnippet = "float outputValue = ".concat(fillValue.toFixed(2), ";");
          } else {
            fillSnippet = "\n        vec3 fill = vec3(".concat(fillValue.join(","), ");\n        float outputValue = fill[coords[3]];");
          }
          this.userCode = "\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n          int y = coords[1];\n          float coordXFloat = (float(x) - params[0]) * params[3] -\n            (float(y) - params[1]) * params[2];\n          float coordYFloat = (float(x) - params[0]) * params[2] +\n            (float(y) - params[1]) * params[3];\n          int coordX = int(round(coordXFloat + params[0]));\n          int coordY = int(round(coordYFloat + params[1]));\n          ".concat(fillSnippet, "\n          if(coordX >= 0 && coordX < ").concat(imageWidth, " && coordY >= 0 && coordY < ").concat(imageHeight, ") {\n            outputValue = getImage(coords[0], coordY, coordX, coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    ");
        }
        return RotateProgram2;
      }()
    );
    var rotateWithOffsetConfig = {
      kernelName: tf.RotateWithOffset,
      backendName: "webgl",
      kernelFunc: function(_a2) {
        var inputs = _a2.inputs, attrs = _a2.attrs, backend = _a2.backend;
        var image = inputs.image;
        var radians = attrs.radians, fillValue = attrs.fillValue, center = attrs.center;
        var webglBackend = backend;
        var program = new RotateProgram(image.shape, fillValue);
        var _b = __read(tf.backend_util.getImageCenter(center, image.shape[1], image.shape[2]), 2), centerX = _b[0], centerY = _b[1];
        var customValues = [[centerX, centerY, Math.sin(radians), Math.cos(radians)]];
        var output = webglBackend.runWebGLProgram(program, [image], image.dtype, customValues);
        return output;
      }
    };
    var ROUND = "\n  // OpenGL ES does not support round function.\n  // The algorithm is based on banker's rounding.\n  float base = floor(x);\n  if ((x - base) < 0.5) {\n    return floor(x);\n  } else if ((x - base) > 0.5) {\n    return ceil(x);\n  } else {\n    if (mod(base, 2.0) == 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n";
    var round = unaryKernelFunc({ opSnippet: ROUND });
    var roundConfig = {
      kernelName: tf.Round,
      backendName: "webgl",
      kernelFunc: round
    };
    var RSQRT = "return inversesqrt(x);";
    var rsqrt = unaryKernelFunc({ opSnippet: RSQRT, cpuKernelImpl: rsqrtImplCPU });
    var rsqrtConfig = {
      kernelName: tf.Rsqrt,
      backendName: "webgl",
      kernelFunc: rsqrt
    };
    var ScatterProgram = (
      /** @class */
      function() {
        function ScatterProgram2(updateSize, sliceDim, indicesRank, updatesRank, strides, shape, summingDupeIndex, defaultIsTensor) {
          if (defaultIsTensor === void 0) {
            defaultIsTensor = false;
          }
          this.variableNames = ["updates", "indices", "defaultValue"];
          this.outputShape = shape;
          var stridesType = getCoordsDataType(strides.length);
          var dtype = getCoordsDataType(shape.length);
          var indicesString = "";
          if (indicesRank === 1) {
            indicesString = "i";
          } else if (indicesRank === 2) {
            indicesString = "i, j";
          }
          var indicesSnippet = "getIndices(".concat(indicesString, ")");
          var updatesString = "";
          if (updatesRank === 1) {
            updatesString = "i";
          } else if (updatesRank === 2) {
            updatesString = "i, coords[1]";
          }
          var updatesSnippet = "getUpdates(".concat(updatesString, ")");
          var defaultValuesString = "";
          if (defaultIsTensor) {
            defaultValuesString = "coords[0], coords[1]";
          }
          var defaultValueSnippet = "getDefaultValue(".concat(defaultValuesString, ")");
          var strideString = sliceDim > 1 ? "strides[j]" : "strides";
          this.userCode = "\n        ".concat(stridesType, " strides = ").concat(stridesType, "(").concat(strides, ");\n\n        void main() {\n          ").concat(dtype, " coords = getOutputCoords();\n          float sum = 0.0;\n          bool found = false;\n          for (int i = 0; i < ").concat(updateSize, "; i++) {\n            int flattenedIndex = 0;\n            for (int j = 0; j < ").concat(sliceDim, "; j++) {\n              int index = round(").concat(indicesSnippet, ");\n              flattenedIndex += index * ").concat(strideString, ";\n            }\n            if (flattenedIndex == coords[0]) {\n              sum += ").concat(updatesSnippet, ";\n              found = true;\n            }\n          }\n          setOutput(mix(").concat(defaultValueSnippet, ", sum, float(found)));\n        }\n      ");
        }
        return ScatterProgram2;
      }()
    );
    var ScatterPackedProgram = (
      /** @class */
      function() {
        function ScatterPackedProgram2(updateSize, sliceDim, indicesRank, updatesRank, strides, shape, summingDupeIndex, defaultIsTensor) {
          if (defaultIsTensor === void 0) {
            defaultIsTensor = false;
          }
          this.variableNames = ["updates", "indices", "defaultValue"];
          this.packedInputs = true;
          this.packedOutput = true;
          this.outputShape = shape;
          var stridesType = getCoordsDataType(strides.length);
          var dtype = getCoordsDataType(shape.length);
          var indicesString = "";
          if (indicesRank === 1) {
            indicesString = "i";
          } else if (indicesRank === 2) {
            indicesString = "i, j";
          }
          var indicesSnippet = "getIndices(".concat(indicesString, ")");
          var updatesString = "";
          if (updatesRank === 1) {
            updatesString = "i";
          } else if (updatesRank === 2) {
            updatesString = "i, coords[1]";
          }
          var updatesSnippet = "getUpdates(".concat(updatesString, ")");
          var defaultValuesString = "";
          if (defaultIsTensor) {
            defaultValuesString = "coords[0], coords[1]";
          }
          var defaultValueSnippet = "getDefaultValue(".concat(defaultValuesString, ")");
          var strideString = sliceDim > 1 ? "strides[j]" : "strides";
          var strideString2 = sliceDim > 1 ? "strides[j + 1]" : "strides";
          this.userCode = "\n        ".concat(stridesType, " strides = ").concat(stridesType, "(").concat(strides, ");\n\n        void main() {\n          ").concat(dtype, " coords = getOutputCoords();\n          vec4 sum = vec4(0.);\n          vec4 found = vec4(0.);\n          for (int i = 0; i < ").concat(updateSize, "; i+=2) {\n            ivec2 flattenedIndex = ivec2(0);\n            for (int j = 0; j < ").concat(sliceDim, "; j+=2) {\n              ivec4 index = round(").concat(indicesSnippet, ");\n              flattenedIndex += index.xz * ").concat(strideString, ";\n              if (j + 1 < ").concat(sliceDim, ") {\n                flattenedIndex += index.yw * ").concat(strideString2, ";\n              }\n            }\n            if (flattenedIndex[0] == coords[0] || flattenedIndex[1] == coords[0] ||\n                flattenedIndex[0] == coords[0] + 1 || flattenedIndex[1] == coords[0] + 1) {\n              vec4 updVals = ").concat(updatesSnippet, ";\n              if (flattenedIndex[0] == coords[0]) {\n                sum.xy += updVals.xy;\n                found.xy = vec2(1.);\n              } else if (flattenedIndex[0] == coords[0] + 1) {\n                sum.zw += updVals.xy;\n                found.zw = vec2(1.);\n              }\n              if (flattenedIndex[1] == coords[0]) {\n                sum.xy += updVals.zw;\n                found.xy = vec2(1.);\n              } else if (flattenedIndex[1] == coords[0] + 1) {\n                sum.zw += updVals.zw;\n                found.zw = vec2(1.);\n              }\n            }\n          }\n          setOutput(mix(").concat(defaultValueSnippet, ", sum, found));\n        }\n      ");
        }
        return ScatterPackedProgram2;
      }()
    );
    function scatterNd(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var indices = inputs.indices, updates = inputs.updates;
      var shape = attrs.shape;
      var _a2 = tf.backend_util.calculateShapes(updates, indices, shape), sliceRank = _a2.sliceRank, numUpdates = _a2.numUpdates, sliceSize = _a2.sliceSize, strides = _a2.strides, outputSize = _a2.outputSize;
      var flattenShape = [outputSize / sliceSize, sliceSize];
      if (outputSize === 0) {
        return backend.makeTensorInfo(shape, indices.dtype);
      }
      var flattenIndices = reshape({ inputs: { x: indices }, backend, attrs: { shape: [numUpdates, sliceRank] } });
      var flattenX = reshape({ inputs: { x: updates }, backend, attrs: { shape: [numUpdates, sliceSize] } });
      var defaultValue = backend.makeTensorInfo([], "float32", new Float32Array([0]));
      var program;
      if (tf.env().getBool("WEBGL_PACK")) {
        program = new ScatterPackedProgram(numUpdates, sliceRank, flattenIndices.shape.length, flattenX.shape.length, strides, flattenShape);
      } else {
        program = new ScatterProgram(numUpdates, sliceRank, flattenIndices.shape.length, flattenX.shape.length, strides, flattenShape);
      }
      var res = backend.runWebGLProgram(program, [flattenX, flattenIndices, defaultValue], flattenX.dtype);
      var reshaped = reshape({ inputs: { x: res }, backend, attrs: { shape } });
      backend.disposeIntermediateTensorInfo(flattenIndices);
      backend.disposeIntermediateTensorInfo(flattenX);
      backend.disposeIntermediateTensorInfo(res);
      backend.disposeIntermediateTensorInfo(defaultValue);
      return reshaped;
    }
    var scatterNdConfig = {
      kernelName: tf.ScatterNd,
      backendName: "webgl",
      kernelFunc: scatterNd
    };
    var SearchSortedProgram = (
      /** @class */
      function() {
        function SearchSortedProgram2(batchSize, numInputs, numValues, side) {
          this.variableNames = ["sortedSequence", "values"];
          this.customUniforms = [{ name: "numInputs", type: "int" }];
          this.outputShape = [batchSize, numValues];
          var webGL2LoopHead = "while (left < right) {";
          var webGL1LoopHead = "for (int i = 0; i < ".concat(Math.ceil(Math.log2(numInputs + 1)), "; ++i) { if (left >= right) break;");
          var loopHead = tf.env().getNumber("WEBGL_VERSION") === 2 ? webGL2LoopHead : webGL1LoopHead;
          var boundComparator = side === "left" ? "<" : "<=";
          this.userCode = "\n       int findBound(int batch, float value) {\n         int left = 0;\n         int right = numInputs;\n         int mid;\n         ".concat(loopHead, "\n           mid = (left + right) / 2;\n           if (getSortedSequence(batch, mid) ").concat(boundComparator, " value) {\n             left = mid + 1;\n           } else {\n             right = mid;\n           }\n         }\n         return right;\n       }\n\n       void main() {\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int valueIndex = coords[1];\n\n         float value = getValues(batch, valueIndex);\n\n         setOutput(float(findBound(batch, value)));\n       }\n     ");
        }
        return SearchSortedProgram2;
      }()
    );
    function searchSorted(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var sortedSequence = inputs.sortedSequence, values = inputs.values;
      var side = attrs.side;
      var program = new SearchSortedProgram(sortedSequence.shape[0], sortedSequence.shape[1], values.shape[1], side);
      var customValues = [[sortedSequence.shape[1]]];
      return backend.runWebGLProgram(program, [sortedSequence, values], "int32", customValues);
    }
    var searchSortedConfig = {
      kernelName: tf.SearchSorted,
      backendName: "webgl",
      kernelFunc: searchSorted
    };
    var SelectProgram = (
      /** @class */
      function() {
        function SelectProgram2(cRank, shape, rank) {
          this.variableNames = ["c", "a", "b"];
          this.outputShape = shape;
          var cCoords;
          var abCoords;
          if (rank > 4) {
            throw Error("Where for rank ".concat(rank, " is not yet supported"));
          }
          if (rank === 1) {
            abCoords = "resRC";
            cCoords = "resRC";
          } else {
            var currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"];
            var cCoordVars = [];
            var abCoordVars = [];
            for (var i = 0; i < shape.length; i++) {
              abCoordVars.push("".concat(currentCoords[i]));
              if (i < cRank) {
                cCoordVars.push("".concat(currentCoords[i]));
              }
            }
            cCoords = cCoordVars.join();
            abCoords = abCoordVars.join();
          }
          var dtype = getCoordsDataType(rank);
          this.userCode = "\n      void main() {\n        ".concat(dtype, " resRC = getOutputCoords();\n        float cVal = getC(").concat(cCoords, ");\n        if (cVal >= 1.0) {\n          setOutput(getA(").concat(abCoords, "));\n        } else {\n          setOutput(getB(").concat(abCoords, "));\n        }\n      }\n    ");
        }
        return SelectProgram2;
      }()
    );
    function select(args) {
      var inputs = args.inputs, backend = args.backend;
      var condition = inputs.condition, t = inputs.t, e = inputs.e;
      var program = new SelectProgram(condition.shape.length, t.shape, t.shape.length);
      return backend.runWebGLProgram(program, [condition, t, e], tf.upcastType(t.dtype, e.dtype));
    }
    var selectConfig = {
      kernelName: tf.Select,
      backendName: "webgl",
      kernelFunc: select
    };
    var SELU = "\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n  // see: https://arxiv.org/abs/1706.02515\n  float scaleAlpha = ".concat(tf.backend_util.SELU_SCALEALPHA, ";\n  float scale = ").concat(tf.backend_util.SELU_SCALE, ";\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\n");
    var selu = unaryKernelFunc({ opSnippet: SELU });
    var seluConfig = {
      kernelName: tf.Selu,
      backendName: "webgl",
      kernelFunc: selu
    };
    var SIGMOID = CHECK_NAN_SNIPPET_UNARY + "\n  return 1.0 / (1.0 + exp(-1.0 * x));\n";
    var SIGMOID_PACKED = "\n  vec4 result = 1.0 / (1.0 + exp(-1.0 * x));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n";
    var sigmoid = unaryKernelFunc({
      opSnippet: SIGMOID,
      packedOpSnippet: SIGMOID_PACKED,
      cpuKernelImpl: sigmoidImplCPU
    });
    var sigmoidConfig = {
      kernelName: tf.Sigmoid,
      backendName: "webgl",
      kernelFunc: sigmoid
    };
    var SIGN = "\n  if (isnan(x)) { return 0.0; }\n  return sign(x);\n";
    var sign = unaryKernelFunc({ opSnippet: SIGN });
    var signConfig = {
      kernelName: tf.Sign,
      backendName: "webgl",
      kernelFunc: sign
    };
    var SIN = CHECK_NAN_SNIPPET_UNARY + "\n  return sin(x);\n";
    var SIN_PACKED = "\n  vec4 result = sin(x);\n  bvec4 isNaN = isnan(x);\n  ".concat(CHECK_NAN_SNIPPET_PACKED, "\n  return result;\n");
    var sin = unaryKernelFunc({ opSnippet: SIN, packedOpSnippet: SIN_PACKED });
    var sinConfig = {
      kernelName: tf.Sin,
      backendName: "webgl",
      kernelFunc: sin
    };
    var SINH = "\n  float e2x = exp(x);\n  return (e2x - 1.0 / e2x) / 2.0;\n";
    var sinh = unaryKernelFunc({ opSnippet: SINH });
    var sinhConfig = {
      kernelName: tf.Sinh,
      backendName: "webgl",
      kernelFunc: sinh
    };
    var SOFTPLUS = "\n  float epsilon = 1.1920928955078125e-7;\n  float threshold = log(epsilon) + 2.0;\n\n  bool too_large = x > -threshold;\n  bool too_small = x < threshold;\n\n  float result;\n  float exp_x = exp(x);\n\n  if (too_large){\n    result = x;\n  }\n  else if (too_small){\n    result = exp_x;\n  }\n  else{\n    result = log(exp_x + 1.0);\n  }\n  return result;\n";
    var softplus = unaryKernelFunc({ opSnippet: SOFTPLUS });
    var softplusConfig = {
      kernelName: tf.Softplus,
      backendName: "webgl",
      kernelFunc: softplus
    };
    var spaceToBatchND = function(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var blockShape = attrs.blockShape, paddings = attrs.paddings;
      tf.util.assert(x.shape.length <= 4, function() {
        return "spaceToBatchND for rank > 4 with a WebGL backend not implemented yet";
      });
      var prod2 = blockShape.reduce(function(a, b) {
        return a * b;
      });
      var completePaddings = [[0, 0]];
      completePaddings.push.apply(completePaddings, __spreadArray([], __read(paddings), false));
      for (var i = 1 + blockShape.length; i < x.shape.length; ++i) {
        completePaddings.push([0, 0]);
      }
      var toDispose = [];
      var paddedX = padV2({
        inputs: { x },
        backend,
        attrs: { paddings: completePaddings, constantValue: 0 }
      });
      var reshapedPaddedShape = tf.backend_util.getReshaped(paddedX.shape, blockShape, prod2, false);
      var permutedReshapedPaddedPermutation = tf.backend_util.getPermuted(reshapedPaddedShape.length, blockShape.length, false);
      var flattenShape = tf.backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod2, false);
      var reshapedPaddedX = reshape({ inputs: { x: paddedX }, backend, attrs: { shape: reshapedPaddedShape } });
      var paddedXT = transpose({
        inputs: { x: reshapedPaddedX },
        backend,
        attrs: { perm: permutedReshapedPaddedPermutation }
      });
      var result = reshape({ inputs: { x: paddedXT }, backend, attrs: { shape: flattenShape } });
      toDispose.push(paddedX);
      toDispose.push(reshapedPaddedX);
      toDispose.push(paddedXT);
      toDispose.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return result;
    };
    var spaceToBatchNDConfig = {
      kernelName: tf.SpaceToBatchND,
      backendName: "webgl",
      kernelFunc: spaceToBatchND
    };
    function sparseFillEmptyRows(args) {
      var inputs = args.inputs, backend = args.backend;
      var indices = inputs.indices, values = inputs.values, denseShape = inputs.denseShape, defaultValue = inputs.defaultValue;
      if (denseShape.shape.length !== 1) {
        throw new Error("Dense shape must be a vector, saw:\n         ".concat(denseShape.shape));
      }
      if (indices.shape.length !== 2) {
        throw new Error("Indices must be a matrix, saw:\n         ".concat(indices.shape));
      }
      if (values.shape.length !== 1) {
        throw new Error("Values must be a vector, saw:\n         ".concat(values.shape));
      }
      if (defaultValue.shape.length !== 0) {
        throw new Error("Default value must be a scalar, saw:\n        ".concat(defaultValue.shape));
      }
      var $indices = backend.readSync(indices.dataId);
      var $values = backend.readSync(values.dataId);
      var $denseShape = backend.readSync(denseShape.dataId);
      var $defaultValue = backend.readSync(defaultValue.dataId)[0];
      var _a2 = __read(sparseFillEmptyRowsImplCPU($indices, indices.shape, indices.dtype, $values, values.dtype, $denseShape, $defaultValue), 5), outputIndices = _a2[0], outputIndicesShape = _a2[1], outputValues = _a2[2], emptyRowIndicator = _a2[3], reverseIndexMap = _a2[4];
      return [
        backend.makeTensorInfo(outputIndicesShape, indices.dtype, outputIndices),
        backend.makeTensorInfo([outputIndicesShape[0]], values.dtype, outputValues),
        backend.makeTensorInfo([emptyRowIndicator.length], "bool", new Uint8Array(emptyRowIndicator.map(function(value) {
          return Number(value);
        }))),
        backend.makeTensorInfo([reverseIndexMap.length], indices.dtype, new Int32Array(reverseIndexMap))
      ];
    }
    var sparseFillEmptyRowsConfig = {
      kernelName: tf.SparseFillEmptyRows,
      backendName: "webgl",
      kernelFunc: sparseFillEmptyRows
    };
    function sparseReshape(args) {
      var inputs = args.inputs, backend = args.backend;
      var inputIndices = inputs.inputIndices, inputShape = inputs.inputShape, newShape = inputs.newShape;
      if (inputIndices.shape.length !== 2) {
        throw new Error("Input indices should be a matrix but received shape ".concat(inputIndices.shape));
      }
      if (inputShape.shape.length !== 1) {
        throw new Error("Input shape should be a vector but received shape ".concat(inputShape.shape));
      }
      if (newShape.shape.length !== 1) {
        throw new Error("Target shape should be a vector but received shape ".concat(newShape.shape));
      }
      var $inputShape = Array.from(backend.readSync(inputShape.dataId));
      var $inputIndices = backend.readSync(inputIndices.dataId);
      var targetShape = Array.from(backend.readSync(newShape.dataId));
      var _a2 = __read(sparseReshapeImplCPU($inputIndices, inputIndices.shape, inputIndices.dtype, $inputShape, targetShape), 3), newIndices = _a2[0], indicesShape = _a2[1], outputShape = _a2[2];
      return [
        backend.makeTensorInfo(indicesShape, inputIndices.dtype, newIndices),
        backend.makeTensorInfo([outputShape.length], newShape.dtype, new Int32Array(outputShape))
      ];
    }
    var sparseReshapeConfig = {
      kernelName: tf.SparseReshape,
      backendName: "webgl",
      kernelFunc: sparseReshape
    };
    function sparseSegmentMean(args) {
      var inputs = args.inputs, backend = args.backend;
      var data = inputs.data, indices = inputs.indices, segmentIds = inputs.segmentIds;
      if (data.shape.length < 1) {
        throw new Error("Data should be at least 1 dimensional but received scalar");
      }
      if (indices.shape.length !== 1) {
        throw new Error("Indices should be a vector but received shape\n              ".concat(indices.shape));
      }
      if (segmentIds.shape.length !== 1) {
        throw new Error("Segment ids should be a vector but received shape\n              ".concat(segmentIds.shape));
      }
      var $data = backend.readSync(data.dataId);
      var $indices = backend.readSync(indices.dataId);
      var $segmentIds = backend.readSync(segmentIds.dataId);
      var _a2 = __read(sparseSegmentReductionImplCPU($data, data.shape, data.dtype, $indices, $segmentIds, true), 2), outputData = _a2[0], outputDataShape = _a2[1];
      return backend.makeTensorInfo(outputDataShape, data.dtype, outputData);
    }
    var sparseSegmentMeanConfig = {
      kernelName: tf.SparseSegmentMean,
      backendName: "webgl",
      kernelFunc: sparseSegmentMean
    };
    function sparseSegmentSum(args) {
      var inputs = args.inputs, backend = args.backend;
      var data = inputs.data, indices = inputs.indices, segmentIds = inputs.segmentIds;
      if (data.shape.length < 1) {
        throw new Error("Data should be at least 1 dimensional but received scalar");
      }
      if (indices.shape.length !== 1) {
        throw new Error("Indices should be a vector but received shape\n             ".concat(indices.shape));
      }
      if (segmentIds.shape.length !== 1) {
        throw new Error("Segment ids should be a vector but received shape\n             ".concat(segmentIds.shape));
      }
      var $data = backend.readSync(data.dataId);
      var $indices = backend.readSync(indices.dataId);
      var $segmentIds = backend.readSync(segmentIds.dataId);
      var _a2 = __read(sparseSegmentReductionImplCPU($data, data.shape, data.dtype, $indices, $segmentIds), 2), outputData = _a2[0], outputDataShape = _a2[1];
      return backend.makeTensorInfo(outputDataShape, data.dtype, outputData);
    }
    var sparseSegmentSumConfig = {
      kernelName: tf.SparseSegmentSum,
      backendName: "webgl",
      kernelFunc: sparseSegmentSum
    };
    function sparseToDense(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var sparseIndices = inputs.sparseIndices, sparseValues = inputs.sparseValues, defaultValue = inputs.defaultValue;
      var outputShape = attrs.outputShape;
      var _a2 = tf.backend_util.calculateShapes(sparseValues, sparseIndices, outputShape), sliceRank = _a2.sliceRank, numUpdates = _a2.numUpdates, sliceSize = _a2.sliceSize, strides = _a2.strides, outputSize = _a2.outputSize;
      var sumDupeIndices = false;
      if (sparseValues.dtype === "string") {
        var indicesBuf = backend.bufferSync(sparseIndices);
        var updatesBuf = backend.bufferSync(sparseValues);
        var $defaultValue = tf.util.decodeString(backend.readSync(defaultValue.dataId)[0]);
        var outBuf = scatterImplCPU(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
        return backend.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);
      }
      var program = new ScatterProgram(numUpdates, sliceRank, sparseIndices.shape.length, sparseValues.shape.length, strides, [outputSize, 1], sumDupeIndices);
      var res = backend.runWebGLProgram(program, [sparseValues, sparseIndices, defaultValue], sparseValues.dtype);
      var reshaped = reshape({ inputs: { x: res }, backend, attrs: { shape: outputShape } });
      backend.disposeIntermediateTensorInfo(res);
      return reshaped;
    }
    var sparseToDenseConfig = {
      kernelName: tf.SparseToDense,
      backendName: "webgl",
      kernelFunc: sparseToDense
    };
    function splitV(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var numOrSizeSplits = attrs.numOrSizeSplits, axis = attrs.axis;
      var $axis = tf.util.parseAxisParam(axis, x.shape)[0];
      var splitSizes = tf.backend_util.prepareSplitSize(x, numOrSizeSplits, $axis);
      var xRank = x.shape.length;
      var begin = new Array(xRank).fill(0);
      var size = x.shape.slice();
      return splitSizes.map(function(s) {
        var sliceSize = __spreadArray([], __read(size), false);
        sliceSize[$axis] = s;
        var sliceT = slice({ inputs: { x }, backend, attrs: { begin, size: sliceSize } });
        begin[$axis] += s;
        return sliceT;
      });
    }
    var splitVConfig = {
      kernelName: tf.SplitV,
      backendName: "webgl",
      kernelFunc: splitV
    };
    var SQRT = "return sqrt(x);";
    var sqrt = unaryKernelFunc({ opSnippet: SQRT, packedOpSnippet: SQRT, cpuKernelImpl: sqrtImplCPU });
    var sqrtConfig = {
      kernelName: tf.Sqrt,
      backendName: "webgl",
      kernelFunc: sqrt
    };
    var SQUARE = "return x * x;";
    var square = unaryKernelFunc({ opSnippet: SQUARE });
    var squareConfig = {
      kernelName: tf.Square,
      backendName: "webgl",
      kernelFunc: square
    };
    var SQUARED_DIFFERENCE = "return (a - b) * (a - b);";
    var squaredDifference = binaryKernelFunc({ opSnippet: SQUARED_DIFFERENCE, packedOpSnippet: SQUARED_DIFFERENCE });
    var squaredDifferenceConfig = {
      kernelName: tf.SquaredDifference,
      backendName: "webgl",
      kernelFunc: squaredDifference
    };
    function staticRegexReplace(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      if (x.dtype !== "string") {
        throw new Error("Input must be of datatype string");
      }
      var $x = backend.readSync(x.dataId);
      var stringInput = tf.backend_util.fromUint8ToStringArray($x);
      var output = staticRegexReplaceImplCPU(stringInput, "string", attrs);
      return backend.makeTensorInfo(x.shape, "string", output);
    }
    var staticRegexReplaceConfig = {
      kernelName: tf.StaticRegexReplace,
      backendName: "webgl",
      kernelFunc: staticRegexReplace
    };
    function step(_a2) {
      var inputs = _a2.inputs, attrs = _a2.attrs, backend = _a2.backend;
      var x = inputs.x;
      var opSnippet = CHECK_NAN_SNIPPET$1 + "\n    return x > 0.0 ? 1.0 : float(".concat(attrs.alpha, ");\n  ");
      var program = new UnaryOpProgram(x.shape, opSnippet);
      return backend.runWebGLProgram(program, [x], x.dtype);
    }
    var stepConfig = {
      kernelName: tf.Step,
      backendName: "webgl",
      kernelFunc: step
    };
    var StridedSliceProgram = (
      /** @class */
      function() {
        function StridedSliceProgram2(begin, strides, size) {
          this.variableNames = ["x"];
          this.outputShape = size;
          var rank = size.length;
          var inputDtype = getCoordsDataType(size.length);
          var dtype = getCoordsDataType(size.length);
          var newCoords = "";
          if (rank === 1) {
            newCoords = "coords * strides + begin";
          } else {
            var outputAxis_1 = 0;
            newCoords = size.map(function(_, i) {
              outputAxis_1++;
              return size.length === 1 ? "coords * strides[".concat(i, "] + begin[").concat(i, "]") : "coords[".concat(outputAxis_1 - 1, "] * strides[").concat(i, "] + begin[").concat(i, "]");
            }).join(",");
          }
          this.userCode = "\n      ".concat(inputDtype, " begin = ").concat(inputDtype, "(").concat(begin, ");\n      ").concat(inputDtype, " strides = ").concat(inputDtype, "(").concat(strides, ");\n\n      void main() {\n        ").concat(dtype, " coords = getOutputCoords();\n        setOutput(getX(").concat(newCoords, "));\n      }\n    ");
        }
        return StridedSliceProgram2;
      }()
    );
    function stridedSlice(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var begin = attrs.begin, end = attrs.end, strides = attrs.strides, beginMask = attrs.beginMask, endMask = attrs.endMask, ellipsisMask = attrs.ellipsisMask, newAxisMask = attrs.newAxisMask, shrinkAxisMask = attrs.shrinkAxisMask;
      var _a2 = tf.slice_util.sliceInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask), finalShapeSparse = _a2.finalShapeSparse, finalShape = _a2.finalShape, isIdentity = _a2.isIdentity, sliceDim0 = _a2.sliceDim0, isSimpleSlice = _a2.isSimpleSlice, $begin = _a2.begin, $end = _a2.end, $strides = _a2.strides;
      var result;
      if (isIdentity) {
        result = reshape({ inputs: { x }, backend, attrs: { shape: finalShape } });
      } else if (sliceDim0 || isSimpleSlice) {
        tf.util.assert(x.shape.length >= 1, function() {
          return "Input must have rank at least 1, got: ".concat(x.shape.length);
        });
        var size = tf.slice_util.computeOutShape($begin, $end, $strides);
        var sliced = slice({ inputs: { x }, backend, attrs: { begin: $begin, size } });
        result = reshape({ inputs: { x: sliced }, backend, attrs: { shape: finalShape } });
        backend.disposeIntermediateTensorInfo(sliced);
      } else {
        var shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);
        if (shouldExecuteOnCPU) {
          var values = backend.readSync(x.dataId);
          var xBuf = tf.buffer(x.shape, x.dtype, values);
          var resultValues = stridedSliceImplCPU(finalShapeSparse, xBuf, $strides, $begin);
          result = backend.makeTensorInfo(finalShape, x.dtype, resultValues.values);
        } else {
          var program = new StridedSliceProgram($begin, $strides, finalShapeSparse);
          result = backend.runWebGLProgram(program, [x], x.dtype);
        }
      }
      var resultReshaped = reshape({ inputs: { x: result }, backend, attrs: { shape: finalShape } });
      backend.disposeIntermediateTensorInfo(result);
      return resultReshaped;
    }
    var stridedSliceConfig = {
      kernelName: tf.StridedSlice,
      backendName: "webgl",
      kernelFunc: stridedSlice
    };
    function stringNGrams(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var separator = attrs.separator, nGramWidths = attrs.nGramWidths, leftPad = attrs.leftPad, rightPad = attrs.rightPad, padWidth = attrs.padWidth, preserveShortSequences = attrs.preserveShortSequences;
      var data = inputs.data, dataSplits = inputs.dataSplits;
      var $data = backend.readSync(data.dataId);
      var $dataSplits = backend.readSync(dataSplits.dataId);
      var _a2 = __read(stringNGramsImplCPU($data, $dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences), 2), nGrams = _a2[0], nGramsSplits = _a2[1];
      return [
        backend.makeTensorInfo([nGrams.length], "string", nGrams),
        backend.makeTensorInfo(dataSplits.shape, "int32", nGramsSplits)
      ];
    }
    var stringNGramsConfig = {
      kernelName: tf.StringNGrams,
      backendName: "webgl",
      kernelFunc: stringNGrams
    };
    function stringSplit(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var skipEmpty = attrs.skipEmpty;
      var input = inputs.input, delimiter = inputs.delimiter;
      if (input.dtype !== "string") {
        throw new Error("Input must be of datatype string");
      }
      if (input.shape.length !== 1) {
        throw new Error("Input must be a vector, got shape: ".concat(input.shape));
      }
      if (delimiter.shape.length !== 0) {
        throw new Error("Delimiter must be a scalar, got shape: ".concat(delimiter.shape));
      }
      var $input = backend.readSync(input.dataId);
      var $delimiter = backend.readSync(delimiter.dataId)[0];
      var _a2 = __read(stringSplitImplCPU($input, $delimiter, skipEmpty), 3), indices = _a2[0], values = _a2[1], shape = _a2[2];
      var outputSize = values.length;
      return [
        backend.makeTensorInfo([outputSize, 2], "int32", indices),
        backend.makeTensorInfo([outputSize], "string", values),
        backend.makeTensorInfo([2], "int32", new Int32Array(shape))
      ];
    }
    var stringSplitConfig = {
      kernelName: tf.StringSplit,
      backendName: "webgl",
      kernelFunc: stringSplit
    };
    function stringToHashBucketFast(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var numBuckets = attrs.numBuckets;
      var input = inputs.input;
      if (input.dtype !== "string") {
        throw new Error("Input must be of datatype string");
      }
      if (numBuckets <= 0) {
        throw new Error("Number of buckets must be at least 1");
      }
      var $input = backend.readSync(input.dataId);
      var output = stringToHashBucketFastImplCPU($input, numBuckets);
      return backend.makeTensorInfo(input.shape, "int32", output);
    }
    var stringToHashBucketFastConfig = {
      kernelName: tf.StringToHashBucketFast,
      backendName: "webgl",
      kernelFunc: stringToHashBucketFast
    };
    var TAN = "return tan(x);";
    var tan = unaryKernelFunc({ opSnippet: TAN });
    var tanConfig = {
      kernelName: tf.Tan,
      backendName: "webgl",
      kernelFunc: tan
    };
    var TANH = "\n  float e2x = exp(-2.0 * abs(x));\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\n";
    var tanh = unaryKernelFunc({ opSnippet: TANH });
    var tanhConfig = {
      kernelName: tf.Tanh,
      backendName: "webgl",
      kernelFunc: tanh
    };
    function tensorScatterUpdate(args) {
      var inputs = args.inputs, backend = args.backend;
      args.attrs;
      var tensor = inputs.tensor, indices = inputs.indices, updates = inputs.updates;
      var _b = tf.backend_util.calculateShapes(updates, indices, tensor.shape), sliceRank = _b.sliceRank, numUpdates = _b.numUpdates, sliceSize = _b.sliceSize, strides = _b.strides, outputSize = _b.outputSize;
      var flattenShape = [outputSize / sliceSize, sliceSize];
      if (outputSize === 0) {
        return backend.makeTensorInfo(tensor.shape, indices.dtype);
      }
      var flattenIndices = reshape({ inputs: { x: indices }, backend, attrs: { shape: [numUpdates, sliceRank] } });
      var flattenX = reshape({ inputs: { x: updates }, backend, attrs: { shape: [numUpdates, sliceSize] } });
      var flattenTensor = reshape({ inputs: { x: tensor }, backend, attrs: { shape: flattenShape } });
      var program = new ScatterProgram(numUpdates, sliceRank, flattenIndices.shape.length, flattenX.shape.length, strides, flattenShape, false, true);
      var res = backend.runWebGLProgram(program, [flattenX, flattenIndices, flattenTensor], flattenTensor.dtype);
      var reshaped = reshape({ inputs: { x: res }, backend, attrs: { shape: tensor.shape } });
      backend.disposeIntermediateTensorInfo(flattenIndices);
      backend.disposeIntermediateTensorInfo(flattenX);
      backend.disposeIntermediateTensorInfo(flattenTensor);
      backend.disposeIntermediateTensorInfo(res);
      return reshaped;
    }
    var tensorScatterUpdateConfig = {
      kernelName: tf.TensorScatterUpdate,
      backendName: "webgl",
      kernelFunc: tensorScatterUpdate
    };
    var TileProgram = (
      /** @class */
      function() {
        function TileProgram2(aShape, reps) {
          this.variableNames = ["A"];
          var outputShape = new Array(aShape.length);
          for (var i = 0; i < outputShape.length; i++) {
            outputShape[i] = aShape[i] * reps[i];
          }
          this.outputShape = outputShape;
          this.rank = outputShape.length;
          var dtype = getCoordsDataType(this.rank);
          var sourceCoords = getSourceCoords(aShape);
          this.userCode = "\n      void main() {\n        ".concat(dtype, " resRC = getOutputCoords();\n        setOutput(getA(").concat(sourceCoords, "));\n      }\n    ");
        }
        return TileProgram2;
      }()
    );
    function getSourceCoords(aShape) {
      var rank = aShape.length;
      if (rank > 5) {
        throw Error("Tile for rank ".concat(rank, " is not yet supported"));
      }
      if (rank === 1) {
        return "imod(resRC, ".concat(aShape[0], ")");
      }
      var currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u"];
      var sourceCoords = [];
      for (var i = 0; i < aShape.length; i++) {
        sourceCoords.push("imod(".concat(currentCoords[i], ", ").concat(aShape[i], ")"));
      }
      return sourceCoords.join();
    }
    function tile(params) {
      var inputs = params.inputs, backend = params.backend, attrs = params.attrs;
      var x = inputs.x;
      var reps = attrs.reps;
      if (x.dtype === "string" || x.shape.length > 5) {
        var data = backend.readSync(x.dataId);
        var value = x.dtype === "string" ? data.map(function(d) {
          return tf.util.decodeString(d);
        }) : data;
        var buf = tf.buffer(x.shape, x.dtype, value);
        var outBuf = tileImplCPU(buf, reps);
        return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
      }
      var program = new TileProgram(x.shape, reps);
      var output = backend.runWebGLProgram(program, [x], x.dtype);
      return output;
    }
    var tileConfig = {
      kernelName: tf.Tile,
      backendName: "webgl",
      kernelFunc: tile
    };
    var SwapProgram = (
      /** @class */
      function() {
        function SwapProgram2(shape) {
          this.variableNames = ["x", "indices"];
          this.customUniforms = [
            { name: "n", type: "int" },
            { name: "firstPass", type: "int" },
            { name: "negativeInf", type: "float" },
            { name: "dir", type: "int" },
            { name: "inc", type: "int" }
          ];
          this.outputShape = shape;
          this.userCode = "\n       void main() {\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // We compare elements pair-wise within a group of size 2 * inc.\n         // The comparing rule for each group alternates between ascending\n         // and descending. Within each group, we compare each pair at\n         // positions i and i+inc. To decide whether an element at position i\n         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than\n         // inc, it is in the first half of the group, we denote it as x0,\n         // otherwise we denote it as x1.\n         // For example, as shown in the Bitonic top K paper referenced above,\n         // Figure5(a) shows that element[1] is in the\n         // second half of the group when group size is 2, but it is in the\n         // first half of the group when group size is 4.\n\n         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;\n         int i = isFirstInPair ? elemIdx : elemIdx - inc;\n\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));\n         float x0 = i0 < n ? getX(batch, i0) : negativeInf;\n         float x1 = i1 < n ? getX(batch, i1) : negativeInf;\n\n         // Denotes which direction indices are in (ascending or descending).\n         bool reverse = imod(elemIdx, 2 * dir) >= dir;\n         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);\n         if (reverse == isGreater) { // Elements in opposite order of direction\n           int iTemp = i0;\n           i0 = i1;\n           i1 = iTemp;\n         }\n         if (isFirstInPair) {\n            setOutput(float(i0));\n         } else {\n            setOutput(float(i1));\n         }\n       }\n     ";
        }
        return SwapProgram2;
      }()
    );
    var MergeProgram = (
      /** @class */
      function() {
        function MergeProgram2(shape) {
          this.variableNames = ["x", "indices"];
          this.customUniforms = [
            { name: "n", type: "int" },
            { name: "firstPass", type: "int" },
            { name: "k", type: "int" }
          ];
          this.outputShape = shape;
          this.userCode = "\n    void main() {\n         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // The output size is half of the previous size.\n         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),\n         // we only need to output the indices at positions |, the indices at\n         // positions _ can be thrown away, see Figure5(b) After Phase 2\n         // (Merge phase) in the Bitonic Top K paper referenced above.\n         // For example, the paper shows we only need to output the orange bars.\n         // The output sequence should look like this | | | | | | | |.\n         // Because the sequence is halved, to map the output index back\n         // to the previous sequence to find the corresponding value,\n         // we need to double the index. When we double the index,\n         // we basically interpolate a position, so 2i looks like\n         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position\n         // of each 2k positions by - elemIdx % k. E.g. for output at\n         // index 4,5,6,7, we want to get the corresponding element at\n         // original index 8,9,10,11, for output at index 8,9,10,11,\n         // we want to get the corresponding element at original index\n         // 16,17,18,19, so on and so forth.\n\n         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));\n\n         float x0 = getX(batch, i0);\n         float x1 = i1 < n ? getX(batch, i1) : x0;\n\n         setOutput(x0 >= x1 ? float(i0) : float(i1));\n       }\n     ";
        }
        return MergeProgram2;
      }()
    );
    function disposeIntermediateTensorInfoOrNull(backend, tensorInfo) {
      if (tensorInfo !== null) {
        backend.disposeIntermediateTensorInfo(tensorInfo);
      }
    }
    function roundUpToPow2(num) {
      var pow2 = 1;
      while (pow2 < num) {
        pow2 *= 2;
      }
      return pow2;
    }
    function topK(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var k = attrs.k, sorted = attrs.sorted;
      var TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD = tf.env().getNumber("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD");
      var TOPK_K_CPU_HANDOFF_THRESHOLD = tf.env().getNumber("TOPK_K_CPU_HANDOFF_THRESHOLD");
      var xShape = x.shape;
      var lastDim = xShape[xShape.length - 1];
      if (backend.shouldExecuteOnCPU([x]) || lastDim < TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD || k > TOPK_K_CPU_HANDOFF_THRESHOLD) {
        var xVals = backend.readSync(x.dataId);
        var _a2 = __read(topKImplCPU(xVals, xShape, x.dtype, k, sorted), 2), allTopKVals = _a2[0], allTopKIndices = _a2[1];
        return [
          backend.makeTensorInfo(allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),
          backend.makeTensorInfo(allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)
        ];
      }
      if (k === 0) {
        xShape[xShape.length - 1] = 0;
        return [
          backend.makeTensorInfo(xShape, x.dtype, []),
          backend.makeTensorInfo(xShape, "int32", [])
        ];
      }
      if (lastDim === 1) {
        return [
          x,
          fill({ attrs: { shape: xShape, dtype: "int32", value: 0 }, backend })
        ];
      }
      var xtexData = backend.texData.get(x.dataId);
      var xIsPacked = xtexData !== null && xtexData.isPacked;
      var xUnPacked = xIsPacked ? backend.unpackTensor(x) : x;
      var xSize = tf.util.sizeFromShape(xShape);
      var batch = xSize / lastDim;
      var x2D = reshape({ inputs: { x: xUnPacked }, attrs: { shape: [batch, lastDim] }, backend });
      if (xIsPacked) {
        disposeIntermediateTensorInfoOrNull(backend, xUnPacked);
      }
      var kPow2 = roundUpToPow2(k);
      var lastDimPow2 = roundUpToPow2(lastDim);
      var indices = null;
      var getInputs = function() {
        return indices === null ? [x2D, x2D] : [x2D, indices];
      };
      var runSwap = function(dir2, inc2, shape) {
        var inputs2 = getInputs();
        var program = new SwapProgram(shape);
        var fistPass = indices === null ? 1 : 0;
        var customValues2 = [[lastDim], [fistPass], [Number.NEGATIVE_INFINITY], [dir2], [inc2]];
        var prevIndices2 = indices;
        indices = backend.runWebGLProgram(program, inputs2, "int32", customValues2);
        disposeIntermediateTensorInfoOrNull(backend, prevIndices2);
      };
      for (var len = 1; len < kPow2; len *= 2) {
        var dir = len * 2;
        for (var inc = len; inc >= 1; inc /= 2) {
          runSwap(dir, inc, [batch, lastDimPow2]);
        }
      }
      for (var indicesSize = lastDimPow2; indicesSize > kPow2; indicesSize /= 2) {
        var inputs_1 = getInputs();
        var mergeProgram = new MergeProgram([batch, indicesSize / 2]);
        var firstPass = indices === null ? 1 : 0;
        var customValues = [[lastDim], [firstPass], [kPow2]];
        var prevIndices_1 = indices;
        indices = backend.runWebGLProgram(mergeProgram, inputs_1, "int32", customValues);
        disposeIntermediateTensorInfoOrNull(backend, prevIndices_1);
        var len = kPow2 / 2;
        var dir = len * 2;
        for (var inc = len; inc >= 1; inc /= 2) {
          runSwap(dir, inc, indices.shape);
        }
      }
      var prevIndices = indices;
      indices = slice({ inputs: { x: indices }, backend, attrs: { begin: 0, size: [batch, k] } });
      disposeIntermediateTensorInfoOrNull(backend, prevIndices);
      var values = gatherV2({ inputs: { x: x2D, indices }, backend, attrs: { axis: 1, batchDims: 1 } });
      disposeIntermediateTensorInfoOrNull(backend, x2D);
      var newShape = xShape.slice(0, -1);
      newShape.push(k);
      prevIndices = indices;
      indices = reshape({ inputs: { x: indices }, attrs: { shape: newShape }, backend });
      disposeIntermediateTensorInfoOrNull(backend, prevIndices);
      var prevValues = values;
      values = reshape({ inputs: { x: values }, attrs: { shape: newShape }, backend });
      disposeIntermediateTensorInfoOrNull(backend, prevValues);
      return [values, indices];
    }
    var topKConfig = {
      kernelName: tf.TopK,
      backendName: "webgl",
      kernelFunc: topK
    };
    var TransformProgram = (
      /** @class */
      function() {
        function TransformProgram2(imageHeight, imageWidth, interpolation, fillMode, fillValue, outShape) {
          this.variableNames = ["Image", "Transforms"];
          this.outputShape = outShape;
          var interpolationModeId = interpolation === "nearest" ? 1 : 2;
          var fillModeId;
          switch (fillMode) {
            case "constant":
              fillModeId = 1;
              break;
            case "reflect":
              fillModeId = 2;
              break;
            case "wrap":
              fillModeId = 3;
              break;
            case "nearest":
              fillModeId = 4;
              break;
            default:
              fillModeId = 1;
              break;
          }
          this.userCode = "\n            float mapCoord(float outCoord, float len) {\n              float inCoord = outCoord;\n              if(".concat(fillModeId, " == 2) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    if (inCoord < sz2) {\n                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +\n                      inCoord;\n                    }\n                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    inCoord -= sz2 * float(int(float(inCoord / sz2)));\n                    if (inCoord >= len) {\n                      inCoord = sz2 - inCoord - 1.0;\n                    }\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (").concat(fillModeId, " == 3) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord -= len * float(int(float(inCoord / sz)));\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (").concat(fillModeId, " == 4) {\n                return clamp(outCoord, 0.0, len - 1.0);\n              } else {\n                return outCoord;\n              }\n            }\n\n            float readWithFillValue(int batch, int coordY, int coordX,\n              int channel) {\n              float outputValue;\n              if (0 <= coordY && coordY < ").concat(imageHeight, " && 0 <= coordX && coordX < ").concat(imageWidth, ") {\n                  outputValue = getImage(batch, coordY, coordX, channel);\n              } else {\n                outputValue = float(").concat(fillValue, ");\n              }\n              return outputValue;\n            }\n\n            void main() {\n              ivec4 coords = getOutputCoords();\n              float outputValue;\n              int batch = coords[0];\n              int x = coords[2];\n              int y = coords[1];\n              int channel = coords[3];\n              float xf = float(x);\n              float yf = float(y);\n              float a1 = getTransforms(batch, 0);\n              float a2 = getTransforms(batch, 1);\n              float a3 = getTransforms(batch, 2);\n              float b1 = getTransforms(batch, 3);\n              float b2 = getTransforms(batch, 4);\n              float b3 = getTransforms(batch, 5);\n              float c1 = getTransforms(batch, 6);\n              float c2 = getTransforms(batch, 7);\n              float projection = c1 * xf + c2 * yf + 1.0;\n              if (projection == 0.0) {\n                outputValue = float(").concat(fillValue, ");\n              } else {\n                float inX = (a1 * xf + a2 * yf + a3) / projection;\n                float inY = (b1 * xf + b2 * yf + b3) / projection;\n                float mapX = mapCoord(inX, float(").concat(imageWidth, "));\n                float mapY = mapCoord(inY, float(").concat(imageHeight, "));\n\n                if (").concat(interpolationModeId, " == 1) {\n                  int coordY = int(round(mapY));\n                  int coordX = int(round(mapX));\n                  outputValue = readWithFillValue(batch, coordY, coordX,\n                    channel);\n                } else {\n                  float yFloor = floor(mapY);\n                  float xFloor = floor(mapX);\n                  float yCeil = yFloor + 1.0;\n                  float xCeil = xFloor + 1.0;\n                  float valueYFloor = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);\n                  float valueYCeil = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);\n                  outputValue = (yCeil - mapY) * valueYFloor +\n                  (mapY - yFloor) * valueYCeil;\n                }\n              }\n              setOutput(outputValue);\n            }\n        ");
        }
        return TransformProgram2;
      }()
    );
    function transform(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var image = inputs.image, transforms = inputs.transforms;
      var interpolation = attrs.interpolation, fillMode = attrs.fillMode, fillValue = attrs.fillValue, outputShape = attrs.outputShape;
      var _a2 = __read(image.shape, 4), batch = _a2[0], imageHeight = _a2[1], imageWidth = _a2[2], numChannels = _a2[3];
      var _b = __read(outputShape != null ? outputShape : [imageHeight, imageWidth], 2), outHeight = _b[0], outWidth = _b[1];
      var outShape = [
        batch,
        outHeight,
        outWidth,
        numChannels
      ];
      var program = new TransformProgram(imageHeight, imageWidth, interpolation, fillMode, fillValue, outShape);
      return backend.runWebGLProgram(program, [image, transforms], "float32");
    }
    var transformConfig = {
      kernelName: tf.Transform,
      backendName: "webgl",
      kernelFunc: transform
    };
    function unique(args) {
      var inputs = args.inputs, attrs = args.attrs, backend = args.backend;
      var axis = attrs.axis;
      var x = inputs.x;
      assertNotComplex(x, "unique");
      console.warn("WARNING: ", "UI might be locked temporarily as data is being downloaded");
      var values = backend.readSync(x.dataId);
      var _a2 = uniqueImplCPU(values, axis, x.shape, x.dtype), outputValues = _a2.outputValues, outputShape = _a2.outputShape, indices = _a2.indices;
      return [
        backend.makeTensorInfo(outputShape, x.dtype, outputValues),
        backend.makeTensorInfo([indices.length], "int32", indices)
      ];
    }
    var uniqueConfig = {
      kernelName: tf.Unique,
      backendName: "webgl",
      kernelFunc: unique
    };
    function unpack(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var value = inputs.value;
      var axis = attrs.axis;
      if (axis < 0) {
        axis += value.shape.length;
      }
      var x = value;
      var xRank = x.shape.length;
      var num = value.shape[axis];
      var outShape = new Array(xRank - 1);
      var outIndex = 0;
      for (var i = 0; i < xRank; i++) {
        if (i !== axis) {
          outShape[outIndex++] = x.shape[i];
        }
      }
      var toDispose = [];
      var begin = new Array(xRank).fill(0);
      var size = x.shape.slice();
      size[axis] = 1;
      var res = new Array(num);
      for (var i = 0; i < res.length; i++) {
        begin[axis] = i;
        var sliced = slice({ inputs: { x }, backend, attrs: { begin, size } });
        var reshaped = reshape({ inputs: { x: sliced }, backend, attrs: { shape: outShape } });
        res[i] = reshaped;
        toDispose.push(sliced);
      }
      toDispose.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return res;
    }
    var unpackConfig = {
      kernelName: tf.Unpack,
      backendName: "webgl",
      kernelFunc: unpack
    };
    var SegmentOpProgram = (
      /** @class */
      function() {
        function SegmentOpProgram2(segOpInfo, segOpType) {
          this.variableNames = ["x", "segmentIds"];
          var windowSize = segOpInfo.windowSize;
          var batchSize = segOpInfo.batchSize;
          var inSize = segOpInfo.inSize;
          var numSegments = segOpInfo.numSegments;
          var outSize = numSegments * Math.ceil(inSize / windowSize);
          this.outputShape = [batchSize, outSize];
          var initializationValue = "0.0";
          var returnValue = "sumValue";
          var windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;
          var windowSizeVec4Remainder = windowSize % 4;
          var updateSnippet = "\n        sumValue += dot(values, segFilter);\n    ";
          var checkValueOutOfBounds = "";
          if (inSize % windowSize > 0) {
            checkValueOutOfBounds = "\n        if (inIdx < 0 || inIdx >= ".concat(inSize, ") {\n          return initializationValue;\n        }\n      ");
          }
          var checkSegmentIdOutOfBounds = "";
          if (inSize % windowSize > 0) {
            checkSegmentIdOutOfBounds = "\n        if (inIdx < 0 || inIdx >= ".concat(inSize, ") {\n          return -1.0;\n        }\n      ");
          }
          this.userCode = "\n      const float initializationValue = ".concat(initializationValue, ";\n\n      float getValue(int batch, int inIdx) {\n        ").concat(checkValueOutOfBounds, "\n        return getX(batch, inIdx);\n      }\n\n      float getSegmentIdAtIndex(int inIdx) {\n        ").concat(checkSegmentIdOutOfBounds, "\n        return getSegmentIds(inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = int(floor(float(outIdx) / float(\n          ").concat(numSegments, ")) * float(").concat(windowSize, "));\n        int currentSeg = int(mod(float(outIdx), float(").concat(numSegments, ")));\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ").concat(windowSizeNearestVec4, "; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\n          );\n\n          ").concat(updateSnippet, "\n        }\n\n        int inIdx = inOffset + ").concat(windowSizeNearestVec4, ";\n        if (").concat(windowSizeVec4Remainder === 1, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            0,\n            0,\n            0\n          );\n\n          ").concat(updateSnippet, "\n        } else if (").concat(windowSizeVec4Remainder === 2, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n              0,\n              0\n          );\n\n          ").concat(updateSnippet, "\n        } else if (").concat(windowSizeVec4Remainder === 3, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            0\n          );\n\n          ").concat(updateSnippet, "\n        }\n        setOutput(").concat(returnValue, ");\n      }\n    ");
        }
        return SegmentOpProgram2;
      }()
    );
    function unsortedSegmentSum(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, segmentIds = inputs.segmentIds;
      var numSegments = attrs.numSegments;
      var xRank = x.shape.length;
      var toDispose = [];
      var axis = 0;
      var permutation = tf.backend_util.getAxesPermutation([axis], xRank);
      var permutedX = x;
      if (permutation != null) {
        permutedX = transpose({ inputs: { x }, backend, attrs: { perm: permutation } });
        toDispose.push(permutedX);
        axis = tf.backend_util.getInnerMostAxes(1, xRank)[0];
      }
      var outShape = tf.backend_util.segment_util.computeOutShape(permutedX.shape, axis, numSegments);
      var inSize = tf.util.sizeFromShape([permutedX.shape[axis]]);
      var a2D = reshape({ inputs: { x: permutedX }, backend, attrs: { shape: [-1, inSize] } });
      toDispose.push(a2D);
      var outputDType = tf.sumOutType(x.dtype);
      var segOpCompute = function(x2, segOpType, segmentIds2, dtype, numSegments2) {
        var batchSize = x2.shape[0];
        var inSize2 = x2.shape[1];
        var windowSize = tf.backend_util.segment_util.segOpComputeOptimalWindowSize(inSize2, numSegments2);
        var segOpInfo = { windowSize, inSize: inSize2, batchSize, numSegments: numSegments2 };
        var program = new SegmentOpProgram(segOpInfo, segOpType);
        var output = backend.compileAndRun(program, [x2, segmentIds2], dtype);
        toDispose.push(output);
        if (output.shape[1] === numSegments2) {
          return output;
        }
        var rangeInfo = range({
          backend,
          attrs: { start: 0, stop: numSegments2, step: 1, dtype: "float32" }
        });
        var tileInfo = tile({
          inputs: { x: rangeInfo },
          backend,
          attrs: { reps: [inSize2 / windowSize] }
        });
        toDispose.push(rangeInfo);
        toDispose.push(tileInfo);
        var result2 = segOpCompute(output, segOpType, tileInfo, dtype, numSegments2);
        return result2;
      };
      var segOpResult = segOpCompute(a2D, "unsortedSegmentSum", segmentIds, outputDType, numSegments);
      var reshaped = reshape({ inputs: { x: segOpResult }, backend, attrs: { shape: outShape } });
      var result = reshaped;
      if (permutation != null) {
        toDispose.push(reshaped);
        var perm = tf.backend_util.getUndoAxesPermutation(permutation);
        result = transpose({ inputs: { x: result }, backend, attrs: { perm } });
      }
      toDispose.forEach(function(t) {
        return backend.disposeIntermediateTensorInfo(t);
      });
      return result;
    }
    var unsortedSegmentSumConfig = {
      kernelName: tf.UnsortedSegmentSum,
      backendName: "webgl",
      kernelFunc: unsortedSegmentSum
    };
    var e_1;
    var _a;
    var kernelConfigs = [
      _fusedMatMulConfig,
      absConfig,
      acosConfig,
      acoshConfig,
      addConfig,
      addNConfig,
      allConfig,
      anyConfig,
      argMaxConfig,
      argMinConfig,
      asinConfig,
      asinhConfig,
      atanConfig,
      atan2Config,
      atanhConfig,
      avgPoolConfig,
      avgPool3DConfig,
      avgPool3DGradConfig,
      avgPoolGradConfig,
      batchMatMulConfig,
      batchNormConfig,
      batchToSpaceNDConfig,
      bincountConfig,
      bitwiseAndConfig,
      broadcastArgsConfig,
      castConfig,
      ceilConfig,
      clipByValueConfig,
      complexConfig,
      complexAbsConfig,
      concatConfig,
      conv2DConfig,
      conv2DBackpropFilterConfig,
      conv2DBackpropInputConfig,
      conv3DConfig,
      conv3DBackpropFilterV2Config,
      conv3DBackpropInputConfig,
      cosConfig,
      coshConfig,
      cropAndResizeConfig,
      cumprodConfig,
      cumsumConfig,
      denseBincountConfig,
      depthToSpaceConfig,
      depthwiseConv2dNativeConfig,
      depthwiseConv2dNativeBackpropFilterConfig,
      depthwiseConv2dNativeBackpropInputConfig,
      diagConfig,
      dilation2DConfig,
      einsumConfig,
      eluConfig,
      eluGradConfig,
      equalConfig,
      erfConfig,
      expConfig,
      expandDimsConfig,
      expm1Config,
      fftConfig,
      fillConfig,
      flipLeftRightConfig,
      floorConfig,
      floorDivConfig,
      fromPixelsConfig,
      fusedConv2DConfig,
      fusedDepthwiseConv2DConfig,
      gatherNdConfig,
      gatherV2Config,
      greaterConfig,
      greaterEqualConfig,
      identityConfig,
      ifftConfig,
      imagConfig,
      isFiniteConfig,
      isInfConfig,
      isNaNConfig,
      leakyReluConfig,
      lessConfig,
      lessEqualConfig,
      linSpaceConfig,
      logConfig,
      log1pConfig,
      logicalAndConfig,
      logicalNotConfig,
      logicalOrConfig,
      LRNConfig,
      LRNGradConfig,
      maxConfig,
      maximumConfig,
      maxPoolConfig,
      maxPool3DConfig,
      maxPool3DGradConfig,
      maxPoolGradConfig,
      maxPoolWithArgmaxConfig,
      meanConfig,
      minConfig,
      minimumConfig,
      mirrorPadConfig,
      modConfig,
      multinomialConfig,
      multiplyConfig,
      negConfig,
      nonMaxSuppressionV3Config,
      nonMaxSuppressionV4Config,
      nonMaxSuppressionV5Config,
      notEqualConfig,
      oneHotConfig,
      onesLikeConfig,
      packConfig,
      padV2Config,
      powConfig,
      preluConfig,
      prodConfig,
      raggedGatherConfig,
      raggedRangeConfig,
      raggedTensorToTensorConfig,
      rangeConfig,
      realConfig,
      realDivConfig,
      reciprocalConfig,
      reluConfig,
      relu6Config,
      reshapeConfig,
      resizeBilinearConfig,
      resizeBilinearGradConfig,
      resizeNearestNeighborConfig,
      resizeNearestNeighborGradConfig,
      reverseConfig,
      rotateWithOffsetConfig,
      roundConfig,
      rsqrtConfig,
      scatterNdConfig,
      searchSortedConfig,
      selectConfig,
      seluConfig,
      sigmoidConfig,
      signConfig,
      sinConfig,
      sinhConfig,
      sliceConfig,
      softmaxConfig,
      softplusConfig,
      spaceToBatchNDConfig,
      sparseFillEmptyRowsConfig,
      sparseReshapeConfig,
      sparseSegmentMeanConfig,
      sparseSegmentSumConfig,
      sparseToDenseConfig,
      splitVConfig,
      sqrtConfig,
      squareConfig,
      squaredDifferenceConfig,
      staticRegexReplaceConfig,
      stepConfig,
      stridedSliceConfig,
      stringNGramsConfig,
      stringSplitConfig,
      stringToHashBucketFastConfig,
      subConfig,
      sumConfig,
      tanConfig,
      tanhConfig,
      tensorScatterUpdateConfig,
      tileConfig,
      topKConfig,
      transformConfig,
      transposeConfig,
      uniqueConfig,
      unpackConfig,
      unsortedSegmentSumConfig,
      zerosLikeConfig
    ];
    try {
      for (kernelConfigs_1 = __values(kernelConfigs), kernelConfigs_1_1 = kernelConfigs_1.next(); !kernelConfigs_1_1.done; kernelConfigs_1_1 = kernelConfigs_1.next()) {
        kernelConfig = kernelConfigs_1_1.value;
        tf.registerKernel(kernelConfig);
      }
    } catch (e_1_1) {
      e_1 = { error: e_1_1 };
    } finally {
      try {
        if (kernelConfigs_1_1 && !kernelConfigs_1_1.done && (_a = kernelConfigs_1.return))
          _a.call(kernelConfigs_1);
      } finally {
        if (e_1)
          throw e_1.error;
      }
    }
    var kernelConfig;
    var kernelConfigs_1;
    var kernelConfigs_1_1;
    exports.GPGPUContext = GPGPUContext;
    exports.MathBackendWebGL = MathBackendWebGL;
    exports.forceHalfFloat = forceHalfFloat;
    exports.gpgpu_util = gpgpu_util;
    exports.setWebGLContext = setWebGLContext;
    exports.version_webgl = version;
    exports.webgl = webgl;
    exports.webgl_util = webgl_util;
  }
});

// node_modules/@tensorflow/tfjs-converter/dist/tf-converter.node.js
var require_tf_converter_node = __commonJS({
  "node_modules/@tensorflow/tfjs-converter/dist/tf-converter.node.js"(exports) {
    "use strict";
    var tfc = require_tf_core_node();
    function _interopNamespaceDefault(e) {
      var n = /* @__PURE__ */ Object.create(null);
      if (e) {
        Object.keys(e).forEach(function(k) {
          if (k !== "default") {
            var d = Object.getOwnPropertyDescriptor(e, k);
            Object.defineProperty(n, k, d.get ? d : {
              enumerable: true,
              get: function() {
                return e[k];
              }
            });
          }
        });
      }
      n.default = e;
      return n;
    }
    function _mergeNamespaces(n, m) {
      m.forEach(function(e) {
        e && typeof e !== "string" && !Array.isArray(e) && Object.keys(e).forEach(function(k) {
          if (k !== "default" && !(k in n)) {
            var d = Object.getOwnPropertyDescriptor(e, k);
            Object.defineProperty(n, k, d.get ? d : {
              enumerable: true,
              get: function() {
                return e[k];
              }
            });
          }
        });
      });
      return n;
    }
    var tfc__namespace = /* @__PURE__ */ _interopNamespaceDefault(tfc);
    var ENV$1 = tfc.env();
    ENV$1.registerFlag("KEEP_INTERMEDIATE_TENSORS", function() {
      return false;
    }, function(debugValue) {
      if (debugValue) {
        console.warn("Keep intermediate tensors is ON. This will print the values of all intermediate tensors during model inference. Not all models support this mode. For details, check e2e/benchmarks/ model_config.js. This significantly impacts performance.");
      }
    });
    var extendStatics = function(d, b) {
      extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(d2, b2) {
        d2.__proto__ = b2;
      } || function(d2, b2) {
        for (var p in b2)
          if (Object.prototype.hasOwnProperty.call(b2, p))
            d2[p] = b2[p];
      };
      return extendStatics(d, b);
    };
    function __extends(d, b) {
      if (typeof b !== "function" && b !== null)
        throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
      extendStatics(d, b);
      function __() {
        this.constructor = d;
      }
      d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    }
    function __awaiter(thisArg, _arguments, P, generator) {
      function adopt(value) {
        return value instanceof P ? value : new P(function(resolve) {
          resolve(value);
        });
      }
      return new (P || (P = Promise))(function(resolve, reject) {
        function fulfilled(value) {
          try {
            step2(generator.next(value));
          } catch (e) {
            reject(e);
          }
        }
        function rejected(value) {
          try {
            step2(generator["throw"](value));
          } catch (e) {
            reject(e);
          }
        }
        function step2(result) {
          result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step2((generator = generator.apply(thisArg, _arguments || [])).next());
      });
    }
    function __generator(thisArg, body) {
      var _ = { label: 0, sent: function() {
        if (t[0] & 1)
          throw t[1];
        return t[1];
      }, trys: [], ops: [] }, f, y, t, g;
      return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
      }), g;
      function verb(n) {
        return function(v) {
          return step2([n, v]);
        };
      }
      function step2(op2) {
        if (f)
          throw new TypeError("Generator is already executing.");
        while (_)
          try {
            if (f = 1, y && (t = op2[0] & 2 ? y["return"] : op2[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op2[1])).done)
              return t;
            if (y = 0, t)
              op2 = [op2[0] & 2, t.value];
            switch (op2[0]) {
              case 0:
              case 1:
                t = op2;
                break;
              case 4:
                _.label++;
                return { value: op2[1], done: false };
              case 5:
                _.label++;
                y = op2[1];
                op2 = [0];
                continue;
              case 7:
                op2 = _.ops.pop();
                _.trys.pop();
                continue;
              default:
                if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op2[0] === 6 || op2[0] === 2)) {
                  _ = 0;
                  continue;
                }
                if (op2[0] === 3 && (!t || op2[1] > t[0] && op2[1] < t[3])) {
                  _.label = op2[1];
                  break;
                }
                if (op2[0] === 6 && _.label < t[1]) {
                  _.label = t[1];
                  t = op2;
                  break;
                }
                if (t && _.label < t[2]) {
                  _.label = t[2];
                  _.ops.push(op2);
                  break;
                }
                if (t[2])
                  _.ops.pop();
                _.trys.pop();
                continue;
            }
            op2 = body.call(thisArg, _);
          } catch (e) {
            op2 = [6, e];
            y = 0;
          } finally {
            f = t = 0;
          }
        if (op2[0] & 5)
          throw op2[1];
        return { value: op2[0] ? op2[1] : void 0, done: true };
      }
    }
    function __values(o) {
      var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
      if (m)
        return m.call(o);
      if (o && typeof o.length === "number")
        return {
          next: function() {
            if (o && i >= o.length)
              o = void 0;
            return { value: o && o[i++], done: !o };
          }
        };
      throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
    }
    function __read(o, n) {
      var m = typeof Symbol === "function" && o[Symbol.iterator];
      if (!m)
        return o;
      var i = m.call(o), r, ar = [], e;
      try {
        while ((n === void 0 || n-- > 0) && !(r = i.next()).done)
          ar.push(r.value);
      } catch (error) {
        e = { error };
      } finally {
        try {
          if (r && !r.done && (m = i["return"]))
            m.call(i);
        } finally {
          if (e)
            throw e.error;
        }
      }
      return ar;
    }
    function __spreadArray(to, from, pack) {
      if (pack || arguments.length === 2)
        for (var i = 0, l = from.length, ar; i < l; i++) {
          if (ar || !(i in from)) {
            if (!ar)
              ar = Array.prototype.slice.call(from, 0, i);
            ar[i] = from[i];
          }
        }
      return to.concat(ar || Array.prototype.slice.call(from));
    }
    var DataType;
    (function(DataType2) {
      DataType2[DataType2["DT_INVALID"] = 0] = "DT_INVALID";
      DataType2[DataType2["DT_FLOAT"] = 1] = "DT_FLOAT";
      DataType2[DataType2["DT_DOUBLE"] = 2] = "DT_DOUBLE";
      DataType2[DataType2["DT_INT32"] = 3] = "DT_INT32";
      DataType2[DataType2["DT_UINT8"] = 4] = "DT_UINT8";
      DataType2[DataType2["DT_INT16"] = 5] = "DT_INT16";
      DataType2[DataType2["DT_INT8"] = 6] = "DT_INT8";
      DataType2[DataType2["DT_STRING"] = 7] = "DT_STRING";
      DataType2[DataType2["DT_COMPLEX64"] = 8] = "DT_COMPLEX64";
      DataType2[DataType2["DT_INT64"] = 9] = "DT_INT64";
      DataType2[DataType2["DT_BOOL"] = 10] = "DT_BOOL";
      DataType2[DataType2["DT_QINT8"] = 11] = "DT_QINT8";
      DataType2[DataType2["DT_QUINT8"] = 12] = "DT_QUINT8";
      DataType2[DataType2["DT_QINT32"] = 13] = "DT_QINT32";
      DataType2[DataType2["DT_BFLOAT16"] = 14] = "DT_BFLOAT16";
      DataType2[DataType2["DT_QINT16"] = 15] = "DT_QINT16";
      DataType2[DataType2["DT_QUINT16"] = 16] = "DT_QUINT16";
      DataType2[DataType2["DT_UINT16"] = 17] = "DT_UINT16";
      DataType2[DataType2["DT_COMPLEX128"] = 18] = "DT_COMPLEX128";
      DataType2[DataType2["DT_HALF"] = 19] = "DT_HALF";
      DataType2[DataType2["DT_RESOURCE"] = 20] = "DT_RESOURCE";
      DataType2[DataType2["DT_VARIANT"] = 21] = "DT_VARIANT";
      DataType2[DataType2["DT_UINT32"] = 22] = "DT_UINT32";
      DataType2[DataType2["DT_UINT64"] = 23] = "DT_UINT64";
      DataType2[DataType2["DT_FLOAT_REF"] = 101] = "DT_FLOAT_REF";
      DataType2[DataType2["DT_DOUBLE_REF"] = 102] = "DT_DOUBLE_REF";
      DataType2[DataType2["DT_INT32_REF"] = 103] = "DT_INT32_REF";
      DataType2[DataType2["DT_UINT8_REF"] = 104] = "DT_UINT8_REF";
      DataType2[DataType2["DT_INT16_REF"] = 105] = "DT_INT16_REF";
      DataType2[DataType2["DT_INT8_REF"] = 106] = "DT_INT8_REF";
      DataType2[DataType2["DT_STRING_REF"] = 107] = "DT_STRING_REF";
      DataType2[DataType2["DT_COMPLEX64_REF"] = 108] = "DT_COMPLEX64_REF";
      DataType2[DataType2["DT_INT64_REF"] = 109] = "DT_INT64_REF";
      DataType2[DataType2["DT_BOOL_REF"] = 110] = "DT_BOOL_REF";
      DataType2[DataType2["DT_QINT8_REF"] = 111] = "DT_QINT8_REF";
      DataType2[DataType2["DT_QUINT8_REF"] = 112] = "DT_QUINT8_REF";
      DataType2[DataType2["DT_QINT32_REF"] = 113] = "DT_QINT32_REF";
      DataType2[DataType2["DT_BFLOAT16_REF"] = 114] = "DT_BFLOAT16_REF";
      DataType2[DataType2["DT_QINT16_REF"] = 115] = "DT_QINT16_REF";
      DataType2[DataType2["DT_QUINT16_REF"] = 116] = "DT_QUINT16_REF";
      DataType2[DataType2["DT_UINT16_REF"] = 117] = "DT_UINT16_REF";
      DataType2[DataType2["DT_COMPLEX128_REF"] = 118] = "DT_COMPLEX128_REF";
      DataType2[DataType2["DT_HALF_REF"] = 119] = "DT_HALF_REF";
      DataType2[DataType2["DT_RESOURCE_REF"] = 120] = "DT_RESOURCE_REF";
      DataType2[DataType2["DT_VARIANT_REF"] = 121] = "DT_VARIANT_REF";
      DataType2[DataType2["DT_UINT32_REF"] = 122] = "DT_UINT32_REF";
      DataType2[DataType2["DT_UINT64_REF"] = 123] = "DT_UINT64_REF";
    })(DataType || (DataType = {}));
    var SaverDef;
    (function(SaverDef2) {
      (function(CheckpointFormatVersion) {
        CheckpointFormatVersion[CheckpointFormatVersion["LEGACY"] = 0] = "LEGACY";
        CheckpointFormatVersion[CheckpointFormatVersion["V1"] = 1] = "V1";
        CheckpointFormatVersion[CheckpointFormatVersion["V2"] = 2] = "V2";
      })(SaverDef2.CheckpointFormatVersion || (SaverDef2.CheckpointFormatVersion = {}));
    })(SaverDef || (SaverDef = {}));
    var CUSTOM_OPS = {};
    function registerOp(name, opFunc) {
      var opMapper = {
        tfOpName: name,
        category: "custom",
        inputs: [],
        attrs: [],
        customExecutor: opFunc
      };
      CUSTOM_OPS[name] = opMapper;
    }
    function getRegisteredOp(name) {
      return CUSTOM_OPS[name];
    }
    function deregisterOp(name) {
      delete CUSTOM_OPS[name];
    }
    function getParamValue(paramName, node, tensorMap, context, resourceManager) {
      var inputParam = node.inputParams[paramName];
      if (inputParam && inputParam.inputIndexStart !== void 0) {
        var start = inputParam.inputIndexStart;
        var end = inputParam.inputIndexEnd === 0 ? void 0 : inputParam.inputIndexEnd === void 0 ? start + 1 : inputParam.inputIndexEnd;
        var shiftedStart = start < 0 ? node.inputNames.length + start : start;
        if (inputParam.type === "tensor") {
          return getTensor(node.inputNames[shiftedStart], tensorMap, context, resourceManager);
        }
        if (inputParam.type === "tensors") {
          var inputs_1 = node.inputs.slice(start, end);
          var inputNames = node.inputNames.slice(start, end).filter(function(_name, index) {
            var _a;
            return ((_a = inputs_1[index]) === null || _a === void 0 ? void 0 : _a.op) !== "NoOp";
          });
          return inputNames.map(function(name) {
            return getTensor(name, tensorMap, context, resourceManager);
          });
        }
        var tensor2 = getTensor(node.inputNames[shiftedStart], tensorMap, context, resourceManager);
        var data = tensor2.dataSync();
        return inputParam.type === "number" ? data[0] : tfc.util.toNestedArray(tensor2.shape, data);
      }
      var attrParam = node.attrParams[paramName];
      return attrParam && attrParam.value;
    }
    function getTensor(name, tensorsMap, context, resourceManager) {
      var _b = __read(parseNodeName(name, context), 2), nodeName = _b[0], index = _b[1];
      if (resourceManager != null) {
        var tensor2 = resourceManager.getHashTableHandleByName(nodeName);
        if (tensor2 != null) {
          return tensor2;
        }
      }
      var contextId = context.currentContextIds.find(function(contextId2) {
        return !!tensorsMap[getNodeNameWithContextId(nodeName, contextId2)];
      });
      return contextId !== void 0 ? tensorsMap[getNodeNameWithContextId(nodeName, contextId)][index] : void 0;
    }
    function getTensorsForCurrentContext(name, tensorsMap, context) {
      return tensorsMap[getNodeNameWithContextId(name, context.currentContextId)];
    }
    function getNodeNameAndIndex(inputName, context) {
      var _b = __read(parseNodeName(inputName, context), 3), nodeName = _b[0], index = _b[1], outputName = _b[2];
      return [
        getNodeNameWithContextId(nodeName, context && context.currentContextId),
        index,
        outputName
      ];
    }
    function getNodeNameWithContextId(name, contextId) {
      return !!contextId ? "".concat(name, "-").concat(contextId) : name;
    }
    function parseNodeName(name, context) {
      if (name === "") {
        return ["", 0, void 0];
      }
      var isCacheEnabled = context != null && context.parseNodeNameCache != null;
      if (isCacheEnabled) {
        var cachedResult = context.parseNodeNameCache.get(name);
        if (cachedResult != null) {
          return cachedResult;
        }
      }
      var parts = name.split(":");
      var result;
      if (parts.length === 1) {
        result = [name, 0, void 0];
      } else {
        var nodeName = parts[0];
        var outputName = parts.length === 3 ? parts[1] : void 0;
        var index = Number(parts[parts.length - 1]);
        result = [nodeName, index, outputName];
      }
      if (isCacheEnabled) {
        context.parseNodeNameCache.set(name, result);
      }
      return result;
    }
    function getPadding(node, tensorMap, context) {
      var pad2 = getParamValue("pad", node, tensorMap, context);
      if (pad2 === "explicit") {
        pad2 = getParamValue("explicitPaddings", node, tensorMap, context);
        var explicitPadding = [[0, 0], [0, 0], [0, 0], [0, 0]];
        for (var i = 0; i < 4; i++) {
          explicitPadding[i][0] = pad2[i * 2];
          explicitPadding[i][1] = pad2[i * 2 + 1];
        }
        return explicitPadding;
      }
      return pad2;
    }
    function cloneTensor(tensor2) {
      return tensor2.kept ? tensor2 : tfc.clone(tensor2);
    }
    var json$i = [
      {
        "tfOpName": "Add",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "AddV2",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "AddN",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "tensors",
            "type": "tensors"
          }
        ]
      },
      {
        "tfOpName": "BiasAdd",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Sub",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "RealDiv",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Div",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "DivNoNan",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "FloorDiv",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Mul",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Maximum",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Minimum",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Pow",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "SquaredDifference",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Mod",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "FloorMod",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      }
    ];
    var arithmetic = {
      __proto__: null,
      json: json$i
    };
    var json$h = [
      {
        "tfOpName": "Abs",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Acos",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Asin",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Atan",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Atan2",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "y",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Ceil",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "ClipByValue",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "clipValueMin",
            "type": "number"
          },
          {
            "start": 2,
            "name": "clipValueMax",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Complex",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "real",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "imag",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "ComplexAbs",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Cos",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Cosh",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Elu",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Exp",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Floor",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Log",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Imag",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "Tout",
            "name": "outputType",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Neg",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Real",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "Tout",
            "name": "outputType",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Prelu",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "alpha",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Relu",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Relu6",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Selu",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Sigmoid",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Sin",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Sinh",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Sqrt",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Rsqrt",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Square",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Tan",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Tanh",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Sign",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Round",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Expm1",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Log1p",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Reciprocal",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Softplus",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Asinh",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Acosh",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Atanh",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Erf",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LeakyRelu",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "alpha",
            "name": "alpha",
            "type": "number",
            "defaultValue": 0.2
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "IsNan",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "IsFinite",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "IsInf",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      }
    ];
    var basicMath = {
      __proto__: null,
      json: json$h
    };
    var json$g = [
      {
        "tfOpName": "EmptyTensorList",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "elementShape",
            "type": "shape"
          },
          {
            "start": 1,
            "name": "maxNumElements",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "LoopCond",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "pred",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "Switch",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "data",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "pred",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "Merge",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "tensors",
            "type": "tensors"
          }
        ]
      },
      {
        "tfOpName": "Enter",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "frame_name",
            "name": "frameName",
            "type": "string"
          },
          {
            "tfName": "is_constant",
            "name": "isConstant",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "Exit",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "NextIteration",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "TensorArrayV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "size",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          },
          {
            "tfName": "element_shape",
            "name": "elementShape",
            "type": "shape"
          },
          {
            "tfName": "dynamic_size",
            "name": "dynamicSize",
            "type": "bool"
          },
          {
            "tfName": "clear_after_read",
            "name": "clearAfterRead",
            "type": "bool"
          },
          {
            "tfName": "identical_element_shapes",
            "name": "identicalElementShapes",
            "type": "bool"
          },
          {
            "tfName": "tensor_array_name",
            "name": "name",
            "type": "string"
          }
        ]
      },
      {
        "tfOpName": "TensorArrayWriteV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "index",
            "type": "number"
          },
          {
            "start": 2,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "flowIn",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "TensorArrayReadV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "index",
            "type": "number"
          },
          {
            "start": 2,
            "name": "flowIn",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "TensorArrayGatherV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "flowIn",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          },
          {
            "tfName": "element_shape",
            "name": "elementShape",
            "type": "shape"
          }
        ]
      },
      {
        "tfOpName": "TensorArrayScatterV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "flowIn",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorArrayConcatV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "flowIn",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          },
          {
            "tfName": "element_shape_except0",
            "name": "elementShapeExcept0",
            "type": "shape",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "TensorArraySplitV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "lengths",
            "type": "number[]"
          },
          {
            "start": 3,
            "name": "flowIn",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorArraySizeV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "flowIn",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "TensorArrayCloseV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "StatelessIf",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "cond",
            "type": "tensor"
          },
          {
            "start": 1,
            "end": 0,
            "name": "args",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "then_branch",
            "name": "thenBranch",
            "type": "func"
          },
          {
            "tfName": "else_branch",
            "name": "elseBranch",
            "type": "func"
          }
        ]
      },
      {
        "tfOpName": "If",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "cond",
            "type": "tensor"
          },
          {
            "start": 1,
            "end": 0,
            "name": "args",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "then_branch",
            "name": "thenBranch",
            "type": "func"
          },
          {
            "tfName": "else_branch",
            "name": "elseBranch",
            "type": "func"
          }
        ]
      },
      {
        "tfOpName": "StatelessWhile",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "args",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "cond",
            "name": "cond",
            "type": "func"
          },
          {
            "tfName": "body",
            "name": "body",
            "type": "func"
          }
        ]
      },
      {
        "tfOpName": "While",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "args",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "cond",
            "name": "cond",
            "type": "func"
          },
          {
            "tfName": "body",
            "name": "body",
            "type": "func"
          }
        ]
      },
      {
        "tfOpName": "TensorListScatter",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "elementShape",
            "type": "shape"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListScatterV2",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "elementShape",
            "type": "shape"
          },
          {
            "start": 3,
            "name": "numElements",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListGather",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "elementShape",
            "type": "shape"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListGetItem",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "index",
            "type": "number"
          },
          {
            "start": 2,
            "name": "elementShape",
            "type": "shape"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListSetItem",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "index",
            "type": "number"
          },
          {
            "start": 2,
            "name": "tensor",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListReserve",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "elementShape",
            "type": "shape"
          },
          {
            "start": 1,
            "name": "numElements",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListFromTensor",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "elementShape",
            "type": "shape"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListStack",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "elementShape",
            "type": "shape"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          },
          {
            "tfName": "num_elements",
            "name": "numElements",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListSplit",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "elementShape",
            "type": "shape"
          },
          {
            "start": 2,
            "name": "lengths",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListConcat",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "element_shape",
            "name": "elementShape",
            "type": "shape"
          },
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListConcatV2",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "element_shape",
            "name": "elementShape",
            "type": "shape"
          },
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListPopBack",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "elementShape",
            "type": "shape"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListPushBack",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "tensor",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListLength",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "TensorListResize",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "size",
            "type": "number"
          }
        ]
      }
    ];
    var control = {
      __proto__: null,
      json: json$g
    };
    var json$f = [
      {
        "tfOpName": "AvgPool",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          },
          {
            "tfName": "ksize",
            "name": "kernelSize",
            "type": "number[]"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "MaxPool",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          },
          {
            "tfName": "ksize",
            "name": "kernelSize",
            "type": "number[]"
          },
          {
            "tfName": "explicit_paddings",
            "name": "explicitPaddings",
            "type": "number[]",
            "defaultValue": [],
            "notSupported": true
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "MaxPoolWithArgmax",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "ksize",
            "name": "kernelSize",
            "type": "number[]"
          },
          {
            "tfName": "include_batch_in_index",
            "name": "includeBatchInIndex",
            "type": "bool"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "AvgPool3D",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          },
          {
            "tfName": "ksize",
            "name": "kernelSize",
            "type": "number[]"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "MaxPool3D",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          },
          {
            "tfName": "ksize",
            "name": "kernelSize",
            "type": "number[]"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Conv1D",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "stride",
            "name": "stride",
            "type": "number"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "defaultValue": "NWC"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "dilation",
            "name": "dilation",
            "type": "number",
            "defaultValue": 1
          }
        ]
      },
      {
        "tfOpName": "Conv2D",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "useCudnnOnGpu",
            "name": "useCudnnOnGpu",
            "type": "bool"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "defaultValue": "NHWC"
          },
          {
            "tfName": "explicit_paddings",
            "name": "explicitPaddings",
            "type": "number[]",
            "defaultValue": []
          },
          {
            "tfName": "dilations",
            "name": "dilations",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "_FusedConv2D",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          },
          {
            "start": 2,
            "end": 0,
            "name": "args",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "num_args",
            "name": "numArgs",
            "type": "number"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "explicit_paddings",
            "name": "explicitPaddings",
            "type": "number[]",
            "defaultValue": []
          },
          {
            "tfName": "use_cudnn_on_gpu",
            "name": "useCudnnOnGpu",
            "type": "bool",
            "defaultValue": true
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "defaultValue": "NHWC"
          },
          {
            "tfName": "dilations",
            "name": "dilations",
            "type": "number[]",
            "defaultValue": [
              1,
              1,
              1,
              1
            ]
          },
          {
            "tfName": "fused_ops",
            "name": "fusedOps",
            "type": "string[]",
            "defaultValue": []
          },
          {
            "tfName": "epsilon",
            "name": "epsilon",
            "type": "number",
            "defaultValue": 1e-4
          },
          {
            "tfName": "leakyrelu_alpha",
            "name": "leakyreluAlpha",
            "type": "number",
            "defaultValue": 0.2
          }
        ]
      },
      {
        "tfOpName": "Conv2DBackpropInput",
        "category": "convolution",
        "inputs": [
          {
            "start": 2,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          },
          {
            "start": 0,
            "name": "outputShape",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          },
          {
            "tfName": "explicit_paddings",
            "name": "explicitPaddings",
            "type": "number[]",
            "defaultValue": []
          },
          {
            "tfName": "dilations",
            "name": "dilations",
            "type": "number[]",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "DepthwiseConv2d",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "input",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "defaultValue": "NHWC"
          },
          {
            "tfName": "explicit_paddings",
            "name": "explicitPaddings",
            "type": "number[]",
            "defaultValue": []
          },
          {
            "tfName": "dilations",
            "name": "dilations",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "DepthwiseConv2dNative",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "input",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "defaultValue": "NHWC"
          },
          {
            "tfName": "explicit_paddings",
            "name": "explicitPaddings",
            "type": "number[]",
            "defaultValue": []
          },
          {
            "tfName": "dilations",
            "name": "dilations",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "FusedDepthwiseConv2dNative",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          },
          {
            "start": 2,
            "end": 0,
            "name": "args",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "num_args",
            "name": "numArgs",
            "type": "number"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "defaultValue": "NHWC"
          },
          {
            "tfName": "dilations",
            "name": "dilations",
            "type": "number[]",
            "defaultValue": [
              1,
              1,
              1,
              1
            ]
          },
          {
            "tfName": "fused_ops",
            "name": "fusedOps",
            "type": "string[]",
            "defaultValue": []
          },
          {
            "tfName": "explicit_paddings",
            "name": "explicitPaddings",
            "type": "number[]",
            "defaultValue": []
          }
        ]
      },
      {
        "tfOpName": "Conv3D",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "defaultValue": "NHWC"
          },
          {
            "tfName": "dilations",
            "name": "dilations",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "Dilation2D",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "rates",
            "name": "dilations",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          }
        ]
      }
    ];
    var convolution = {
      __proto__: null,
      json: json$f
    };
    var json$e = [
      {
        "tfOpName": "Fill",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "shape",
            "type": "number[]"
          },
          {
            "start": 1,
            "name": "value",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "LinSpace",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "start",
            "type": "number"
          },
          {
            "start": 1,
            "name": "stop",
            "type": "number"
          },
          {
            "start": 2,
            "name": "num",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "OneHot",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "indices",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "depth",
            "type": "number"
          },
          {
            "start": 2,
            "name": "onValue",
            "type": "number",
            "defaultValue": 1
          },
          {
            "start": 3,
            "name": "offValue",
            "type": "number",
            "defaultValue": 0
          }
        ],
        "attrs": [
          {
            "tfName": "axis",
            "name": "axis",
            "type": "number",
            "notSupported": true
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "Ones",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "shape",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "OnesLike",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "RandomStandardNormal",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "shape",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "seed",
            "name": "seed",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "seed2",
            "name": "seed2",
            "type": "number",
            "defaultValue": 0,
            "notSupported": true
          },
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          },
          {
            "tfName": "T",
            "name": "T",
            "type": "number",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "RandomUniform",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "shape",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "minval",
            "name": "minval",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "maxval",
            "name": "maxval",
            "type": "number",
            "defaultValue": 1
          },
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          },
          {
            "tfName": "seed",
            "name": "seed",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "seed2",
            "name": "seed2",
            "type": "number",
            "defaultValue": 0,
            "notSupported": true
          },
          {
            "tfName": "T",
            "name": "T",
            "type": "number",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "RandomUniformInt",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "shape",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "minval",
            "name": "minval",
            "type": "number"
          },
          {
            "tfName": "maxval",
            "name": "maxval",
            "type": "number"
          },
          {
            "tfName": "seed",
            "name": "seed",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "seed2",
            "name": "seed2",
            "type": "number",
            "defaultValue": 0,
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Range",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "start",
            "type": "number"
          },
          {
            "start": 1,
            "name": "stop",
            "type": "number"
          },
          {
            "start": 2,
            "name": "step",
            "type": "number",
            "defaultValue": 0
          }
        ],
        "attrs": [
          {
            "tfName": "Tidx",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TruncatedNormal",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "shape",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "means",
            "name": "mean",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "stddev",
            "name": "stdDev",
            "type": "number",
            "defaultValue": 1
          },
          {
            "tfName": "seed",
            "name": "seed",
            "type": "number"
          },
          {
            "tfName": "seed2",
            "name": "seed2",
            "type": "number",
            "defaultValue": 0,
            "notSupported": true
          },
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          },
          {
            "tfName": "T",
            "name": "T",
            "type": "number",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Zeros",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "shape",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "ZerosLike",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "Multinomial",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "logits",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "numSamples",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "seed",
            "name": "seed",
            "type": "number"
          },
          {
            "tfName": "seed2",
            "name": "seed2",
            "type": "number"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          },
          {
            "tfName": "output_dtype",
            "name": "output_dtype",
            "type": "dtype"
          }
        ]
      }
    ];
    var creation = {
      __proto__: null,
      json: json$e
    };
    var json$d = [
      {
        "tfOpName": "NonMaxSuppressionV2",
        "category": "dynamic",
        "inputs": [
          {
            "start": 0,
            "name": "boxes",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "scores",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "maxOutputSize",
            "type": "number"
          },
          {
            "start": 3,
            "name": "iouThreshold",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "NonMaxSuppressionV3",
        "category": "dynamic",
        "inputs": [
          {
            "start": 0,
            "name": "boxes",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "scores",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "maxOutputSize",
            "type": "number"
          },
          {
            "start": 3,
            "name": "iouThreshold",
            "type": "number"
          },
          {
            "start": 4,
            "name": "scoreThreshold",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "NonMaxSuppressionV4",
        "category": "dynamic",
        "inputs": [
          {
            "start": 0,
            "name": "boxes",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "scores",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "maxOutputSize",
            "type": "number"
          },
          {
            "start": 3,
            "name": "iouThreshold",
            "type": "number"
          },
          {
            "start": 4,
            "name": "scoreThreshold",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "T_threshold",
            "name": "threshold",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "pad_to_max_output_size",
            "name": "padToMaxOutputSize",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "NonMaxSuppressionV5",
        "category": "dynamic",
        "inputs": [
          {
            "start": 0,
            "name": "boxes",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "scores",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "maxOutputSize",
            "type": "number"
          },
          {
            "start": 3,
            "name": "iouThreshold",
            "type": "number"
          },
          {
            "start": 4,
            "name": "scoreThreshold",
            "type": "number"
          },
          {
            "start": 5,
            "name": "softNmsSigma",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "Where",
        "category": "dynamic",
        "inputs": [
          {
            "start": 0,
            "name": "condition",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "ListDiff",
        "category": "dynamic",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "y",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      }
    ];
    var dynamic = {
      __proto__: null,
      json: json$d
    };
    var json$c = [
      {
        "tfOpName": "LowerBound",
        "category": "evaluation",
        "inputs": [
          {
            "start": 0,
            "name": "sortedSequence",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "values",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "TopKV2",
        "category": "evaluation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "k",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "sorted",
            "name": "sorted",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "UpperBound",
        "category": "evaluation",
        "inputs": [
          {
            "start": 0,
            "name": "sortedSequence",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "values",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "Unique",
        "category": "evaluation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "UniqueV2",
        "category": "evaluation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number"
          }
        ]
      }
    ];
    var evaluation = {
      __proto__: null,
      json: json$c
    };
    var json$b = [
      {
        "tfOpName": "PlaceholderWithDefault",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "default",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "shape",
            "name": "shape",
            "type": "shape"
          },
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "Placeholder",
        "category": "graph",
        "attrs": [
          {
            "tfName": "shape",
            "name": "shape",
            "type": "shape"
          },
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "Const",
        "category": "graph"
      },
      {
        "tfOpName": "Identity",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "IdentityN",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "x",
            "type": "tensors"
          }
        ]
      },
      {
        "tfOpName": "Snapshot",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "Rank",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "Size",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "Shape",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "ShapeN",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "x",
            "type": "tensors"
          }
        ]
      },
      {
        "tfOpName": "Print",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "data",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "message",
            "name": "message",
            "type": "string"
          },
          {
            "tfName": "first_n",
            "name": "firstN",
            "type": "number",
            "notSupported": true
          },
          {
            "tfName": "summarize",
            "name": "summarize",
            "type": "number",
            "defaultValue": 3
          }
        ]
      },
      {
        "tfOpName": "NoOp",
        "category": "graph",
        "inputs": []
      },
      {
        "tfOpName": "StopGradient",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "FakeQuantWithMinMaxVars",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "min",
            "name": "min",
            "type": "number"
          },
          {
            "tfName": "max",
            "name": "max",
            "type": "number"
          }
        ]
      }
    ];
    var graph = {
      __proto__: null,
      json: json$b
    };
    var json$a = [
      {
        "tfOpName": "HashTable",
        "category": "hash_table",
        "inputs": [],
        "attrs": [
          {
            "tfName": "shared_name",
            "name": "sharedName",
            "type": "string"
          },
          {
            "tfName": "use_node_name_sharing",
            "name": "useNodeNameSharing",
            "type": "bool"
          },
          {
            "tfName": "key_dtype",
            "name": "keyDType",
            "type": "dtype"
          },
          {
            "tfName": "value_dtype",
            "name": "valueDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "HashTableV2",
        "category": "hash_table",
        "inputs": [],
        "attrs": [
          {
            "tfName": "shared_name",
            "name": "sharedName",
            "type": "string"
          },
          {
            "tfName": "use_node_name_sharing",
            "name": "useNodeNameSharing",
            "type": "bool"
          },
          {
            "tfName": "key_dtype",
            "name": "keyDType",
            "type": "dtype"
          },
          {
            "tfName": "value_dtype",
            "name": "valueDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "LookupTableImport",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "keys",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "values",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "Tin",
            "name": "tIn",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "Tout",
            "name": "tOut",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LookupTableImportV2",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "keys",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "values",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "Tin",
            "name": "tIn",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "Tout",
            "name": "tOut",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LookupTableFind",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "keys",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "defaultValue",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "Tin",
            "name": "tIn",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "Tout",
            "name": "tOut",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LookupTableFindV2",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "keys",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "defaultValue",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "Tin",
            "name": "tIn",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "Tout",
            "name": "tOut",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LookupTableSize",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "LookupTableSizeV2",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "InitializeTable",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "keys",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "values",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "InitializeTableV2",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "keys",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "values",
            "type": "tensor"
          }
        ]
      }
    ];
    var hashTable = {
      __proto__: null,
      json: json$a
    };
    var json$9 = [
      {
        "tfOpName": "ResizeBilinear",
        "category": "image",
        "inputs": [
          {
            "start": 0,
            "name": "images",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "size",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "align_corners",
            "name": "alignCorners",
            "type": "bool"
          },
          {
            "tfName": "half_pixel_centers",
            "name": "halfPixelCenters",
            "type": "bool"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "ResizeNearestNeighbor",
        "category": "image",
        "inputs": [
          {
            "start": 0,
            "name": "images",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "size",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "align_corners",
            "name": "alignCorners",
            "type": "bool"
          },
          {
            "tfName": "half_pixel_centers",
            "name": "halfPixelCenters",
            "type": "bool"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "CropAndResize",
        "category": "image",
        "inputs": [
          {
            "start": 0,
            "name": "image",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "boxes",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "boxInd",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "cropSize",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "method",
            "name": "method",
            "type": "string"
          },
          {
            "tfName": "extrapolation_value",
            "name": "extrapolationValue",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "ImageProjectiveTransformV3",
        "category": "image",
        "inputs": [
          {
            "start": 0,
            "name": "images",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "transforms",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "outputShape",
            "type": "number[]"
          },
          {
            "start": 3,
            "name": "fillValue",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "interpolation",
            "name": "interpolation",
            "type": "string"
          },
          {
            "tfName": "fill_mode",
            "name": "fillMode",
            "type": "string"
          }
        ]
      }
    ];
    var image$1 = {
      __proto__: null,
      json: json$9
    };
    var json$8 = [
      {
        "tfOpName": "Equal",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "NotEqual",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Greater",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "GreaterEqual",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Less",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LessEqual",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LogicalAnd",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LogicalNot",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LogicalOr",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Select",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "condition",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "SelectV2",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "condition",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "BitwiseAnd",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "y",
            "type": "tensor"
          }
        ]
      }
    ];
    var logical = {
      __proto__: null,
      json: json$8
    };
    var json$7 = [
      {
        "tfOpName": "_FusedMatMul",
        "category": "matrices",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          },
          {
            "start": 2,
            "end": 0,
            "name": "args",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "num_args",
            "name": "numArgs",
            "type": "number"
          },
          {
            "tfName": "fused_ops",
            "name": "fusedOps",
            "type": "string[]",
            "defaultValue": []
          },
          {
            "tfName": "epsilon",
            "name": "epsilon",
            "type": "number",
            "defaultValue": 1e-4
          },
          {
            "tfName": "transpose_a",
            "name": "transposeA",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "transpose_b",
            "name": "transposeB",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "leakyrelu_alpha",
            "name": "leakyreluAlpha",
            "type": "number",
            "defaultValue": 0.2
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "MatMul",
        "category": "matrices",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "transpose_a",
            "name": "transposeA",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "transpose_b",
            "name": "transposeB",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "BatchMatMul",
        "category": "matrices",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "adj_x",
            "name": "transposeA",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "adj_y",
            "name": "transposeB",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "BatchMatMulV2",
        "category": "matrices",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "adj_x",
            "name": "transposeA",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "adj_y",
            "name": "transposeB",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Transpose",
        "category": "matrices",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "perm",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Einsum",
        "category": "matrices",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "tensors",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "equation",
            "name": "equation",
            "type": "string"
          },
          {
            "tfName": "N",
            "name": "n",
            "type": "number",
            "defaultValue": 2
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "MatrixBandPart",
        "category": "matrices",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "numLower",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "numUpper",
            "type": "tensor"
          }
        ]
      }
    ];
    var matrices = {
      __proto__: null,
      json: json$7
    };
    var json$6 = [
      {
        "tfOpName": "EuclideanNorm",
        "category": "normalization",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool",
            "defaultValue": false
          }
        ]
      },
      {
        "tfOpName": "FusedBatchNorm",
        "category": "normalization",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "scale",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "offset",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "mean",
            "type": "tensor"
          },
          {
            "start": 4,
            "name": "variance",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "epsilon",
            "name": "epsilon",
            "type": "number",
            "defaultValue": 1e-3
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "FusedBatchNormV2",
        "category": "normalization",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "scale",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "offset",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "mean",
            "type": "tensor"
          },
          {
            "start": 4,
            "name": "variance",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "epsilon",
            "name": "epsilon",
            "type": "number",
            "defaultValue": 1e-3
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "FusedBatchNormV3",
        "category": "normalization",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "scale",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "offset",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "mean",
            "type": "tensor"
          },
          {
            "start": 4,
            "name": "variance",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "epsilon",
            "name": "epsilon",
            "type": "number",
            "defaultValue": 1e-3
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LRN",
        "category": "normalization",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "depth_radius",
            "name": "radius",
            "type": "number",
            "defaultValue": 5
          },
          {
            "tfName": "bias",
            "name": "bias",
            "type": "number",
            "defaultValue": 1
          },
          {
            "tfName": "alpha",
            "name": "alpha",
            "type": "number",
            "defaultValue": 1
          },
          {
            "tfName": "beta",
            "name": "beta",
            "type": "number",
            "defaultValue": 0.5
          }
        ]
      },
      {
        "tfOpName": "Softmax",
        "category": "normalization",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "LogSoftmax",
        "category": "normalization",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      }
    ];
    var normalization = {
      __proto__: null,
      json: json$6
    };
    var json$5 = [
      {
        "tfOpName": "Bincount",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "size",
            "type": "number"
          },
          {
            "start": 2,
            "name": "weights",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "DenseBincount",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "size",
            "type": "number"
          },
          {
            "start": 2,
            "name": "weights",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "binary_output",
            "name": "binaryOutput",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "Max",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "Mean",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "Min",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "Sum",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "All",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "Any",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "ArgMax",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "ArgMin",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "Prod",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Cumprod",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "exclusive",
            "name": "exclusive",
            "type": "bool"
          },
          {
            "tfName": "reverse",
            "name": "reverse",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "Cumsum",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "exclusive",
            "name": "exclusive",
            "type": "bool"
          },
          {
            "tfName": "reverse",
            "name": "reverse",
            "type": "bool"
          }
        ]
      }
    ];
    var reduction = {
      __proto__: null,
      json: json$5
    };
    var json$4 = [
      {
        "tfOpName": "ConcatV2",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "end": -1,
            "name": "tensors",
            "type": "tensors"
          },
          {
            "start": -1,
            "name": "axis",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "N",
            "name": "n",
            "type": "number",
            "defaultValue": 2
          }
        ]
      },
      {
        "tfOpName": "Concat",
        "category": "slice_join",
        "inputs": [
          {
            "start": 1,
            "end": 0,
            "name": "tensors",
            "type": "tensors"
          },
          {
            "start": 0,
            "name": "axis",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "N",
            "name": "n",
            "type": "number",
            "defaultValue": 2
          }
        ]
      },
      {
        "tfOpName": "GatherV2",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "axis",
            "type": "number",
            "defaultValue": 0
          }
        ],
        "attrs": [
          {
            "tfName": "batch_dims",
            "name": "batchDims",
            "type": "number",
            "defaultValue": 0
          }
        ]
      },
      {
        "tfOpName": "Gather",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "validate_indices",
            "name": "validateIndices",
            "type": "bool",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Reverse",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "dims",
            "type": "bool[]"
          }
        ]
      },
      {
        "tfOpName": "ReverseV2",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "Slice",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "begin",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "size",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "StridedSlice",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "begin",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "end",
            "type": "number[]"
          },
          {
            "start": 3,
            "name": "strides",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "begin_mask",
            "name": "beginMask",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "end_mask",
            "name": "endMask",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "new_axis_mask",
            "name": "newAxisMask",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "ellipsis_mask",
            "name": "ellipsisMask",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "shrink_axis_mask",
            "name": "shrinkAxisMask",
            "type": "number",
            "defaultValue": 0
          }
        ]
      },
      {
        "tfOpName": "Pack",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "tensors",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "axis",
            "name": "axis",
            "type": "number",
            "defaultValue": 0
          }
        ]
      },
      {
        "tfOpName": "Unpack",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "axis",
            "name": "axis",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "num",
            "name": "num",
            "type": "number",
            "defaultValue": 0,
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Tile",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "reps",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "Split",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "axis",
            "type": "number",
            "defaultValue": 0
          },
          {
            "start": 1,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "num_split",
            "name": "numOrSizeSplits",
            "type": "number",
            "defaultValue": 1
          }
        ]
      },
      {
        "tfOpName": "SplitV",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "numOrSizeSplits",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "axis",
            "type": "number",
            "defaultValue": 0
          }
        ]
      },
      {
        "tfOpName": "ScatterNd",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "indices",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "values",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "shape",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "GatherNd",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "SparseToDense",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "sparseIndices",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "outputShape",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "sparseValues",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "defaultValue",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "validate_indices",
            "name": "validateIndices",
            "type": "bool",
            "defaultValue": false,
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "TensorScatterUpdate",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "values",
            "type": "tensor"
          }
        ]
      }
    ];
    var sliceJoin = {
      __proto__: null,
      json: json$4
    };
    var json$3 = [
      {
        "tfOpName": "SparseFillEmptyRows",
        "category": "sparse",
        "inputs": [
          {
            "start": 0,
            "name": "indices",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "values",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "denseShape",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "defaultValue",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "SparseReshape",
        "category": "sparse",
        "inputs": [
          {
            "start": 0,
            "name": "inputIndices",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "inputShape",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "newShape",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "SparseSegmentMean",
        "category": "sparse",
        "inputs": [
          {
            "start": 0,
            "name": "data",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "segmentIds",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "SparseSegmentSum",
        "category": "sparse",
        "inputs": [
          {
            "start": 0,
            "name": "data",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "segmentIds",
            "type": "tensor"
          }
        ]
      }
    ];
    var sparse$1 = {
      __proto__: null,
      json: json$3
    };
    var json$2 = [
      {
        "tfOpName": "FFT",
        "category": "spectral",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "IFFT",
        "category": "spectral",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "RFFT",
        "category": "spectral",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "fft_length",
            "type": "number",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "IRFFT",
        "category": "spectral",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "fft_length",
            "type": "number",
            "notSupported": true
          }
        ]
      }
    ];
    var spectral$1 = {
      __proto__: null,
      json: json$2
    };
    var json$1 = [
      {
        "tfOpName": "StaticRegexReplace",
        "category": "string",
        "inputs": [
          {
            "start": 0,
            "name": "input",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "pattern",
            "name": "pattern",
            "type": "string"
          },
          {
            "tfName": "rewrite",
            "name": "rewrite",
            "type": "string"
          },
          {
            "tfName": "replace_global",
            "name": "replaceGlobal",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "StringNGrams",
        "category": "string",
        "inputs": [
          {
            "start": 0,
            "name": "data",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "dataSplits",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "separator",
            "name": "separator",
            "type": "string"
          },
          {
            "tfName": "ngram_widths",
            "name": "nGramWidths",
            "type": "number[]"
          },
          {
            "tfName": "left_pad",
            "name": "leftPad",
            "type": "string"
          },
          {
            "tfName": "right_pad",
            "name": "rightPad",
            "type": "string"
          },
          {
            "tfName": "pad_width",
            "name": "padWidth",
            "type": "number"
          },
          {
            "tfName": "preserve_short_sequences",
            "name": "preserveShortSequences",
            "type": "bool"
          }
        ],
        "outputs": [
          "ngrams",
          "ngrams_splits"
        ]
      },
      {
        "tfOpName": "StringSplit",
        "category": "string",
        "inputs": [
          {
            "start": 0,
            "name": "input",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "delimiter",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "skip_empty",
            "name": "skipEmpty",
            "type": "bool"
          }
        ],
        "outputs": [
          "indices",
          "values",
          "shape"
        ]
      },
      {
        "tfOpName": "StringToHashBucketFast",
        "category": "string",
        "inputs": [
          {
            "start": 0,
            "name": "input",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "num_buckets",
            "name": "numBuckets",
            "type": "number"
          }
        ]
      }
    ];
    var string$1 = {
      __proto__: null,
      json: json$1
    };
    var json = [
      {
        "tfOpName": "Cast",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "SrcT",
            "name": "sdtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "DstT",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "ExpandDims",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "MirrorPad",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "padding",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "mode",
            "name": "mode",
            "type": "string"
          }
        ]
      },
      {
        "tfOpName": "Pad",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "padding",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "constant_value",
            "name": "constantValue",
            "type": "number",
            "defaultValue": 0
          }
        ]
      },
      {
        "tfOpName": "PadV2",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "padding",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "constantValue",
            "type": "number",
            "defaultValue": 0
          }
        ]
      },
      {
        "tfOpName": "Reshape",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "shape",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "EnsureShape",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "shape",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "Squeeze",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "axis",
            "tfDeprecatedName": "squeeze_dims",
            "name": "axis",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "SpaceToBatchND",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "blockShape",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "paddings",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "BatchToSpaceND",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "blockShape",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "crops",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "DepthToSpace",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "block_size",
            "name": "blockSize",
            "type": "number"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string"
          }
        ]
      },
      {
        "tfOpName": "BroadcastTo",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "shape",
            "type": "number[]"
          }
        ],
        "attrs": []
      },
      {
        "tfOpName": "BroadcastArgs",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "s0",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "s1",
            "type": "tensor"
          }
        ],
        "attrs": []
      }
    ];
    var transformation = {
      __proto__: null,
      json
    };
    var OperationMapper = (
      /** @class */
      function() {
        function OperationMapper2() {
          var ops = [
            arithmetic,
            basicMath,
            control,
            convolution,
            creation,
            dynamic,
            evaluation,
            graph,
            hashTable,
            image$1,
            logical,
            matrices,
            normalization,
            reduction,
            sliceJoin,
            sparse$1,
            spectral$1,
            string$1,
            transformation
          ];
          var mappersJson = [].concat.apply([], __spreadArray([], __read(ops.map(function(op2) {
            return op2.json;
          })), false));
          this.opMappers = mappersJson.reduce(function(map, mapper) {
            map[mapper.tfOpName] = mapper;
            return map;
          }, {});
        }
        Object.defineProperty(OperationMapper2, "Instance", {
          // Singleton instance for the mapper
          get: function() {
            return this._instance || (this._instance = new this());
          },
          enumerable: false,
          configurable: true
        });
        OperationMapper2.prototype.transformGraph = function(graph2, signature) {
          var _this = this;
          if (signature === void 0) {
            signature = {};
          }
          var tfNodes = graph2.node;
          var placeholders = [];
          var weights = [];
          var initNodes = [];
          var nodes = tfNodes.reduce(function(map, node) {
            map[node.name] = _this.mapNode(node);
            if (node.op.startsWith("Placeholder")) {
              placeholders.push(map[node.name]);
            } else if (node.op === "Const") {
              weights.push(map[node.name]);
            } else if (node.input == null || node.input.length === 0) {
              initNodes.push(map[node.name]);
            }
            return map;
          }, {});
          var inputs = [];
          var outputs = [];
          var inputNodeNameToKey = {};
          var outputNodeNameToKey = {};
          if (signature != null) {
            inputNodeNameToKey = this.mapSignatureEntries(signature.inputs);
            outputNodeNameToKey = this.mapSignatureEntries(signature.outputs);
          }
          var allNodes = Object.keys(nodes);
          allNodes.forEach(function(key) {
            var node = nodes[key];
            node.inputNames.forEach(function(name, index) {
              var _a = __read(getNodeNameAndIndex(name), 3), nodeName = _a[0], outputName = _a[2];
              var inputNode = nodes[nodeName];
              if (inputNode.outputs != null) {
                var outputIndex = inputNode.outputs.indexOf(outputName);
                if (outputIndex !== -1) {
                  var inputName = "".concat(nodeName, ":").concat(outputIndex);
                  node.inputNames[index] = inputName;
                }
              }
              node.inputs.push(inputNode);
              inputNode.children.push(node);
            });
          });
          if (Object.keys(outputNodeNameToKey).length === 0) {
            allNodes.forEach(function(key) {
              var node = nodes[key];
              if (node.children.length === 0) {
                outputs.push(node);
              }
            });
          } else {
            Object.keys(outputNodeNameToKey).forEach(function(name) {
              var _a = __read(getNodeNameAndIndex(name), 1), nodeName = _a[0];
              var node = nodes[nodeName];
              if (node != null) {
                node.signatureKey = outputNodeNameToKey[name];
                outputs.push(node);
              }
            });
          }
          if (Object.keys(inputNodeNameToKey).length > 0) {
            Object.keys(inputNodeNameToKey).forEach(function(name) {
              var _a = __read(getNodeNameAndIndex(name), 1), nodeName = _a[0];
              var node = nodes[nodeName];
              if (node) {
                node.signatureKey = inputNodeNameToKey[name];
                inputs.push(node);
              }
            });
          } else {
            inputs = placeholders;
          }
          var functions = {};
          if (graph2.library != null && graph2.library.function != null) {
            functions = graph2.library.function.reduce(function(functions2, func) {
              functions2[func.signature.name] = _this.mapFunction(func);
              return functions2;
            }, {});
          }
          var result = { nodes, inputs, outputs, weights, placeholders, signature, functions };
          if (initNodes.length > 0) {
            result.initNodes = initNodes;
          }
          return result;
        };
        OperationMapper2.prototype.mapSignatureEntries = function(entries) {
          return Object.keys(entries || {}).reduce(function(prev, curr) {
            prev[entries[curr].name] = curr;
            return prev;
          }, {});
        };
        OperationMapper2.prototype.mapNode = function(node) {
          var mapper = getRegisteredOp(node.op) || this.opMappers[node.op] || {};
          if (node.attr == null) {
            node.attr = {};
          }
          var newNode = {
            name: node.name,
            op: node.op,
            category: mapper.category,
            inputNames: (node.input || []).map(function(input) {
              return input.startsWith("^") ? input.slice(1) : input;
            }),
            inputs: [],
            children: [],
            inputParams: {},
            attrParams: {},
            rawAttrs: node.attr,
            outputs: mapper.outputs
          };
          if (mapper.inputs != null) {
            newNode.inputParams = mapper.inputs.reduce(function(map, param) {
              map[param.name] = {
                type: param.type,
                inputIndexStart: param.start,
                inputIndexEnd: param.end
              };
              return map;
            }, {});
          }
          if (mapper.attrs != null) {
            newNode.attrParams = mapper.attrs.reduce(function(map, param) {
              var type = param.type;
              var value = void 0;
              switch (param.type) {
                case "string":
                  value = getStringParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getStringParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "string[]":
                  value = getStringArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getStringArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "number":
                  value = getNumberParam(node.attr, param.tfName, param.defaultValue || 0);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getNumberParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "number[]":
                  value = getNumericArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getNumericArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "bool":
                  value = getBoolParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getBoolParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "bool[]":
                  value = getBoolArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getBoolArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "shape":
                  value = getTensorShapeParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getTensorShapeParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "shape[]":
                  value = getTensorShapeArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getTensorShapeArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "dtype":
                  value = getDtypeParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getDtypeParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "dtype[]":
                  value = getDtypeArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getDtypeArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "func":
                  value = getFuncParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getFuncParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "tensor":
                case "tensors":
                  break;
                default:
                  throw new Error("Unsupported param type: ".concat(param.type, " for op: ").concat(node.op));
              }
              map[param.name] = { value, type };
              return map;
            }, {});
          }
          return newNode;
        };
        OperationMapper2.prototype.mapFunction = function(functionDef) {
          var _this = this;
          var tfNodes = functionDef.nodeDef;
          var placeholders = [];
          var weights = [];
          var nodes = {};
          if (tfNodes != null) {
            nodes = tfNodes.reduce(function(map, node) {
              map[node.name] = _this.mapNode(node);
              if (node.op === "Const") {
                weights.push(map[node.name]);
              }
              return map;
            }, {});
          }
          var inputs = [];
          var outputs = [];
          functionDef.signature.inputArg.forEach(function(arg) {
            var _a = __read(getNodeNameAndIndex(arg.name), 1), nodeName = _a[0];
            var node = {
              name: nodeName,
              op: "Placeholder",
              inputs: [],
              inputNames: [],
              category: "graph",
              inputParams: {},
              attrParams: { dtype: { value: parseDtypeParam(arg.type), type: "dtype" } },
              children: []
            };
            node.signatureKey = arg.name;
            inputs.push(node);
            nodes[nodeName] = node;
          });
          var allNodes = Object.keys(nodes);
          allNodes.forEach(function(key) {
            var node = nodes[key];
            node.inputNames.forEach(function(name, index) {
              var _a = __read(getNodeNameAndIndex(name), 3), nodeName = _a[0], outputName = _a[2];
              var inputNode = nodes[nodeName];
              if (inputNode.outputs != null) {
                var outputIndex = inputNode.outputs.indexOf(outputName);
                if (outputIndex !== -1) {
                  var inputName = "".concat(nodeName, ":").concat(outputIndex);
                  node.inputNames[index] = inputName;
                }
              }
              node.inputs.push(inputNode);
              inputNode.children.push(node);
            });
          });
          var returnNodeMap = functionDef.ret;
          functionDef.signature.outputArg.forEach(function(output) {
            var _a = __read(getNodeNameAndIndex(returnNodeMap[output.name]), 2), nodeName = _a[0], index = _a[1];
            var node = nodes[nodeName];
            if (node != null) {
              node.defaultOutput = index;
              outputs.push(node);
            }
          });
          var signature = this.mapArgsToSignature(functionDef);
          return { nodes, inputs, outputs, weights, placeholders, signature };
        };
        OperationMapper2.prototype.mapArgsToSignature = function(functionDef) {
          var _this = this;
          return {
            methodName: functionDef.signature.name,
            inputs: functionDef.signature.inputArg.reduce(function(map, arg) {
              map[arg.name] = _this.mapArgToTensorInfo(arg);
              return map;
            }, {}),
            outputs: functionDef.signature.outputArg.reduce(function(map, arg) {
              map[arg.name] = _this.mapArgToTensorInfo(arg, functionDef.ret);
              return map;
            }, {})
          };
        };
        OperationMapper2.prototype.mapArgToTensorInfo = function(arg, nameMap) {
          var name = arg.name;
          if (nameMap != null) {
            name = nameMap[name];
          }
          return { name, dtype: arg.type };
        };
        return OperationMapper2;
      }()
    );
    function decodeBase64(text) {
      var global2 = tfc.env().global;
      if (typeof global2.atob !== "undefined") {
        return global2.atob(text);
      } else if (typeof Buffer !== "undefined") {
        return new Buffer(text, "base64").toString();
      } else {
        throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()");
      }
    }
    function parseStringParam(s, keepCase) {
      var value = Array.isArray(s) ? String.fromCharCode.apply(null, s) : decodeBase64(s);
      return keepCase ? value : value.toLowerCase();
    }
    function getStringParam(attrs, name, def, keepCase) {
      if (keepCase === void 0) {
        keepCase = false;
      }
      var param = attrs[name];
      if (param != null) {
        return parseStringParam(param.s, keepCase);
      }
      return def;
    }
    function getBoolParam(attrs, name, def) {
      var param = attrs[name];
      return param ? param.b : def;
    }
    function getNumberParam(attrs, name, def) {
      var param = attrs[name] || {};
      var value = param["i"] != null ? param["i"] : param["f"] != null ? param["f"] : def;
      return typeof value === "number" ? value : parseInt(value, 10);
    }
    function parseDtypeParam(value) {
      if (typeof value === "string") {
        value = DataType[value];
      }
      switch (value) {
        case DataType.DT_FLOAT:
        case DataType.DT_HALF:
          return "float32";
        case DataType.DT_INT32:
        case DataType.DT_INT64:
        case DataType.DT_INT8:
        case DataType.DT_UINT8:
          return "int32";
        case DataType.DT_BOOL:
          return "bool";
        case DataType.DT_DOUBLE:
          return "float32";
        case DataType.DT_STRING:
          return "string";
        default:
          return null;
      }
    }
    function getFuncParam(attrs, name, def) {
      var param = attrs[name];
      if (param && param.func) {
        return param.func.name;
      }
      return def;
    }
    function getDtypeParam(attrs, name, def) {
      var param = attrs[name];
      if (param && param.type) {
        return parseDtypeParam(param.type);
      }
      return def;
    }
    function getDtypeArrayParam(attrs, name, def) {
      var param = attrs[name];
      if (param && param.list && param.list.type) {
        return param.list.type.map(function(v) {
          return parseDtypeParam(v);
        });
      }
      return def;
    }
    function parseTensorShapeParam(shape) {
      if (shape.unknownRank) {
        return void 0;
      }
      if (shape.dim != null) {
        return shape.dim.map(function(dim) {
          return typeof dim.size === "number" ? dim.size : parseInt(dim.size, 10);
        });
      }
      return [];
    }
    function getTensorShapeParam(attrs, name, def) {
      var param = attrs[name];
      if (param && param.shape) {
        return parseTensorShapeParam(param.shape);
      }
      return def;
    }
    function getNumericArrayParam(attrs, name, def) {
      var param = attrs[name];
      if (param) {
        return ((param.list.f && param.list.f.length ? param.list.f : param.list.i) || []).map(function(v) {
          return typeof v === "number" ? v : parseInt(v, 10);
        });
      }
      return def;
    }
    function getStringArrayParam(attrs, name, def, keepCase) {
      if (keepCase === void 0) {
        keepCase = false;
      }
      var param = attrs[name];
      if (param && param.list && param.list.s) {
        return param.list.s.map(function(v) {
          return parseStringParam(v, keepCase);
        });
      }
      return def;
    }
    function getTensorShapeArrayParam(attrs, name, def) {
      var param = attrs[name];
      if (param && param.list && param.list.shape) {
        return param.list.shape.map(function(v) {
          return parseTensorShapeParam(v);
        });
      }
      return def;
    }
    function getBoolArrayParam(attrs, name, def) {
      var param = attrs[name];
      if (param && param.list && param.list.b) {
        return param.list.b;
      }
      return def;
    }
    var NodeValueImpl = (
      /** @class */
      function() {
        function NodeValueImpl2(node, tensorMap, context) {
          var _this = this;
          this.node = node;
          this.tensorMap = tensorMap;
          this.context = context;
          this.inputs = [];
          this.attrs = {};
          this.inputs = node.inputNames.map(function(name) {
            return _this.getInput(name);
          });
          if (node.rawAttrs != null) {
            this.attrs = Object.keys(node.rawAttrs).reduce(function(attrs, key) {
              attrs[key] = _this.getAttr(key);
              return attrs;
            }, {});
          }
        }
        NodeValueImpl2.prototype.getInput = function(name) {
          return getTensor(name, this.tensorMap, this.context);
        };
        NodeValueImpl2.prototype.getAttr = function(name, defaultValue) {
          var value = this.node.rawAttrs[name];
          if (value.tensor != null) {
            return getTensor(name, this.tensorMap, this.context);
          }
          if (value.i != null || value.f != null) {
            return getNumberParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.s != null) {
            return getStringParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.b != null) {
            return getBoolParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.shape != null) {
            return getTensorShapeParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.type != null) {
            return getDtypeParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.list != null) {
            if (value.list.i != null || value.list.f != null) {
              return getNumericArrayParam(this.node.rawAttrs, name, defaultValue);
            }
            if (value.list.s != null) {
              return getStringArrayParam(this.node.rawAttrs, name, defaultValue);
            }
            if (value.list.shape != null) {
              return getTensorShapeArrayParam(this.node.rawAttrs, name, defaultValue);
            }
            if (value.list.b != null) {
              return getBoolArrayParam(this.node.rawAttrs, name, defaultValue);
            }
            if (value.list.type != null) {
              return getDtypeArrayParam(this.node.rawAttrs, name, defaultValue);
            }
          }
          return defaultValue;
        };
        return NodeValueImpl2;
      }()
    );
    var EPSILON_FLOAT32 = 1e-7;
    var EPSILON_FLOAT16 = 1e-4;
    var KernelBackend = (
      /** @class */
      function() {
        function KernelBackend2() {
        }
        KernelBackend2.prototype.refCount = function(dataId) {
          return notYetImplemented("refCount");
        };
        KernelBackend2.prototype.incRef = function(dataId) {
          return notYetImplemented("incRef");
        };
        KernelBackend2.prototype.timerAvailable = function() {
          return true;
        };
        KernelBackend2.prototype.time = function(f) {
          return notYetImplemented("time");
        };
        KernelBackend2.prototype.read = function(dataId) {
          return notYetImplemented("read");
        };
        KernelBackend2.prototype.readSync = function(dataId) {
          return notYetImplemented("readSync");
        };
        KernelBackend2.prototype.readToGPU = function(dataId, options) {
          return notYetImplemented("readToGPU");
        };
        KernelBackend2.prototype.numDataIds = function() {
          return notYetImplemented("numDataIds");
        };
        KernelBackend2.prototype.disposeData = function(dataId, force) {
          return notYetImplemented("disposeData");
        };
        KernelBackend2.prototype.write = function(values, shape, dtype) {
          return notYetImplemented("write");
        };
        KernelBackend2.prototype.move = function(dataId, values, shape, dtype, refCount) {
          return notYetImplemented("move");
        };
        KernelBackend2.prototype.createTensorFromGPUData = function(values, shape, dtype) {
          return notYetImplemented("createTensorFromGPUData");
        };
        KernelBackend2.prototype.memory = function() {
          return notYetImplemented("memory");
        };
        KernelBackend2.prototype.floatPrecision = function() {
          return notYetImplemented("floatPrecision");
        };
        KernelBackend2.prototype.epsilon = function() {
          return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;
        };
        KernelBackend2.prototype.dispose = function() {
          return notYetImplemented("dispose");
        };
        return KernelBackend2;
      }()
    );
    function notYetImplemented(kernelName) {
      throw new Error("'".concat(kernelName, "' not yet implemented or not found in the registry. ") + "This kernel may not be supported by the tfjs backend you have chosen");
    }
    function assert(expr, msg) {
      if (!expr) {
        throw new Error(typeof msg === "string" ? msg : msg());
      }
    }
    function assertShapesMatch(shapeA, shapeB, errorMessagePrefix) {
      if (errorMessagePrefix === void 0) {
        errorMessagePrefix = "";
      }
      assert(arraysEqual(shapeA, shapeB), function() {
        return errorMessagePrefix + " Shapes ".concat(shapeA, " and ").concat(shapeB, " must match");
      });
    }
    function assertNonNull(a) {
      assert(a != null, function() {
        return "The input to the tensor constructor must be a non-null value.";
      });
    }
    function sizeFromShape(shape) {
      if (shape.length === 0) {
        return 1;
      }
      var size = shape[0];
      for (var i = 1; i < shape.length; i++) {
        size *= shape[i];
      }
      return size;
    }
    function arraysEqualWithNull(n1, n2) {
      if (n1 === n2) {
        return true;
      }
      if (n1 == null || n2 == null) {
        return false;
      }
      if (n1.length !== n2.length) {
        return false;
      }
      for (var i = 0; i < n1.length; i++) {
        if (n1[i] !== null && n2[i] !== null && n1[i] !== n2[i]) {
          return false;
        }
      }
      return true;
    }
    function arraysEqual(n1, n2) {
      if (n1 === n2) {
        return true;
      }
      if (n1 == null || n2 == null) {
        return false;
      }
      if (n1.length !== n2.length) {
        return false;
      }
      for (var i = 0; i < n1.length; i++) {
        if (n1[i] !== n2[i]) {
          return false;
        }
      }
      return true;
    }
    function isInt(a) {
      return a % 1 === 0;
    }
    function rightPad(a, size) {
      if (size <= a.length) {
        return a;
      }
      return a + " ".repeat(size - a.length);
    }
    function parseAxisParam(axis, shape) {
      var rank = shape.length;
      axis = axis == null ? shape.map(function(s, i) {
        return i;
      }) : [].concat(axis);
      assert(axis.every(function(ax) {
        return ax >= -rank && ax < rank;
      }), function() {
        return "All values in axis param must be in range [-".concat(rank, ", ").concat(rank, ") but ") + "got axis ".concat(axis);
      });
      assert(axis.every(function(ax) {
        return isInt(ax);
      }), function() {
        return "All values in axis param must be integers but " + "got axis ".concat(axis);
      });
      return axis.map(function(a) {
        return a < 0 ? rank + a : a;
      });
    }
    function squeezeShape(shape, axis) {
      var newShape = [];
      var keptDims = [];
      var isEmptyArray = axis != null && Array.isArray(axis) && axis.length === 0;
      var axes = axis == null || isEmptyArray ? null : parseAxisParam(axis, shape).sort();
      var j = 0;
      for (var i = 0; i < shape.length; ++i) {
        if (axes != null) {
          if (axes[j] === i && shape[i] !== 1) {
            throw new Error("Can't squeeze axis ".concat(i, " since its dim '").concat(shape[i], "' is not 1"));
          }
          if ((axes[j] == null || axes[j] > i) && shape[i] === 1) {
            newShape.push(shape[i]);
            keptDims.push(i);
          }
          if (axes[j] <= i) {
            j++;
          }
        }
        if (shape[i] !== 1) {
          newShape.push(shape[i]);
          keptDims.push(i);
        }
      }
      return { newShape, keptDims };
    }
    function getTypedArrayFromDType(dtype, size) {
      return getArrayFromDType(dtype, size);
    }
    function getArrayFromDType(dtype, size) {
      var values = null;
      if (dtype == null || dtype === "float32") {
        values = new Float32Array(size);
      } else if (dtype === "int32") {
        values = new Int32Array(size);
      } else if (dtype === "bool") {
        values = new Uint8Array(size);
      } else if (dtype === "string") {
        values = new Array(size);
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
      return values;
    }
    function checkConversionForErrors(vals, dtype) {
      for (var i = 0; i < vals.length; i++) {
        var num = vals[i];
        if (isNaN(num) || !isFinite(num)) {
          throw Error("A tensor of type ".concat(dtype, " being uploaded contains ").concat(num, "."));
        }
      }
    }
    function isValidDtype(dtype) {
      return dtype === "bool" || dtype === "complex64" || dtype === "float32" || dtype === "int32" || dtype === "string";
    }
    function bytesPerElement(dtype) {
      if (dtype === "float32" || dtype === "int32") {
        return 4;
      } else if (dtype === "complex64") {
        return 8;
      } else if (dtype === "bool") {
        return 1;
      } else {
        throw new Error("Unknown dtype ".concat(dtype));
      }
    }
    function bytesFromStringArray(arr) {
      if (arr == null) {
        return 0;
      }
      var bytes = 0;
      arr.forEach(function(x) {
        return bytes += x.length;
      });
      return bytes;
    }
    function isString(value) {
      return typeof value === "string" || value instanceof String;
    }
    function isBoolean(value) {
      return typeof value === "boolean";
    }
    function isNumber(value) {
      return typeof value === "number";
    }
    function inferDtype(values) {
      if (Array.isArray(values)) {
        return inferDtype(values[0]);
      }
      if (values instanceof Float32Array) {
        return "float32";
      } else if (values instanceof Int32Array || values instanceof Uint8Array || values instanceof Uint8ClampedArray) {
        return "int32";
      } else if (isNumber(values)) {
        return "float32";
      } else if (isString(values)) {
        return "string";
      } else if (isBoolean(values)) {
        return "bool";
      }
      return "float32";
    }
    function isFunction(f) {
      return !!(f && f.constructor && f.call && f.apply);
    }
    function computeStrides(shape) {
      var rank = shape.length;
      if (rank < 2) {
        return [];
      }
      var strides = new Array(rank - 1);
      strides[rank - 2] = shape[rank - 1];
      for (var i = rank - 3; i >= 0; --i) {
        strides[i] = strides[i + 1] * shape[i + 1];
      }
      return strides;
    }
    function createNestedArray(offset, shape, a, isComplex) {
      if (isComplex === void 0) {
        isComplex = false;
      }
      var ret = new Array();
      if (shape.length === 1) {
        var d = shape[0] * (isComplex ? 2 : 1);
        for (var i = 0; i < d; i++) {
          ret[i] = a[offset + i];
        }
      } else {
        var d = shape[0];
        var rest = shape.slice(1);
        var len = rest.reduce(function(acc, c) {
          return acc * c;
        }) * (isComplex ? 2 : 1);
        for (var i = 0; i < d; i++) {
          ret[i] = createNestedArray(offset + i * len, rest, a, isComplex);
        }
      }
      return ret;
    }
    function toNestedArray(shape, a, isComplex) {
      if (isComplex === void 0) {
        isComplex = false;
      }
      if (shape.length === 0) {
        return a[0];
      }
      var size = shape.reduce(function(acc, c) {
        return acc * c;
      }) * (isComplex ? 2 : 1);
      if (size === 0) {
        return [];
      }
      if (size !== a.length) {
        throw new Error("[".concat(shape, "] does not match the input size ").concat(a.length).concat(isComplex ? " for a complex tensor" : "", "."));
      }
      return createNestedArray(0, shape, a, isComplex);
    }
    function makeOnesTypedArray(size, dtype) {
      var array = makeZerosTypedArray(size, dtype);
      for (var i = 0; i < array.length; i++) {
        array[i] = 1;
      }
      return array;
    }
    function makeZerosTypedArray(size, dtype) {
      if (dtype == null || dtype === "float32" || dtype === "complex64") {
        return new Float32Array(size);
      } else if (dtype === "int32") {
        return new Int32Array(size);
      } else if (dtype === "bool") {
        return new Uint8Array(size);
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
    }
    function assertNonNegativeIntegerDimensions(shape) {
      shape.forEach(function(dimSize) {
        assert(Number.isInteger(dimSize) && dimSize >= 0, function() {
          return "Tensor must have a shape comprised of positive integers but got " + "shape [".concat(shape, "].");
        });
      });
    }
    function isPromise(object) {
      return object && object.then && typeof object.then === "function";
    }
    var TENSORFLOWJS_FLAGS_PREFIX = "tfjsflags";
    var Environment = (
      /** @class */
      function() {
        function Environment2(global2) {
          this.global = global2;
          this.flags = {};
          this.flagRegistry = {};
          this.urlFlags = {};
          this.getQueryParams = getQueryParams;
          this.populateURLFlags();
        }
        Environment2.prototype.setPlatform = function(platformName, platform) {
          if (this.platform != null) {
            if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
              console.warn("Platform ".concat(this.platformName, " has already been set. ") + "Overwriting the platform with ".concat(platformName, "."));
            }
          }
          this.platformName = platformName;
          this.platform = platform;
        };
        Environment2.prototype.registerFlag = function(flagName, evaluationFn, setHook) {
          this.flagRegistry[flagName] = { evaluationFn, setHook };
          if (this.urlFlags[flagName] != null) {
            var flagValue = this.urlFlags[flagName];
            if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
              console.warn("Setting feature override from URL ".concat(flagName, ": ").concat(flagValue, "."));
            }
            this.set(flagName, flagValue);
          }
        };
        Environment2.prototype.getAsync = function(flagName) {
          return __awaiter(this, void 0, void 0, function() {
            var _a, _b;
            return __generator(this, function(_c) {
              switch (_c.label) {
                case 0:
                  if (flagName in this.flags) {
                    return [2, this.flags[flagName]];
                  }
                  _a = this.flags;
                  _b = flagName;
                  return [4, this.evaluateFlag(flagName)];
                case 1:
                  _a[_b] = _c.sent();
                  return [2, this.flags[flagName]];
              }
            });
          });
        };
        Environment2.prototype.get = function(flagName) {
          if (flagName in this.flags) {
            return this.flags[flagName];
          }
          var flagValue = this.evaluateFlag(flagName);
          if (isPromise(flagValue)) {
            throw new Error("Flag ".concat(flagName, " cannot be synchronously evaluated. ") + "Please use getAsync() instead.");
          }
          this.flags[flagName] = flagValue;
          return this.flags[flagName];
        };
        Environment2.prototype.getNumber = function(flagName) {
          return this.get(flagName);
        };
        Environment2.prototype.getBool = function(flagName) {
          return this.get(flagName);
        };
        Environment2.prototype.getString = function(flagName) {
          return this.get(flagName);
        };
        Environment2.prototype.getFlags = function() {
          return this.flags;
        };
        Object.defineProperty(Environment2.prototype, "features", {
          // For backwards compatibility.
          get: function() {
            return this.flags;
          },
          enumerable: false,
          configurable: true
        });
        Environment2.prototype.set = function(flagName, value) {
          if (this.flagRegistry[flagName] == null) {
            throw new Error("Cannot set flag ".concat(flagName, " as it has not been registered."));
          }
          this.flags[flagName] = value;
          if (this.flagRegistry[flagName].setHook != null) {
            this.flagRegistry[flagName].setHook(value);
          }
        };
        Environment2.prototype.evaluateFlag = function(flagName) {
          if (this.flagRegistry[flagName] == null) {
            throw new Error("Cannot evaluate flag '".concat(flagName, "': no evaluation function found."));
          }
          return this.flagRegistry[flagName].evaluationFn();
        };
        Environment2.prototype.setFlags = function(flags) {
          this.flags = Object.assign({}, flags);
        };
        Environment2.prototype.reset = function() {
          this.flags = {};
          this.urlFlags = {};
          this.populateURLFlags();
        };
        Environment2.prototype.populateURLFlags = function() {
          var _this = this;
          if (typeof this.global === "undefined" || typeof this.global.location === "undefined" || typeof this.global.location.search === "undefined") {
            return;
          }
          var urlParams = this.getQueryParams(this.global.location.search);
          if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {
            var keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(",");
            keyValues.forEach(function(keyValue) {
              var _a = __read(keyValue.split(":"), 2), key = _a[0], value = _a[1];
              _this.urlFlags[key] = parseValue(key, value);
            });
          }
        };
        return Environment2;
      }()
    );
    function getQueryParams(queryString) {
      var params = {};
      queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, function(s) {
        var t = [];
        for (var _i = 1; _i < arguments.length; _i++) {
          t[_i - 1] = arguments[_i];
        }
        decodeParam(params, t[0], t[1]);
        return t.join("=");
      });
      return params;
    }
    function decodeParam(params, name, value) {
      params[decodeURIComponent(name)] = decodeURIComponent(value || "");
    }
    function parseValue(flagName, value) {
      var lowerCaseValue = value.toLowerCase();
      if (lowerCaseValue === "true" || lowerCaseValue === "false") {
        return lowerCaseValue === "true";
      } else if ("".concat(+lowerCaseValue) === lowerCaseValue) {
        return +lowerCaseValue;
      } else {
        return value;
      }
    }
    function env() {
      return ENV;
    }
    var ENV = null;
    function setEnvironmentGlobal(environment) {
      ENV = environment;
    }
    var globalNameSpace;
    function getGlobalNamespace() {
      if (globalNameSpace == null) {
        var ns = void 0;
        if (typeof window !== "undefined") {
          ns = window;
        } else if (typeof global !== "undefined") {
          ns = global;
        } else if (typeof process !== "undefined") {
          ns = process;
        } else if (typeof self !== "undefined") {
          ns = self;
        } else {
          throw new Error("Could not find a global object");
        }
        globalNameSpace = ns;
      }
      return globalNameSpace;
    }
    function getGlobalMap() {
      var ns = getGlobalNamespace();
      if (ns._tfGlobals == null) {
        ns._tfGlobals = /* @__PURE__ */ new Map();
      }
      return ns._tfGlobals;
    }
    function getGlobal(key, init) {
      var globalMap = getGlobalMap();
      if (globalMap.has(key)) {
        return globalMap.get(key);
      } else {
        var singleton = init();
        globalMap.set(key, singleton);
        return globalMap.get(key);
      }
    }
    var Abs = "Abs";
    var Acos = "Acos";
    var Acosh = "Acosh";
    var Add = "Add";
    var AddN = "AddN";
    var All = "All";
    var Any = "Any";
    var ArgMax = "ArgMax";
    var ArgMin = "ArgMin";
    var Asin = "Asin";
    var Asinh = "Asinh";
    var Atan = "Atan";
    var Atanh = "Atanh";
    var Atan2 = "Atan2";
    var AvgPool = "AvgPool";
    var AvgPool3D = "AvgPool3D";
    var BatchMatMul = "BatchMatMul";
    var BatchToSpaceND = "BatchToSpaceND";
    var Bincount = "Bincount";
    var BitwiseAnd = "BitwiseAnd";
    var BroadcastArgs = "BroadcastArgs";
    var Cast = "Cast";
    var Ceil = "Ceil";
    var ClipByValue = "ClipByValue";
    var Complex = "Complex";
    var ComplexAbs = "ComplexAbs";
    var Concat = "Concat";
    var Conv2D = "Conv2D";
    var Conv2DBackpropFilter = "Conv2DBackpropFilter";
    var Conv2DBackpropInput = "Conv2DBackpropInput";
    var Conv3D = "Conv3D";
    var Conv3DBackpropInputV2 = "Conv3DBackpropInputV2";
    var Cos = "Cos";
    var Cosh = "Cosh";
    var Cumprod = "Cumprod";
    var Cumsum = "Cumsum";
    var CropAndResize = "CropAndResize";
    var DenseBincount = "DenseBincount";
    var DepthToSpace = "DepthToSpace";
    var DepthwiseConv2dNative = "DepthwiseConv2dNative";
    var DepthwiseConv2dNativeBackpropFilter = "DepthwiseConv2dNativeBackpropFilter";
    var DepthwiseConv2dNativeBackpropInput = "DepthwiseConv2dNativeBackpropInput";
    var Diag = "Diag";
    var Dilation2D = "Dilation2D";
    var RealDiv = "RealDiv";
    var Einsum = "Einsum";
    var Elu = "Elu";
    var Erf = "Erf";
    var Equal = "Equal";
    var Exp = "Exp";
    var ExpandDims = "ExpandDims";
    var Expm1 = "Expm1";
    var FFT = "FFT";
    var Fill = "Fill";
    var FlipLeftRight = "FlipLeftRight";
    var Floor = "Floor";
    var FloorDiv = "FloorDiv";
    var FusedBatchNorm = "FusedBatchNorm";
    var GatherV2 = "GatherV2";
    var GatherNd = "GatherNd";
    var Greater = "Greater";
    var GreaterEqual = "GreaterEqual";
    var Identity = "Identity";
    var IFFT = "IFFT";
    var Imag = "Imag";
    var IsFinite = "IsFinite";
    var IsInf = "IsInf";
    var IsNan = "IsNan";
    var LeakyRelu = "LeakyRelu";
    var Less = "Less";
    var LessEqual = "LessEqual";
    var LinSpace = "LinSpace";
    var Log = "Log";
    var Log1p = "Log1p";
    var LogicalAnd = "LogicalAnd";
    var LogicalNot = "LogicalNot";
    var LogicalOr = "LogicalOr";
    var LRN = "LRN";
    var Max = "Max";
    var Maximum = "Maximum";
    var MaxPool = "MaxPool";
    var MaxPool3D = "MaxPool3D";
    var MaxPoolWithArgmax = "MaxPoolWithArgmax";
    var Mean = "Mean";
    var Min = "Min";
    var Minimum = "Minimum";
    var MirrorPad = "MirrorPad";
    var Mod = "Mod";
    var Multinomial = "Multinomial";
    var Multiply = "Multiply";
    var Neg = "Neg";
    var NotEqual = "NotEqual";
    var NonMaxSuppressionV3 = "NonMaxSuppressionV3";
    var NonMaxSuppressionV4 = "NonMaxSuppressionV4";
    var NonMaxSuppressionV5 = "NonMaxSuppressionV5";
    var OnesLike = "OnesLike";
    var OneHot = "OneHot";
    var Pack = "Pack";
    var PadV2 = "PadV2";
    var Pow = "Pow";
    var Prelu = "Prelu";
    var Prod = "Prod";
    var RaggedGather = "RaggedGather";
    var RaggedRange = "RaggedRange";
    var RaggedTensorToTensor = "RaggedTensorToTensor";
    var Range = "Range";
    var Real = "Real";
    var Reciprocal = "Reciprocal";
    var Relu = "Relu";
    var Reshape = "Reshape";
    var ResizeNearestNeighbor = "ResizeNearestNeighbor";
    var ResizeBilinear = "ResizeBilinear";
    var Relu6 = "Relu6";
    var Reverse = "Reverse";
    var Round = "Round";
    var Rsqrt = "Rsqrt";
    var ScatterNd = "ScatterNd";
    var TensorScatterUpdate = "TensorScatterUpdate";
    var SearchSorted = "SearchSorted";
    var Select = "Select";
    var Selu = "Selu";
    var Slice = "Slice";
    var Sin = "Sin";
    var Sinh = "Sinh";
    var Sign = "Sign";
    var Sigmoid = "Sigmoid";
    var Softplus = "Softplus";
    var Sqrt = "Sqrt";
    var Sum = "Sum";
    var SpaceToBatchND = "SpaceToBatchND";
    var SplitV = "SplitV";
    var Softmax = "Softmax";
    var SparseFillEmptyRows = "SparseFillEmptyRows";
    var SparseReshape = "SparseReshape";
    var SparseSegmentMean = "SparseSegmentMean";
    var SparseSegmentSum = "SparseSegmentSum";
    var SparseToDense = "SparseToDense";
    var SquaredDifference = "SquaredDifference";
    var StaticRegexReplace = "StaticRegexReplace";
    var StridedSlice = "StridedSlice";
    var StringNGrams = "StringNGrams";
    var StringSplit = "StringSplit";
    var StringToHashBucketFast = "StringToHashBucketFast";
    var Sub = "Sub";
    var Tan = "Tan";
    var Tanh = "Tanh";
    var Tile = "Tile";
    var TopK = "TopK";
    var Transform = "Transform";
    var Transpose = "Transpose";
    var Unique = "Unique";
    var Unpack = "Unpack";
    var UnsortedSegmentSum = "UnsortedSegmentSum";
    var ZerosLike = "ZerosLike";
    var Step = "Step";
    var RotateWithOffset = "RotateWithOffset";
    var _FusedMatMul = "_FusedMatMul";
    var FusedConv2D = "FusedConv2D";
    var FusedDepthwiseConv2D = "FusedDepthwiseConv2D";
    function warn() {
      var msg = [];
      for (var _i = 0; _i < arguments.length; _i++) {
        msg[_i] = arguments[_i];
      }
      if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
        console.warn.apply(console, __spreadArray([], __read(msg), false));
      }
    }
    var kernelRegistry = getGlobal("kernelRegistry", function() {
      return /* @__PURE__ */ new Map();
    });
    var gradRegistry = getGlobal("gradRegistry", function() {
      return /* @__PURE__ */ new Map();
    });
    function getKernel(kernelName, backendName) {
      var key = makeKey(kernelName, backendName);
      return kernelRegistry.get(key);
    }
    function getGradient(kernelName) {
      return gradRegistry.get(kernelName);
    }
    function getKernelsForBackend(backendName) {
      var it = kernelRegistry.entries();
      var result = [];
      while (true) {
        var _a = it.next(), done = _a.done, value = _a.value;
        if (done) {
          break;
        }
        var _b = __read(value, 2), key = _b[0], config = _b[1];
        var _c = __read(key.split("_"), 1), backend2 = _c[0];
        if (backend2 === backendName) {
          result.push(config);
        }
      }
      return result;
    }
    function makeKey(kernelName, backendName) {
      return "".concat(backendName, "_").concat(kernelName);
    }
    function isTypedArrayBrowser(a) {
      return a instanceof Float32Array || a instanceof Int32Array || a instanceof Uint8Array || a instanceof Uint8ClampedArray;
    }
    var commonjsGlobal = typeof globalThis !== "undefined" ? globalThis : typeof window !== "undefined" ? window : typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : {};
    function getDefaultExportFromCjs(x) {
      return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, "default") ? x["default"] : x;
    }
    function getAugmentedNamespace(n) {
      if (n.__esModule)
        return n;
      var f = n.default;
      if (typeof f == "function") {
        var a = function a2() {
          if (this instanceof a2) {
            var args = [null];
            args.push.apply(args, arguments);
            var Ctor = Function.bind.apply(f, args);
            return new Ctor();
          }
          return f.apply(this, arguments);
        };
        a.prototype = f.prototype;
      } else
        a = {};
      Object.defineProperty(a, "__esModule", { value: true });
      Object.keys(n).forEach(function(k) {
        var d = Object.getOwnPropertyDescriptor(n, k);
        Object.defineProperty(a, k, d.get ? d : {
          enumerable: true,
          get: function() {
            return n[k];
          }
        });
      });
      return a;
    }
    var long = Long$1;
    var wasm = null;
    try {
      wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([
        0,
        97,
        115,
        109,
        1,
        0,
        0,
        0,
        1,
        13,
        2,
        96,
        0,
        1,
        127,
        96,
        4,
        127,
        127,
        127,
        127,
        1,
        127,
        3,
        7,
        6,
        0,
        1,
        1,
        1,
        1,
        1,
        6,
        6,
        1,
        127,
        1,
        65,
        0,
        11,
        7,
        50,
        6,
        3,
        109,
        117,
        108,
        0,
        1,
        5,
        100,
        105,
        118,
        95,
        115,
        0,
        2,
        5,
        100,
        105,
        118,
        95,
        117,
        0,
        3,
        5,
        114,
        101,
        109,
        95,
        115,
        0,
        4,
        5,
        114,
        101,
        109,
        95,
        117,
        0,
        5,
        8,
        103,
        101,
        116,
        95,
        104,
        105,
        103,
        104,
        0,
        0,
        10,
        191,
        1,
        6,
        4,
        0,
        35,
        0,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        126,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        127,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        128,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        129,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        130,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11
      ])), {}).exports;
    } catch (e) {
    }
    function Long$1(low, high, unsigned) {
      this.low = low | 0;
      this.high = high | 0;
      this.unsigned = !!unsigned;
    }
    Long$1.prototype.__isLong__;
    Object.defineProperty(Long$1.prototype, "__isLong__", { value: true });
    function isLong(obj) {
      return (obj && obj["__isLong__"]) === true;
    }
    Long$1.isLong = isLong;
    var INT_CACHE = {};
    var UINT_CACHE = {};
    function fromInt(value, unsigned) {
      var obj, cachedObj, cache;
      if (unsigned) {
        value >>>= 0;
        if (cache = 0 <= value && value < 256) {
          cachedObj = UINT_CACHE[value];
          if (cachedObj)
            return cachedObj;
        }
        obj = fromBits(value, (value | 0) < 0 ? -1 : 0, true);
        if (cache)
          UINT_CACHE[value] = obj;
        return obj;
      } else {
        value |= 0;
        if (cache = -128 <= value && value < 128) {
          cachedObj = INT_CACHE[value];
          if (cachedObj)
            return cachedObj;
        }
        obj = fromBits(value, value < 0 ? -1 : 0, false);
        if (cache)
          INT_CACHE[value] = obj;
        return obj;
      }
    }
    Long$1.fromInt = fromInt;
    function fromNumber(value, unsigned) {
      if (isNaN(value))
        return unsigned ? UZERO : ZERO;
      if (unsigned) {
        if (value < 0)
          return UZERO;
        if (value >= TWO_PWR_64_DBL)
          return MAX_UNSIGNED_VALUE;
      } else {
        if (value <= -TWO_PWR_63_DBL)
          return MIN_VALUE;
        if (value + 1 >= TWO_PWR_63_DBL)
          return MAX_VALUE;
      }
      if (value < 0)
        return fromNumber(-value, unsigned).neg();
      return fromBits(value % TWO_PWR_32_DBL | 0, value / TWO_PWR_32_DBL | 0, unsigned);
    }
    Long$1.fromNumber = fromNumber;
    function fromBits(lowBits, highBits, unsigned) {
      return new Long$1(lowBits, highBits, unsigned);
    }
    Long$1.fromBits = fromBits;
    var pow_dbl = Math.pow;
    function fromString(str, unsigned, radix) {
      if (str.length === 0)
        throw Error("empty string");
      if (str === "NaN" || str === "Infinity" || str === "+Infinity" || str === "-Infinity")
        return ZERO;
      if (typeof unsigned === "number") {
        radix = unsigned, unsigned = false;
      } else {
        unsigned = !!unsigned;
      }
      radix = radix || 10;
      if (radix < 2 || 36 < radix)
        throw RangeError("radix");
      var p;
      if ((p = str.indexOf("-")) > 0)
        throw Error("interior hyphen");
      else if (p === 0) {
        return fromString(str.substring(1), unsigned, radix).neg();
      }
      var radixToPower = fromNumber(pow_dbl(radix, 8));
      var result = ZERO;
      for (var i = 0; i < str.length; i += 8) {
        var size = Math.min(8, str.length - i), value = parseInt(str.substring(i, i + size), radix);
        if (size < 8) {
          var power = fromNumber(pow_dbl(radix, size));
          result = result.mul(power).add(fromNumber(value));
        } else {
          result = result.mul(radixToPower);
          result = result.add(fromNumber(value));
        }
      }
      result.unsigned = unsigned;
      return result;
    }
    Long$1.fromString = fromString;
    function fromValue(val, unsigned) {
      if (typeof val === "number")
        return fromNumber(val, unsigned);
      if (typeof val === "string")
        return fromString(val, unsigned);
      return fromBits(val.low, val.high, typeof unsigned === "boolean" ? unsigned : val.unsigned);
    }
    Long$1.fromValue = fromValue;
    var TWO_PWR_16_DBL = 1 << 16;
    var TWO_PWR_24_DBL = 1 << 24;
    var TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;
    var TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;
    var TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;
    var TWO_PWR_24 = fromInt(TWO_PWR_24_DBL);
    var ZERO = fromInt(0);
    Long$1.ZERO = ZERO;
    var UZERO = fromInt(0, true);
    Long$1.UZERO = UZERO;
    var ONE = fromInt(1);
    Long$1.ONE = ONE;
    var UONE = fromInt(1, true);
    Long$1.UONE = UONE;
    var NEG_ONE = fromInt(-1);
    Long$1.NEG_ONE = NEG_ONE;
    var MAX_VALUE = fromBits(4294967295 | 0, 2147483647 | 0, false);
    Long$1.MAX_VALUE = MAX_VALUE;
    var MAX_UNSIGNED_VALUE = fromBits(4294967295 | 0, 4294967295 | 0, true);
    Long$1.MAX_UNSIGNED_VALUE = MAX_UNSIGNED_VALUE;
    var MIN_VALUE = fromBits(0, 2147483648 | 0, false);
    Long$1.MIN_VALUE = MIN_VALUE;
    var LongPrototype = Long$1.prototype;
    LongPrototype.toInt = function toInt() {
      return this.unsigned ? this.low >>> 0 : this.low;
    };
    LongPrototype.toNumber = function toNumber() {
      if (this.unsigned)
        return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);
      return this.high * TWO_PWR_32_DBL + (this.low >>> 0);
    };
    LongPrototype.toString = function toString(radix) {
      radix = radix || 10;
      if (radix < 2 || 36 < radix)
        throw RangeError("radix");
      if (this.isZero())
        return "0";
      if (this.isNegative()) {
        if (this.eq(MIN_VALUE)) {
          var radixLong = fromNumber(radix), div2 = this.div(radixLong), rem1 = div2.mul(radixLong).sub(this);
          return div2.toString(radix) + rem1.toInt().toString(radix);
        } else
          return "-" + this.neg().toString(radix);
      }
      var radixToPower = fromNumber(pow_dbl(radix, 6), this.unsigned), rem = this;
      var result = "";
      while (true) {
        var remDiv = rem.div(radixToPower), intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0, digits = intval.toString(radix);
        rem = remDiv;
        if (rem.isZero())
          return digits + result;
        else {
          while (digits.length < 6)
            digits = "0" + digits;
          result = "" + digits + result;
        }
      }
    };
    LongPrototype.getHighBits = function getHighBits() {
      return this.high;
    };
    LongPrototype.getHighBitsUnsigned = function getHighBitsUnsigned() {
      return this.high >>> 0;
    };
    LongPrototype.getLowBits = function getLowBits() {
      return this.low;
    };
    LongPrototype.getLowBitsUnsigned = function getLowBitsUnsigned() {
      return this.low >>> 0;
    };
    LongPrototype.getNumBitsAbs = function getNumBitsAbs() {
      if (this.isNegative())
        return this.eq(MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();
      var val = this.high != 0 ? this.high : this.low;
      for (var bit = 31; bit > 0; bit--)
        if ((val & 1 << bit) != 0)
          break;
      return this.high != 0 ? bit + 33 : bit + 1;
    };
    LongPrototype.isZero = function isZero() {
      return this.high === 0 && this.low === 0;
    };
    LongPrototype.eqz = LongPrototype.isZero;
    LongPrototype.isNegative = function isNegative() {
      return !this.unsigned && this.high < 0;
    };
    LongPrototype.isPositive = function isPositive() {
      return this.unsigned || this.high >= 0;
    };
    LongPrototype.isOdd = function isOdd() {
      return (this.low & 1) === 1;
    };
    LongPrototype.isEven = function isEven() {
      return (this.low & 1) === 0;
    };
    LongPrototype.equals = function equals(other) {
      if (!isLong(other))
        other = fromValue(other);
      if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1)
        return false;
      return this.high === other.high && this.low === other.low;
    };
    LongPrototype.eq = LongPrototype.equals;
    LongPrototype.notEquals = function notEquals(other) {
      return !this.eq(
        /* validates */
        other
      );
    };
    LongPrototype.neq = LongPrototype.notEquals;
    LongPrototype.ne = LongPrototype.notEquals;
    LongPrototype.lessThan = function lessThan(other) {
      return this.comp(
        /* validates */
        other
      ) < 0;
    };
    LongPrototype.lt = LongPrototype.lessThan;
    LongPrototype.lessThanOrEqual = function lessThanOrEqual(other) {
      return this.comp(
        /* validates */
        other
      ) <= 0;
    };
    LongPrototype.lte = LongPrototype.lessThanOrEqual;
    LongPrototype.le = LongPrototype.lessThanOrEqual;
    LongPrototype.greaterThan = function greaterThan(other) {
      return this.comp(
        /* validates */
        other
      ) > 0;
    };
    LongPrototype.gt = LongPrototype.greaterThan;
    LongPrototype.greaterThanOrEqual = function greaterThanOrEqual(other) {
      return this.comp(
        /* validates */
        other
      ) >= 0;
    };
    LongPrototype.gte = LongPrototype.greaterThanOrEqual;
    LongPrototype.ge = LongPrototype.greaterThanOrEqual;
    LongPrototype.compare = function compare(other) {
      if (!isLong(other))
        other = fromValue(other);
      if (this.eq(other))
        return 0;
      var thisNeg = this.isNegative(), otherNeg = other.isNegative();
      if (thisNeg && !otherNeg)
        return -1;
      if (!thisNeg && otherNeg)
        return 1;
      if (!this.unsigned)
        return this.sub(other).isNegative() ? -1 : 1;
      return other.high >>> 0 > this.high >>> 0 || other.high === this.high && other.low >>> 0 > this.low >>> 0 ? -1 : 1;
    };
    LongPrototype.comp = LongPrototype.compare;
    LongPrototype.negate = function negate() {
      if (!this.unsigned && this.eq(MIN_VALUE))
        return MIN_VALUE;
      return this.not().add(ONE);
    };
    LongPrototype.neg = LongPrototype.negate;
    LongPrototype.add = function add2(addend) {
      if (!isLong(addend))
        addend = fromValue(addend);
      var a48 = this.high >>> 16;
      var a32 = this.high & 65535;
      var a16 = this.low >>> 16;
      var a00 = this.low & 65535;
      var b48 = addend.high >>> 16;
      var b32 = addend.high & 65535;
      var b16 = addend.low >>> 16;
      var b00 = addend.low & 65535;
      var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
      c00 += a00 + b00;
      c16 += c00 >>> 16;
      c00 &= 65535;
      c16 += a16 + b16;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c32 += a32 + b32;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c48 += a48 + b48;
      c48 &= 65535;
      return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
    };
    LongPrototype.subtract = function subtract(subtrahend) {
      if (!isLong(subtrahend))
        subtrahend = fromValue(subtrahend);
      return this.add(subtrahend.neg());
    };
    LongPrototype.sub = LongPrototype.subtract;
    LongPrototype.multiply = function multiply(multiplier) {
      if (this.isZero())
        return ZERO;
      if (!isLong(multiplier))
        multiplier = fromValue(multiplier);
      if (wasm) {
        var low = wasm.mul(this.low, this.high, multiplier.low, multiplier.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      if (multiplier.isZero())
        return ZERO;
      if (this.eq(MIN_VALUE))
        return multiplier.isOdd() ? MIN_VALUE : ZERO;
      if (multiplier.eq(MIN_VALUE))
        return this.isOdd() ? MIN_VALUE : ZERO;
      if (this.isNegative()) {
        if (multiplier.isNegative())
          return this.neg().mul(multiplier.neg());
        else
          return this.neg().mul(multiplier).neg();
      } else if (multiplier.isNegative())
        return this.mul(multiplier.neg()).neg();
      if (this.lt(TWO_PWR_24) && multiplier.lt(TWO_PWR_24))
        return fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned);
      var a48 = this.high >>> 16;
      var a32 = this.high & 65535;
      var a16 = this.low >>> 16;
      var a00 = this.low & 65535;
      var b48 = multiplier.high >>> 16;
      var b32 = multiplier.high & 65535;
      var b16 = multiplier.low >>> 16;
      var b00 = multiplier.low & 65535;
      var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
      c00 += a00 * b00;
      c16 += c00 >>> 16;
      c00 &= 65535;
      c16 += a16 * b00;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c16 += a00 * b16;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c32 += a32 * b00;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c32 += a16 * b16;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c32 += a00 * b32;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;
      c48 &= 65535;
      return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
    };
    LongPrototype.mul = LongPrototype.multiply;
    LongPrototype.divide = function divide(divisor) {
      if (!isLong(divisor))
        divisor = fromValue(divisor);
      if (divisor.isZero())
        throw Error("division by zero");
      if (wasm) {
        if (!this.unsigned && this.high === -2147483648 && divisor.low === -1 && divisor.high === -1) {
          return this;
        }
        var low = (this.unsigned ? wasm.div_u : wasm.div_s)(this.low, this.high, divisor.low, divisor.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      if (this.isZero())
        return this.unsigned ? UZERO : ZERO;
      var approx, rem, res;
      if (!this.unsigned) {
        if (this.eq(MIN_VALUE)) {
          if (divisor.eq(ONE) || divisor.eq(NEG_ONE))
            return MIN_VALUE;
          else if (divisor.eq(MIN_VALUE))
            return ONE;
          else {
            var halfThis = this.shr(1);
            approx = halfThis.div(divisor).shl(1);
            if (approx.eq(ZERO)) {
              return divisor.isNegative() ? ONE : NEG_ONE;
            } else {
              rem = this.sub(divisor.mul(approx));
              res = approx.add(rem.div(divisor));
              return res;
            }
          }
        } else if (divisor.eq(MIN_VALUE))
          return this.unsigned ? UZERO : ZERO;
        if (this.isNegative()) {
          if (divisor.isNegative())
            return this.neg().div(divisor.neg());
          return this.neg().div(divisor).neg();
        } else if (divisor.isNegative())
          return this.div(divisor.neg()).neg();
        res = ZERO;
      } else {
        if (!divisor.unsigned)
          divisor = divisor.toUnsigned();
        if (divisor.gt(this))
          return UZERO;
        if (divisor.gt(this.shru(1)))
          return UONE;
        res = UZERO;
      }
      rem = this;
      while (rem.gte(divisor)) {
        approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));
        var log2 = Math.ceil(Math.log(approx) / Math.LN2), delta = log2 <= 48 ? 1 : pow_dbl(2, log2 - 48), approxRes = fromNumber(approx), approxRem = approxRes.mul(divisor);
        while (approxRem.isNegative() || approxRem.gt(rem)) {
          approx -= delta;
          approxRes = fromNumber(approx, this.unsigned);
          approxRem = approxRes.mul(divisor);
        }
        if (approxRes.isZero())
          approxRes = ONE;
        res = res.add(approxRes);
        rem = rem.sub(approxRem);
      }
      return res;
    };
    LongPrototype.div = LongPrototype.divide;
    LongPrototype.modulo = function modulo(divisor) {
      if (!isLong(divisor))
        divisor = fromValue(divisor);
      if (wasm) {
        var low = (this.unsigned ? wasm.rem_u : wasm.rem_s)(this.low, this.high, divisor.low, divisor.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      return this.sub(this.div(divisor).mul(divisor));
    };
    LongPrototype.mod = LongPrototype.modulo;
    LongPrototype.rem = LongPrototype.modulo;
    LongPrototype.not = function not() {
      return fromBits(~this.low, ~this.high, this.unsigned);
    };
    LongPrototype.and = function and(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low & other.low, this.high & other.high, this.unsigned);
    };
    LongPrototype.or = function or(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low | other.low, this.high | other.high, this.unsigned);
    };
    LongPrototype.xor = function xor(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);
    };
    LongPrototype.shiftLeft = function shiftLeft(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      if ((numBits &= 63) === 0)
        return this;
      else if (numBits < 32)
        return fromBits(this.low << numBits, this.high << numBits | this.low >>> 32 - numBits, this.unsigned);
      else
        return fromBits(0, this.low << numBits - 32, this.unsigned);
    };
    LongPrototype.shl = LongPrototype.shiftLeft;
    LongPrototype.shiftRight = function shiftRight(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      if ((numBits &= 63) === 0)
        return this;
      else if (numBits < 32)
        return fromBits(this.low >>> numBits | this.high << 32 - numBits, this.high >> numBits, this.unsigned);
      else
        return fromBits(this.high >> numBits - 32, this.high >= 0 ? 0 : -1, this.unsigned);
    };
    LongPrototype.shr = LongPrototype.shiftRight;
    LongPrototype.shiftRightUnsigned = function shiftRightUnsigned(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      numBits &= 63;
      if (numBits === 0)
        return this;
      else {
        var high = this.high;
        if (numBits < 32) {
          var low = this.low;
          return fromBits(low >>> numBits | high << 32 - numBits, high >>> numBits, this.unsigned);
        } else if (numBits === 32)
          return fromBits(high, 0, this.unsigned);
        else
          return fromBits(high >>> numBits - 32, 0, this.unsigned);
      }
    };
    LongPrototype.shru = LongPrototype.shiftRightUnsigned;
    LongPrototype.shr_u = LongPrototype.shiftRightUnsigned;
    LongPrototype.toSigned = function toSigned() {
      if (!this.unsigned)
        return this;
      return fromBits(this.low, this.high, false);
    };
    LongPrototype.toUnsigned = function toUnsigned() {
      if (this.unsigned)
        return this;
      return fromBits(this.low, this.high, true);
    };
    LongPrototype.toBytes = function toBytes(le) {
      return le ? this.toBytesLE() : this.toBytesBE();
    };
    LongPrototype.toBytesLE = function toBytesLE() {
      var hi = this.high, lo = this.low;
      return [
        lo & 255,
        lo >>> 8 & 255,
        lo >>> 16 & 255,
        lo >>> 24,
        hi & 255,
        hi >>> 8 & 255,
        hi >>> 16 & 255,
        hi >>> 24
      ];
    };
    LongPrototype.toBytesBE = function toBytesBE() {
      var hi = this.high, lo = this.low;
      return [
        hi >>> 24,
        hi >>> 16 & 255,
        hi >>> 8 & 255,
        hi & 255,
        lo >>> 24,
        lo >>> 16 & 255,
        lo >>> 8 & 255,
        lo & 255
      ];
    };
    Long$1.fromBytes = function fromBytes(bytes, unsigned, le) {
      return le ? Long$1.fromBytesLE(bytes, unsigned) : Long$1.fromBytesBE(bytes, unsigned);
    };
    Long$1.fromBytesLE = function fromBytesLE(bytes, unsigned) {
      return new Long$1(bytes[0] | bytes[1] << 8 | bytes[2] << 16 | bytes[3] << 24, bytes[4] | bytes[5] << 8 | bytes[6] << 16 | bytes[7] << 24, unsigned);
    };
    Long$1.fromBytesBE = function fromBytesBE(bytes, unsigned) {
      return new Long$1(bytes[4] << 24 | bytes[5] << 16 | bytes[6] << 8 | bytes[7], bytes[0] << 24 | bytes[1] << 16 | bytes[2] << 8 | bytes[3], unsigned);
    };
    var long$1 = /* @__PURE__ */ getDefaultExportFromCjs(long);
    var LongExports = /* @__PURE__ */ _mergeNamespaces({
      __proto__: null,
      default: long$1
    }, [long]);
    var Long = (
      // tslint:disable-next-line
      long$1 || LongExports
    );
    function hexToLong(hex) {
      return Long.fromString(hex, true, 16);
    }
    hexToLong("c3a5c85c97cb3127");
    hexToLong("b492b66fbe98f273");
    hexToLong("9ae16a3b2f90404f");
    function noConversionNeeded(a, dtype) {
      return a instanceof Float32Array && dtype === "float32" || a instanceof Int32Array && dtype === "int32" || a instanceof Uint8Array && dtype === "bool";
    }
    function toTypedArray(a, dtype) {
      if (dtype === "string") {
        throw new Error("Cannot convert a string[] to a TypedArray");
      }
      if (Array.isArray(a)) {
        a = flatten(a);
      }
      if (env().getBool("DEBUG")) {
        checkConversionForErrors(a, dtype);
      }
      if (noConversionNeeded(a, dtype)) {
        return a;
      }
      if (dtype == null || dtype === "float32" || dtype === "complex64") {
        return new Float32Array(a);
      } else if (dtype === "int32") {
        return new Int32Array(a);
      } else if (dtype === "bool") {
        var bool = new Uint8Array(a.length);
        for (var i = 0; i < bool.length; ++i) {
          if (Math.round(a[i]) !== 0) {
            bool[i] = 1;
          }
        }
        return bool;
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
    }
    function now() {
      return env().platform.now();
    }
    function encodeString(s, encoding) {
      if (encoding === void 0) {
        encoding = "utf-8";
      }
      encoding = encoding || "utf-8";
      return env().platform.encode(s, encoding);
    }
    function decodeString(bytes, encoding) {
      if (encoding === void 0) {
        encoding = "utf-8";
      }
      encoding = encoding || "utf-8";
      return env().platform.decode(bytes, encoding);
    }
    function isTypedArray(a) {
      if (env().platform.isTypedArray != null) {
        return env().platform.isTypedArray(a);
      } else {
        return isTypedArrayBrowser(a);
      }
    }
    function flatten(arr, result, skipTypedArray) {
      var e_1, _a;
      if (result === void 0) {
        result = [];
      }
      if (skipTypedArray === void 0) {
        skipTypedArray = false;
      }
      if (result == null) {
        result = [];
      }
      if (typeof arr === "boolean" || typeof arr === "number" || typeof arr === "string" || isPromise(arr) || arr == null || isTypedArray(arr) && skipTypedArray) {
        result.push(arr);
      } else if (Array.isArray(arr) || isTypedArray(arr)) {
        for (var i = 0; i < arr.length; ++i) {
          flatten(arr[i], result, skipTypedArray);
        }
      } else {
        var maxIndex = -1;
        try {
          for (var _b = __values(Object.keys(arr)), _c = _b.next(); !_c.done; _c = _b.next()) {
            var key = _c.value;
            if (/^([1-9]+[0-9]*|0)$/.test(key)) {
              maxIndex = Math.max(maxIndex, Number(key));
            }
          }
        } catch (e_1_1) {
          e_1 = { error: e_1_1 };
        } finally {
          try {
            if (_c && !_c.done && (_a = _b.return))
              _a.call(_b);
          } finally {
            if (e_1)
              throw e_1.error;
          }
        }
        for (var i = 0; i <= maxIndex; i++) {
          flatten(arr[i], result, skipTypedArray);
        }
      }
      return result;
    }
    var Profiler = (
      /** @class */
      function() {
        function Profiler2(backendTimer, logger) {
          this.backendTimer = backendTimer;
          this.logger = logger;
          if (logger == null) {
            this.logger = new Logger();
          }
        }
        Profiler2.prototype.profileKernel = function(kernelName, inputs, f) {
          var e_1, _a;
          var outputs;
          var holdResultWrapperFn = function() {
            outputs = f();
          };
          var timer;
          var start = now();
          if (this.backendTimer.timerAvailable()) {
            timer = this.backendTimer.time(holdResultWrapperFn);
          } else {
            holdResultWrapperFn();
            try {
              for (var outputs_1 = __values(outputs), outputs_1_1 = outputs_1.next(); !outputs_1_1.done; outputs_1_1 = outputs_1.next()) {
                var output = outputs_1_1.value;
                output.dataSync();
              }
            } catch (e_1_1) {
              e_1 = { error: e_1_1 };
            } finally {
              try {
                if (outputs_1_1 && !outputs_1_1.done && (_a = outputs_1.return))
                  _a.call(outputs_1);
              } finally {
                if (e_1)
                  throw e_1.error;
              }
            }
            timer = Promise.resolve({ kernelMs: now() - start });
          }
          if (env().getBool("CHECK_COMPUTATION_FOR_ERRORS")) {
            var _loop_1 = function(i2) {
              var output2 = outputs[i2];
              output2.data().then(function(tensorVals) {
                checkComputationForErrors(tensorVals, output2.dtype, kernelName);
              });
            };
            for (var i = 0; i < outputs.length; i++) {
              _loop_1(i);
            }
          }
          var kernelProfile = {
            kernelName,
            outputs,
            inputs,
            timeMs: timer.then(function(timing) {
              return timing.kernelMs;
            }),
            extraInfo: timer.then(function(timing) {
              return timing.getExtraProfileInfo != null ? timing.getExtraProfileInfo() : "";
            })
          };
          return kernelProfile;
        };
        Profiler2.prototype.logKernelProfile = function(kernelProfile) {
          var _this = this;
          var kernelName = kernelProfile.kernelName, outputs = kernelProfile.outputs, timeMs = kernelProfile.timeMs, inputs = kernelProfile.inputs, extraInfo = kernelProfile.extraInfo;
          outputs.forEach(function(result) {
            Promise.all([result.data(), timeMs, extraInfo]).then(function(valueContainer) {
              _this.logger.logKernelProfile(kernelName, result, valueContainer[0], valueContainer[1], inputs, valueContainer[2]);
            });
          });
        };
        return Profiler2;
      }()
    );
    function checkComputationForErrors(vals, dtype, kernelName) {
      if (dtype !== "float32") {
        return false;
      }
      for (var i = 0; i < vals.length; i++) {
        var num = vals[i];
        if (isNaN(num) || !isFinite(num)) {
          console.warn("Found ".concat(num, " in the result of '").concat(kernelName, "'"));
          return true;
        }
      }
      return false;
    }
    var Logger = (
      /** @class */
      function() {
        function Logger2() {
        }
        Logger2.prototype.logKernelProfile = function(name, result, vals, timeMs, inputs, extraInfo) {
          var time = typeof timeMs === "number" ? rightPad("".concat(timeMs, "ms"), 9) : timeMs["error"];
          var paddedName = rightPad(name, 25);
          var rank = result.rank;
          var size = result.size;
          var shape = rightPad(result.shape.toString(), 14);
          var inputShapesDescription = "";
          for (var name_1 in inputs) {
            var input = inputs[name_1];
            if (input != null) {
              var inputShape = input.shape || result.shape;
              var inputRank = inputShape.length;
              inputShapesDescription += "".concat(name_1, ": ").concat(inputRank, "D ").concat(inputRank > 0 ? inputShape : "", " ");
            }
          }
          console.log("%c".concat(paddedName, "	%c").concat(time, "	%c").concat(rank, "D ").concat(shape, "	%c").concat(size, "	%c").concat(inputShapesDescription, "	%c").concat(extraInfo), "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
        };
        return Logger2;
      }()
    );
    function getFilteredNodesXToY(tape, xs, y) {
      var tensorsFromX = {};
      var nodesFromX = {};
      for (var i = 0; i < xs.length; i++) {
        tensorsFromX[xs[i].id] = true;
      }
      for (var i = 0; i < tape.length; i++) {
        var node = tape[i];
        var nodeInputs = node.inputs;
        for (var inputName in nodeInputs) {
          var input = nodeInputs[inputName];
          var anyInputFromX = false;
          for (var j = 0; j < xs.length; j++) {
            if (tensorsFromX[input.id]) {
              node.outputs.forEach(function(output) {
                return tensorsFromX[output.id] = true;
              });
              anyInputFromX = true;
              nodesFromX[node.id] = true;
              break;
            }
          }
          if (anyInputFromX) {
            break;
          }
        }
      }
      var tensorsLeadToY = {};
      tensorsLeadToY[y.id] = true;
      var nodesToY = {};
      for (var i = tape.length - 1; i >= 0; i--) {
        var node = tape[i];
        var nodeInputs = node.inputs;
        for (var j = 0; j < node.outputs.length; j++) {
          if (tensorsLeadToY[node.outputs[j].id]) {
            for (var inputName in nodeInputs) {
              tensorsLeadToY[nodeInputs[inputName].id] = true;
              nodesToY[node.id] = true;
            }
            break;
          }
        }
      }
      var filteredTape = [];
      for (var i = 0; i < tape.length; i++) {
        var node = tape[i];
        if (nodesFromX[node.id] && nodesToY[node.id]) {
          var prunedInputs = {};
          for (var inputName in node.inputs) {
            var nodeInput = node.inputs[inputName];
            if (tensorsFromX[nodeInput.id]) {
              prunedInputs[inputName] = nodeInput;
            }
          }
          var prunedNode = Object.assign({}, node);
          prunedNode.inputs = prunedInputs;
          prunedNode.outputs = node.outputs;
          filteredTape.push(prunedNode);
        }
      }
      return filteredTape;
    }
    function backpropagateGradients(tensorAccumulatedGradientMap, filteredTape, tidy2, add2) {
      var _loop_1 = function(i2) {
        var node = filteredTape[i2];
        var dys = [];
        node.outputs.forEach(function(o) {
          var gradTensor = tensorAccumulatedGradientMap[o.id];
          if (gradTensor != null) {
            dys.push(gradTensor);
          } else {
            dys.push(null);
          }
        });
        if (node.gradient == null) {
          throw new Error("Cannot compute gradient: gradient function not found " + "for ".concat(node.kernelName, "."));
        }
        var inputGradients = node.gradient(dys);
        var _loop_2 = function(inputName2) {
          if (!(inputName2 in inputGradients)) {
            throw new Error("Cannot backprop through input ".concat(inputName2, ". ") + "Available gradients found: ".concat(Object.keys(inputGradients), "."));
          }
          var dx = tidy2(function() {
            return inputGradients[inputName2]();
          });
          if (dx.dtype !== "float32") {
            throw new Error("Error in gradient for op ".concat(node.kernelName, ". The gradient of input ") + "".concat(inputName2, " must have 'float32' dtype, but has '").concat(dx.dtype, "'"));
          }
          var x = node.inputs[inputName2];
          if (!arraysEqual(dx.shape, x.shape)) {
            throw new Error("Error in gradient for op ".concat(node.kernelName, ". The gradient of input ") + "'".concat(inputName2, "' has shape '").concat(dx.shape, "', which does not match ") + "the shape of the input '".concat(x.shape, "'"));
          }
          if (tensorAccumulatedGradientMap[x.id] == null) {
            tensorAccumulatedGradientMap[x.id] = dx;
          } else {
            var curGradient = tensorAccumulatedGradientMap[x.id];
            tensorAccumulatedGradientMap[x.id] = add2(curGradient, dx);
            curGradient.dispose();
          }
        };
        for (var inputName in node.inputs) {
          _loop_2(inputName);
        }
      };
      for (var i = filteredTape.length - 1; i >= 0; i--) {
        _loop_1(i);
      }
    }
    var FORMAT_LIMIT_NUM_VALS = 20;
    var FORMAT_NUM_FIRST_LAST_VALS = 3;
    var FORMAT_NUM_SIG_DIGITS = 7;
    function tensorToString(vals, shape, dtype, verbose) {
      var strides = computeStrides(shape);
      var padPerCol = computeMaxSizePerColumn(vals, shape, dtype, strides);
      var rank = shape.length;
      var valsLines = subTensorToString(vals, shape, dtype, strides, padPerCol);
      var lines = ["Tensor"];
      if (verbose) {
        lines.push("  dtype: ".concat(dtype));
        lines.push("  rank: ".concat(rank));
        lines.push("  shape: [".concat(shape, "]"));
        lines.push("  values:");
      }
      lines.push(valsLines.map(function(l) {
        return "    " + l;
      }).join("\n"));
      return lines.join("\n");
    }
    function computeMaxSizePerColumn(vals, shape, dtype, strides) {
      var n = sizeFromShape(shape);
      var numCols = strides[strides.length - 1];
      var padPerCol = new Array(numCols).fill(0);
      var rank = shape.length;
      var valuesOrTuples = dtype === "complex64" ? createComplexTuples(vals) : vals;
      if (rank > 1) {
        for (var row = 0; row < n / numCols; row++) {
          var offset = row * numCols;
          for (var j = 0; j < numCols; j++) {
            padPerCol[j] = Math.max(padPerCol[j], valToString(valuesOrTuples[offset + j], 0, dtype).length);
          }
        }
      }
      return padPerCol;
    }
    function valToString(val, pad2, dtype) {
      var valStr;
      if (Array.isArray(val)) {
        valStr = "".concat(parseFloat(val[0].toFixed(FORMAT_NUM_SIG_DIGITS)), " + ") + "".concat(parseFloat(val[1].toFixed(FORMAT_NUM_SIG_DIGITS)), "j");
      } else if (isString(val)) {
        valStr = "'".concat(val, "'");
      } else if (dtype === "bool") {
        valStr = boolNumToString(val);
      } else {
        valStr = parseFloat(val.toFixed(FORMAT_NUM_SIG_DIGITS)).toString();
      }
      return rightPad(valStr, pad2);
    }
    function boolNumToString(v) {
      return v === 0 ? "false" : "true";
    }
    function subTensorToString(vals, shape, dtype, strides, padPerCol, isLast) {
      if (isLast === void 0) {
        isLast = true;
      }
      var storagePerElement = dtype === "complex64" ? 2 : 1;
      var size = shape[0];
      var rank = shape.length;
      if (rank === 0) {
        if (dtype === "complex64") {
          var complexTuple = createComplexTuples(vals);
          return [valToString(complexTuple[0], 0, dtype)];
        }
        if (dtype === "bool") {
          return [boolNumToString(vals[0])];
        }
        return [vals[0].toString()];
      }
      if (rank === 1) {
        if (size > FORMAT_LIMIT_NUM_VALS) {
          var firstValsSize = FORMAT_NUM_FIRST_LAST_VALS * storagePerElement;
          var firstVals = Array.from(vals.slice(0, firstValsSize));
          var lastVals = Array.from(vals.slice((size - FORMAT_NUM_FIRST_LAST_VALS) * storagePerElement, size * storagePerElement));
          if (dtype === "complex64") {
            firstVals = createComplexTuples(firstVals);
            lastVals = createComplexTuples(lastVals);
          }
          return [
            "[" + firstVals.map(function(x, i2) {
              return valToString(x, padPerCol[i2], dtype);
            }).join(", ") + ", ..., " + lastVals.map(function(x, i2) {
              return valToString(x, padPerCol[size - FORMAT_NUM_FIRST_LAST_VALS + i2], dtype);
            }).join(", ") + "]"
          ];
        }
        var displayVals = dtype === "complex64" ? createComplexTuples(vals) : Array.from(vals);
        return [
          "[" + displayVals.map(function(x, i2) {
            return valToString(x, padPerCol[i2], dtype);
          }).join(", ") + "]"
        ];
      }
      var subshape = shape.slice(1);
      var substrides = strides.slice(1);
      var stride = strides[0] * storagePerElement;
      var lines = [];
      if (size > FORMAT_LIMIT_NUM_VALS) {
        for (var i = 0; i < FORMAT_NUM_FIRST_LAST_VALS; i++) {
          var start = i * stride;
          var end = start + stride;
          lines.push.apply(lines, __spreadArray([], __read(subTensorToString(
            vals.slice(start, end),
            subshape,
            dtype,
            substrides,
            padPerCol,
            false
            /* isLast */
          )), false));
        }
        lines.push("...");
        for (var i = size - FORMAT_NUM_FIRST_LAST_VALS; i < size; i++) {
          var start = i * stride;
          var end = start + stride;
          lines.push.apply(lines, __spreadArray([], __read(subTensorToString(
            vals.slice(start, end),
            subshape,
            dtype,
            substrides,
            padPerCol,
            i === size - 1
            /* isLast */
          )), false));
        }
      } else {
        for (var i = 0; i < size; i++) {
          var start = i * stride;
          var end = start + stride;
          lines.push.apply(lines, __spreadArray([], __read(subTensorToString(
            vals.slice(start, end),
            subshape,
            dtype,
            substrides,
            padPerCol,
            i === size - 1
            /* isLast */
          )), false));
        }
      }
      var sep = rank === 2 ? "," : "";
      lines[0] = "[" + (size > 0 ? lines[0] + sep : "");
      for (var i = 1; i < lines.length - 1; i++) {
        lines[i] = " " + lines[i] + sep;
      }
      var newLineSep = ",\n";
      for (var i = 2; i < rank; i++) {
        newLineSep += "\n";
      }
      lines[lines.length - 1] = " " + lines[lines.length - 1] + "]" + (isLast ? "" : newLineSep);
      return lines;
    }
    function createComplexTuples(vals) {
      var complexTuples = [];
      for (var i = 0; i < vals.length; i += 2) {
        complexTuples.push([vals[i], vals[i + 1]]);
      }
      return complexTuples;
    }
    var TensorBuffer = (
      /** @class */
      function() {
        function TensorBuffer2(shape, dtype, values) {
          var _this = this;
          this.dtype = dtype;
          this.shape = shape.slice();
          this.size = sizeFromShape(shape);
          if (values != null) {
            var n_1 = values.length;
            assert(n_1 === this.size, function() {
              return "Length of values '".concat(n_1, "' does not match the size ") + "inferred by the shape '".concat(_this.size, "'.");
            });
          }
          if (dtype === "complex64") {
            throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");
          }
          this.values = values || getArrayFromDType(dtype, this.size);
          this.strides = computeStrides(shape);
        }
        TensorBuffer2.prototype.set = function(value) {
          var _this = this;
          var locs = [];
          for (var _i = 1; _i < arguments.length; _i++) {
            locs[_i - 1] = arguments[_i];
          }
          if (locs.length === 0) {
            locs = [0];
          }
          assert(locs.length === this.rank, function() {
            return "The number of provided coordinates (".concat(locs.length, ") must ") + "match the rank (".concat(_this.rank, ")");
          });
          var index = this.locToIndex(locs);
          this.values[index] = value;
        };
        TensorBuffer2.prototype.get = function() {
          var e_1, _b;
          var locs = [];
          for (var _i = 0; _i < arguments.length; _i++) {
            locs[_i] = arguments[_i];
          }
          if (locs.length === 0) {
            locs = [0];
          }
          var i = 0;
          try {
            for (var locs_1 = __values(locs), locs_1_1 = locs_1.next(); !locs_1_1.done; locs_1_1 = locs_1.next()) {
              var loc = locs_1_1.value;
              if (loc < 0 || loc >= this.shape[i]) {
                var msg = "Requested out of range element at ".concat(locs, ". ") + "  Buffer shape=".concat(this.shape);
                throw new Error(msg);
              }
              i++;
            }
          } catch (e_1_1) {
            e_1 = { error: e_1_1 };
          } finally {
            try {
              if (locs_1_1 && !locs_1_1.done && (_b = locs_1.return))
                _b.call(locs_1);
            } finally {
              if (e_1)
                throw e_1.error;
            }
          }
          var index = locs[locs.length - 1];
          for (var i_1 = 0; i_1 < locs.length - 1; ++i_1) {
            index += this.strides[i_1] * locs[i_1];
          }
          return this.values[index];
        };
        TensorBuffer2.prototype.locToIndex = function(locs) {
          if (this.rank === 0) {
            return 0;
          } else if (this.rank === 1) {
            return locs[0];
          }
          var index = locs[locs.length - 1];
          for (var i = 0; i < locs.length - 1; ++i) {
            index += this.strides[i] * locs[i];
          }
          return index;
        };
        TensorBuffer2.prototype.indexToLoc = function(index) {
          if (this.rank === 0) {
            return [];
          } else if (this.rank === 1) {
            return [index];
          }
          var locs = new Array(this.shape.length);
          for (var i = 0; i < locs.length - 1; ++i) {
            locs[i] = Math.floor(index / this.strides[i]);
            index -= locs[i] * this.strides[i];
          }
          locs[locs.length - 1] = index;
          return locs;
        };
        Object.defineProperty(TensorBuffer2.prototype, "rank", {
          get: function() {
            return this.shape.length;
          },
          enumerable: false,
          configurable: true
        });
        TensorBuffer2.prototype.toTensor = function() {
          return trackerFn().makeTensor(this.values, this.shape, this.dtype);
        };
        return TensorBuffer2;
      }()
    );
    var trackerFn = null;
    var opHandler = null;
    function setTensorTracker(fn) {
      trackerFn = fn;
    }
    var Tensor = (
      /** @class */
      function() {
        function Tensor2(shape, dtype, dataId, id) {
          this.kept = false;
          this.isDisposedInternal = false;
          this.shape = shape.slice();
          this.dtype = dtype || "float32";
          this.size = sizeFromShape(shape);
          this.strides = computeStrides(shape);
          this.dataId = dataId;
          this.id = id;
          this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
        }
        Object.defineProperty(Tensor2.prototype, "rank", {
          get: function() {
            return this.shape.length;
          },
          enumerable: false,
          configurable: true
        });
        Tensor2.prototype.buffer = function() {
          return __awaiter(this, void 0, void 0, function() {
            var vals;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  return [4, this.data()];
                case 1:
                  vals = _b.sent();
                  return [2, opHandler.buffer(this.shape, this.dtype, vals)];
              }
            });
          });
        };
        Tensor2.prototype.bufferSync = function() {
          return opHandler.buffer(this.shape, this.dtype, this.dataSync());
        };
        Tensor2.prototype.array = function() {
          return __awaiter(this, void 0, void 0, function() {
            var vals;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  return [4, this.data()];
                case 1:
                  vals = _b.sent();
                  return [2, toNestedArray(this.shape, vals, this.dtype === "complex64")];
              }
            });
          });
        };
        Tensor2.prototype.arraySync = function() {
          return toNestedArray(this.shape, this.dataSync(), this.dtype === "complex64");
        };
        Tensor2.prototype.data = function() {
          return __awaiter(this, void 0, void 0, function() {
            var data, bytes;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  this.throwIfDisposed();
                  data = trackerFn().read(this.dataId);
                  if (!(this.dtype === "string"))
                    return [3, 2];
                  return [4, data];
                case 1:
                  bytes = _b.sent();
                  try {
                    return [2, bytes.map(function(b) {
                      return decodeString(b);
                    })];
                  } catch (_a) {
                    throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
                  }
                  _b.label = 2;
                case 2:
                  return [2, data];
              }
            });
          });
        };
        Tensor2.prototype.dataToGPU = function(options) {
          this.throwIfDisposed();
          return trackerFn().readToGPU(this.dataId, options);
        };
        Tensor2.prototype.dataSync = function() {
          this.throwIfDisposed();
          var data = trackerFn().readSync(this.dataId);
          if (this.dtype === "string") {
            try {
              return data.map(function(b) {
                return decodeString(b);
              });
            } catch (_a) {
              throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
            }
          }
          return data;
        };
        Tensor2.prototype.bytes = function() {
          return __awaiter(this, void 0, void 0, function() {
            var data;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  this.throwIfDisposed();
                  return [4, trackerFn().read(this.dataId)];
                case 1:
                  data = _b.sent();
                  if (this.dtype === "string") {
                    return [2, data];
                  } else {
                    return [2, new Uint8Array(data.buffer)];
                  }
              }
            });
          });
        };
        Tensor2.prototype.dispose = function() {
          if (this.isDisposed) {
            return;
          }
          if (this.kerasMask) {
            this.kerasMask.dispose();
          }
          trackerFn().disposeTensor(this);
          this.isDisposedInternal = true;
        };
        Object.defineProperty(Tensor2.prototype, "isDisposed", {
          get: function() {
            return this.isDisposedInternal;
          },
          enumerable: false,
          configurable: true
        });
        Tensor2.prototype.throwIfDisposed = function() {
          if (this.isDisposed) {
            throw new Error("Tensor is disposed.");
          }
        };
        Tensor2.prototype.print = function(verbose) {
          if (verbose === void 0) {
            verbose = false;
          }
          return opHandler.print(this, verbose);
        };
        Tensor2.prototype.clone = function() {
          this.throwIfDisposed();
          return opHandler.clone(this);
        };
        Tensor2.prototype.toString = function(verbose) {
          if (verbose === void 0) {
            verbose = false;
          }
          var vals = this.dataSync();
          return tensorToString(vals, this.shape, this.dtype, verbose);
        };
        Tensor2.prototype.cast = function(dtype) {
          this.throwIfDisposed();
          return opHandler.cast(this, dtype);
        };
        Tensor2.prototype.variable = function(trainable, name, dtype) {
          if (trainable === void 0) {
            trainable = true;
          }
          this.throwIfDisposed();
          return trackerFn().makeVariable(this, trainable, name, dtype);
        };
        return Tensor2;
      }()
    );
    Object.defineProperty(Tensor, Symbol.hasInstance, {
      value: function(instance) {
        return !!instance && instance.data != null && instance.dataSync != null && instance.throwIfDisposed != null;
      }
    });
    function getGlobalTensorClass() {
      return getGlobal("Tensor", function() {
        return Tensor;
      });
    }
    getGlobalTensorClass();
    var Variable = (
      /** @class */
      function(_super) {
        __extends(Variable2, _super);
        function Variable2(initialValue, trainable, name, tensorId) {
          var _this = _super.call(this, initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId) || this;
          _this.trainable = trainable;
          _this.name = name;
          return _this;
        }
        Variable2.prototype.assign = function(newValue) {
          if (newValue.dtype !== this.dtype) {
            throw new Error("dtype of the new value (".concat(newValue.dtype, ") and ") + "previous value (".concat(this.dtype, ") must match"));
          }
          if (!arraysEqual(newValue.shape, this.shape)) {
            throw new Error("shape of the new value (".concat(newValue.shape, ") and ") + "previous value (".concat(this.shape, ") must match"));
          }
          trackerFn().disposeTensor(this);
          this.dataId = newValue.dataId;
          trackerFn().incRef(
            this,
            null
            /* backend */
          );
        };
        Variable2.prototype.dispose = function() {
          trackerFn().disposeVariable(this);
          this.isDisposedInternal = true;
        };
        return Variable2;
      }(Tensor)
    );
    Object.defineProperty(Variable, Symbol.hasInstance, {
      value: function(instance) {
        return instance instanceof Tensor && instance.assign != null && instance.assign instanceof Function;
      }
    });
    var Rank;
    (function(Rank2) {
      Rank2["R0"] = "R0";
      Rank2["R1"] = "R1";
      Rank2["R2"] = "R2";
      Rank2["R3"] = "R3";
      Rank2["R4"] = "R4";
      Rank2["R5"] = "R5";
      Rank2["R6"] = "R6";
    })(Rank || (Rank = {}));
    var UpcastInt32AndMap;
    (function(UpcastInt32AndMap2) {
      UpcastInt32AndMap2["float32"] = "float32";
      UpcastInt32AndMap2["int32"] = "int32";
      UpcastInt32AndMap2["bool"] = "int32";
      UpcastInt32AndMap2["complex64"] = "complex64";
    })(UpcastInt32AndMap || (UpcastInt32AndMap = {}));
    var UpcastBoolAndMap;
    (function(UpcastBoolAndMap2) {
      UpcastBoolAndMap2["float32"] = "float32";
      UpcastBoolAndMap2["int32"] = "int32";
      UpcastBoolAndMap2["bool"] = "bool";
      UpcastBoolAndMap2["complex64"] = "complex64";
    })(UpcastBoolAndMap || (UpcastBoolAndMap = {}));
    var UpcastFloat32AndMap;
    (function(UpcastFloat32AndMap2) {
      UpcastFloat32AndMap2["float32"] = "float32";
      UpcastFloat32AndMap2["int32"] = "float32";
      UpcastFloat32AndMap2["bool"] = "float32";
      UpcastFloat32AndMap2["complex64"] = "complex64";
    })(UpcastFloat32AndMap || (UpcastFloat32AndMap = {}));
    var UpcastComplex64AndMap;
    (function(UpcastComplex64AndMap2) {
      UpcastComplex64AndMap2["float32"] = "complex64";
      UpcastComplex64AndMap2["int32"] = "complex64";
      UpcastComplex64AndMap2["bool"] = "complex64";
      UpcastComplex64AndMap2["complex64"] = "complex64";
    })(UpcastComplex64AndMap || (UpcastComplex64AndMap = {}));
    var upcastTypeMap = {
      "float32": UpcastFloat32AndMap,
      "int32": UpcastInt32AndMap,
      "bool": UpcastBoolAndMap,
      "complex64": UpcastComplex64AndMap
    };
    function upcastType(typeA, typeB) {
      if (typeA === "string" || typeB === "string") {
        if (typeA === "string" && typeB === "string") {
          return "string";
        }
        throw new Error("Can not upcast ".concat(typeA, " with ").concat(typeB));
      }
      return upcastTypeMap[typeA][typeB];
    }
    function isWebGLData(values) {
      return values != null && typeof values === "object" && "texture" in values && values.texture instanceof WebGLTexture;
    }
    function isWebGPUData(values) {
      return typeof GPUBuffer !== "undefined" && values != null && typeof values === "object" && "buffer" in values && values.buffer instanceof GPUBuffer;
    }
    function makeTypesMatch(a, b) {
      if (a.dtype === b.dtype) {
        return [a, b];
      }
      var dtype = upcastType(a.dtype, b.dtype);
      return [a.cast(dtype), b.cast(dtype)];
    }
    function assertTypesMatch(a, b) {
      assert(a.dtype === b.dtype, function() {
        return "The dtypes of the first(".concat(a.dtype, ") and") + " second(".concat(b.dtype, ") input must match");
      });
    }
    function getTensorsInContainer(result) {
      var list = [];
      var seen = /* @__PURE__ */ new Set();
      walkTensorContainer(result, list, seen);
      return list;
    }
    function walkTensorContainer(container, list, seen) {
      if (container == null) {
        return;
      }
      if (container instanceof Tensor) {
        list.push(container);
        return;
      }
      if (!isIterable(container)) {
        return;
      }
      var iterable = container;
      for (var k in iterable) {
        var val = iterable[k];
        if (!seen.has(val)) {
          seen.add(val);
          walkTensorContainer(val, list, seen);
        }
      }
    }
    function isIterable(obj) {
      return Array.isArray(obj) || typeof obj === "object";
    }
    function isRegisteredKernelInvocation(kernelInvocation) {
      return kernelInvocation.kernelName != null;
    }
    var EngineState = (
      /** @class */
      function() {
        function EngineState2() {
          this.registeredVariables = {};
          this.nextTapeNodeId = 0;
          this.numBytes = 0;
          this.numTensors = 0;
          this.numStringTensors = 0;
          this.numDataBuffers = 0;
          this.gradientDepth = 0;
          this.kernelDepth = 0;
          this.scopeStack = [];
          this.numDataMovesStack = [];
          this.nextScopeId = 0;
          this.tensorInfo = /* @__PURE__ */ new WeakMap();
          this.profiling = false;
          this.activeProfile = {
            newBytes: 0,
            newTensors: 0,
            peakBytes: 0,
            kernels: [],
            result: null,
            get kernelNames() {
              return Array.from(new Set(this.kernels.map(function(k) {
                return k.name;
              })));
            }
          };
        }
        EngineState2.prototype.dispose = function() {
          for (var variableName in this.registeredVariables) {
            this.registeredVariables[variableName].dispose();
          }
        };
        return EngineState2;
      }()
    );
    var Engine = (
      /** @class */
      function() {
        function Engine2(ENV2) {
          this.ENV = ENV2;
          this.registry = {};
          this.registryFactory = {};
          this.pendingBackendInitId = 0;
          this.state = new EngineState();
        }
        Engine2.prototype.ready = function() {
          return __awaiter(this, void 0, void 0, function() {
            var sortedBackends, i, backendName, success;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  if (this.pendingBackendInit != null) {
                    return [2, this.pendingBackendInit.then(function() {
                    })];
                  }
                  if (this.backendInstance != null) {
                    return [
                      2
                      /*return*/
                    ];
                  }
                  sortedBackends = this.getSortedBackends();
                  i = 0;
                  _a.label = 1;
                case 1:
                  if (!(i < sortedBackends.length))
                    return [3, 5];
                  backendName = sortedBackends[i];
                  return [4, this.initializeBackend(backendName).success];
                case 2:
                  success = _a.sent();
                  if (!success)
                    return [3, 4];
                  return [4, this.setBackend(backendName)];
                case 3:
                  _a.sent();
                  return [
                    2
                    /*return*/
                  ];
                case 4:
                  i++;
                  return [3, 1];
                case 5:
                  throw new Error("Could not initialize any backends, all backend initializations failed.");
              }
            });
          });
        };
        Object.defineProperty(Engine2.prototype, "backend", {
          get: function() {
            if (this.pendingBackendInit != null) {
              throw new Error("Backend '".concat(this.backendName, "' has not yet been initialized. Make ") + "sure to await tf.ready() or await tf.setBackend() before calling other methods");
            }
            if (this.backendInstance == null) {
              var _a = this.initializeBackendsAndReturnBest(), name = _a.name, asyncInit = _a.asyncInit;
              if (asyncInit) {
                throw new Error("The highest priority backend '".concat(name, "' has not yet been ") + "initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods");
              }
              this.setBackend(name);
            }
            return this.backendInstance;
          },
          enumerable: false,
          configurable: true
        });
        Engine2.prototype.backendNames = function() {
          return Object.keys(this.registryFactory);
        };
        Engine2.prototype.findBackend = function(backendName) {
          if (!(backendName in this.registry)) {
            if (backendName in this.registryFactory) {
              var asyncInit = this.initializeBackend(backendName).asyncInit;
              if (asyncInit) {
                return null;
              }
            } else {
              return null;
            }
          }
          return this.registry[backendName];
        };
        Engine2.prototype.findBackendFactory = function(backendName) {
          if (!(backendName in this.registryFactory)) {
            return null;
          }
          return this.registryFactory[backendName].factory;
        };
        Engine2.prototype.registerBackend = function(backendName, factory, priority) {
          if (priority === void 0) {
            priority = 1;
          }
          if (backendName in this.registryFactory) {
            warn("".concat(backendName, " backend was already registered. ") + "Reusing existing backend factory.");
            return false;
          }
          this.registryFactory[backendName] = { factory, priority };
          return true;
        };
        Engine2.prototype.setBackend = function(backendName) {
          return __awaiter(this, void 0, void 0, function() {
            var _a, success, asyncInit, result, _b;
            return __generator(this, function(_c) {
              switch (_c.label) {
                case 0:
                  if (this.registryFactory[backendName] == null) {
                    throw new Error("Backend name '".concat(backendName, "' not found in registry"));
                  }
                  this.backendName = backendName;
                  if (!(this.registry[backendName] == null))
                    return [3, 4];
                  this.backendInstance = null;
                  _a = this.initializeBackend(backendName), success = _a.success, asyncInit = _a.asyncInit;
                  if (!asyncInit)
                    return [3, 2];
                  return [4, success];
                case 1:
                  _b = _c.sent();
                  return [3, 3];
                case 2:
                  _b = success;
                  _c.label = 3;
                case 3:
                  result = _b;
                  if (!result) {
                    return [2, false];
                  }
                  _c.label = 4;
                case 4:
                  this.backendInstance = this.registry[backendName];
                  this.setupRegisteredKernels();
                  this.profiler = new Profiler(this.backendInstance);
                  return [2, true];
              }
            });
          });
        };
        Engine2.prototype.setupRegisteredKernels = function() {
          var _this = this;
          var kernels = getKernelsForBackend(this.backendName);
          kernels.forEach(function(kernel) {
            if (kernel.setupFunc != null) {
              kernel.setupFunc(_this.backendInstance);
            }
          });
        };
        Engine2.prototype.disposeRegisteredKernels = function(backendName) {
          var _this = this;
          var kernels = getKernelsForBackend(backendName);
          kernels.forEach(function(kernel) {
            if (kernel.disposeFunc != null) {
              kernel.disposeFunc(_this.registry[backendName]);
            }
          });
        };
        Engine2.prototype.initializeBackend = function(backendName) {
          var _this = this;
          var registryFactoryEntry = this.registryFactory[backendName];
          if (registryFactoryEntry == null) {
            throw new Error("Cannot initialize backend ".concat(backendName, ", no registration found."));
          }
          try {
            var backend2 = registryFactoryEntry.factory();
            if (backend2 && !(backend2 instanceof KernelBackend) && typeof backend2.then === "function") {
              var promiseId_1 = ++this.pendingBackendInitId;
              var success = backend2.then(function(backendInstance) {
                if (promiseId_1 < _this.pendingBackendInitId) {
                  return false;
                }
                _this.registry[backendName] = backendInstance;
                _this.pendingBackendInit = null;
                return true;
              }).catch(function(err) {
                if (promiseId_1 < _this.pendingBackendInitId) {
                  return false;
                }
                _this.pendingBackendInit = null;
                warn("Initialization of backend ".concat(backendName, " failed"));
                warn(err.stack || err.message);
                return false;
              });
              this.pendingBackendInit = success;
              return { success, asyncInit: true };
            } else {
              this.registry[backendName] = backend2;
              return { success: true, asyncInit: false };
            }
          } catch (err) {
            warn("Initialization of backend ".concat(backendName, " failed"));
            warn(err.stack || err.message);
            return { success: false, asyncInit: false };
          }
        };
        Engine2.prototype.removeBackend = function(backendName) {
          if (!(backendName in this.registryFactory)) {
            throw new Error("".concat(backendName, " backend not found in registry"));
          }
          if (this.backendName === backendName && this.pendingBackendInit != null) {
            this.pendingBackendInitId++;
          }
          if (backendName in this.registry) {
            this.disposeRegisteredKernels(backendName);
            this.registry[backendName].dispose();
            delete this.registry[backendName];
          }
          delete this.registryFactory[backendName];
          if (this.backendName === backendName) {
            this.pendingBackendInit = null;
            this.backendName = null;
            this.backendInstance = null;
          }
        };
        Engine2.prototype.getSortedBackends = function() {
          var _this = this;
          if (Object.keys(this.registryFactory).length === 0) {
            throw new Error("No backend found in registry.");
          }
          return Object.keys(this.registryFactory).sort(function(a, b) {
            return _this.registryFactory[b].priority - _this.registryFactory[a].priority;
          });
        };
        Engine2.prototype.initializeBackendsAndReturnBest = function() {
          var sortedBackends = this.getSortedBackends();
          for (var i = 0; i < sortedBackends.length; i++) {
            var backendName = sortedBackends[i];
            var _a = this.initializeBackend(backendName), success = _a.success, asyncInit = _a.asyncInit;
            if (asyncInit || success) {
              return { name: backendName, asyncInit };
            }
          }
          throw new Error("Could not initialize any backends, all backend initializations failed.");
        };
        Engine2.prototype.moveData = function(backend2, dataId) {
          var info = this.state.tensorInfo.get(dataId);
          var srcBackend = info.backend;
          var values = this.readSync(dataId);
          var refCount = srcBackend.refCount(dataId);
          srcBackend.disposeData(dataId, true);
          info.backend = backend2;
          backend2.move(dataId, values, info.shape, info.dtype, refCount);
          if (this.shouldCheckForMemLeaks()) {
            this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
          }
        };
        Engine2.prototype.tidy = function(nameOrFn, fn) {
          var _this = this;
          var name = null;
          if (fn == null) {
            if (typeof nameOrFn !== "function") {
              throw new Error("Please provide a function to tidy()");
            }
            fn = nameOrFn;
          } else {
            if (typeof nameOrFn !== "string" && !(nameOrFn instanceof String)) {
              throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
            }
            if (typeof fn !== "function") {
              throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
            }
            name = nameOrFn;
          }
          var result;
          return this.scopedRun(function() {
            return _this.startScope(name);
          }, function() {
            return _this.endScope(result);
          }, function() {
            result = fn();
            if (result instanceof Promise) {
              console.error("Cannot return a Promise inside of tidy.");
            }
            return result;
          });
        };
        Engine2.prototype.scopedRun = function(start, end, f) {
          start();
          try {
            var res = f();
            end();
            return res;
          } catch (ex) {
            end();
            throw ex;
          }
        };
        Engine2.prototype.nextTensorId = function() {
          return Engine2.nextTensorId++;
        };
        Engine2.prototype.nextVariableId = function() {
          return Engine2.nextVariableId++;
        };
        Engine2.prototype.clone = function(x) {
          var y = ENGINE.runKernel(Identity, { x });
          var inputs = { x };
          var grad = function(dy) {
            return {
              x: function() {
                var dtype = "float32";
                var gradInputs = { x: dy };
                var attrs = { dtype };
                return ENGINE.runKernel(
                  Cast,
                  gradInputs,
                  // tslint:disable-next-line: no-unnecessary-type-assertion
                  attrs
                );
              }
            };
          };
          var saved = [];
          this.addTapeNode(this.state.activeScope.name, inputs, [y], grad, saved, {});
          return y;
        };
        Engine2.prototype.runKernel = function(kernelName, inputs, attrs) {
          if (this.backendName == null) {
            this.backend;
          }
          var hasKernel = getKernel(kernelName, this.backendName) != null;
          if (!hasKernel) {
            throw new Error("Kernel '".concat(kernelName, "' not registered for backend '").concat(this.backendName, "'"));
          }
          return this.runKernelFunc({ kernelName, inputs, attrs });
        };
        Engine2.prototype.shouldCheckForMemLeaks = function() {
          return this.ENV.getBool("IS_TEST");
        };
        Engine2.prototype.checkKernelForMemLeak = function(kernelName, numDataIdsBefore, outInfos) {
          var numDataIdsAfter = this.backend.numDataIds();
          var numOutputDataIds = 0;
          outInfos.forEach(function(info) {
            numOutputDataIds += info.dtype === "complex64" ? 3 : 1;
          });
          var numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];
          var dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;
          if (dataIdsLeaked > 0) {
            throw new Error("Backend '".concat(this.backendName, "' has an internal memory leak ") + "(".concat(dataIdsLeaked, " data ids) after running '").concat(kernelName, "'"));
          }
        };
        Engine2.prototype.runKernelFunc = function(kernelParams) {
          var _this = this;
          var outputs;
          var saved = [];
          var isTapeOn = this.isTapeOn();
          var startingBytecount = this.state.numBytes;
          var startingNumTensors = this.state.numTensors;
          if (this.shouldCheckForMemLeaks()) {
            this.state.numDataMovesStack.push(0);
          }
          var kernelFunc;
          if (this.backendName == null) {
            this.backend;
          }
          var out;
          var kernelOrScopeName = isRegisteredKernelInvocation(kernelParams) ? kernelParams.kernelName : this.state.activeScope != null ? this.state.activeScope.name : "";
          if (isRegisteredKernelInvocation(kernelParams)) {
            var kernelName_1 = kernelParams.kernelName, inputs_1 = kernelParams.inputs, attrs_1 = kernelParams.attrs;
            if (this.backendName == null) {
              this.backend;
            }
            var kernel_1 = getKernel(kernelName_1, this.backendName);
            assert(kernel_1 != null, function() {
              return "Cannot find registered kernel '".concat(kernelName_1, "' for backend '").concat(_this.backendName, "'");
            });
            kernelFunc = function() {
              var numDataIdsBefore = _this.backend.numDataIds();
              out = kernel_1.kernelFunc({ inputs: inputs_1, attrs: attrs_1, backend: _this.backend });
              var outInfos = Array.isArray(out) ? out : [out];
              if (_this.shouldCheckForMemLeaks()) {
                _this.checkKernelForMemLeak(kernelName_1, numDataIdsBefore, outInfos);
              }
              var outTensors = outInfos.map(function(outInfo) {
                if (outInfo.rank != null) {
                  return outInfo;
                }
                return _this.makeTensorFromTensorInfo(outInfo);
              });
              if (isTapeOn) {
                var tensorsToSave = _this.getTensorsForGradient(kernelName_1, inputs_1, outTensors);
                saved = _this.saveTensorsForBackwardMode(tensorsToSave);
              }
              return outTensors;
            };
          } else {
            var forwardFunc_1 = kernelParams.forwardFunc;
            var saveFunc_1 = function(tensors) {
              if (!isTapeOn) {
                return;
              }
              saved = tensors.map(function(tensor2) {
                return _this.keep(_this.clone(tensor2));
              });
            };
            kernelFunc = function() {
              var numDataIdsBefore = _this.backend.numDataIds();
              out = _this.tidy(function() {
                return forwardFunc_1(_this.backend, saveFunc_1);
              });
              var outs = Array.isArray(out) ? out : [out];
              if (_this.shouldCheckForMemLeaks()) {
                _this.checkKernelForMemLeak(kernelOrScopeName, numDataIdsBefore, outs);
              }
              return outs;
            };
          }
          var inputs = kernelParams.inputs, attrs = kernelParams.attrs;
          var backwardsFunc = isRegisteredKernelInvocation(kernelParams) ? null : kernelParams.backwardsFunc;
          var kernelProfile;
          this.scopedRun(
            // Stop recording to a tape when running a kernel.
            function() {
              return _this.state.kernelDepth++;
            },
            function() {
              return _this.state.kernelDepth--;
            },
            function() {
              if (!_this.ENV.getBool("DEBUG") && !_this.state.profiling) {
                outputs = kernelFunc();
              } else {
                kernelProfile = _this.profiler.profileKernel(kernelOrScopeName, inputs, function() {
                  return kernelFunc();
                });
                if (_this.ENV.getBool("DEBUG")) {
                  _this.profiler.logKernelProfile(kernelProfile);
                }
                outputs = kernelProfile.outputs;
              }
            }
          );
          if (isTapeOn) {
            this.addTapeNode(kernelOrScopeName, inputs, outputs, backwardsFunc, saved, attrs);
          }
          if (this.state.profiling) {
            this.state.activeProfile.kernels.push({
              name: kernelOrScopeName,
              bytesAdded: this.state.numBytes - startingBytecount,
              totalBytesSnapshot: this.state.numBytes,
              tensorsAdded: this.state.numTensors - startingNumTensors,
              totalTensorsSnapshot: this.state.numTensors,
              inputShapes: Object.keys(inputs).map(function(key) {
                return inputs[key] != null ? inputs[key].shape : null;
              }),
              outputShapes: outputs.map(function(item) {
                return item.shape;
              }),
              kernelTimeMs: kernelProfile.timeMs,
              extraInfo: kernelProfile.extraInfo
            });
          }
          return Array.isArray(out) ? outputs : outputs[0];
        };
        Engine2.prototype.saveTensorsForBackwardMode = function(tensors) {
          var _this = this;
          var saved = tensors.map(function(tensor2) {
            return _this.keep(_this.clone(tensor2));
          });
          return saved;
        };
        Engine2.prototype.getTensorsForGradient = function(kernelName, inputs, outputs) {
          var gradConfig = getGradient(kernelName);
          if (gradConfig != null) {
            var inputsToSave = gradConfig.inputsToSave || [];
            var outputsToSave_1 = gradConfig.outputsToSave || [];
            var inputTensorsToSave = void 0;
            if (gradConfig.saveAllInputs) {
              assert(Array.isArray(inputs), function() {
                return "saveAllInputs is true, expected inputs to be an array.";
              });
              inputTensorsToSave = Object.keys(inputs).map(function(key) {
                return inputs[key];
              });
            } else {
              inputTensorsToSave = inputsToSave.map(function(inputName) {
                return inputs[inputName];
              });
            }
            var outputTensorsToSave = outputs.filter(function(_, i) {
              return outputsToSave_1[i];
            });
            return inputTensorsToSave.concat(outputTensorsToSave);
          }
          return [];
        };
        Engine2.prototype.makeTensor = function(values, shape, dtype, backend2) {
          if (values == null) {
            throw new Error("Values passed to engine.makeTensor() are null");
          }
          dtype = dtype || "float32";
          backend2 = backend2 || this.backend;
          var backendVals = values;
          if (dtype === "string" && isString(values[0])) {
            backendVals = values.map(function(d) {
              return encodeString(d);
            });
          }
          var dataId = backend2.write(backendVals, shape, dtype);
          var t = new Tensor(shape, dtype, dataId, this.nextTensorId());
          this.trackTensor(t, backend2);
          if (dtype === "string") {
            var info = this.state.tensorInfo.get(dataId);
            var newBytes = bytesFromStringArray(backendVals);
            this.state.numBytes += newBytes - info.bytes;
            info.bytes = newBytes;
          }
          return t;
        };
        Engine2.prototype.makeTensorFromDataId = function(dataId, shape, dtype, backend2) {
          dtype = dtype || "float32";
          var tensorInfo = { dataId, shape, dtype };
          return this.makeTensorFromTensorInfo(tensorInfo, backend2);
        };
        Engine2.prototype.makeTensorFromTensorInfo = function(tensorInfo, backend2) {
          var dataId = tensorInfo.dataId, shape = tensorInfo.shape, dtype = tensorInfo.dtype;
          var t = new Tensor(shape, dtype, dataId, this.nextTensorId());
          this.trackTensor(t, backend2);
          return t;
        };
        Engine2.prototype.makeVariable = function(initialValue, trainable, name, dtype) {
          if (trainable === void 0) {
            trainable = true;
          }
          name = name || this.nextVariableId().toString();
          if (dtype != null && dtype !== initialValue.dtype) {
            initialValue = initialValue.cast(dtype);
          }
          var v = new Variable(initialValue, trainable, name, this.nextTensorId());
          if (this.state.registeredVariables[v.name] != null) {
            throw new Error("Variable with name ".concat(v.name, " was already registered"));
          }
          this.state.registeredVariables[v.name] = v;
          this.incRef(v, this.backend);
          return v;
        };
        Engine2.prototype.trackTensor = function(a, backend2) {
          this.state.numTensors++;
          if (a.dtype === "string") {
            this.state.numStringTensors++;
          }
          var bytes = 0;
          if (a.dtype !== "complex64" && a.dtype !== "string") {
            bytes = a.size * bytesPerElement(a.dtype);
          }
          this.state.numBytes += bytes;
          if (!this.state.tensorInfo.has(a.dataId)) {
            this.state.numDataBuffers++;
            this.state.tensorInfo.set(a.dataId, {
              backend: backend2 || this.backend,
              dtype: a.dtype,
              shape: a.shape,
              bytes
            });
          }
          if (!(a instanceof Variable)) {
            this.track(a);
          }
        };
        Engine2.prototype.incRef = function(a, backend2) {
          this.trackTensor(a, backend2);
          this.backend.incRef(a.dataId);
        };
        Engine2.prototype.removeDataId = function(dataId, backend2) {
          if (this.state.tensorInfo.has(dataId) && this.state.tensorInfo.get(dataId).backend === backend2) {
            this.state.tensorInfo.delete(dataId);
            this.state.numDataBuffers--;
          }
        };
        Engine2.prototype.disposeTensor = function(a) {
          if (!this.state.tensorInfo.has(a.dataId)) {
            return;
          }
          var info = this.state.tensorInfo.get(a.dataId);
          this.state.numTensors--;
          if (a.dtype === "string") {
            this.state.numStringTensors--;
            this.state.numBytes -= info.bytes;
          }
          if (a.dtype !== "complex64" && a.dtype !== "string") {
            var bytes = a.size * bytesPerElement(a.dtype);
            this.state.numBytes -= bytes;
          }
          if (info.backend.disposeData(a.dataId)) {
            this.removeDataId(a.dataId, info.backend);
          }
        };
        Engine2.prototype.disposeVariables = function() {
          for (var varName in this.state.registeredVariables) {
            var v = this.state.registeredVariables[varName];
            this.disposeVariable(v);
          }
        };
        Engine2.prototype.disposeVariable = function(v) {
          this.disposeTensor(v);
          if (this.state.registeredVariables[v.name] != null) {
            delete this.state.registeredVariables[v.name];
          }
        };
        Engine2.prototype.memory = function() {
          var info = this.backend.memory();
          info.numTensors = this.state.numTensors;
          info.numDataBuffers = this.state.numDataBuffers;
          info.numBytes = this.state.numBytes;
          if (this.state.numStringTensors > 0) {
            info.unreliable = true;
            if (info.reasons == null) {
              info.reasons = [];
            }
            info.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)");
          }
          return info;
        };
        Engine2.prototype.profile = function(query) {
          return __awaiter(this, void 0, void 0, function() {
            var startBytes, startNumTensors, _a, _b, _c, kernel, _d, _e, e_1_1;
            var e_1, _f;
            return __generator(this, function(_g) {
              switch (_g.label) {
                case 0:
                  this.state.profiling = true;
                  startBytes = this.state.numBytes;
                  startNumTensors = this.state.numTensors;
                  this.state.activeProfile.kernels = [];
                  _a = this.state.activeProfile;
                  return [4, query()];
                case 1:
                  _a.result = _g.sent();
                  this.state.profiling = false;
                  this.state.activeProfile.peakBytes = Math.max.apply(Math, __spreadArray([], __read(this.state.activeProfile.kernels.map(function(d) {
                    return d.totalBytesSnapshot;
                  })), false));
                  this.state.activeProfile.newBytes = this.state.numBytes - startBytes;
                  this.state.activeProfile.newTensors = this.state.numTensors - startNumTensors;
                  _g.label = 2;
                case 2:
                  _g.trys.push([2, 8, 9, 10]);
                  _b = __values(this.state.activeProfile.kernels), _c = _b.next();
                  _g.label = 3;
                case 3:
                  if (!!_c.done)
                    return [3, 7];
                  kernel = _c.value;
                  _d = kernel;
                  return [4, kernel.kernelTimeMs];
                case 4:
                  _d.kernelTimeMs = _g.sent();
                  _e = kernel;
                  return [4, kernel.extraInfo];
                case 5:
                  _e.extraInfo = _g.sent();
                  _g.label = 6;
                case 6:
                  _c = _b.next();
                  return [3, 3];
                case 7:
                  return [3, 10];
                case 8:
                  e_1_1 = _g.sent();
                  e_1 = { error: e_1_1 };
                  return [3, 10];
                case 9:
                  try {
                    if (_c && !_c.done && (_f = _b.return))
                      _f.call(_b);
                  } finally {
                    if (e_1)
                      throw e_1.error;
                  }
                  return [
                    7
                    /*endfinally*/
                  ];
                case 10:
                  return [2, this.state.activeProfile];
              }
            });
          });
        };
        Engine2.prototype.isTapeOn = function() {
          return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;
        };
        Engine2.prototype.addTapeNode = function(kernelName, inputs, outputs, gradientsFunc, saved, attrs) {
          var _this = this;
          var tapeNode = { id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved };
          var gradConfig = getGradient(kernelName);
          if (gradConfig != null) {
            gradientsFunc = gradConfig.gradFunc;
          }
          if (gradientsFunc != null) {
            tapeNode.gradient = function(dys) {
              dys = dys.map(function(dy, i) {
                if (dy == null) {
                  var output = outputs[i];
                  var vals = makeZerosTypedArray(output.size, output.dtype);
                  return _this.makeTensor(vals, output.shape, output.dtype);
                }
                return dy;
              });
              return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);
            };
          }
          this.state.activeTape.push(tapeNode);
        };
        Engine2.prototype.keep = function(result) {
          result.kept = true;
          return result;
        };
        Engine2.prototype.startTape = function() {
          if (this.state.gradientDepth === 0) {
            this.state.activeTape = [];
          }
          this.state.gradientDepth++;
        };
        Engine2.prototype.endTape = function() {
          this.state.gradientDepth--;
        };
        Engine2.prototype.startScope = function(name) {
          var scopeInfo = {
            track: [],
            name: "unnamed scope",
            id: this.state.nextScopeId++
          };
          if (name) {
            scopeInfo.name = name;
          }
          this.state.scopeStack.push(scopeInfo);
          this.state.activeScope = scopeInfo;
        };
        Engine2.prototype.endScope = function(result) {
          var _this = this;
          var tensorsToTrackInParent = getTensorsInContainer(result);
          var tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map(function(t) {
            return t.id;
          }));
          for (var i = 0; i < this.state.activeScope.track.length; i++) {
            var tensor2 = this.state.activeScope.track[i];
            if (!tensor2.kept && !tensorsToTrackInParentSet.has(tensor2.id)) {
              tensor2.dispose();
            }
          }
          var oldScope = this.state.scopeStack.pop();
          this.state.activeScope = this.state.scopeStack.length === 0 ? null : this.state.scopeStack[this.state.scopeStack.length - 1];
          tensorsToTrackInParent.forEach(function(tensor3) {
            if (!tensor3.kept && tensor3.scopeId === oldScope.id) {
              _this.track(tensor3);
            }
          });
        };
        Engine2.prototype.gradients = function(f, xs, dy, allowNoGradients) {
          var _this = this;
          if (allowNoGradients === void 0) {
            allowNoGradients = false;
          }
          assert(xs.length > 0, function() {
            return "gradients() received an empty list of xs.";
          });
          if (dy != null && dy.dtype !== "float32") {
            throw new Error("dy must have 'float32' dtype, but has '".concat(dy.dtype, "'"));
          }
          var y = this.scopedRun(function() {
            return _this.startTape();
          }, function() {
            return _this.endTape();
          }, function() {
            return _this.tidy("forward", f);
          });
          assert(y instanceof Tensor, function() {
            return "The result y returned by f() must be a tensor.";
          });
          var filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);
          if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {
            throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
          }
          return this.tidy("backward", function() {
            var accumulatedGradientMap = {};
            accumulatedGradientMap[y.id] = dy == null ? ones$1(y.shape) : dy;
            backpropagateGradients(
              accumulatedGradientMap,
              filteredTape,
              // Pass the tidy function to avoid circular dep with `tape.ts`.
              function(f2) {
                return _this.tidy(f2);
              },
              // Pass an add function to avoide a circular dep with `tape.ts`.
              add$1
            );
            var grads = xs.map(function(x) {
              return accumulatedGradientMap[x.id];
            });
            if (_this.state.gradientDepth === 0) {
              _this.state.activeTape.forEach(function(node) {
                var e_2, _a;
                try {
                  for (var _b = __values(node.saved), _c = _b.next(); !_c.done; _c = _b.next()) {
                    var tensor2 = _c.value;
                    tensor2.dispose();
                  }
                } catch (e_2_1) {
                  e_2 = { error: e_2_1 };
                } finally {
                  try {
                    if (_c && !_c.done && (_a = _b.return))
                      _a.call(_b);
                  } finally {
                    if (e_2)
                      throw e_2.error;
                  }
                }
              });
              _this.state.activeTape = null;
            }
            return { value: y, grads };
          });
        };
        Engine2.prototype.customGrad = function(f) {
          var _this = this;
          assert(isFunction(f), function() {
            return "The f passed in customGrad(f) must be a function.";
          });
          return function() {
            var inputs = [];
            for (var _i = 0; _i < arguments.length; _i++) {
              inputs[_i] = arguments[_i];
            }
            assert(inputs.every(function(t) {
              return t instanceof Tensor;
            }), function() {
              return "The args passed in customGrad(f)(x1, x2,...) must all be tensors";
            });
            var res;
            var inputMap = {};
            inputs.forEach(function(input, i) {
              inputMap[i] = input;
            });
            var forwardFunc = function(_, save) {
              res = f.apply(void 0, __spreadArray([], __read(__spreadArray(__spreadArray([], __read(inputs), false), [save], false)), false));
              assert(res.value instanceof Tensor, function() {
                return "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor";
              });
              assert(isFunction(res.gradFunc), function() {
                return "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.";
              });
              return res.value;
            };
            var backwardsFunc = function(dy, saved) {
              var gradRes = res.gradFunc(dy, saved);
              var grads = Array.isArray(gradRes) ? gradRes : [gradRes];
              assert(grads.length === inputs.length, function() {
                return "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).";
              });
              assert(grads.every(function(t) {
                return t instanceof Tensor;
              }), function() {
                return "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.";
              });
              var gradMap = {};
              grads.forEach(function(grad, i) {
                gradMap[i] = function() {
                  return grad;
                };
              });
              return gradMap;
            };
            return _this.runKernelFunc({
              forwardFunc,
              backwardsFunc,
              inputs: inputMap
            });
          };
        };
        Engine2.prototype.readSync = function(dataId) {
          var info = this.state.tensorInfo.get(dataId);
          return info.backend.readSync(dataId);
        };
        Engine2.prototype.read = function(dataId) {
          var info = this.state.tensorInfo.get(dataId);
          return info.backend.read(dataId);
        };
        Engine2.prototype.readToGPU = function(dataId, options) {
          var info = this.state.tensorInfo.get(dataId);
          return info.backend.readToGPU(dataId, options);
        };
        Engine2.prototype.time = function(query) {
          return __awaiter(this, void 0, void 0, function() {
            var start, timingInfo;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  start = now();
                  return [4, this.backend.time(query)];
                case 1:
                  timingInfo = _a.sent();
                  timingInfo.wallMs = now() - start;
                  return [2, timingInfo];
              }
            });
          });
        };
        Engine2.prototype.track = function(result) {
          if (this.state.activeScope != null) {
            result.scopeId = this.state.activeScope.id;
            this.state.activeScope.track.push(result);
          }
          return result;
        };
        Object.defineProperty(Engine2.prototype, "registeredVariables", {
          get: function() {
            return this.state.registeredVariables;
          },
          enumerable: false,
          configurable: true
        });
        Engine2.prototype.reset = function() {
          this.pendingBackendInitId++;
          this.state.dispose();
          this.ENV.reset();
          this.state = new EngineState();
          for (var backendName in this.registry) {
            this.disposeRegisteredKernels(backendName);
            this.registry[backendName].dispose();
            delete this.registry[backendName];
          }
          this.backendName = null;
          this.backendInstance = null;
          this.pendingBackendInit = null;
        };
        return Engine2;
      }()
    );
    Engine.nextTensorId = 0;
    Engine.nextVariableId = 0;
    function ones$1(shape) {
      var values = makeOnesTypedArray(sizeFromShape(shape), "float32");
      return ENGINE.makeTensor(values, shape, "float32");
    }
    function getOrMakeEngine() {
      var ns = getGlobalNamespace();
      if (ns._tfengine == null) {
        var environment = new Environment(ns);
        ns._tfengine = new Engine(environment);
      }
      setEnvironmentGlobal(ns._tfengine.ENV);
      setTensorTracker(function() {
        return ns._tfengine;
      });
      return ns._tfengine;
    }
    var ENGINE = getOrMakeEngine();
    function add$1(a, b) {
      var inputs = { a, b };
      return ENGINE.runKernel(Add, inputs);
    }
    function inferShape(val, dtype) {
      var firstElem = val;
      if (isTypedArray(val)) {
        return dtype === "string" ? [] : [val.length];
      }
      if (isWebGLData(val)) {
        var usedChannels = val.channels || "RGBA";
        return [val.height, val.width * usedChannels.length];
      } else if (isWebGPUData(val)) {
        return [val.buffer.size / (dtype == null ? 4 : bytesPerElement(dtype))];
      }
      if (!Array.isArray(val)) {
        return [];
      }
      var shape = [];
      while (Array.isArray(firstElem) || isTypedArray(firstElem) && dtype !== "string") {
        shape.push(firstElem.length);
        firstElem = firstElem[0];
      }
      if (Array.isArray(val) && env().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")) {
        deepAssertShapeConsistency(val, shape, []);
      }
      return shape;
    }
    function deepAssertShapeConsistency(val, shape, indices) {
      indices = indices || [];
      if (!Array.isArray(val) && !isTypedArray(val)) {
        assert(shape.length === 0, function() {
          return "Element arr[".concat(indices.join("]["), "] is a primitive, ") + "but should be an array/TypedArray of ".concat(shape[0], " elements");
        });
        return;
      }
      assert(shape.length > 0, function() {
        return "Element arr[".concat(indices.join("]["), "] should be a primitive, ") + "but is an array of ".concat(val.length, " elements");
      });
      assert(val.length === shape[0], function() {
        return "Element arr[".concat(indices.join("]["), "] should have ").concat(shape[0], " ") + "elements, but has ".concat(val.length, " elements");
      });
      var subShape = shape.slice(1);
      for (var i = 0; i < val.length; ++i) {
        deepAssertShapeConsistency(val[i], subShape, indices.concat(i));
      }
    }
    function assertDtype(expectedDtype, actualDType, argName, functionName) {
      if (expectedDtype === "string_or_numeric") {
        return;
      }
      if (expectedDtype == null) {
        throw new Error("Expected dtype cannot be null.");
      }
      if (expectedDtype !== "numeric" && expectedDtype !== actualDType || expectedDtype === "numeric" && actualDType === "string") {
        throw new Error("Argument '".concat(argName, "' passed to '").concat(functionName, "' must ") + "be ".concat(expectedDtype, " tensor, but got ").concat(actualDType, " tensor"));
      }
    }
    function convertToTensor(x, argName, functionName, parseAsDtype) {
      if (parseAsDtype === void 0) {
        parseAsDtype = "numeric";
      }
      if (x instanceof getGlobalTensorClass()) {
        assertDtype(parseAsDtype, x.dtype, argName, functionName);
        return x;
      }
      var inferredDtype = inferDtype(x);
      if (inferredDtype !== "string" && ["bool", "int32", "float32"].indexOf(parseAsDtype) >= 0) {
        inferredDtype = parseAsDtype;
      }
      assertDtype(parseAsDtype, inferredDtype, argName, functionName);
      if (x == null || !isTypedArray(x) && !Array.isArray(x) && typeof x !== "number" && typeof x !== "boolean" && typeof x !== "string") {
        var type = x == null ? "null" : x.constructor.name;
        throw new Error("Argument '".concat(argName, "' passed to '").concat(functionName, "' must be a ") + "Tensor or TensorLike, but got '".concat(type, "'"));
      }
      var inferredShape = inferShape(x, inferredDtype);
      if (!isTypedArray(x) && !Array.isArray(x)) {
        x = [x];
      }
      var skipTypedArray = true;
      var values = inferredDtype !== "string" ? toTypedArray(x, inferredDtype) : flatten(x, [], skipTypedArray);
      return ENGINE.makeTensor(values, inferredShape, inferredDtype);
    }
    function convertToTensorArray(arg, argName, functionName, parseAsDtype) {
      if (parseAsDtype === void 0) {
        parseAsDtype = "numeric";
      }
      if (!Array.isArray(arg)) {
        throw new Error("Argument ".concat(argName, " passed to ").concat(functionName, " must be a ") + "`Tensor[]` or `TensorLike[]`");
      }
      var tensors = arg;
      return tensors.map(function(t, i) {
        return convertToTensor(t, "".concat(argName, "[").concat(i, "]"), functionName, parseAsDtype);
      });
    }
    var OP_SCOPE_SUFFIX = "__op";
    function op(f) {
      var keys = Object.keys(f);
      if (keys.length !== 1) {
        throw new Error("Please provide an object with a single key (operation name) mapping to a function. Got an object with " + "".concat(keys.length, " keys."));
      }
      var opName = keys[0];
      var fn = f[opName];
      if (opName.endsWith("_")) {
        opName = opName.substring(0, opName.length - 1);
      }
      opName = opName + OP_SCOPE_SUFFIX;
      var f2 = function() {
        var args = [];
        for (var _i = 0; _i < arguments.length; _i++) {
          args[_i] = arguments[_i];
        }
        ENGINE.startScope(opName);
        try {
          var result = fn.apply(void 0, __spreadArray([], __read(args), false));
          if (isPromise(result)) {
            console.error("Cannot return a Promise inside of tidy.");
          }
          ENGINE.endScope(result);
          return result;
        } catch (ex) {
          ENGINE.endScope(null);
          throw ex;
        }
      };
      Object.defineProperty(f2, "name", { value: opName, configurable: true });
      return f2;
    }
    function abs_(x) {
      var $x = convertToTensor(x, "x", "abs");
      if ($x.dtype === "complex64") {
        var inputs = { x: $x };
        return ENGINE.runKernel(ComplexAbs, inputs);
      } else {
        var inputs = { x: $x };
        return ENGINE.runKernel(Abs, inputs);
      }
    }
    var abs = /* @__PURE__ */ op({ abs_ });
    function acos_(x) {
      var $x = convertToTensor(x, "x", "acos");
      var inputs = { x: $x };
      return ENGINE.runKernel(Acos, inputs);
    }
    var acos = /* @__PURE__ */ op({ acos_ });
    function acosh_(x) {
      var $x = convertToTensor(x, "x", "acosh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Acosh, inputs);
    }
    var acosh = /* @__PURE__ */ op({ acosh_ });
    function add_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "add");
      var $b = convertToTensor(b, "b", "add");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Add, inputs);
    }
    var add = /* @__PURE__ */ op({ add_ });
    function addN_(tensors) {
      assert(Array.isArray(tensors), function() {
        return "The argument passed to tf.addN() must be a list of tensors";
      });
      assert(tensors.length >= 1, function() {
        return "Must pass at least one tensor to tf.addN(), but got " + "".concat(tensors.length);
      });
      var $tensors = tensors.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "addN");
      });
      var firstTensor = $tensors[0];
      $tensors.forEach(function(t) {
        if (t.dtype !== firstTensor.dtype) {
          throw new Error("All tensors passed to tf.addN() must have the same dtype");
        }
      });
      $tensors.forEach(function(t) {
        if (!arraysEqual(t.shape, firstTensor.shape)) {
          throw new Error("All tensors passed to tf.addN() must have the same shape");
        }
      });
      var inputs = $tensors;
      return ENGINE.runKernel(AddN, inputs);
    }
    var addN = /* @__PURE__ */ op({ addN_ });
    function all_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "all", "bool");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(All, inputs, attrs);
    }
    var all = /* @__PURE__ */ op({ all_ });
    function any_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "any", "bool");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Any, inputs, attrs);
    }
    var any = /* @__PURE__ */ op({ any_ });
    function argMax_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "argMax");
      var inputs = { x: $x };
      var attrs = { axis };
      return ENGINE.runKernel(ArgMax, inputs, attrs);
    }
    var argMax = /* @__PURE__ */ op({ argMax_ });
    function argMin_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "argMin");
      var inputs = { x: $x };
      var attrs = { axis };
      return ENGINE.runKernel(ArgMin, inputs, attrs);
    }
    var argMin = /* @__PURE__ */ op({ argMin_ });
    function asin_(x) {
      var $x = convertToTensor(x, "x", "asin");
      var inputs = { x: $x };
      return ENGINE.runKernel(Asin, inputs);
    }
    var asin = /* @__PURE__ */ op({ asin_ });
    function asinh_(x) {
      var $x = convertToTensor(x, "x", "asinh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Asinh, inputs);
    }
    var asinh = /* @__PURE__ */ op({ asinh_ });
    function atan_(x) {
      var $x = convertToTensor(x, "x", "atan");
      var inputs = { x: $x };
      return ENGINE.runKernel(Atan, inputs);
    }
    var atan = /* @__PURE__ */ op({ atan_ });
    function atan2_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "atan2");
      var $b = convertToTensor(b, "b", "atan2");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Atan2, inputs);
    }
    var atan2 = /* @__PURE__ */ op({ atan2_ });
    function atanh_(x) {
      var $x = convertToTensor(x, "x", "atanh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Atanh, inputs);
    }
    var atanh = /* @__PURE__ */ op({ atanh_ });
    function cast_(x, dtype) {
      var $x = convertToTensor(x, "x", "cast");
      if (!isValidDtype(dtype)) {
        throw new Error("Failed to cast to unknown dtype ".concat(dtype));
      }
      if (dtype === "string" && $x.dtype !== "string" || dtype !== "string" && $x.dtype === "string") {
        throw new Error("Only strings can be casted to strings");
      }
      var inputs = { x: $x };
      var attrs = { dtype };
      return ENGINE.runKernel(Cast, inputs, attrs);
    }
    var cast = /* @__PURE__ */ op({ cast_ });
    function computePool2DInfo(inShape, filterSize, strides, dilations, pad2, roundingMode, dataFormat) {
      if (dataFormat === void 0) {
        dataFormat = "channelsLast";
      }
      var _a = __read(parseTupleParam(filterSize), 2), filterHeight = _a[0], filterWidth = _a[1];
      var filterShape;
      if (dataFormat === "channelsLast") {
        filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];
      } else if (dataFormat === "channelsFirst") {
        filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];
      } else {
        throw new Error("Unknown dataFormat ".concat(dataFormat));
      }
      return computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, false, dataFormat);
    }
    function computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, depthwise, dataFormat) {
      var _a, _b;
      if (depthwise === void 0) {
        depthwise = false;
      }
      if (dataFormat === void 0) {
        dataFormat = "channelsLast";
      }
      var _c = __read([-1, -1, -1, -1], 4), batchSize = _c[0], inHeight = _c[1], inWidth = _c[2], inChannels = _c[3];
      if (dataFormat === "channelsLast") {
        _a = __read(inShape, 4), batchSize = _a[0], inHeight = _a[1], inWidth = _a[2], inChannels = _a[3];
      } else if (dataFormat === "channelsFirst") {
        _b = __read(inShape, 4), batchSize = _b[0], inChannels = _b[1], inHeight = _b[2], inWidth = _b[3];
      } else {
        throw new Error("Unknown dataFormat ".concat(dataFormat));
      }
      var _d = __read(filterShape, 4), filterHeight = _d[0], filterWidth = _d[1], filterChannels = _d[3];
      var _e = __read(parseTupleParam(strides), 2), strideHeight = _e[0], strideWidth = _e[1];
      var _f = __read(parseTupleParam(dilations), 2), dilationHeight = _f[0], dilationWidth = _f[1];
      var effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
      var effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
      var _g = getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode, dataFormat), padInfo = _g.padInfo, outHeight = _g.outHeight, outWidth = _g.outWidth;
      var outChannels = depthwise ? filterChannels * inChannels : filterChannels;
      var outShape;
      if (dataFormat === "channelsFirst") {
        outShape = [batchSize, outChannels, outHeight, outWidth];
      } else if (dataFormat === "channelsLast") {
        outShape = [batchSize, outHeight, outWidth, outChannels];
      }
      return {
        batchSize,
        dataFormat,
        inHeight,
        inWidth,
        inChannels,
        outHeight,
        outWidth,
        outChannels,
        padInfo,
        strideHeight,
        strideWidth,
        filterHeight,
        filterWidth,
        effectiveFilterHeight,
        effectiveFilterWidth,
        dilationHeight,
        dilationWidth,
        inShape,
        outShape,
        filterShape
      };
    }
    function computeOutputShape2D(inShape, fieldSize, stride, zeroPad, roundingMode) {
      if (zeroPad == null) {
        zeroPad = computeDefaultPad(inShape, fieldSize, stride);
      }
      var inputRows = inShape[0];
      var inputCols = inShape[1];
      var outputRows = round$1((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
      var outputCols = round$1((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
      return [outputRows, outputCols];
    }
    function computeDefaultPad(inputShape, fieldSize, stride, dilation) {
      if (dilation === void 0) {
        dilation = 1;
      }
      var effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);
      return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);
    }
    function parseTupleParam(param) {
      if (typeof param === "number") {
        return [param, param, param];
      }
      if (param.length === 2) {
        return [param[0], param[1], 1];
      }
      return param;
    }
    function getEffectiveFilterSize(filterSize, dilation) {
      if (dilation <= 1) {
        return filterSize;
      }
      return filterSize + (filterSize - 1) * (dilation - 1);
    }
    function getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode, dataFormat) {
      var padInfo;
      var outHeight;
      var outWidth;
      if (typeof pad2 === "number") {
        var padType = pad2 === 0 ? "VALID" : "NUMBER";
        padInfo = { top: pad2, bottom: pad2, left: pad2, right: pad2, type: padType };
        var outShape = computeOutputShape2D([inHeight, inWidth], filterHeight, strideHeight, pad2, roundingMode);
        outHeight = outShape[0];
        outWidth = outShape[1];
      } else if (pad2 === "same") {
        outHeight = Math.ceil(inHeight / strideHeight);
        outWidth = Math.ceil(inWidth / strideWidth);
        var padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);
        var padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);
        var top = Math.floor(padAlongHeight / 2);
        var bottom = padAlongHeight - top;
        var left = Math.floor(padAlongWidth / 2);
        var right = padAlongWidth - left;
        padInfo = { top, bottom, left, right, type: "SAME" };
      } else if (pad2 === "valid") {
        padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: "VALID" };
        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);
        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);
      } else if (typeof pad2 === "object") {
        var top = dataFormat === "channelsLast" ? pad2[1][0] : pad2[2][0];
        var bottom = dataFormat === "channelsLast" ? pad2[1][1] : pad2[2][1];
        var left = dataFormat === "channelsLast" ? pad2[2][0] : pad2[3][0];
        var right = dataFormat === "channelsLast" ? pad2[2][1] : pad2[3][1];
        var padType = top === 0 && bottom === 0 && left === 0 && right === 0 ? "VALID" : "EXPLICIT";
        padInfo = { top, bottom, left, right, type: padType };
        outHeight = round$1((inHeight - filterHeight + top + bottom) / strideHeight + 1, roundingMode);
        outWidth = round$1((inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);
      } else {
        throw Error("Unknown padding parameter: ".concat(pad2));
      }
      return { padInfo, outHeight, outWidth };
    }
    function round$1(value, roundingMode) {
      if (!roundingMode) {
        return Math.trunc(value);
      }
      switch (roundingMode) {
        case "round":
          return Math.round(value);
        case "ceil":
          return Math.ceil(value);
        case "floor":
          return Math.floor(value);
        default:
          throw new Error("Unknown roundingMode ".concat(roundingMode));
      }
    }
    function tupleValuesAreOne(param) {
      var _a = __read(parseTupleParam(param), 3), dimA = _a[0], dimB = _a[1], dimC = _a[2];
      return dimA === 1 && dimB === 1 && dimC === 1;
    }
    function eitherStridesOrDilationsAreOne(strides, dilations) {
      return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);
    }
    function stridesOrDilationsArePositive(values) {
      return parseTupleParam(values).every(function(value) {
        return value > 0;
      });
    }
    function checkPadOnDimRoundingMode(opDesc, pad2, dimRoundingMode) {
      if (dimRoundingMode != null) {
        if (typeof pad2 === "string") {
          throw Error("Error in ".concat(opDesc, ": pad must be an integer when using ") + "dimRoundingMode ".concat(dimRoundingMode, " but got pad ").concat(pad2, "."));
        } else if (typeof pad2 === "number") {
          assert(isInt(pad2), function() {
            return "Error in ".concat(opDesc, ": pad must be an integer when using ") + "dimRoundingMode ".concat(dimRoundingMode, " but got pad ").concat(pad2, ".");
          });
        } else if (typeof pad2 === "object") {
          pad2.forEach(function(p) {
            p.forEach(function(v) {
              assert(isInt(v), function() {
                return "Error in ".concat(opDesc, ": pad must be an integer when using ") + "dimRoundingMode ".concat(dimRoundingMode, " but got pad ").concat(v, ".");
              });
            });
          });
        } else {
          throw Error("Error in ".concat(opDesc, ": Unknown padding parameter: ").concat(pad2));
        }
      }
    }
    function reshape_(x, shape) {
      var $x = convertToTensor(x, "x", "reshape", "string_or_numeric");
      var inputs = { x: $x };
      var attrs = { shape };
      return ENGINE.runKernel(Reshape, inputs, attrs);
    }
    var reshape = /* @__PURE__ */ op({ reshape_ });
    function avgPool_(x, filterSize, strides, pad2, dimRoundingMode) {
      var $x = convertToTensor(x, "x", "avgPool", "float32");
      var dilations = 1;
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in avgPool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in avgPool: x must be rank 4 but got rank ".concat(x4D.rank, ".");
      });
      checkPadOnDimRoundingMode("avgPool", pad2, dimRoundingMode);
      var inputs = { x: x4D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
      var res = ENGINE.runKernel(AvgPool, inputs, attrs);
      res = cast(res, $x.dtype);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var avgPool = /* @__PURE__ */ op({ avgPool_ });
    function avgPool3d_(x, filterSize, strides, pad2, dimRoundingMode, dataFormat) {
      if (dataFormat === void 0) {
        dataFormat = "NDHWC";
      }
      var $x = convertToTensor(x, "x", "avgPool3d", "float32");
      var x5D = $x;
      var reshapedTo5D = false;
      if ($x.rank === 4) {
        reshapedTo5D = true;
        x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
      }
      assert(x5D.rank === 5, function() {
        return "Error in avgPool3d: x must be rank 5 but got rank ".concat(x5D.rank, ".");
      });
      assert(dataFormat === "NDHWC", function() {
        return "Error in avgPool3d: Only NDHWC is currently supported, " + "but got dataFormat of ".concat(dataFormat);
      });
      assert(typeof strides === "number" && strides > 0 || Array.isArray(strides) && strides[0] > 0 && strides[1] > 0 && strides[2] > 0, function() {
        return "Error in avgPool3d: Stride must be > 0, but got '".concat(strides, "'");
      });
      checkPadOnDimRoundingMode("avgPool3d", pad2, dimRoundingMode);
      var inputs = { x: x5D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat };
      var res = ENGINE.runKernel(AvgPool3D, inputs, attrs);
      res = cast(res, x5D.dtype);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var avgPool3d = /* @__PURE__ */ op({ avgPool3d_ });
    function clone_(x) {
      var $x = convertToTensor(x, "x", "clone", "string_or_numeric");
      var inputs = { x: $x };
      return ENGINE.runKernel(Identity, inputs);
    }
    var clone = /* @__PURE__ */ op({ clone_ });
    function concat_(tensors, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      assert(tensors.length >= 1, function() {
        return "Pass at least one tensor to concat";
      });
      var $tensors = convertToTensorArray(tensors, "tensors", "concat", "string_or_numeric");
      if ($tensors[0].dtype === "complex64") {
        $tensors.forEach(function(tensor2) {
          if (tensor2.dtype !== "complex64") {
            throw new Error("Cannot concatenate complex64 tensors with a tensor\n          with dtype ".concat(tensor2.dtype, ". "));
          }
        });
      }
      if ($tensors.length === 1) {
        return clone($tensors[0]);
      }
      var inputs = $tensors;
      var attr = { axis };
      return ENGINE.runKernel(Concat, inputs, attr);
    }
    var concat = /* @__PURE__ */ op({ concat_ });
    function matMul_(a, b, transposeA, transposeB) {
      var _a;
      if (transposeA === void 0) {
        transposeA = false;
      }
      if (transposeB === void 0) {
        transposeB = false;
      }
      var $a = convertToTensor(a, "a", "matMul");
      var $b = convertToTensor(b, "b", "matMul");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      var attrs = { transposeA, transposeB };
      return ENGINE.runKernel(BatchMatMul, inputs, attrs);
    }
    var matMul$1 = /* @__PURE__ */ op({ matMul_ });
    function mul_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "mul");
      var $b = convertToTensor(b, "b", "mul");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Multiply, inputs);
    }
    var mul = /* @__PURE__ */ op({ mul_ });
    function sigmoid_(x) {
      var $x = convertToTensor(x, "x", "sigmoid", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sigmoid, inputs);
    }
    var sigmoid = /* @__PURE__ */ op({ sigmoid_ });
    function slice_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice", "string_or_numeric");
      if ($x.rank === 0) {
        throw new Error("Slicing scalar is not possible");
      }
      var inputs = { x: $x };
      var attrs = { begin, size };
      return ENGINE.runKernel(Slice, inputs, attrs);
    }
    var slice = /* @__PURE__ */ op({ slice_ });
    function tanh_(x) {
      var $x = convertToTensor(x, "x", "tanh", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Tanh, inputs);
    }
    var tanh = /* @__PURE__ */ op({ tanh_ });
    function basicLSTMCell_(forgetBias, lstmKernel, lstmBias, data, c, h) {
      var $forgetBias = convertToTensor(forgetBias, "forgetBias", "basicLSTMCell");
      var $lstmKernel = convertToTensor(lstmKernel, "lstmKernel", "basicLSTMCell");
      var $lstmBias = convertToTensor(lstmBias, "lstmBias", "basicLSTMCell");
      var $data = convertToTensor(data, "data", "basicLSTMCell");
      var $c = convertToTensor(c, "c", "basicLSTMCell");
      var $h = convertToTensor(h, "h", "basicLSTMCell");
      var combined = concat([$data, $h], 1);
      var weighted = matMul$1(combined, $lstmKernel);
      var res = add(weighted, $lstmBias);
      var batchSize = res.shape[0];
      var sliceCols = res.shape[1] / 4;
      var sliceSize = [batchSize, sliceCols];
      var i = slice(res, [0, 0], sliceSize);
      var j = slice(res, [0, sliceCols], sliceSize);
      var f = slice(res, [0, sliceCols * 2], sliceSize);
      var o = slice(res, [0, sliceCols * 3], sliceSize);
      var newC = add(mul(sigmoid(i), tanh(j)), mul($c, sigmoid(add($forgetBias, f))));
      var newH = mul(tanh(newC), sigmoid(o));
      return [newC, newH];
    }
    var basicLSTMCell = /* @__PURE__ */ op({ basicLSTMCell_ });
    function batchToSpaceND_(x, blockShape, crops) {
      var $x = convertToTensor(x, "x", "batchToSpaceND");
      var prod2 = blockShape.reduce(function(a, b) {
        return a * b;
      });
      assert($x.rank >= 1 + blockShape.length, function() {
        return "input rank is ".concat($x.rank, " but should be > than blockShape.length ").concat(blockShape.length);
      });
      assert(crops.length === blockShape.length, function() {
        return "crops.length is ".concat(crops.length, " but should be equal to blockShape.length  ").concat(blockShape.length);
      });
      assert($x.shape[0] % prod2 === 0, function() {
        return "input tensor batch is ".concat($x.shape[0], " but is not divisible by the product of ") + "the elements of blockShape ".concat(blockShape.join(" * "), " === ").concat(prod2);
      });
      var inputs = { x: $x };
      var attrs = { blockShape, crops };
      return ENGINE.runKernel(BatchToSpaceND, inputs, attrs);
    }
    var batchToSpaceND = /* @__PURE__ */ op({ batchToSpaceND_ });
    function xAs4D(x) {
      var x4D;
      if (x.rank === 0 || x.rank === 1) {
        x4D = reshape(x, [1, 1, 1, x.size]);
      } else if (x.rank === 2) {
        x4D = reshape(x, [1, 1, x.shape[0], x.shape[1]]);
      } else if (x.rank === 3) {
        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
      } else {
        x4D = x;
      }
      return x4D;
    }
    function batchNorm_(x, mean2, variance, offset, scale, varianceEpsilon) {
      if (varianceEpsilon == null) {
        varianceEpsilon = 1e-3;
      }
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($mean.rank === $variance.rank, function() {
        return "Batch normalization gradient requires mean and variance to have equal ranks.";
      });
      assert($offset == null || $mean.rank === $offset.rank, function() {
        return "Batch normalization gradient requires mean and offset to have equal ranks.";
      });
      assert($scale == null || $mean.rank === $scale.rank, function() {
        return "Batch normalization gradient requires mean and scale to have equal ranks.";
      });
      var x4D = xAs4D($x);
      var inputs = {
        x: x4D,
        scale: $scale,
        offset: $offset,
        mean: $mean,
        variance: $variance
      };
      var attrs = { varianceEpsilon };
      var res = ENGINE.runKernel(FusedBatchNorm, inputs, attrs);
      return reshape(res, $x.shape);
    }
    var batchNorm = /* @__PURE__ */ op({ batchNorm_ });
    function batchNorm2d_(x, mean2, variance, offset, scale, varianceEpsilon) {
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($x.rank === 2, function() {
        return "Error in batchNorm2D: x must be rank 2 but got rank " + "".concat($x.rank, ".");
      });
      assert($mean.rank === 2 || $mean.rank === 1, function() {
        return "Error in batchNorm2D: mean must be rank 2 or rank 1 but " + "got rank ".concat($mean.rank, ".");
      });
      assert($variance.rank === 2 || $variance.rank === 1, function() {
        return "Error in batchNorm2D: variance must be rank 2 or rank 1 " + "but got rank ".concat($variance.rank, ".");
      });
      if ($scale != null) {
        assert($scale.rank === 2 || $scale.rank === 1, function() {
          return "Error in batchNorm2D: scale must be rank 2 or rank 1 " + "but got rank ".concat($scale.rank, ".");
        });
      }
      if ($offset != null) {
        assert($offset.rank === 2 || $offset.rank === 1, function() {
          return "Error in batchNorm2D: offset must be rank 2 or rank 1 " + "but got rank ".concat($offset.rank, ".");
        });
      }
      return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
    }
    var batchNorm2d = /* @__PURE__ */ op({ batchNorm2d_ });
    function batchNorm3d_(x, mean2, variance, offset, scale, varianceEpsilon) {
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($x.rank === 3, function() {
        return "Error in batchNorm3D: x must be rank 3 but got rank " + "".concat($x.rank, ".");
      });
      assert($mean.rank === 3 || $mean.rank === 1, function() {
        return "Error in batchNorm3D: mean must be rank 3 or rank 1 but " + "got rank ".concat($mean.rank, ".");
      });
      assert($variance.rank === 3 || $variance.rank === 1, function() {
        return "Error in batchNorm3D: variance must be rank 3 or rank 1 " + "but got rank ".concat($variance.rank, ".");
      });
      if ($scale != null) {
        assert($scale.rank === 3 || $scale.rank === 1, function() {
          return "Error in batchNorm3D: scale must be rank 3 or rank 1 " + "but got rank ".concat($scale.rank, ".");
        });
      }
      if ($offset != null) {
        assert($offset.rank === 3 || $offset.rank === 1, function() {
          return "Error in batchNorm3D: offset must be rank 3 or rank 1 " + "but got rank ".concat($offset.rank, ".");
        });
      }
      return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
    }
    var batchNorm3d = /* @__PURE__ */ op({ batchNorm3d_ });
    function batchNorm4d_(x, mean2, variance, offset, scale, varianceEpsilon) {
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($x.rank === 4, function() {
        return "Error in batchNorm4D: x must be rank 4 but got rank " + "".concat($x.rank, ".");
      });
      assert($mean.rank === 4 || $mean.rank === 1, function() {
        return "Error in batchNorm4D: mean must be rank 4 or rank 1 but " + "got rank ".concat($mean.rank, ".");
      });
      assert($variance.rank === 4 || $variance.rank === 1, function() {
        return "Error in batchNorm4D: variance must be rank 4 or rank 1 " + "but got rank ".concat($variance.rank, ".");
      });
      if ($scale != null) {
        assert($scale.rank === 4 || $scale.rank === 1, function() {
          return "Error in batchNorm4D: scale must be rank 4 or rank 1 " + "but got rank ".concat($scale.rank, ".");
        });
      }
      if ($offset != null) {
        assert($offset.rank === 4 || $offset.rank === 1, function() {
          return "Error in batchNorm4D: offset must be rank 4 or rank 1 " + "but got rank ".concat($offset.rank, ".");
        });
      }
      return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
    }
    var batchNorm4d = /* @__PURE__ */ op({ batchNorm4d_ });
    function bincount_(x, weights, size) {
      var $x = convertToTensor(x, "x", "bincount");
      var $weights = convertToTensor(weights, "weights", "bincount");
      assert($x.dtype === "int32", function() {
        return "Error in bincount: input " + "dtype must be int32, but got ".concat($x.dtype);
      });
      assert(size >= 0, function() {
        return "size must be non-negative, but got ".concat(size, ".");
      });
      assert($weights.size === $x.size || $weights.size === 0, function() {
        return "Error in bincount: weights must have the same size as input or" + "0-length, but got input shape: ".concat($x.shape, ", weights shape: ") + "".concat($weights.shape, ".");
      });
      var inputs = { x: $x, weights: $weights };
      var attrs = { size };
      return ENGINE.runKernel(Bincount, inputs, attrs);
    }
    var bincount = /* @__PURE__ */ op({ bincount_ });
    function bitwiseAnd_(x, y) {
      var $x = convertToTensor(x, "x", "bitwiseAnd");
      var $y = convertToTensor(y, "y", "bitwiseAnd");
      if (!arraysEqual($x.shape, $y.shape)) {
        throw new Error("BitwiseAnd: Tensors must have the same shape. x: ".concat($x.shape, ", y: ").concat($y.shape));
      }
      if ($x.dtype !== "int32" || $y.dtype !== "int32") {
        throw new Error("BitwiseAnd: Only supports 'int32' values in tensor, found type of x: ".concat($x.dtype, " and type of y: ").concat($y.dtype));
      }
      var inputs = { a: $x, b: $y };
      return ENGINE.runKernel(BitwiseAnd, inputs);
    }
    var bitwiseAnd = /* @__PURE__ */ op({ bitwiseAnd_ });
    function broadcastArgs_(s0, s1) {
      var shape1Input = convertToTensor(s0, "s0", "broadcastArgs", "int32");
      var shape2Input = convertToTensor(s1, "s1", "broadcastArgs", "int32");
      if (shape1Input.rank !== 1) {
        throw new Error("broadcastArgs(): first input must be a vector (rank=1). " + "Has rank ".concat(shape1Input.rank));
      }
      if (shape2Input.rank !== 1) {
        throw new Error("broadcastArgs(): second input must be a vector (rank=1). " + "Has rank ".concat(shape2Input.rank));
      }
      var inputs = { s0: shape1Input, s1: shape2Input };
      return ENGINE.runKernel(BroadcastArgs, inputs);
    }
    var broadcastArgs = /* @__PURE__ */ op({ broadcastArgs_ });
    function broadcastTo_(x, shape) {
      var input = convertToTensor(x, "broadcastTo", "x");
      var xShape = input.shape;
      assertNonNegativeIntegerDimensions(shape);
      if (shape.length < input.rank) {
        throw new Error("broadcastTo(): shape.length=".concat(shape.length, " < input.rank=").concat(input.rank, "."));
      }
      if (shape.length > input.rank) {
        var newShape = input.shape.slice();
        while (newShape.length < shape.length) {
          newShape.unshift(1);
        }
        input = reshape(input, newShape);
      }
      var inputShape = input.shape;
      var reps = Array.from(shape);
      for (var i = shape.length - 1; i >= 0; i--) {
        if (inputShape[i] === shape[i]) {
          reps[i] = 1;
        } else if (input.shape[i] !== 1) {
          throw new Error("broadcastTo(): [".concat(xShape, "] cannot be broadcast to [").concat(shape, "]."));
        }
      }
      var axes = reps.map(function(n, i2) {
        return n > 1 ? i2 : -1;
      }).filter(function(i2) {
        return i2 >= 0;
      });
      if (axes.length === 0) {
        return clone(input);
      }
      var inputs = { x: input };
      var attrs = { reps };
      return ENGINE.runKernel(Tile, inputs, attrs);
    }
    var broadcastTo = /* @__PURE__ */ op({ broadcastTo_ });
    function buffer(shape, dtype, values) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      dtype = dtype || "float32";
      assertNonNegativeIntegerDimensions(shape);
      return new TensorBuffer(shape, dtype, values);
    }
    function ceil_(x) {
      var $x = convertToTensor(x, "x", "ceil", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Ceil, inputs);
    }
    var ceil = /* @__PURE__ */ op({ ceil_ });
    function fill(shape, value, dtype) {
      assertNonNegativeIntegerDimensions(shape);
      dtype = dtype || inferDtype(value);
      var attrs = { shape, value, dtype };
      return ENGINE.runKernel(Fill, {}, attrs);
    }
    function clipByValue_(x, clipValueMin, clipValueMax) {
      var $x = convertToTensor(x, "x", "clipByValue");
      assert(clipValueMin <= clipValueMax, function() {
        return "Error in clip: min (".concat(clipValueMin, ") must be ") + "less than or equal to max (".concat(clipValueMax, ").");
      });
      if (clipValueMin === clipValueMax) {
        return fill($x.shape, clipValueMin, $x.dtype);
      }
      var inputs = { x: $x };
      var attrs = { clipValueMin, clipValueMax };
      return ENGINE.runKernel(ClipByValue, inputs, attrs);
    }
    var clipByValue = /* @__PURE__ */ op({ clipByValue_ });
    function complex_(real2, imag2) {
      var $real = convertToTensor(real2, "real", "complex");
      var $imag = convertToTensor(imag2, "imag", "complex");
      assertShapesMatch($real.shape, $imag.shape, "real and imag shapes, ".concat($real.shape, " and ").concat($imag.shape, ", ") + "must match in call to tf.complex().");
      var inputs = { real: $real, imag: $imag };
      return ENGINE.runKernel(Complex, inputs);
    }
    var complex = /* @__PURE__ */ op({ complex_ });
    function concat1d_(tensors) {
      return concat(
        tensors,
        0
        /* axis */
      );
    }
    var concat1d = /* @__PURE__ */ op({ concat1d_ });
    function concat2d_(tensors, axis) {
      return concat(tensors, axis);
    }
    var concat2d = /* @__PURE__ */ op({ concat2d_ });
    function concat3d_(tensors, axis) {
      return concat(tensors, axis);
    }
    var concat3d = /* @__PURE__ */ op({ concat3d_ });
    function concat4d_(tensors, axis) {
      return concat(tensors, axis);
    }
    var concat4d = /* @__PURE__ */ op({ concat4d_ });
    function conv2d_(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var $x = convertToTensor(x, "x", "conv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "conv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in conv2d: input must be rank 4, but got rank ".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in conv2d: filter must be rank 4, but got rank " + "".concat($filter.rank, ".");
      });
      checkPadOnDimRoundingMode("conv2d", pad2, dimRoundingMode);
      var inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      assert(inDepth === $filter.shape[2], function() {
        return "Error in conv2d: depth of input (".concat(inDepth, ") must match ") + "input depth for filter ".concat($filter.shape[2], ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in conv2D: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      assert(stridesOrDilationsArePositive(dilations), function() {
        return "Error in conv2D: Dilated rates should be larger than 0.";
      });
      assert(stridesOrDilationsArePositive(strides), function() {
        return "Error in conv2D: Strides should be larger than 0.";
      });
      var inputs = { x: x4D, filter: $filter };
      var attrs = { strides, pad: pad2, dataFormat, dilations, dimRoundingMode };
      var res = ENGINE.runKernel(Conv2D, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var conv2d$1 = /* @__PURE__ */ op({ conv2d_ });
    function conv1d_(x, filter, stride, pad2, dataFormat, dilation, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NWC";
      }
      if (dilation === void 0) {
        dilation = 1;
      }
      var $x = convertToTensor(x, "x", "conv1d");
      var $filter = convertToTensor(filter, "filter", "conv1d");
      var x3D = $x;
      var reshapedTo3D = false;
      if ($x.rank === 2) {
        reshapedTo3D = true;
        x3D = reshape($x, [1, $x.shape[0], $x.shape[1]]);
      }
      assert(x3D.rank === 3, function() {
        return "Error in conv1d: input must be rank 3, but got rank ".concat(x3D.rank, ".");
      });
      assert($filter.rank === 3, function() {
        return "Error in conv1d: filter must be rank 3, but got rank " + "".concat($filter.rank, ".");
      });
      checkPadOnDimRoundingMode("conv1d", pad2, dimRoundingMode);
      assert(x3D.shape[2] === $filter.shape[1], function() {
        return "Error in conv1d: depth of input (".concat(x3D.shape[2], ") must match ") + "input depth for filter ".concat($filter.shape[1], ".");
      });
      assert(eitherStridesOrDilationsAreOne(stride, dilation), function() {
        return "Error in conv1D: Either stride or dilation must be 1. " + "Got stride ".concat(stride, " and dilation '").concat(dilation, "'");
      });
      assert(stridesOrDilationsArePositive(dilation), function() {
        return "Error in conv1D: Dilated rates should be larger than 0.";
      });
      assert(stridesOrDilationsArePositive(stride), function() {
        return "Error in conv1D: Stride should be larger than 0.";
      });
      assert(dataFormat === "NWC", function() {
        return "Error in conv1d: got dataFormat of ".concat(dataFormat, " but only NWC is currently supported.");
      });
      var filter4D = reshape($filter, [1, $filter.shape[0], $filter.shape[1], $filter.shape[2]]);
      var input4D = reshape(x3D, [x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]]);
      var strides = [1, stride];
      var dilations = [1, dilation];
      var conv2dDataFormat = "NHWC";
      var res = conv2d$1(input4D, filter4D, strides, pad2, conv2dDataFormat, dilations, dimRoundingMode);
      if (reshapedTo3D) {
        return reshape(res, [res.shape[2], res.shape[3]]);
      }
      return reshape(res, [res.shape[0], res.shape[2], res.shape[3]]);
    }
    var conv1d = /* @__PURE__ */ op({ conv1d_ });
    function conv2DBackpropInput_(xShape, dy, filter, strides, pad2, dataFormat, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      assert(xShape.length === dy.rank, function() {
        return "Length of inShape " + "(".concat(xShape.length, ") and rank of dy (").concat(dy.rank, ") must match");
      });
      var xShape4D = xShape;
      var dy4D = dy;
      var reshapedTo4D = false;
      if (dy.rank === 3) {
        reshapedTo4D = true;
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
        xShape4D = [1, xShape[0], xShape[1], xShape[2]];
      }
      assert(xShape4D.length === 4, function() {
        return "Error in conv2dDerInput: inShape must be length 4, but got length " + "".concat(xShape4D.length, ".");
      });
      assert(dy4D.rank === 4, function() {
        return "Error in conv2dDerInput: dy must be rank 4, but got " + "rank ".concat(dy4D.rank);
      });
      assert(filter.rank === 4, function() {
        return "Error in conv2dDerInput: filter must be rank 4, but got " + "rank ".concat(filter.rank);
      });
      var inDepth = dataFormat === "NHWC" ? xShape4D[3] : xShape4D[1];
      var outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
      assert(inDepth === filter.shape[2], function() {
        return "Error in conv2dDerInput: depth of input (".concat(inDepth, ") must ") + "match input depth for filter ".concat(filter.shape[2], ".");
      });
      assert(outDepth === filter.shape[3], function() {
        return "Error in conv2dDerInput: depth of output (".concat(outDepth, ") must ") + "match output depth for filter ".concat(filter.shape[3], ".");
      });
      checkPadOnDimRoundingMode("conv2dDerInput", pad2, dimRoundingMode);
      var inputs = { dy: dy4D, filter };
      var attrs = { strides, pad: pad2, dataFormat, dimRoundingMode, inputShape: xShape4D };
      var res = ENGINE.runKernel(Conv2DBackpropInput, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var conv2DBackpropInput = /* @__PURE__ */ op({ conv2DBackpropInput_ });
    function conv2dTranspose_(x, filter, outputShape, strides, pad2, dimRoundingMode) {
      var $x = convertToTensor(x, "x", "conv2dTranspose");
      var $filter = convertToTensor(filter, "filter", "conv2dTranspose");
      return conv2DBackpropInput(outputShape, $x, $filter, strides, pad2, "NHWC", dimRoundingMode);
    }
    var conv2dTranspose = /* @__PURE__ */ op({ conv2dTranspose_ });
    function conv3d_(x, filter, strides, pad2, dataFormat, dilations) {
      if (dataFormat === void 0) {
        dataFormat = "NDHWC";
      }
      if (dilations === void 0) {
        dilations = [1, 1, 1];
      }
      var $x = convertToTensor(x, "x", "conv3d");
      var $filter = convertToTensor(filter, "filter", "conv3d");
      var x5D = $x;
      var reshapedTo5D = false;
      if ($x.rank === 4) {
        reshapedTo5D = true;
        x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
      }
      assert(x5D.rank === 5, function() {
        return "Error in conv3d: input must be rank 5, but got rank ".concat(x5D.rank, ".");
      });
      assert($filter.rank === 5, function() {
        return "Error in conv3d: filter must be rank 5, but got rank " + "".concat($filter.rank, ".");
      });
      assert(x5D.shape[4] === $filter.shape[3], function() {
        return "Error in conv3d: depth of input (".concat(x5D.shape[4], ") must match ") + "input depth for filter ".concat($filter.shape[3], ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in conv3D: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      assert(dataFormat === "NDHWC", function() {
        return "Error in conv3d: got dataFormat of ".concat(dataFormat, " but only NDHWC is currently supported.");
      });
      assert(stridesOrDilationsArePositive(dilations), function() {
        return "Error in conv3D: Dilated rates should be larger than 0.";
      });
      assert(stridesOrDilationsArePositive(strides), function() {
        return "Error in conv3D: Strides should be larger than 0.";
      });
      var inputs = { x: x5D, filter: $filter };
      var attrs = { strides, pad: pad2, dataFormat, dilations };
      var res = ENGINE.runKernel(Conv3D, inputs, attrs);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var conv3d = /* @__PURE__ */ op({ conv3d_ });
    function conv3DBackpropInput_(xShape, dy, filter, strides, pad2) {
      assert(xShape.length === dy.rank, function() {
        return "Length of inShape " + "(".concat(xShape.length, ") and rank of dy (").concat(dy.rank, ") must match");
      });
      var xShape5D = xShape;
      var dy5D = dy;
      var reshapedTo5D = false;
      if (dy.rank === 4) {
        reshapedTo5D = true;
        dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);
        xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];
      }
      var inDepth = xShape5D[4];
      var outDepth = dy5D.shape[4];
      assert(xShape5D.length === 5, function() {
        return "Error in conv3dDerInput: inShape must be length 5, but got length " + "".concat(xShape5D.length, ".");
      });
      assert(dy5D.rank === 5, function() {
        return "Error in conv3dDerInput: dy must be rank 5, but got " + "rank ".concat(dy5D.rank);
      });
      assert(filter.rank === 5, function() {
        return "Error in conv3dDerInput: filter must be rank 5, but got " + "rank ".concat(filter.rank);
      });
      assert(inDepth === filter.shape[3], function() {
        return "Error in conv3dDerInput: depth of input (".concat(inDepth, ") must ") + "match input depth for filter ".concat(filter.shape[3], ".");
      });
      assert(outDepth === filter.shape[4], function() {
        return "Error in conv3dDerInput: depth of output (".concat(outDepth, ") must ") + "match output depth for filter ".concat(filter.shape[4], ".");
      });
      var inputs = { dy: dy5D, filter };
      var attrs = { pad: pad2, strides, inputShape: xShape5D };
      var res = ENGINE.runKernel(Conv3DBackpropInputV2, inputs, attrs);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var conv3DBackpropInput = /* @__PURE__ */ op({ conv3DBackpropInput_ });
    function conv3dTranspose_(x, filter, outputShape, strides, pad2) {
      var $x = convertToTensor(x, "x", "conv3dTranspose");
      var $filter = convertToTensor(filter, "filter", "conv3dTranspose");
      return conv3DBackpropInput(outputShape, $x, $filter, strides, pad2);
    }
    var conv3dTranspose = /* @__PURE__ */ op({ conv3dTranspose_ });
    function cos_(x) {
      var $x = convertToTensor(x, "x", "cos", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Cos, inputs);
    }
    var cos = /* @__PURE__ */ op({ cos_ });
    function cosh_(x) {
      var $x = convertToTensor(x, "x", "cosh", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Cosh, inputs);
    }
    var cosh = /* @__PURE__ */ op({ cosh_ });
    function cumprod_(x, axis, exclusive, reverse2) {
      if (axis === void 0) {
        axis = 0;
      }
      if (exclusive === void 0) {
        exclusive = false;
      }
      if (reverse2 === void 0) {
        reverse2 = false;
      }
      var $x = convertToTensor(x, "x", "cumprod");
      var inputs = { x: $x };
      var attrs = { axis, exclusive, reverse: reverse2 };
      return ENGINE.runKernel(Cumprod, inputs, attrs);
    }
    var cumprod = /* @__PURE__ */ op({ cumprod_ });
    function cumsum_(x, axis, exclusive, reverse2) {
      if (axis === void 0) {
        axis = 0;
      }
      if (exclusive === void 0) {
        exclusive = false;
      }
      if (reverse2 === void 0) {
        reverse2 = false;
      }
      var $x = convertToTensor(x, "x", "cumsum");
      var inputs = { x: $x };
      var attrs = { axis, exclusive, reverse: reverse2 };
      return ENGINE.runKernel(Cumsum, inputs, attrs);
    }
    var cumsum = /* @__PURE__ */ op({ cumsum_ });
    function denseBincount_(x, weights, size, binaryOutput) {
      if (binaryOutput === void 0) {
        binaryOutput = false;
      }
      var $x = convertToTensor(x, "x", "denseBincount");
      var $weights = convertToTensor(weights, "weights", "denseBincount");
      assert($x.dtype === "int32", function() {
        return "Error in denseBincount: input " + "dtype must be int32, but got ".concat($x.dtype);
      });
      assert($x.rank <= 2, function() {
        return "Error in denseBincount: input must be at most rank 2, but got " + "rank ".concat($x.rank, ".");
      });
      assert(size >= 0, function() {
        return "size must be non-negative, but got ".concat(size, ".");
      });
      assert($weights.size === $x.size || $weights.size === 0, function() {
        return "Error in denseBincount: weights must have the same shape as x or " + "0-length, but got x shape: ".concat($x.shape, ", weights shape: ") + "".concat($weights.shape, ".");
      });
      var inputs = { x: $x, weights: $weights };
      var attrs = { size, binaryOutput };
      return ENGINE.runKernel(DenseBincount, inputs, attrs);
    }
    var denseBincount = /* @__PURE__ */ op({ denseBincount_ });
    function depthToSpace_(x, blockSize, dataFormat) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var $x = convertToTensor(x, "x", "depthToSpace", "float32");
      var inputHeight = dataFormat === "NHWC" ? $x.shape[1] : $x.shape[2];
      var inputWidth = dataFormat === "NHWC" ? $x.shape[2] : $x.shape[3];
      var inputDepth = dataFormat === "NHWC" ? $x.shape[3] : $x.shape[1];
      assert(blockSize > 1, function() {
        return "blockSize should be > 1 for depthToSpace, but was: ".concat(blockSize);
      });
      assert(inputHeight * blockSize >= 0, function() {
        return "Negative dimension size caused by overflow when multiplying\n    ".concat(inputHeight, " and ").concat(blockSize, "  for depthToSpace with input shape\n    ").concat($x.shape);
      });
      assert(inputWidth * blockSize >= 0, function() {
        return "Negative dimension size caused by overflow when multiplying\n    ".concat(inputWidth, " and ").concat(blockSize, " for depthToSpace with input shape\n        ").concat($x.shape);
      });
      assert(inputDepth % (blockSize * blockSize) === 0, function() {
        return "Dimension size must be evenly divisible by ".concat(blockSize * blockSize, " but is ").concat(inputDepth, " for depthToSpace with input shape ").concat($x.shape);
      });
      var inputs = { x: $x };
      var attrs = { blockSize, dataFormat };
      return ENGINE.runKernel(DepthToSpace, inputs, attrs);
    }
    var depthToSpace = /* @__PURE__ */ op({ depthToSpace_ });
    function depthwiseConv2d_(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in depthwiseConv2d: input must be rank 4, but got " + "rank ".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in depthwiseConv2d: filter must be rank 4, but got rank " + "".concat($filter.rank, ".");
      });
      var inChannels = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      assert(inChannels === $filter.shape[2], function() {
        return "Error in depthwiseConv2d: number of input channels " + "(".concat(inChannels, ") must match the inChannels dimension in ") + "filter ".concat($filter.shape[2], ".");
      });
      checkPadOnDimRoundingMode("depthwiseConv2d", pad2, dimRoundingMode);
      var inputs = { x: x4D, filter: $filter };
      var attrs = { strides, pad: pad2, dataFormat, dilations, dimRoundingMode };
      var res = ENGINE.runKernel(DepthwiseConv2dNative, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var depthwiseConv2d$1 = /* @__PURE__ */ op({ depthwiseConv2d_ });
    function diag_(x) {
      var $x = convertToTensor(x, "x", "diag");
      var inputs = { x: $x };
      return ENGINE.runKernel(Diag, inputs);
    }
    var diag = /* @__PURE__ */ op({ diag_ });
    function dilation2d_(x, filter, strides, pad2, dilations, dataFormat) {
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var $x = convertToTensor(x, "x", "dilation2d");
      var $filter = convertToTensor(filter, "filter", "dilation2d");
      assert($x.rank === 3 || $x.rank === 4, function() {
        return "Error in dilation2d: input must be rank 3 or 4, but got rank " + "".concat($x.rank, ".");
      });
      assert($filter.rank === 3, function() {
        return "Error in dilation2d: filter must be rank 3, but got rank " + "".concat($filter.rank, ".");
      });
      assert(dataFormat === "NHWC", function() {
        return "Error in dilation2d: Only NHWC is currently supported, " + "but got dataFormat of ".concat(dataFormat);
      });
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
        reshapedTo4D = true;
      }
      assert(x4D.shape[3] === $filter.shape[2], function() {
        return "Error in dilation2d:  input and filter must have the same depth: ".concat(x4D.shape[3], " vs ").concat($filter.shape[2]);
      });
      var inputs = { x: x4D, filter: $filter };
      var attrs = { strides, pad: pad2, dilations };
      var res = ENGINE.runKernel(Dilation2D, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var dilation2d = /* @__PURE__ */ op({ dilation2d_ });
    function floorDiv_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "floorDiv");
      var $b = convertToTensor(b, "b", "floorDiv");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(FloorDiv, inputs);
    }
    var floorDiv = /* @__PURE__ */ op({ floorDiv_ });
    function div_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "div");
      var $b = convertToTensor(b, "b", "div");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      if ($a.dtype === "int32" && $b.dtype === "int32") {
        return floorDiv($a, $b);
      }
      var inputs = { a: $a, b: $b };
      var attrs = {};
      return ENGINE.runKernel(RealDiv, inputs, attrs);
    }
    var div = /* @__PURE__ */ op({ div_ });
    function getReductionAxes(inShape, outShape) {
      var result = [];
      for (var i = 0; i < outShape.length; i++) {
        var inDim = inShape[inShape.length - i - 1];
        var outAxis = outShape.length - i - 1;
        var outDim = outShape[outAxis];
        if (inDim == null || inDim === 1 && outDim > 1) {
          result.unshift(outAxis);
        }
      }
      return result;
    }
    function assertAndGetBroadcastShape(shapeA, shapeB) {
      var l = Math.max(shapeA.length, shapeB.length);
      var result = new Array(l);
      for (var i = 0; i < l; i++) {
        var a = shapeA[shapeA.length - i - 1];
        if (a == null) {
          a = 1;
        }
        var b = shapeB[shapeB.length - i - 1];
        if (b == null) {
          b = 1;
        }
        if (a === 1) {
          result[l - i - 1] = b;
        } else if (b === 1) {
          result[l - i - 1] = a;
        } else if (a !== b) {
          var errMsg = "Operands could not be broadcast together with shapes " + "".concat(shapeA, " and ").concat(shapeB, ".");
          throw Error(errMsg);
        } else {
          result[l - i - 1] = a;
        }
      }
      return result;
    }
    function equal_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "equal", "string_or_numeric");
      var $b = convertToTensor(b, "b", "equal", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Equal, inputs);
    }
    var equal = /* @__PURE__ */ op({ equal_ });
    function where_(condition, a, b) {
      var $a = convertToTensor(a, "a", "where");
      var $b = convertToTensor(b, "b", "where");
      var $condition = convertToTensor(condition, "condition", "where", "bool");
      var broadcastShape = assertAndGetBroadcastShape(assertAndGetBroadcastShape($condition.shape, $a.shape), $b.shape);
      var $broadcastedCondition = broadcastTo($condition, broadcastShape);
      var $broadcastedA = broadcastTo($a, broadcastShape);
      var $broadcastedB = broadcastTo($b, broadcastShape);
      var inputs = {
        condition: $broadcastedCondition,
        t: $broadcastedA,
        e: $broadcastedB
      };
      return ENGINE.runKernel(Select, inputs);
    }
    var where = /* @__PURE__ */ op({ where_ });
    function zerosLike_(x) {
      var $x = convertToTensor(x, "x", "zerosLike");
      var inputs = { x: $x };
      return ENGINE.runKernel(ZerosLike, inputs);
    }
    var zerosLike = /* @__PURE__ */ op({ zerosLike_ });
    function divNoNan_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "div");
      var $b = convertToTensor(b, "b", "div");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var divResult = div($a, $b);
      var zeros2 = zerosLike(divResult);
      var bEqualsZero = equal($b, zeros2);
      return where(bEqualsZero, zeros2, divResult);
    }
    var divNoNan = /* @__PURE__ */ op({ divNoNan_ });
    function dot_(t1, t2) {
      var $t1 = convertToTensor(t1, "t1", "dot");
      var $t2 = convertToTensor(t2, "t2", "dot");
      assert(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), function() {
        return "Error in dot: inputs must all be rank 1 or 2, but got ranks " + "".concat($t1.rank, " and ").concat($t2.rank, ".");
      });
      var t1Inner = $t1.rank === 1 ? $t1.size : $t1.shape[1];
      var t2Inner = $t2.rank === 1 ? $t2.size : $t2.shape[0];
      assert(t1Inner === t2Inner, function() {
        return "Error in dot: inner dimensions of inputs must match, but got " + "".concat(t1Inner, " and ").concat(t2Inner, ".");
      });
      if ($t1.rank === 1 && $t2.rank === 1) {
        var t12D = reshape($t1, [1, -1]);
        var t22D = reshape($t2, [-1, 1]);
        var t1t2 = matMul$1(t12D, t22D);
        return reshape(t1t2, []);
      } else if ($t1.rank === 1 && $t2.rank === 2) {
        var t12D = reshape($t1, [1, -1]);
        var t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
        var t1t2 = matMul$1(t12D, t22D);
        return reshape(t1t2, [t1t2.size]);
      } else if ($t1.rank === 2 && $t2.rank === 1) {
        var t22D = reshape($t2, [-1, 1]);
        var t1t2 = matMul$1($t1, t22D);
        return reshape(t1t2, [t1t2.size]);
      } else {
        var t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
        var t1t2 = matMul$1($t1, t22D);
        return t1t2;
      }
    }
    var dot = /* @__PURE__ */ op({ dot_ });
    function einsum_(equation) {
      var tensors = [];
      for (var _i = 1; _i < arguments.length; _i++) {
        tensors[_i - 1] = arguments[_i];
      }
      var $tensors = tensors.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "einsum");
      });
      var attrs = { equation };
      return ENGINE.runKernel(Einsum, $tensors, attrs);
    }
    var einsum = /* @__PURE__ */ op({ einsum_ });
    function elu_(x) {
      var $x = convertToTensor(x, "x", "elu", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Elu, inputs);
    }
    var elu = /* @__PURE__ */ op({ elu_ });
    function ensureShape_(x, shape) {
      var $x = convertToTensor(x, "x", "ensureShape", "string_or_numeric");
      if (!arraysEqualWithNull($x.shape, shape)) {
        throw new Error("EnsureShape: Shape of tensor ".concat($x.shape, " is not compatible with expected shape ").concat(shape));
      }
      return x;
    }
    var ensureShape = /* @__PURE__ */ op({ ensureShape_ });
    function erf_(x) {
      var $x = convertToTensor(x, "x", "erf");
      assert($x.dtype === "int32" || $x.dtype === "float32", function() {
        return "Input dtype must be `int32` or `float32`.";
      });
      if ($x.dtype === "int32") {
        $x = cast($x, "float32");
      }
      var inputs = { x: $x };
      return ENGINE.runKernel(Erf, inputs);
    }
    var erf = /* @__PURE__ */ op({ erf_ });
    function combineLocations(outputLoc, reduceLoc, axes) {
      var rank = outputLoc.length + reduceLoc.length;
      var loc = [];
      var outIdx = 0;
      var reduceIdx = 0;
      for (var dim = 0; dim < rank; dim++) {
        if (axes.indexOf(dim) === -1) {
          loc.push(outputLoc[outIdx++]);
        } else {
          loc.push(reduceLoc[reduceIdx++]);
        }
      }
      return loc;
    }
    function expandShapeToKeepDim(shape, axes) {
      var reduceSubShape = axes.map(function(x) {
        return 1;
      });
      return combineLocations(shape, reduceSubShape, axes);
    }
    function max_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "max");
      var inputs = { x: $x };
      var attrs = { reductionIndices: axis, keepDims };
      return ENGINE.runKernel(Max, inputs, attrs);
    }
    var max = /* @__PURE__ */ op({ max_ });
    function min_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "min");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Min, inputs, attrs);
    }
    var min = /* @__PURE__ */ op({ min_ });
    function pow_(base, exp2) {
      var _a;
      var $base = convertToTensor(base, "base", "pow");
      var $exp = convertToTensor(exp2, "exp", "pow");
      _a = __read(makeTypesMatch($base, $exp), 2), $base = _a[0], $exp = _a[1];
      var inputs = { a: $base, b: $exp };
      return ENGINE.runKernel(Pow, inputs);
    }
    var pow = /* @__PURE__ */ op({ pow_ });
    function makeTensor(values, shape, inferredShape, dtype) {
      if (dtype == null) {
        dtype = inferDtype(values);
      } else if (dtype === "complex64") {
        throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");
      }
      if (isWebGPUData(values) || isWebGLData(values)) {
        if (dtype !== "float32" && dtype !== "int32") {
          throw new Error("Creating tensor from GPU data only supports " + "'float32'|'int32' dtype, while the dtype is ".concat(dtype, "."));
        }
        return ENGINE.backend.createTensorFromGPUData(values, shape || inferredShape, dtype);
      }
      if (!isTypedArray(values) && !Array.isArray(values) && typeof values !== "number" && typeof values !== "boolean" && typeof values !== "string") {
        throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");
      }
      if (shape != null) {
        assertNonNegativeIntegerDimensions(shape);
        var providedSize_1 = sizeFromShape(shape);
        var inferredSize_1 = sizeFromShape(inferredShape);
        assert(providedSize_1 === inferredSize_1, function() {
          return "Based on the provided shape, [".concat(shape, "], the tensor should have ") + "".concat(providedSize_1, " values but has ").concat(inferredSize_1);
        });
        for (var i = 0; i < inferredShape.length; ++i) {
          var inferred = inferredShape[i];
          var flatDimsDontMatch = i === inferredShape.length - 1 ? inferred !== sizeFromShape(shape.slice(i)) : true;
          assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, function() {
            return "Error creating a new Tensor. Inferred shape " + "(".concat(inferredShape, ") does not match the provided ") + "shape (".concat(shape, "). ");
          });
        }
      }
      if (!isTypedArray(values) && !Array.isArray(values)) {
        values = [values];
      }
      shape = shape || inferredShape;
      values = dtype !== "string" ? toTypedArray(values, dtype) : flatten(values, [], true);
      return ENGINE.makeTensor(values, shape, dtype);
    }
    function scalar(value, dtype) {
      if ((isTypedArray(value) && dtype !== "string" || Array.isArray(value)) && dtype !== "complex64") {
        throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
      }
      if (dtype === "string" && isTypedArray(value) && !(value instanceof Uint8Array)) {
        throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
      }
      var shape = [];
      var inferredShape = [];
      return makeTensor(value, shape, inferredShape, dtype);
    }
    function sqrt_(x) {
      var $x = convertToTensor(x, "x", "sqrt", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sqrt, inputs);
    }
    var sqrt = /* @__PURE__ */ op({ sqrt_ });
    function square_(x) {
      var $x = convertToTensor(x, "x", "square");
      var attrs = {};
      return ENGINE.runKernel("Square", { x: $x }, attrs);
    }
    var square = /* @__PURE__ */ op({ square_ });
    function sum_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "sum");
      if ($x.dtype === "bool") {
        $x = cast($x, "int32");
      }
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Sum, inputs, attrs);
    }
    var sum = /* @__PURE__ */ op({ sum_ });
    function norm_(x, ord, axis, keepDims) {
      if (ord === void 0) {
        ord = "euclidean";
      }
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      x = convertToTensor(x, "x", "norm");
      var norm2 = normImpl(x, ord, axis);
      var keepDimsShape = norm2.shape;
      if (keepDims) {
        var axes = parseAxisParam(axis, x.shape);
        keepDimsShape = expandShapeToKeepDim(norm2.shape, axes);
      }
      return reshape(norm2, keepDimsShape);
    }
    function normImpl(x, p, axis) {
      if (axis === void 0) {
        axis = null;
      }
      if (x.rank === 0) {
        return abs(x);
      }
      if (x.rank !== 1 && axis === null) {
        return normImpl(reshape(x, [-1]), p, axis);
      }
      if (x.rank === 1 || typeof axis === "number" || Array.isArray(axis) && axis.length === 1) {
        if (p === 1) {
          return sum(abs(x), axis);
        }
        if (p === Infinity) {
          return max(abs(x), axis);
        }
        if (p === -Infinity) {
          return min(abs(x), axis);
        }
        if (p === "euclidean" || p === 2) {
          return sqrt(sum(pow(abs(x), scalar(2, "int32")), axis));
        }
        throw new Error("Error in norm: invalid ord value: ".concat(p));
      }
      if (Array.isArray(axis) && axis.length === 2) {
        if (p === 1) {
          return max(sum(abs(x), axis[0]), axis[1] - 1);
        }
        if (p === Infinity) {
          return max(sum(abs(x), axis[1]), axis[0]);
        }
        if (p === -Infinity) {
          return min(sum(abs(x), axis[1]), axis[0]);
        }
        if (p === "fro" || p === "euclidean") {
          return sqrt(sum(square(x), axis));
        }
        throw new Error("Error in norm: invalid ord value: ".concat(p));
      }
      throw new Error("Error in norm: invalid axis: ".concat(axis));
    }
    var norm = /* @__PURE__ */ op({ norm_ });
    function euclideanNorm_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      return norm(x, "euclidean", axis, keepDims);
    }
    var euclideanNorm = /* @__PURE__ */ op({ euclideanNorm_ });
    function exp_(x) {
      var $x = convertToTensor(x, "x", "exp");
      var inputs = { x: $x };
      return ENGINE.runKernel(Exp, inputs);
    }
    var exp = /* @__PURE__ */ op({ exp_ });
    function expandDims_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "expandDims", "string_or_numeric");
      assert(axis <= $x.rank, function() {
        return "Axis must be <= rank of the tensor";
      });
      var inputs = { input: $x };
      var attrs = { dim: axis };
      return ENGINE.runKernel(ExpandDims, inputs, attrs);
    }
    var expandDims = /* @__PURE__ */ op({ expandDims_ });
    function expm1_(x) {
      var $x = convertToTensor(x, "x", "expm1");
      var inputs = { x: $x };
      return ENGINE.runKernel(Expm1, inputs);
    }
    var expm1 = /* @__PURE__ */ op({ expm1_ });
    function tile_(x, reps) {
      var $x = convertToTensor(x, "x", "tile", "string_or_numeric");
      assert($x.rank === reps.length, function() {
        return "Error in transpose: rank of input ".concat($x.rank, " ") + "must match length of reps ".concat(reps, ".");
      });
      var inputs = { x: $x };
      var attrs = { reps };
      return ENGINE.runKernel(Tile, inputs, attrs);
    }
    var tile = /* @__PURE__ */ op({ tile_ });
    function eye_(numRows, numColumns, batchShape, dtype) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      if (numColumns == null) {
        numColumns = numRows;
      }
      var buff = buffer([numRows, numColumns], dtype);
      var n = numRows <= numColumns ? numRows : numColumns;
      for (var i = 0; i < n; ++i) {
        buff.set(1, i, i);
      }
      var out = reshape(buff.toTensor(), [numRows, numColumns]);
      if (batchShape == null) {
        return out;
      } else {
        if (batchShape.length === 1) {
          return tile(expandDims(out, 0), [batchShape[0], 1, 1]);
        } else if (batchShape.length === 2) {
          return tile(expandDims(expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);
        } else if (batchShape.length === 3) {
          return tile(expandDims(expandDims(expandDims(out, 0), 0), 0), [
            batchShape[0],
            batchShape[1],
            batchShape[2],
            1,
            1
          ]);
        } else {
          throw new Error("eye() currently supports only 1D and 2D " + // tslint:disable-next-line:no-any
          "batchShapes, but received ".concat(batchShape.length, "D."));
        }
      }
    }
    var eye = /* @__PURE__ */ op({ eye_ });
    function floor_(x) {
      var $x = convertToTensor(x, "x", "floor", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Floor, inputs);
    }
    var floor = /* @__PURE__ */ op({ floor_ });
    function gather_(x, indices, axis, batchDims) {
      if (axis === void 0) {
        axis = 0;
      }
      if (batchDims === void 0) {
        batchDims = 0;
      }
      var $x = convertToTensor(x, "x", "gather");
      var $indices = convertToTensor(indices, "indices", "gather", "int32");
      var inputs = { x: $x, indices: $indices };
      var attrs = { axis, batchDims };
      return ENGINE.runKernel(GatherV2, inputs, attrs);
    }
    var gather = /* @__PURE__ */ op({ gather_ });
    function greater_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "greater", "string_or_numeric");
      var $b = convertToTensor(b, "b", "greater", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Greater, inputs);
    }
    var greater = /* @__PURE__ */ op({ greater_ });
    function greaterEqual_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "greaterEqual", "string_or_numeric");
      var $b = convertToTensor(b, "b", "greaterEqual", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(GreaterEqual, inputs);
    }
    var greaterEqual = /* @__PURE__ */ op({ greaterEqual_ });
    function imag_(input) {
      var $input = convertToTensor(input, "input", "imag");
      var inputs = { input: $input };
      return ENGINE.runKernel(Imag, inputs);
    }
    var imag = /* @__PURE__ */ op({ imag_ });
    function isFinite_(x) {
      var $x = convertToTensor(x, "x", "isFinite");
      var inputs = { x: $x };
      return ENGINE.runKernel(IsFinite, inputs);
    }
    var isFinite$1 = /* @__PURE__ */ op({ isFinite_ });
    function isInf_(x) {
      var $x = convertToTensor(x, "x", "isInf");
      var inputs = { x: $x };
      return ENGINE.runKernel(IsInf, inputs);
    }
    var isInf = /* @__PURE__ */ op({ isInf_ });
    function isNaN_(x) {
      var $x = convertToTensor(x, "x", "isNaN");
      var inputs = { x: $x };
      return ENGINE.runKernel(IsNan, inputs);
    }
    var isNaN$1 = /* @__PURE__ */ op({ isNaN_ });
    function leakyRelu_(x, alpha) {
      if (alpha === void 0) {
        alpha = 0.2;
      }
      var $x = convertToTensor(x, "x", "leakyRelu");
      var inputs = { x: $x };
      var attrs = { alpha };
      return ENGINE.runKernel(LeakyRelu, inputs, attrs);
    }
    var leakyRelu = /* @__PURE__ */ op({ leakyRelu_ });
    function less_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "less", "string_or_numeric");
      var $b = convertToTensor(b, "b", "less", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Less, inputs);
    }
    var less = /* @__PURE__ */ op({ less_ });
    function lessEqual_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "lessEqual", "string_or_numeric");
      var $b = convertToTensor(b, "b", "lessEqual", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(LessEqual, inputs);
    }
    var lessEqual = /* @__PURE__ */ op({ lessEqual_ });
    function linspace(start, stop, num) {
      if (num <= 0) {
        throw new Error("The number of values should be positive.");
      }
      var attrs = { start, stop, num };
      return ENGINE.runKernel(LinSpace, {}, attrs);
    }
    function localResponseNormalization_(x, depthRadius, bias, alpha, beta) {
      if (depthRadius === void 0) {
        depthRadius = 5;
      }
      if (bias === void 0) {
        bias = 1;
      }
      if (alpha === void 0) {
        alpha = 1;
      }
      if (beta === void 0) {
        beta = 0.5;
      }
      var $x = convertToTensor(x, "x", "localResponseNormalization");
      assert($x.rank === 4 || $x.rank === 3, function() {
        return "Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ".concat($x.rank, ".");
      });
      assert(isInt(depthRadius), function() {
        return "Error in localResponseNormalization: depthRadius must be an " + "integer but got depthRadius ".concat(depthRadius, ".");
      });
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      var inputs = { x: x4D };
      var attrs = { depthRadius, bias, alpha, beta };
      var res = ENGINE.runKernel(LRN, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      } else {
        return res;
      }
    }
    var localResponseNormalization = /* @__PURE__ */ op({ localResponseNormalization_ });
    function log_(x) {
      var $x = convertToTensor(x, "x", "log", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Log, inputs);
    }
    var log = /* @__PURE__ */ op({ log_ });
    function log1p_(x) {
      var $x = convertToTensor(x, "x", "log1p");
      var inputs = { x: $x };
      return ENGINE.runKernel(Log1p, inputs);
    }
    var log1p = /* @__PURE__ */ op({ log1p_ });
    function customGrad(f) {
      return ENGINE.customGrad(f);
    }
    function neg_(x) {
      var $x = convertToTensor(x, "x", "neg");
      var inputs = { x: $x };
      return ENGINE.runKernel(Neg, inputs);
    }
    var neg = /* @__PURE__ */ op({ neg_ });
    function softplus_(x) {
      var $x = convertToTensor(x, "x", "softplus");
      var inputs = { x: $x };
      return ENGINE.runKernel(Softplus, inputs);
    }
    var softplus = /* @__PURE__ */ op({ softplus_ });
    function logSigmoid_(x) {
      var $x = convertToTensor(x, "x", "logSigmoid");
      var customOp = customGrad(function(x2) {
        var value = neg(softplus(neg(x2)));
        var gradFunc = function(dy) {
          var derX = mul(dy, sigmoid(neg(x2)));
          return derX;
        };
        return { value, gradFunc };
      });
      return customOp($x);
    }
    var logSigmoid = /* @__PURE__ */ op({ logSigmoid_ });
    function sub_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "sub");
      var $b = convertToTensor(b, "b", "sub");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Sub, inputs);
    }
    var sub = /* @__PURE__ */ op({ sub_ });
    function logSoftmax_(logits, axis) {
      if (axis === void 0) {
        axis = -1;
      }
      var $logits = convertToTensor(logits, "logits", "logSoftmax");
      if (axis === -1) {
        axis = $logits.rank - 1;
      }
      if (axis !== $logits.rank - 1) {
        throw Error("Log Softmax along a non-last dimension is not yet supported. " + "Logits was rank ".concat($logits.rank, " and axis was ").concat(axis));
      }
      var customOp = customGrad(function(logits2, save) {
        var keepDims = true;
        var xMax = max(logits2, axis, true);
        var shifted = sub(logits2, xMax);
        var value = sub(cast(shifted, "float32"), log(sum(exp(shifted), axis, keepDims)));
        save([value]);
        var gradFunc = function(dy, saved) {
          var _a = __read(saved, 1), value2 = _a[0];
          var keepDims2 = true;
          var softmax2 = exp(value2);
          return sub(dy, mul(sum(dy, axis, keepDims2), softmax2));
        };
        return { value, gradFunc };
      });
      return customOp($logits);
    }
    var logSoftmax = /* @__PURE__ */ op({ logSoftmax_ });
    function logSumExp_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "logSumExp");
      var axes = parseAxisParam(axis, $x.shape);
      var xMax = max(
        $x,
        axes,
        true
        /* keepDims */
      );
      var a = sub($x, xMax);
      var b = exp(a);
      var c = sum(b, axes);
      var d = log(c);
      var res = add(reshape(xMax, d.shape), d);
      if (keepDims) {
        var newShape = expandShapeToKeepDim(res.shape, axes);
        return reshape(res, newShape);
      }
      return res;
    }
    var logSumExp = /* @__PURE__ */ op({ logSumExp_ });
    function logicalAnd_(a, b) {
      var $a = convertToTensor(a, "a", "logicalAnd", "bool");
      var $b = convertToTensor(b, "b", "logicalAnd", "bool");
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(LogicalAnd, inputs);
    }
    var logicalAnd = /* @__PURE__ */ op({ logicalAnd_ });
    function logicalNot_(x) {
      var $x = convertToTensor(x, "x", "logicalNot", "bool");
      var inputs = { x: $x };
      return ENGINE.runKernel(LogicalNot, inputs);
    }
    var logicalNot = /* @__PURE__ */ op({ logicalNot_ });
    function logicalOr_(a, b) {
      var $a = convertToTensor(a, "a", "logicalOr", "bool");
      var $b = convertToTensor(b, "b", "logicalOr", "bool");
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(LogicalOr, inputs);
    }
    var logicalOr = /* @__PURE__ */ op({ logicalOr_ });
    function logicalXor_(a, b) {
      var $a = convertToTensor(a, "a", "logicalXor", "bool");
      var $b = convertToTensor(b, "b", "logicalXor", "bool");
      assertAndGetBroadcastShape($a.shape, $b.shape);
      return logicalAnd(logicalOr(a, b), logicalNot(logicalAnd(a, b)));
    }
    var logicalXor = /* @__PURE__ */ op({ logicalXor_ });
    var INT32_MAX = 2147483648;
    function searchSorted_(sortedSequence, values, side) {
      if (side === void 0) {
        side = "left";
      }
      var $sortedSequence = convertToTensor(sortedSequence, "sortedSequence", "searchSorted");
      var $values = convertToTensor(values, "values", "searchSorted");
      var sequenceSize = $sortedSequence.shape[$sortedSequence.shape.length - 1];
      var valuesSize = $values.shape[$values.shape.length - 1];
      var $sortedSequence2D = reshape($sortedSequence, [-1, sequenceSize]);
      var $values2D = reshape($values, [-1, valuesSize]);
      if ($sortedSequence2D.rank < 2) {
        throw new Error("Sorted input argument must be at least 2-dimensional");
      }
      if ($sortedSequence2D.shape[0] !== $values2D.shape[0]) {
        throw new Error("Leading dimension of 'sortedSequence' and 'values' must match.");
      }
      if (sizeFromShape($values2D.shape) >= INT32_MAX) {
        throw new Error("values tensor size must less than ".concat(INT32_MAX));
      }
      if ($sortedSequence2D.shape[1] >= INT32_MAX) {
        throw new Error("trailing dim_size must less than ".concat(INT32_MAX, " for int32 output type, was ").concat($sortedSequence2D.shape[1]));
      }
      var inputs = {
        sortedSequence: $sortedSequence2D,
        values: $values2D
      };
      var attrs = { side };
      return ENGINE.runKernel(SearchSorted, inputs, attrs);
    }
    var searchSorted = /* @__PURE__ */ op({ searchSorted_ });
    function lowerBound(sortedSequence, values) {
      return searchSorted(sortedSequence, values, "left");
    }
    function maxPool_(x, filterSize, strides, pad2, dimRoundingMode) {
      var $x = convertToTensor(x, "x", "maxPool");
      var dilations = 1;
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in maxPool: input must be rank 4 but got rank ".concat(x4D.rank, ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in maxPool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      checkPadOnDimRoundingMode("maxPool", pad2, dimRoundingMode);
      var inputs = { x: x4D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
      var res = ENGINE.runKernel(MaxPool, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var maxPool = /* @__PURE__ */ op({ maxPool_ });
    function maxPool3d_(x, filterSize, strides, pad2, dimRoundingMode, dataFormat) {
      if (filterSize === void 0) {
        filterSize = [1, 1, 1];
      }
      if (dataFormat === void 0) {
        dataFormat = "NDHWC";
      }
      var $x = convertToTensor(x, "x", "maxPool3d");
      var x5D = $x;
      var reshapedTo5D = false;
      if ($x.rank === 4) {
        reshapedTo5D = true;
        x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
      }
      assert(x5D.rank === 5, function() {
        return "Error in maxPool3d: x must be rank 5 but got rank ".concat(x5D.rank, ".");
      });
      assert(dataFormat === "NDHWC", function() {
        return "Error in maxPool3d: Only NDHWC is currently supported, " + "but got dataFormat of ".concat(dataFormat);
      });
      checkPadOnDimRoundingMode("maxPool3d", pad2, dimRoundingMode);
      var inputs = { x: x5D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat };
      var res = ENGINE.runKernel(MaxPool3D, inputs, attrs);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var maxPool3d = /* @__PURE__ */ op({ maxPool3d_ });
    function maxPoolWithArgmax_(x, filterSize, strides, pad2, includeBatchInIndex) {
      if (includeBatchInIndex === void 0) {
        includeBatchInIndex = false;
      }
      var $x = convertToTensor(x, "x", "maxPoolWithArgmax");
      var inputs = { x: $x };
      var attrs = { filterSize, strides, pad: pad2, includeBatchInIndex };
      var result = ENGINE.runKernel(MaxPoolWithArgmax, inputs, attrs);
      return { result: result[0], indexes: result[1] };
    }
    var maxPoolWithArgmax = /* @__PURE__ */ op({ maxPoolWithArgmax_ });
    function maximum_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "maximum");
      var $b = convertToTensor(b, "b", "maximum");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      if ($a.dtype === "bool") {
        $a = cast($a, "int32");
        $b = cast($b, "int32");
      }
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Maximum, inputs);
    }
    var maximum = /* @__PURE__ */ op({ maximum_ });
    function mean_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "mean");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Mean, inputs, attrs);
    }
    var mean = /* @__PURE__ */ op({ mean_ });
    function zeros(shape, dtype) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype === "complex64") {
        var real2 = zeros(shape, "float32");
        var imag2 = zeros(shape, "float32");
        return complex(real2, imag2);
      }
      var values = makeZerosTypedArray(sizeFromShape(shape), dtype);
      return ENGINE.makeTensor(values, shape, dtype);
    }
    function ones(shape, dtype) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype === "complex64") {
        var real2 = ones(shape, "float32");
        var imag2 = zeros(shape, "float32");
        return complex(real2, imag2);
      }
      var values = makeOnesTypedArray(sizeFromShape(shape), dtype);
      return ENGINE.makeTensor(values, shape, dtype);
    }
    function meshgrid(x, y, _a) {
      var _b = _a === void 0 ? {} : _a, _c = _b.indexing, indexing = _c === void 0 ? "xy" : _c;
      if (indexing !== "xy" && indexing !== "ij") {
        throw new TypeError("".concat(indexing, " is not a valid third argument to meshgrid"));
      }
      if (x === void 0) {
        return [];
      }
      var $x = convertToTensor(x, "x", "meshgrid", x instanceof Tensor ? x.dtype : "float32");
      if (y === void 0) {
        return [$x];
      }
      var $y = convertToTensor(y, "y", "meshgrid", y instanceof Tensor ? y.dtype : "float32");
      var w = sizeFromShape($x.shape);
      var h = sizeFromShape($y.shape);
      if (indexing === "xy") {
        $x = reshape($x, [1, -1]);
        $y = reshape($y, [-1, 1]);
        return [
          matMul$1(ones([h, 1], $x.dtype), $x),
          matMul$1($y, ones([1, w], $y.dtype))
        ];
      }
      $x = reshape($x, [-1, 1]);
      $y = reshape($y, [1, -1]);
      return [
        matMul$1($x, ones([1, h], $x.dtype)),
        matMul$1(ones([w, 1], $y.dtype), $y)
      ];
    }
    function minimum_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "minimum");
      var $b = convertToTensor(b, "b", "minimum");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      if ($a.dtype === "bool") {
        $a = cast($a, "int32");
        $b = cast($b, "int32");
      }
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Minimum, inputs);
    }
    var minimum = /* @__PURE__ */ op({ minimum_ });
    function mirrorPad_(x, paddings, mode) {
      assert(mode === "reflect" || mode === "symmetric", function() {
        return "Invalid mode. Mode must be either reflect or symmetric. " + "Got ".concat(mode, ".");
      });
      var $x = convertToTensor(x, "x", "mirrorPad");
      if ($x.rank === 0) {
        throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
      }
      assert(paddings.length === $x.rank, function() {
        return "Padding doesn't match input. Must be ".concat($x.rank, ". ") + "Got ".concat(paddings.length, ".");
      });
      var shapeOffset = mode === "reflect" ? 1 : 0;
      var _loop_1 = function(i2) {
        assert(paddings[i2].length === 2, function() {
          return "Invalid number of paddings. Must be length of 2 each.";
        });
        assert(paddings[i2][0] >= 0 && paddings[i2][0] <= $x.shape[i2] - shapeOffset && paddings[i2][1] >= 0 && paddings[i2][1] <= $x.shape[i2] - shapeOffset, function() {
          return "Padding in dimension ".concat(i2, " cannot be greater than or equal ") + "to ".concat($x.shape[i2] - shapeOffset, " or less than 0 for input of ") + "shape ".concat($x.shape);
        });
      };
      for (var i = 0; i < $x.rank; i++) {
        _loop_1(i);
      }
      var attrs = { paddings, mode };
      var inputs = { x: $x };
      return ENGINE.runKernel(MirrorPad, inputs, attrs);
    }
    var mirrorPad = /* @__PURE__ */ op({ mirrorPad_ });
    function mod_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "mod");
      var $b = convertToTensor(b, "b", "mod");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Mod, inputs);
    }
    var mod = /* @__PURE__ */ op({ mod_ });
    function moments_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      x = convertToTensor(x, "x", "moments");
      var axes = parseAxisParam(axis, x.shape);
      var xMean = mean(x, axes, keepDims);
      var keepDimsShape = xMean.shape;
      if (!keepDims) {
        keepDimsShape = expandShapeToKeepDim(xMean.shape, axes);
      }
      var devSquared = square(sub(cast(x, "float32"), reshape(xMean, keepDimsShape)));
      var variance = mean(devSquared, axes, keepDims);
      return { mean: xMean, variance };
    }
    var moments = /* @__PURE__ */ op({ moments_ });
    function multiRNNCell_(lstmCells, data, c, h) {
      var $data = convertToTensor(data, "data", "multiRNNCell");
      var $c = convertToTensorArray(c, "c", "multiRNNCell");
      var $h = convertToTensorArray(h, "h", "multiRNNCell");
      var input = $data;
      var newStates = [];
      for (var i = 0; i < lstmCells.length; i++) {
        var output = lstmCells[i](input, $c[i], $h[i]);
        newStates.push(output[0]);
        newStates.push(output[1]);
        input = output[1];
      }
      var newC = [];
      var newH = [];
      for (var i = 0; i < newStates.length; i += 2) {
        newC.push(newStates[i]);
        newH.push(newStates[i + 1]);
      }
      return [newC, newH];
    }
    var multiRNNCell = /* @__PURE__ */ op({ multiRNNCell_ });
    function multinomial_(logits, numSamples, seed, normalized) {
      if (normalized === void 0) {
        normalized = false;
      }
      var $logits = convertToTensor(logits, "logits", "multinomial");
      var numOutcomes = $logits.size;
      var origRank = $logits.rank;
      if (numOutcomes < 2) {
        throw new Error("Error in multinomial: you need at least 2 outcomes, but got " + "".concat(numOutcomes, "."));
      }
      if (origRank > 2) {
        throw new Error("Rank of probabilities must be 1 or 2, but is ".concat(origRank));
      }
      seed = seed || Math.random();
      var logits2D = origRank === 1 ? reshape($logits, [1, -1]) : $logits;
      var inputs = { logits: logits2D };
      var attrs = { numSamples, seed, normalized };
      var res = ENGINE.runKernel(Multinomial, inputs, attrs);
      return origRank === 1 ? reshape(res, [res.size]) : res;
    }
    var multinomial = /* @__PURE__ */ op({ multinomial_ });
    function notEqual_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "notEqual", "string_or_numeric");
      var $b = convertToTensor(b, "b", "notEqual", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(NotEqual, inputs);
    }
    var notEqual = /* @__PURE__ */ op({ notEqual_ });
    function oneHot_(indices, depth, onValue, offValue, dtype) {
      if (onValue === void 0) {
        onValue = 1;
      }
      if (offValue === void 0) {
        offValue = 0;
      }
      if (dtype === void 0) {
        dtype = "int32";
      }
      if (depth < 2) {
        throw new Error("Error in oneHot: depth must be >=2, but it is ".concat(depth));
      }
      var $indices = convertToTensor(indices, "indices", "oneHot", "int32");
      var inputs = { indices: $indices };
      var attrs = { dtype, depth, onValue, offValue };
      return ENGINE.runKernel(OneHot, inputs, attrs);
    }
    var oneHot = /* @__PURE__ */ op({ oneHot_ });
    function onesLike_(x) {
      var $x = convertToTensor(x, "x", "onesLike");
      var inputs = { x: $x };
      return ENGINE.runKernel(OnesLike, inputs);
    }
    var onesLike = /* @__PURE__ */ op({ onesLike_ });
    function outerProduct_(v1, v2) {
      var $v1 = convertToTensor(v1, "v1", "outerProduct");
      var $v2 = convertToTensor(v2, "v2", "outerProduct");
      assert($v1.rank === 1 && $v2.rank === 1, function() {
        return "Error in outerProduct: inputs must be rank 1, but got ranks " + "".concat($v1.rank, " and ").concat($v2.rank, ".");
      });
      var v12D = reshape($v1, [-1, 1]);
      var v22D = reshape($v2, [1, -1]);
      return matMul$1(v12D, v22D);
    }
    var outerProduct = /* @__PURE__ */ op({ outerProduct_ });
    function pad_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      var $x = convertToTensor(x, "x", "pad");
      if ($x.rank === 0) {
        throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
      }
      var attrs = { paddings, constantValue };
      var inputs = { x: $x };
      return ENGINE.runKernel(PadV2, inputs, attrs);
    }
    var pad = /* @__PURE__ */ op({ pad_ });
    function pad1d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 2, function() {
        return "Invalid number of paddings. Must be length of 2.";
      });
      return pad(x, [paddings], constantValue);
    }
    var pad1d = /* @__PURE__ */ op({ pad1d_ });
    function pad2d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 2 && paddings[0].length === 2 && paddings[1].length === 2, function() {
        return "Invalid number of paddings. Must be length of 2 each.";
      });
      return pad(x, paddings, constantValue);
    }
    var pad2d = /* @__PURE__ */ op({ pad2d_ });
    function pad3d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 3 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2, function() {
        return "Invalid number of paddings. Must be length of 2 each.";
      });
      return pad(x, paddings, constantValue);
    }
    var pad3d = /* @__PURE__ */ op({ pad3d_ });
    function pad4d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 4 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2 && paddings[3].length === 2, function() {
        return "Invalid number of paddings. Must be length of 2 each.";
      });
      return pad(x, paddings, constantValue);
    }
    var pad4d = /* @__PURE__ */ op({ pad4d_ });
    function spaceToBatchND_(x, blockShape, paddings) {
      var $x = convertToTensor(x, "x", "spaceToBatchND");
      assert($x.rank >= 1 + blockShape.length, function() {
        return "input rank ".concat($x.rank, " should be > than [blockShape] ").concat(blockShape.length);
      });
      assert(paddings.length === blockShape.length, function() {
        return "paddings.shape[0] ".concat(paddings.length, " must be equal to [blockShape] ").concat(blockShape.length);
      });
      assert($x.shape.reduce(function(a, b, i) {
        if (i > 0 && i <= blockShape.length) {
          return a && (b + paddings[i - 1][0] + paddings[i - 1][1]) % blockShape[i - 1] === 0;
        }
        return a;
      }, true), function() {
        return "input spatial dimensions ".concat($x.shape.slice(1), " with paddings ").concat(paddings.toString(), " must be divisible by blockShapes ").concat(blockShape.toString());
      });
      var inputs = { x: $x };
      var attrs = { blockShape, paddings };
      return ENGINE.runKernel(SpaceToBatchND, inputs, attrs);
    }
    var spaceToBatchND = /* @__PURE__ */ op({ spaceToBatchND_ });
    function pool_(input, windowShape, poolingType, pad2, dilations, strides, dimRoundingMode) {
      if (dilations == null) {
        dilations = [1, 1];
      }
      if (strides == null) {
        strides = 1;
      }
      if (pad2 === 0) {
        pad2 = "valid";
      }
      var $x = convertToTensor(input, "x", "maxPool");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in pool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var convInfo = computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad2);
      var dilation = [convInfo.dilationHeight, convInfo.dilationWidth];
      var basePadding;
      if (pad2 === "same") {
        basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);
      } else {
        basePadding = [[0, 0], [0, 0]];
      }
      var isDilationOne = dilation[0] === 1 && dilation[1] === 1;
      var _a = __read(requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding), 2), adjustedPadding = _a[0], adjustedCrops = _a[1];
      var convertedPad = isDilationOne ? pad2 : "valid";
      var convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);
      var forwardOp = poolingType === "avg" ? function() {
        return avgPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode);
      } : function() {
        return maxPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode);
      };
      var y = forwardOp();
      var res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    function requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {
      var padStart = basePadding.map(function(b) {
        return b[0];
      });
      var origPadEnd = basePadding.map(function(b) {
        return b[1];
      });
      var fullInputShape = inputShape.concat(padStart, origPadEnd);
      var padEndExtra = blockShape.map(function(b, i) {
        return (b - fullInputShape[i] % b) % b;
      });
      var padEnd = origPadEnd.map(function(s, i) {
        return s + padEndExtra[i];
      });
      var paddings = blockShape.map(function(_, i) {
        return [padStart[i], padEnd[i]];
      });
      var crops = blockShape.map(function(_, i) {
        return [0, padEndExtra[i]];
      });
      return [paddings, crops];
    }
    function withSpaceToBatchBasePaddings(filterShape, dilation) {
      var dilatedFilterShape = filterShape.map(function(s, i) {
        return s + (s - 1) * (dilation[i] - 1);
      });
      var padExtraShape = dilatedFilterShape.map(function(s) {
        return s - 1;
      });
      var padExtraStart = padExtraShape.map(function(s) {
        return Math.floor(s / 2);
      });
      var padExtraEnd = padExtraShape.map(function(s, i) {
        return s - padExtraStart[i];
      });
      return padExtraShape.map(function(_, i) {
        return [padExtraStart[i], padExtraEnd[i]];
      });
    }
    var pool = /* @__PURE__ */ op({ pool_ });
    function prelu_(x, alpha) {
      var $x = convertToTensor(x, "x", "prelu");
      var $alpha = convertToTensor(alpha, "alpha", "prelu");
      var inputs = { x: $x, alpha: $alpha };
      return ENGINE.runKernel(Prelu, inputs);
    }
    var prelu = /* @__PURE__ */ op({ prelu_ });
    function print(x, verbose) {
      if (verbose === void 0) {
        verbose = false;
      }
      console.log(x.toString(verbose));
    }
    function prod_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "prod");
      if ($x.dtype === "bool") {
        $x = cast($x, "int32");
      }
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Prod, inputs, attrs);
    }
    var prod = /* @__PURE__ */ op({ prod_ });
    function raggedGather_(paramsNestedSplits, paramsDenseValues, indices, outputRaggedRank) {
      var $paramsNestedSplits = paramsNestedSplits.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "raggedGather", "int32");
      });
      var $paramsDenseValues = convertToTensor(paramsDenseValues, "paramsDenseValues", "raggedGather");
      var $indices = convertToTensor(indices, "indices", "raggedGather", "int32");
      var inputs = {
        paramsNestedSplits: $paramsNestedSplits,
        paramsDenseValues: $paramsDenseValues,
        indices: $indices
      };
      var attrs = { outputRaggedRank };
      var result = ENGINE.runKernel(RaggedGather, inputs, attrs);
      return {
        outputNestedSplits: result.slice(0, result.length - 1),
        outputDenseValues: result[result.length - 1]
      };
    }
    var raggedGather = /* @__PURE__ */ op({ raggedGather_ });
    function raggedRange_(starts, limits, deltas) {
      var $starts = convertToTensor(starts, "starts", "raggedRange");
      var $limits = convertToTensor(limits, "limits", "raggedRange", $starts.dtype);
      var $deltas = convertToTensor(deltas, "deltas", "raggedRange", $starts.dtype);
      var inputs = {
        starts: $starts,
        limits: $limits,
        deltas: $deltas
      };
      var result = ENGINE.runKernel(RaggedRange, inputs);
      return {
        rtNestedSplits: result[0],
        rtDenseValues: result[1]
      };
    }
    var raggedRange = /* @__PURE__ */ op({ raggedRange_ });
    function raggedTensorToTensor_(shape, values, defaultValue, rowPartitionTensors, rowPartitionTypes) {
      var $shape = convertToTensor(shape, "shape", "raggedTensorToTensor", "int32");
      var $values = convertToTensor(values, "values", "raggedTensorToTensor");
      var $defaultValue = convertToTensor(defaultValue, "defaultValue", "raggedTensorToTensor", $values.dtype);
      var $rowPartitionTensors = rowPartitionTensors.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "raggedTensorToTensor", "int32");
      });
      var inputs = {
        shape: $shape,
        values: $values,
        defaultValue: $defaultValue,
        rowPartitionTensors: $rowPartitionTensors
      };
      var attrs = { rowPartitionTypes };
      return ENGINE.runKernel(RaggedTensorToTensor, inputs, attrs);
    }
    var raggedTensorToTensor = /* @__PURE__ */ op({ raggedTensorToTensor_ });
    function rand_(shape, randFunction, dtype) {
      assertNonNegativeIntegerDimensions(shape);
      var size = sizeFromShape(shape);
      var values = null;
      if (dtype == null || dtype === "float32") {
        values = new Float32Array(size);
      } else if (dtype === "int32") {
        values = new Int32Array(size);
      } else if (dtype === "bool") {
        values = new Uint8Array(size);
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
      for (var i = 0; i < size; i++) {
        values[i] = randFunction();
      }
      return ENGINE.makeTensor(values, shape, dtype);
    }
    var rand = /* @__PURE__ */ op({ rand_ });
    var alea$1 = { exports: {} };
    (function(module2) {
      (function(global2, module3, define2) {
        function Alea(seed) {
          var me = this, mash = Mash();
          me.next = function() {
            var t = 2091639 * me.s0 + me.c * 23283064365386963e-26;
            me.s0 = me.s1;
            me.s1 = me.s2;
            return me.s2 = t - (me.c = t | 0);
          };
          me.c = 1;
          me.s0 = mash(" ");
          me.s1 = mash(" ");
          me.s2 = mash(" ");
          me.s0 -= mash(seed);
          if (me.s0 < 0) {
            me.s0 += 1;
          }
          me.s1 -= mash(seed);
          if (me.s1 < 0) {
            me.s1 += 1;
          }
          me.s2 -= mash(seed);
          if (me.s2 < 0) {
            me.s2 += 1;
          }
          mash = null;
        }
        function copy(f, t) {
          t.c = f.c;
          t.s0 = f.s0;
          t.s1 = f.s1;
          t.s2 = f.s2;
          return t;
        }
        function impl(seed, opts) {
          var xg = new Alea(seed), state = opts && opts.state, prng = xg.next;
          prng.int32 = function() {
            return xg.next() * 4294967296 | 0;
          };
          prng.double = function() {
            return prng() + (prng() * 2097152 | 0) * 11102230246251565e-32;
          };
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        function Mash() {
          var n = 4022871197;
          var mash = function(data) {
            data = String(data);
            for (var i = 0; i < data.length; i++) {
              n += data.charCodeAt(i);
              var h = 0.02519603282416938 * n;
              n = h >>> 0;
              h -= n;
              h *= n;
              n = h >>> 0;
              h -= n;
              n += h * 4294967296;
            }
            return (n >>> 0) * 23283064365386963e-26;
          };
          return mash;
        }
        if (module3 && module3.exports) {
          module3.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.alea = impl;
        }
      })(
        commonjsGlobal,
        module2,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(alea$1);
    var aleaExports = alea$1.exports;
    var xor128$1 = { exports: {} };
    (function(module2) {
      (function(global2, module3, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.next = function() {
            var t = me.x ^ me.x << 11;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            return me.w ^= me.w >>> 19 ^ t ^ t >>> 8;
          };
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 64; k++) {
            me.x ^= strseed.charCodeAt(k) | 0;
            me.next();
          }
        }
        function copy(f, t) {
          t.x = f.x;
          t.y = f.y;
          t.z = f.z;
          t.w = f.w;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module3 && module3.exports) {
          module3.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xor128 = impl;
        }
      })(
        commonjsGlobal,
        module2,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xor128$1);
    var xor128Exports = xor128$1.exports;
    var xorwow$1 = { exports: {} };
    (function(module2) {
      (function(global2, module3, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var t = me.x ^ me.x >>> 2;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            me.w = me.v;
            return (me.d = me.d + 362437 | 0) + (me.v = me.v ^ me.v << 4 ^ (t ^ t << 1)) | 0;
          };
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.v = 0;
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 64; k++) {
            me.x ^= strseed.charCodeAt(k) | 0;
            if (k == strseed.length) {
              me.d = me.x << 10 ^ me.x >>> 4;
            }
            me.next();
          }
        }
        function copy(f, t) {
          t.x = f.x;
          t.y = f.y;
          t.z = f.z;
          t.w = f.w;
          t.v = f.v;
          t.d = f.d;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module3 && module3.exports) {
          module3.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xorwow = impl;
        }
      })(
        commonjsGlobal,
        module2,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xorwow$1);
    var xorwowExports = xorwow$1.exports;
    var xorshift7$1 = { exports: {} };
    (function(module2) {
      (function(global2, module3, define2) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var X = me.x, i = me.i, t, v;
            t = X[i];
            t ^= t >>> 7;
            v = t ^ t << 24;
            t = X[i + 1 & 7];
            v ^= t ^ t >>> 10;
            t = X[i + 3 & 7];
            v ^= t ^ t >>> 3;
            t = X[i + 4 & 7];
            v ^= t ^ t << 7;
            t = X[i + 7 & 7];
            t = t ^ t << 13;
            v ^= t ^ t << 9;
            X[i] = v;
            me.i = i + 1 & 7;
            return v;
          };
          function init(me2, seed2) {
            var j, X = [];
            if (seed2 === (seed2 | 0)) {
              X[0] = seed2;
            } else {
              seed2 = "" + seed2;
              for (j = 0; j < seed2.length; ++j) {
                X[j & 7] = X[j & 7] << 15 ^ seed2.charCodeAt(j) + X[j + 1 & 7] << 13;
              }
            }
            while (X.length < 8)
              X.push(0);
            for (j = 0; j < 8 && X[j] === 0; ++j)
              ;
            if (j == 8)
              X[7] = -1;
            else
              X[j];
            me2.x = X;
            me2.i = 0;
            for (j = 256; j > 0; --j) {
              me2.next();
            }
          }
          init(me, seed);
        }
        function copy(f, t) {
          t.x = f.x.slice();
          t.i = f.i;
          return t;
        }
        function impl(seed, opts) {
          if (seed == null)
            seed = +/* @__PURE__ */ new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.x)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module3 && module3.exports) {
          module3.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xorshift7 = impl;
        }
      })(
        commonjsGlobal,
        module2,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xorshift7$1);
    var xorshift7Exports = xorshift7$1.exports;
    var xor4096$1 = { exports: {} };
    (function(module2) {
      (function(global2, module3, define2) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var w = me.w, X = me.X, i = me.i, t, v;
            me.w = w = w + 1640531527 | 0;
            v = X[i + 34 & 127];
            t = X[i = i + 1 & 127];
            v ^= v << 13;
            t ^= t << 17;
            v ^= v >>> 15;
            t ^= t >>> 12;
            v = X[i] = v ^ t;
            me.i = i;
            return v + (w ^ w >>> 16) | 0;
          };
          function init(me2, seed2) {
            var t, v, i, j, w, X = [], limit = 128;
            if (seed2 === (seed2 | 0)) {
              v = seed2;
              seed2 = null;
            } else {
              seed2 = seed2 + "\0";
              v = 0;
              limit = Math.max(limit, seed2.length);
            }
            for (i = 0, j = -32; j < limit; ++j) {
              if (seed2)
                v ^= seed2.charCodeAt((j + 32) % seed2.length);
              if (j === 0)
                w = v;
              v ^= v << 10;
              v ^= v >>> 15;
              v ^= v << 4;
              v ^= v >>> 13;
              if (j >= 0) {
                w = w + 1640531527 | 0;
                t = X[j & 127] ^= v + w;
                i = 0 == t ? i + 1 : 0;
              }
            }
            if (i >= 128) {
              X[(seed2 && seed2.length || 0) & 127] = -1;
            }
            i = 127;
            for (j = 4 * 128; j > 0; --j) {
              v = X[i + 34 & 127];
              t = X[i = i + 1 & 127];
              v ^= v << 13;
              t ^= t << 17;
              v ^= v >>> 15;
              t ^= t >>> 12;
              X[i] = v ^ t;
            }
            me2.w = w;
            me2.X = X;
            me2.i = i;
          }
          init(me, seed);
        }
        function copy(f, t) {
          t.i = f.i;
          t.w = f.w;
          t.X = f.X.slice();
          return t;
        }
        function impl(seed, opts) {
          if (seed == null)
            seed = +/* @__PURE__ */ new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.X)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module3 && module3.exports) {
          module3.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.xor4096 = impl;
        }
      })(
        commonjsGlobal,
        // window object or global
        module2,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xor4096$1);
    var xor4096Exports = xor4096$1.exports;
    var tychei$1 = { exports: {} };
    (function(module2) {
      (function(global2, module3, define2) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var b = me.b, c = me.c, d = me.d, a = me.a;
            b = b << 25 ^ b >>> 7 ^ c;
            c = c - d | 0;
            d = d << 24 ^ d >>> 8 ^ a;
            a = a - b | 0;
            me.b = b = b << 20 ^ b >>> 12 ^ c;
            me.c = c = c - d | 0;
            me.d = d << 16 ^ c >>> 16 ^ a;
            return me.a = a - b | 0;
          };
          me.a = 0;
          me.b = 0;
          me.c = 2654435769 | 0;
          me.d = 1367130551;
          if (seed === Math.floor(seed)) {
            me.a = seed / 4294967296 | 0;
            me.b = seed | 0;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 20; k++) {
            me.b ^= strseed.charCodeAt(k) | 0;
            me.next();
          }
        }
        function copy(f, t) {
          t.a = f.a;
          t.b = f.b;
          t.c = f.c;
          t.d = f.d;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module3 && module3.exports) {
          module3.exports = impl;
        } else if (define2 && define2.amd) {
          define2(function() {
            return impl;
          });
        } else {
          this.tychei = impl;
        }
      })(
        commonjsGlobal,
        module2,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(tychei$1);
    var tycheiExports = tychei$1.exports;
    var seedrandom$1 = { exports: {} };
    var _nodeResolve_empty = {};
    var _nodeResolve_empty$1 = {
      __proto__: null,
      default: _nodeResolve_empty
    };
    var require$$0 = /* @__PURE__ */ getAugmentedNamespace(_nodeResolve_empty$1);
    (function(module2) {
      (function(global2, pool2, math) {
        var width = 256, chunks = 6, digits = 52, rngname = "random", startdenom = math.pow(width, chunks), significance = math.pow(2, digits), overflow = significance * 2, mask = width - 1, nodecrypto;
        function seedrandom2(seed, options, callback) {
          var key = [];
          options = options == true ? { entropy: true } : options || {};
          var shortseed = mixkey(flatten2(options.entropy ? [seed, tostring(pool2)] : seed == null ? autoseed() : seed, 3), key);
          var arc4 = new ARC4(key);
          var prng = function() {
            var n = arc4.g(chunks), d = startdenom, x = 0;
            while (n < significance) {
              n = (n + x) * width;
              d *= width;
              x = arc4.g(1);
            }
            while (n >= overflow) {
              n /= 2;
              d /= 2;
              x >>>= 1;
            }
            return (n + x) / d;
          };
          prng.int32 = function() {
            return arc4.g(4) | 0;
          };
          prng.quick = function() {
            return arc4.g(4) / 4294967296;
          };
          prng.double = prng;
          mixkey(tostring(arc4.S), pool2);
          return (options.pass || callback || function(prng2, seed2, is_math_call, state) {
            if (state) {
              if (state.S) {
                copy(state, arc4);
              }
              prng2.state = function() {
                return copy(arc4, {});
              };
            }
            if (is_math_call) {
              math[rngname] = prng2;
              return seed2;
            } else
              return prng2;
          })(prng, shortseed, "global" in options ? options.global : this == math, options.state);
        }
        function ARC4(key) {
          var t, keylen = key.length, me = this, i = 0, j = me.i = me.j = 0, s = me.S = [];
          if (!keylen) {
            key = [keylen++];
          }
          while (i < width) {
            s[i] = i++;
          }
          for (i = 0; i < width; i++) {
            s[i] = s[j = mask & j + key[i % keylen] + (t = s[i])];
            s[j] = t;
          }
          (me.g = function(count) {
            var t2, r = 0, i2 = me.i, j2 = me.j, s2 = me.S;
            while (count--) {
              t2 = s2[i2 = mask & i2 + 1];
              r = r * width + s2[mask & (s2[i2] = s2[j2 = mask & j2 + t2]) + (s2[j2] = t2)];
            }
            me.i = i2;
            me.j = j2;
            return r;
          })(width);
        }
        function copy(f, t) {
          t.i = f.i;
          t.j = f.j;
          t.S = f.S.slice();
          return t;
        }
        function flatten2(obj, depth) {
          var result = [], typ = typeof obj, prop;
          if (depth && typ == "object") {
            for (prop in obj) {
              try {
                result.push(flatten2(obj[prop], depth - 1));
              } catch (e) {
              }
            }
          }
          return result.length ? result : typ == "string" ? obj : obj + "\0";
        }
        function mixkey(seed, key) {
          var stringseed = seed + "", smear, j = 0;
          while (j < stringseed.length) {
            key[mask & j] = mask & (smear ^= key[mask & j] * 19) + stringseed.charCodeAt(j++);
          }
          return tostring(key);
        }
        function autoseed() {
          try {
            var out;
            if (nodecrypto && (out = nodecrypto.randomBytes)) {
              out = out(width);
            } else {
              out = new Uint8Array(width);
              (global2.crypto || global2.msCrypto).getRandomValues(out);
            }
            return tostring(out);
          } catch (e) {
            var browser = global2.navigator, plugins = browser && browser.plugins;
            return [+/* @__PURE__ */ new Date(), global2, plugins, global2.screen, tostring(pool2)];
          }
        }
        function tostring(a) {
          return String.fromCharCode.apply(0, a);
        }
        mixkey(math.random(), pool2);
        if (module2.exports) {
          module2.exports = seedrandom2;
          try {
            nodecrypto = require$$0;
          } catch (ex) {
          }
        } else {
          math["seed" + rngname] = seedrandom2;
        }
      })(
        // global: `self` in browsers (including strict mode and web workers),
        // otherwise `this` in Node and other environments
        typeof self !== "undefined" ? self : commonjsGlobal,
        [],
        // pool: entropy pool starts empty
        Math
        // math: package containing random, pow, and seedrandom
      );
    })(seedrandom$1);
    var seedrandomExports = seedrandom$1.exports;
    var alea = aleaExports;
    var xor128 = xor128Exports;
    var xorwow = xorwowExports;
    var xorshift7 = xorshift7Exports;
    var xor4096 = xor4096Exports;
    var tychei = tycheiExports;
    var sr = seedrandomExports;
    sr.alea = alea;
    sr.xor128 = xor128;
    sr.xorwow = xorwow;
    sr.xorshift7 = xorshift7;
    sr.xor4096 = xor4096;
    sr.tychei = tychei;
    var seedrandom = sr;
    var MPRandGauss = (
      /** @class */
      function() {
        function MPRandGauss2(mean2, stdDeviation, dtype, truncated, seed) {
          this.mean = mean2;
          this.stdDev = stdDeviation;
          this.dtype = dtype;
          this.nextVal = NaN;
          this.truncated = truncated;
          if (this.truncated) {
            this.upper = this.mean + this.stdDev * 2;
            this.lower = this.mean - this.stdDev * 2;
          }
          var seedValue = seed ? seed : Math.random();
          this.random = seedrandom.alea(seedValue.toString());
        }
        MPRandGauss2.prototype.nextValue = function() {
          if (!isNaN(this.nextVal)) {
            var value = this.nextVal;
            this.nextVal = NaN;
            return value;
          }
          var resultX, resultY;
          var isValid = false;
          while (!isValid) {
            var v1 = void 0, v2 = void 0, s = void 0;
            do {
              v1 = 2 * this.random() - 1;
              v2 = 2 * this.random() - 1;
              s = v1 * v1 + v2 * v2;
            } while (s >= 1 || s === 0);
            var mul2 = Math.sqrt(-2 * Math.log(s) / s);
            resultX = this.mean + this.stdDev * v1 * mul2;
            resultY = this.mean + this.stdDev * v2 * mul2;
            if (!this.truncated || this.isValidTruncated(resultX)) {
              isValid = true;
            }
          }
          if (!this.truncated || this.isValidTruncated(resultY)) {
            this.nextVal = this.convertValue(resultY);
          }
          return this.convertValue(resultX);
        };
        MPRandGauss2.prototype.convertValue = function(value) {
          if (this.dtype == null || this.dtype === "float32") {
            return value;
          }
          return Math.round(value);
        };
        MPRandGauss2.prototype.isValidTruncated = function(value) {
          return value <= this.upper && value >= this.lower;
        };
        return MPRandGauss2;
      }()
    );
    var RandGamma = (
      /** @class */
      function() {
        function RandGamma2(alpha, beta, dtype, seed) {
          this.alpha = alpha;
          this.beta = 1 / beta;
          this.dtype = dtype;
          var seedValue = seed ? seed : Math.random();
          this.randu = seedrandom.alea(seedValue.toString());
          this.randn = new MPRandGauss(0, 1, dtype, false, this.randu());
          if (alpha < 1) {
            this.d = alpha + 2 / 3;
          } else {
            this.d = alpha - 1 / 3;
          }
          this.c = 1 / Math.sqrt(9 * this.d);
        }
        RandGamma2.prototype.nextValue = function() {
          var x2, v0, v1, x, u, v;
          while (true) {
            do {
              x = this.randn.nextValue();
              v = 1 + this.c * x;
            } while (v <= 0);
            v *= v * v;
            x2 = x * x;
            v0 = 1 - 0.331 * x2 * x2;
            v1 = 0.5 * x2 + this.d * (1 - v + Math.log(v));
            u = this.randu();
            if (u < v0 || Math.log(u) < v1) {
              break;
            }
          }
          v = 1 / this.beta * this.d * v;
          if (this.alpha < 1) {
            v *= Math.pow(this.randu(), 1 / this.alpha);
          }
          return this.convertValue(v);
        };
        RandGamma2.prototype.convertValue = function(value) {
          if (this.dtype === "float32") {
            return value;
          }
          return Math.round(value);
        };
        return RandGamma2;
      }()
    );
    var UniformRandom = (
      /** @class */
      function() {
        function UniformRandom2(min2, max2, dtype, seed) {
          if (min2 === void 0) {
            min2 = 0;
          }
          if (max2 === void 0) {
            max2 = 1;
          }
          var _this = this;
          this.canReturnFloat = function() {
            return _this.dtype == null || _this.dtype === "float32";
          };
          this.min = min2;
          this.range = max2 - min2;
          this.dtype = dtype;
          if (seed == null) {
            seed = Math.random();
          }
          if (typeof seed === "number") {
            seed = seed.toString();
          }
          if (!this.canReturnFloat() && this.range <= 1) {
            throw new Error("The difference between ".concat(min2, " - ").concat(max2, " <= 1 and dtype is not float"));
          }
          this.random = seedrandom.alea(seed);
        }
        UniformRandom2.prototype.convertValue = function(value) {
          if (this.canReturnFloat()) {
            return value;
          }
          return Math.round(value);
        };
        UniformRandom2.prototype.nextValue = function() {
          return this.convertValue(this.min + this.range * this.random());
        };
        return UniformRandom2;
      }()
    );
    function randomGamma_(shape, alpha, beta, dtype, seed) {
      if (beta === void 0) {
        beta = 1;
      }
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      if (beta == null) {
        beta = 1;
      }
      if (dtype == null) {
        dtype = "float32";
      }
      if (dtype !== "float32" && dtype !== "int32") {
        throw new Error("Unsupported data type ".concat(dtype));
      }
      var rgamma = new RandGamma(alpha, beta, dtype, seed);
      var res = buffer(shape, dtype);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = rgamma.nextValue();
      }
      return res.toTensor();
    }
    var randomGamma = /* @__PURE__ */ op({ randomGamma_ });
    function randomNormal_(shape, mean2, stdDev, dtype, seed) {
      if (mean2 === void 0) {
        mean2 = 0;
      }
      if (stdDev === void 0) {
        stdDev = 1;
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype != null && dtype === "bool") {
        throw new Error("Unsupported data type ".concat(dtype));
      }
      var randGauss = new MPRandGauss(mean2, stdDev, dtype, false, seed);
      var res = buffer(shape, dtype);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = randGauss.nextValue();
      }
      return res.toTensor();
    }
    var randomNormal = /* @__PURE__ */ op({ randomNormal_ });
    function randomStandardNormal_(shape, dtype, seed) {
      if (dtype != null && dtype === "bool") {
        throw new Error("Unsupported data type ".concat(dtype));
      }
      return randomNormal(shape, 0, 1, dtype, seed);
    }
    var randomStandardNormal = /* @__PURE__ */ op({ randomStandardNormal_ });
    function randomUniform_(shape, minval, maxval, dtype, seed) {
      if (minval === void 0) {
        minval = 0;
      }
      if (maxval === void 0) {
        maxval = 1;
      }
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      var res = buffer(shape, dtype);
      var random = new UniformRandom(minval, maxval, null, seed);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = random.nextValue();
      }
      return res.toTensor();
    }
    var randomUniform = /* @__PURE__ */ op({ randomUniform_ });
    function randomUniformInt_(shape, minval, maxval, seed) {
      return randomUniform(shape, minval, maxval, "int32", seed);
    }
    var randomUniformInt = /* @__PURE__ */ op({ randomUniformInt_ });
    function range(start, stop, step2, dtype) {
      if (step2 === void 0) {
        step2 = 1;
      }
      if (dtype === void 0) {
        dtype = "float32";
      }
      if (step2 === 0) {
        throw new Error("Cannot have a step of zero");
      }
      var attrs = { start, stop, step: step2, dtype };
      return ENGINE.runKernel(Range, {}, attrs);
    }
    function real_(input) {
      var $input = convertToTensor(input, "input", "real");
      var inputs = { input: $input };
      return ENGINE.runKernel(Real, inputs);
    }
    var real = /* @__PURE__ */ op({ real_ });
    function reciprocal_(x) {
      var $x = convertToTensor(x, "x", "reciprocal");
      var inputs = { x: $x };
      return ENGINE.runKernel(Reciprocal, inputs);
    }
    var reciprocal = /* @__PURE__ */ op({ reciprocal_ });
    function relu_(x) {
      var $x = convertToTensor(x, "x", "relu");
      var inputs = { x: $x };
      return ENGINE.runKernel(Relu, inputs);
    }
    var relu = /* @__PURE__ */ op({ relu_ });
    function relu6_(x) {
      var $x = convertToTensor(x, "x", "relu6");
      var inputs = { x: $x };
      return ENGINE.runKernel(Relu6, inputs);
    }
    var relu6 = /* @__PURE__ */ op({ relu6_ });
    function reverse_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      var inputs = { x: $x };
      var attrs = { dims: axis };
      return ENGINE.runKernel(Reverse, inputs, attrs);
    }
    var reverse = /* @__PURE__ */ op({ reverse_ });
    function reverse1d_(x) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 1, function() {
        return "Error in reverse1D: x must be rank 1 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, 0);
    }
    var reverse1d = /* @__PURE__ */ op({ reverse1d_ });
    function reverse2d_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 2, function() {
        return "Error in reverse2D: x must be rank 2 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, axis);
    }
    var reverse2d = /* @__PURE__ */ op({ reverse2d_ });
    function reverse3d_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 3, function() {
        return "Error in reverse3D: x must be rank 3 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, axis);
    }
    var reverse3d = /* @__PURE__ */ op({ reverse3d_ });
    function reverse4d_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 4, function() {
        return "Error in reverse4D: x must be rank 4 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, axis);
    }
    var reverse4d = /* @__PURE__ */ op({ reverse4d_ });
    function round_(x) {
      var $x = convertToTensor(x, "x", "round");
      var inputs = { x: $x };
      return ENGINE.runKernel(Round, inputs);
    }
    var round = /* @__PURE__ */ op({ round_ });
    function rsqrt_(x) {
      var $x = convertToTensor(x, "x", "rsqrt", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Rsqrt, inputs);
    }
    var rsqrt = /* @__PURE__ */ op({ rsqrt_ });
    function selu_(x) {
      var $x = convertToTensor(x, "x", "selu");
      var inputs = { x: $x };
      return ENGINE.runKernel(Selu, inputs);
    }
    var selu = /* @__PURE__ */ op({ selu_ });
    function separableConv2d_(x, depthwiseFilter, pointwiseFilter, strides, pad2, dilation, dataFormat) {
      if (dilation === void 0) {
        dilation = [1, 1];
      }
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var $x = convertToTensor(x, "x", "separableConv2d");
      var $depthwiseFilter = convertToTensor(depthwiseFilter, "depthwiseFilter", "separableConv2d");
      var $pointwiseFilter = convertToTensor(pointwiseFilter, "pointwiseFilter", "separableConv2d");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      if (dataFormat === "NCHW") {
        throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
      }
      assert(x4D.rank === 4, function() {
        return "Error in separableConv2d: input must be rank 4, but got " + "rank ".concat(x4D.rank, ".");
      });
      assert($depthwiseFilter.rank === 4, function() {
        return "Error in separableConv2d: depthwise filter must be rank 4, but " + "got rank ".concat($depthwiseFilter.rank, ".");
      });
      assert($pointwiseFilter.rank === 4, function() {
        return "Error in separableConv2d: pointwise filter must be rank 4, but " + "got rank ".concat($depthwiseFilter.rank, ".");
      });
      assert($pointwiseFilter.shape[0] === 1, function() {
        return "Error in separableConv2d: the first dimension of pointwise filter " + " must be 1, but got ".concat($pointwiseFilter.shape[0], ".");
      });
      assert($pointwiseFilter.shape[1] === 1, function() {
        return "Error in separableConv2d: the second dimension of pointwise " + "filter must be 1, but got ".concat($pointwiseFilter.shape[1], ".");
      });
      var inChannels = $depthwiseFilter.shape[2];
      var channelMultiplier = $depthwiseFilter.shape[3];
      assert($pointwiseFilter.shape[2] === inChannels * channelMultiplier, function() {
        return "Error in separableConv2d: the third dimension of pointwise filter " + "must be ".concat(inChannels * channelMultiplier, ", ") + "but got ".concat($pointwiseFilter.shape[2], ".");
      });
      var depthwise = depthwiseConv2d$1(x4D, $depthwiseFilter, strides, pad2, dataFormat, dilation);
      var pointwiseStride = 1;
      var res = conv2d$1(depthwise, $pointwiseFilter, pointwiseStride, "valid", dataFormat);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var separableConv2d = /* @__PURE__ */ op({ separableConv2d_ });
    function setdiff1dAsync_(x, y) {
      return __awaiter(this, void 0, void 0, function() {
        var $x, $y, xVals, yVals, ySet, outputSize, i, buffer2, indices, i, p;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $x = convertToTensor(x, "x", "setdiff1d");
              $y = convertToTensor(y, "y", "setdiff1d");
              assert($x.dtype === $y.dtype, function() {
                return "x and y should have the same dtype, but got x (".concat($x.dtype, ") and y (").concat($y.dtype, ").");
              });
              assert($x.rank === 1, function() {
                return "x should be 1D tensor, but got x (".concat($x.shape, ").");
              });
              assert($y.rank === 1, function() {
                return "y should be 1D tensor, but got y (".concat($y.shape, ").");
              });
              return [4, $x.data()];
            case 1:
              xVals = _a.sent();
              return [4, $y.data()];
            case 2:
              yVals = _a.sent();
              ySet = new Set(yVals);
              outputSize = 0;
              for (i = 0; i < xVals.length; i++) {
                if (!ySet.has(xVals[i])) {
                  outputSize++;
                }
              }
              buffer2 = new TensorBuffer([outputSize], $x.dtype);
              indices = new TensorBuffer([outputSize], "int32");
              for (i = 0, p = 0; i < xVals.length; i++) {
                if (!ySet.has(xVals[i])) {
                  buffer2.values[p] = xVals[i];
                  indices.values[p] = i;
                  p++;
                }
              }
              return [2, [buffer2.toTensor(), indices.toTensor()]];
          }
        });
      });
    }
    var setdiff1dAsync = setdiff1dAsync_;
    function sign_(x) {
      var $x = convertToTensor(x, "x", "sign");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sign, inputs);
    }
    var sign = /* @__PURE__ */ op({ sign_ });
    function sin_(x) {
      var $x = convertToTensor(x, "x", "sin", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sin, inputs);
    }
    var sin = /* @__PURE__ */ op({ sin_ });
    function sinh_(x) {
      var $x = convertToTensor(x, "x", "sinh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sinh, inputs);
    }
    var sinh = /* @__PURE__ */ op({ sinh_ });
    function slice1d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice1d");
      assert($x.rank === 1, function() {
        return "slice1d expects a rank-1 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, [begin], [size]);
    }
    var slice1d = /* @__PURE__ */ op({ slice1d_ });
    function slice2d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice2d");
      assert($x.rank === 2, function() {
        return "slice2d expects a rank-2 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, begin, size);
    }
    var slice2d = /* @__PURE__ */ op({ slice2d_ });
    function slice3d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice3d");
      assert($x.rank === 3, function() {
        return "slice3d expects a rank-3 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, begin, size);
    }
    var slice3d = /* @__PURE__ */ op({ slice3d_ });
    function slice4d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice4d");
      assert($x.rank === 4, function() {
        return "slice4d expects a rank-4 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, begin, size);
    }
    var slice4d = /* @__PURE__ */ op({ slice4d_ });
    function softmax_(logits, dim) {
      if (dim === void 0) {
        dim = -1;
      }
      var $logits = convertToTensor(logits, "logits", "softmax", "float32");
      if (dim === -1) {
        dim = $logits.rank - 1;
      }
      if (dim !== $logits.rank - 1) {
        throw Error("Softmax along a non-last dimension is not yet supported. " + "Logits was rank ".concat($logits.rank, " and dim was ").concat(dim));
      }
      var inputs = { logits: $logits };
      var attrs = { dim };
      return ENGINE.runKernel(Softmax, inputs, attrs);
    }
    var softmax = /* @__PURE__ */ op({ softmax_ });
    function fft_(input) {
      assert(input.dtype === "complex64", function() {
        return "The dtype for tf.spectral.fft() must be complex64 " + "but got ".concat(input.dtype, ".");
      });
      var inputs = { input };
      return ENGINE.runKernel(FFT, inputs);
    }
    var fft = /* @__PURE__ */ op({ fft_ });
    function ifft_(input) {
      assert(input.dtype === "complex64", function() {
        return "The dtype for tf.spectral.ifft() must be complex64 " + "but got ".concat(input.dtype, ".");
      });
      var inputs = { input };
      return ENGINE.runKernel(IFFT, inputs);
    }
    var ifft = /* @__PURE__ */ op({ ifft_ });
    function irfft_(input) {
      var innerDimensionSize = input.shape[input.shape.length - 1];
      var batch = input.size / innerDimensionSize;
      var ret;
      if (innerDimensionSize <= 2) {
        var complexInput = reshape(input, [batch, innerDimensionSize]);
        ret = ifft(complexInput);
      } else {
        var outputShape = [batch, 2 * (innerDimensionSize - 1)];
        var realInput = reshape(real(input), [batch, innerDimensionSize]);
        var imagInput = reshape(imag(input), [batch, innerDimensionSize]);
        var realConjugate = reverse(slice(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);
        var imagConjugate = mul(reverse(slice(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1), scalar(-1));
        var r = concat([realInput, realConjugate], 1);
        var i = concat([imagInput, imagConjugate], 1);
        var complexInput = reshape(complex(r, i), [outputShape[0], outputShape[1]]);
        ret = ifft(complexInput);
      }
      ret = real(ret);
      if (input.rank === 3 && input.shape[0] !== 0) {
        var temp = ret;
        var batch_1 = input.shape[0];
        ret = reshape(ret, [batch_1, ret.shape[0] / batch_1, ret.shape[1]]);
        temp.dispose();
      }
      return ret;
    }
    var irfft = /* @__PURE__ */ op({ irfft_ });
    function split_(x, numOrSizeSplits, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "split");
      var inputs = { x: $x };
      var attr = { numOrSizeSplits, axis };
      return ENGINE.runKernel(SplitV, inputs, attr);
    }
    var split$1 = /* @__PURE__ */ op({ split_ });
    function rfft_(input, fftLength) {
      assert(input.dtype === "float32", function() {
        return "The dtype for rfft() must be real value but got ".concat(input.dtype);
      });
      var innerDimensionSize = input.shape[input.shape.length - 1];
      var batch = input.size / innerDimensionSize;
      var adjustedInput;
      if (fftLength != null && fftLength < innerDimensionSize) {
        var begin = input.shape.map(function(v) {
          return 0;
        });
        var size = input.shape.map(function(v) {
          return v;
        });
        size[input.shape.length - 1] = fftLength;
        adjustedInput = slice(input, begin, size);
        innerDimensionSize = fftLength;
      } else if (fftLength != null && fftLength > innerDimensionSize) {
        var zerosShape = input.shape.map(function(v) {
          return v;
        });
        zerosShape[input.shape.length - 1] = fftLength - innerDimensionSize;
        adjustedInput = concat([input, zeros(zerosShape)], input.shape.length - 1);
        innerDimensionSize = fftLength;
      } else {
        adjustedInput = input;
      }
      var zerosInput = zerosLike(adjustedInput);
      var complexInput = reshape(complex(adjustedInput, zerosInput), [batch, innerDimensionSize]);
      var ret = fft(complexInput);
      var half = Math.floor(innerDimensionSize / 2) + 1;
      var realValues = real(ret);
      var imagValues = imag(ret);
      var realComplexConjugate = split$1(realValues, [half, innerDimensionSize - half], realValues.shape.length - 1);
      var imagComplexConjugate = split$1(imagValues, [half, innerDimensionSize - half], imagValues.shape.length - 1);
      var outputShape = adjustedInput.shape.slice();
      outputShape[adjustedInput.shape.length - 1] = half;
      return reshape(complex(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);
    }
    var rfft = /* @__PURE__ */ op({ rfft_ });
    function squaredDifference_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "squaredDifference");
      var $b = convertToTensor(b, "b", "squaredDifference");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      var attrs = {};
      return ENGINE.runKernel(SquaredDifference, inputs, attrs);
    }
    var squaredDifference = /* @__PURE__ */ op({ squaredDifference_ });
    function squeeze_(x, axis) {
      var $x = convertToTensor(x, "x", "squeeze", "string_or_numeric");
      return reshape($x, squeezeShape($x.shape, axis).newShape);
    }
    var squeeze = /* @__PURE__ */ op({ squeeze_ });
    function stack_(tensors, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $tensors = convertToTensorArray(tensors, "tensors", "stack", "string_or_numeric");
      assert($tensors.length >= 1, function() {
        return "Pass at least one tensor to tf.stack";
      });
      if ($tensors.length > 0) {
        assert(axis <= $tensors[0].rank, function() {
          return "Axis must be <= rank of the tensor";
        });
      }
      var inputs = $tensors;
      var attrs = { axis };
      return ENGINE.runKernel(Pack, inputs, attrs);
    }
    var stack = /* @__PURE__ */ op({ stack_ });
    function step_(x, alpha) {
      if (alpha === void 0) {
        alpha = 0;
      }
      var $x = convertToTensor(x, "x", "step");
      var inputs = { x: $x };
      var attrs = { alpha };
      return ENGINE.runKernel(Step, inputs, attrs);
    }
    var step = /* @__PURE__ */ op({ step_ });
    function stridedSlice_(x, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
      if (beginMask === void 0) {
        beginMask = 0;
      }
      if (endMask === void 0) {
        endMask = 0;
      }
      if (ellipsisMask === void 0) {
        ellipsisMask = 0;
      }
      if (newAxisMask === void 0) {
        newAxisMask = 0;
      }
      if (shrinkAxisMask === void 0) {
        shrinkAxisMask = 0;
      }
      var $x = convertToTensor(x, "x", "stridedSlice", "string_or_numeric");
      var inputs = { x: $x };
      var attrs = {
        begin,
        end,
        strides,
        beginMask,
        endMask,
        ellipsisMask,
        newAxisMask,
        shrinkAxisMask
      };
      return ENGINE.runKernel(StridedSlice, inputs, attrs);
    }
    var stridedSlice = /* @__PURE__ */ op({ stridedSlice_ });
    function tan_(x) {
      var $x = convertToTensor(x, "x", "tan", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Tan, inputs);
    }
    var tan = /* @__PURE__ */ op({ tan_ });
    function tensor(values, shape, dtype) {
      var inferredShape = inferShape(values, dtype);
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor1d(values, dtype) {
      assertNonNull(values);
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 1) {
        throw new Error("tensor1d() requires values to be a flat/TypedArray");
      }
      var shape = null;
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor2d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 2) {
        throw new Error("tensor2d() requires shape to have two numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 2 && inferredShape.length !== 1) {
        throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor3d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 3) {
        throw new Error("tensor3d() requires shape to have three numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 3 && inferredShape.length !== 1) {
        throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor4d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 4) {
        throw new Error("tensor4d() requires shape to have four numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 4 && inferredShape.length !== 1) {
        throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor5d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 5) {
        throw new Error("tensor5d() requires shape to have five numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 5 && inferredShape.length !== 1) {
        throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor6d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 6) {
        throw new Error("tensor6d() requires shape to have six numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 6 && inferredShape.length !== 1) {
        throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");
      }
      shape = shape || inferredShape;
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function validateUpdateShape(shape, indices, updates) {
      var sliceDim = indices.rank > 1 ? indices.shape[indices.rank - 1] : 1;
      var batchDim = indices.rank > 1 ? indices.rank - 1 : 1;
      var shapeError = "Must have updates.shape = indices.shape[:batchDim] + " + "shape[sliceDim:], got updates.shape: ".concat(updates.shape) + ", indices.shape: ".concat(indices.shape, ", shape: ").concat(shape) + ", sliceDim: ".concat(sliceDim, ", and batchDim: ").concat(batchDim, ".");
      if (updates.rank < batchDim) {
        throw new Error(shapeError + " update.rank < ".concat(batchDim, ". "));
      }
      if (shape.length < sliceDim + (updates.rank - batchDim)) {
        throw new Error(shapeError + " Output shape length < ".concat(sliceDim + (updates.rank - batchDim)));
      }
      if (updates.rank !== batchDim + shape.length - sliceDim) {
        throw new Error(shapeError + " update.rank != ".concat(batchDim + shape.length - sliceDim));
      }
      for (var d = 0; d < batchDim; ++d) {
        if (updates.shape[d] !== indices.shape[d]) {
          throw new Error(shapeError + " updates.shape[".concat(d, "] (").concat(updates.shape[d], ") != indices.shape[").concat(d, "] (").concat(indices.shape[d], ")."));
        }
      }
      for (var d = 0; d < updates.rank - batchDim; ++d) {
        if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {
          throw new Error(shapeError + " updates.shape[".concat(d + batchDim, "] (").concat(updates.shape[d + batchDim], ") != shape[").concat(d + batchDim, "] (").concat(shape[d + batchDim], ")"));
        }
      }
    }
    function validateInput$1(updates, indices, shape) {
      if (indices.rank < 1) {
        throw new Error("tf.scatterND() expects the indices to be rank 1 or higher," + " but the rank was ".concat(indices.rank, "."));
      }
      if (updates.rank < 1) {
        throw new Error("tf.scatterND() expects the updates to be rank 1 or higher," + " but the rank was ".concat(updates.rank, "."));
      }
      if (indices.dtype !== "int32") {
        throw new Error("The dtype of 'indices' should be int32, but got dtype: ".concat(indices.dtype));
      }
      if (shape.length < 1) {
        throw new Error("Output rank must be greater or equal to 1, but got shape: ".concat(shape));
      }
      if (shape.length === 0) {
        if (indices.size === 0) {
          throw new Error("Indices specified for empty output. indices shape: ".concat(indices.shape));
        }
        if (updates.size === 0) {
          throw new Error("Updates specified for empty output. updates shape: ".concat(updates.shape));
        }
      }
      validateUpdateShape(shape, indices, updates);
    }
    function tensorScatterUpdate_(tensor2, indices, updates) {
      var $tensor = convertToTensor(tensor2, "tensor", "tensorScatterupdate");
      var $indices = convertToTensor(indices, "indices", "tensorScatterupdate", "int32");
      var $updates = convertToTensor(updates, "updates", "tensorScatterupdate");
      validateInput$1($updates, $indices, $tensor.shape);
      if ($tensor.dtype !== $updates.dtype) {
        throw new Error("tensor and updates must have the same dtype, instead they are ".concat($tensor.dtype, " and ").concat($updates.dtype, "."));
      }
      var inputs = {
        tensor: $tensor,
        indices: $indices,
        updates: $updates
      };
      var attrs = {};
      return ENGINE.runKernel(TensorScatterUpdate, inputs, attrs);
    }
    var tensorScatterUpdate = op({ tensorScatterUpdate_ });
    function topk_(x, k, sorted) {
      if (k === void 0) {
        k = 1;
      }
      if (sorted === void 0) {
        sorted = true;
      }
      var $x = convertToTensor(x, "x", "topk");
      if ($x.rank === 0) {
        throw new Error("topk() expects the input to be of rank 1 or higher");
      }
      var lastDim = $x.shape[$x.shape.length - 1];
      if (k < 0) {
        throw new Error("'k' passed to topk() must be >= 0 but got ".concat(k));
      }
      if (k > lastDim) {
        throw new Error("'k' passed to topk() must be <= the last dimension (".concat(lastDim, ") ") + "but got ".concat(k));
      }
      var inputs = { x: $x };
      var attrs = { k, sorted };
      var _a = __read(ENGINE.runKernel(TopK, inputs, attrs), 2), values = _a[0], indices = _a[1];
      return { values, indices };
    }
    var topk = /* @__PURE__ */ op({ topk_ });
    function truncatedNormal_(shape, mean2, stdDev, dtype, seed) {
      if (mean2 === void 0) {
        mean2 = 0;
      }
      if (stdDev === void 0) {
        stdDev = 1;
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype != null && dtype === "bool") {
        throw new Error("Unsupported data type $ { dtype }");
      }
      var randGauss = new MPRandGauss(mean2, stdDev, dtype, true, seed);
      var res = buffer(shape, dtype);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = randGauss.nextValue();
      }
      return res.toTensor();
    }
    var truncatedNormal = /* @__PURE__ */ op({ truncatedNormal_ });
    function unique_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "unique", "string_or_numeric");
      assert($x.rank > 0, function() {
        return "The input tensor must be at least 1D";
      });
      var inputs = { x: $x };
      var attrs = { axis };
      var _a = __read(ENGINE.runKernel(Unique, inputs, attrs), 2), values = _a[0], indices = _a[1];
      return { values, indices };
    }
    var unique = /* @__PURE__ */ op({ unique_ });
    function unsortedSegmentSum_(x, segmentIds, numSegments) {
      var $x = convertToTensor(x, "x", "unsortedSegmentSum");
      var $segmentIds = convertToTensor(segmentIds, "segmentIds", "unsortedSegmentSum", "int32");
      assert(isInt(numSegments), function() {
        return "numSegments must be of dtype int";
      });
      var inputs = { x: $x, segmentIds: $segmentIds };
      var attrs = { numSegments };
      return ENGINE.runKernel(UnsortedSegmentSum, inputs, attrs);
    }
    var unsortedSegmentSum = /* @__PURE__ */ op({ unsortedSegmentSum_ });
    function unstack_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "unstack", "string_or_numeric");
      assert(axis >= -$x.shape.length && axis < $x.shape.length, function() {
        return "Axis = ".concat(axis, " is not in [-").concat($x.shape.length, ", ").concat($x.shape.length, ")");
      });
      var inputs = { value: $x };
      var attrs = { axis };
      return ENGINE.runKernel(Unpack, inputs, attrs);
    }
    var unstack = /* @__PURE__ */ op({ unstack_ });
    function upperBound(sortedSequence, values) {
      return searchSorted(sortedSequence, values, "right");
    }
    function variable(initialValue, trainable, name, dtype) {
      if (trainable === void 0) {
        trainable = true;
      }
      return ENGINE.makeVariable(initialValue, trainable, name, dtype);
    }
    function whereImpl(condShape, condVals) {
      var indices = [];
      for (var i = 0; i < condVals.length; i++) {
        if (condVals[i]) {
          indices.push(i);
        }
      }
      var inBuffer = buffer(condShape, "int32");
      var out = buffer([indices.length, condShape.length], "int32");
      for (var i = 0; i < indices.length; i++) {
        var loc = inBuffer.indexToLoc(indices[i]);
        var offset = i * condShape.length;
        out.values.set(loc, offset);
      }
      return out.toTensor();
    }
    function whereAsync_(condition) {
      return __awaiter(this, void 0, void 0, function() {
        var $condition, vals, res;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $condition = convertToTensor(condition, "condition", "whereAsync", "bool");
              return [4, $condition.data()];
            case 1:
              vals = _a.sent();
              res = whereImpl($condition.shape, vals);
              if (condition !== $condition) {
                $condition.dispose();
              }
              return [2, res];
          }
        });
      });
    }
    var whereAsync = whereAsync_;
    function booleanMaskAsync_(tensor2, mask, axis) {
      return __awaiter(this, void 0, void 0, function() {
        var $tensor, $mask, axisFrom, maskDim, tensorShape, leadingSize, i, targetTensorShape, reshapedTensor, reshapedMask, positivePositions, indices, res;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $tensor = convertToTensor(tensor2, "tensor", "boolMask");
              $mask = convertToTensor(mask, "mask", "boolMask", "bool");
              axisFrom = axis == null ? 0 : axis;
              maskDim = $mask.rank;
              tensorShape = $tensor.shape;
              assert(maskDim > 0, function() {
                return "mask cannot be scalar";
              });
              assertShapesMatch(tensorShape.slice(axisFrom, axisFrom + maskDim), $mask.shape, "mask's shape must match the first K dimensions of tensor's shape,");
              leadingSize = 1;
              for (i = axisFrom; i < axisFrom + maskDim; i++) {
                leadingSize *= tensorShape[i];
              }
              targetTensorShape = tensorShape.slice(0, axisFrom).concat([leadingSize], tensorShape.slice(axisFrom + maskDim));
              reshapedTensor = reshape($tensor, targetTensorShape);
              reshapedMask = reshape($mask, [-1]);
              return [4, whereAsync(reshapedMask)];
            case 1:
              positivePositions = _a.sent();
              indices = squeeze(positivePositions, [1]);
              res = gather(reshapedTensor, indices, axisFrom);
              if (tensor2 !== $tensor) {
                $tensor.dispose();
              }
              if (mask !== $mask) {
                $mask.dispose();
              }
              indices.dispose();
              reshapedTensor.dispose();
              reshapedMask.dispose();
              positivePositions.dispose();
              return [2, res];
          }
        });
      });
    }
    var booleanMaskAsync = booleanMaskAsync_;
    function tidy(nameOrFn, fn) {
      return ENGINE.tidy(nameOrFn, fn);
    }
    function dispose(container) {
      var tensors = getTensorsInContainer(container);
      tensors.forEach(function(tensor2) {
        return tensor2.dispose();
      });
    }
    function getBackend() {
      return ENGINE.backendName;
    }
    function backend() {
      return ENGINE.backend;
    }
    function transpose_(x, perm, conjugate) {
      var $x = convertToTensor(x, "x", "transpose");
      if (perm == null) {
        perm = $x.shape.map(function(s, i) {
          return i;
        }).reverse();
      }
      assert($x.rank === perm.length, function() {
        return "Error in transpose: rank of input ".concat($x.rank, " ") + "must match length of perm ".concat(perm, ".");
      });
      perm.forEach(function(axis) {
        assert(axis >= 0 && axis < $x.rank, function() {
          return "All entries in 'perm' must be between 0 and ".concat($x.rank - 1) + " but got ".concat(perm);
        });
      });
      if ($x.rank <= 1) {
        return $x.clone();
      }
      var inputs = { x: $x };
      var attrs = { perm };
      if ($x.dtype === "complex64") {
        return tidy(function() {
          var $real = real($x);
          var $imag = imag($x);
          $real = ENGINE.runKernel(Transpose, { x: $real }, attrs);
          $imag = ENGINE.runKernel(Transpose, { x: $imag }, attrs);
          if (conjugate) {
            $imag = neg($imag);
          }
          return complex($real, $imag);
        });
      }
      return ENGINE.runKernel(Transpose, inputs, attrs);
    }
    var transpose = /* @__PURE__ */ op({ transpose_ });
    function movingAverage_(v, x, decay, step2, zeroDebias) {
      if (zeroDebias === void 0) {
        zeroDebias = true;
      }
      var $v = convertToTensor(v, "v", "movingAverage");
      var $x = convertToTensor(x, "x", "movingAverage");
      var $decay = convertToTensor(decay, "decay", "movingAverage");
      assertTypesMatch($v, $x);
      assert(arraysEqual($v.shape, $x.shape), function() {
        return "Shape mismatch in v and x";
      });
      var one = scalar(1);
      var oneMinusDecay = sub(one, $decay);
      var update = mul(sub($x, $v), oneMinusDecay);
      if (zeroDebias) {
        assert(step2 != null, function() {
          return "When using zeroDebias: true, step is required.";
        });
        var $step = convertToTensor(step2, "step", "movingAverage");
        update = div(update, sub(one, pow($decay, $step)));
      }
      return add($v, update);
    }
    var movingAverage = /* @__PURE__ */ op({ movingAverage_ });
    function scatterND_(indices, updates, shape) {
      assertNonNegativeIntegerDimensions(shape);
      var $indices = convertToTensor(indices, "indices", "scatterND", "int32");
      var $updates = convertToTensor(updates, "updates", "scatterND");
      validateInput$1($updates, $indices, shape);
      var inputs = { indices: $indices, updates: $updates };
      var attrs = { shape };
      return ENGINE.runKernel(ScatterNd, inputs, attrs);
    }
    var scatterND = /* @__PURE__ */ op({ scatterND_ });
    function validateInput(sparseIndices, sparseValues, outputShape, defaultValues) {
      if (sparseIndices.dtype !== "int32") {
        throw new Error("tf.sparseToDense() expects the indices to be int32 type," + " but the dtype was ".concat(sparseIndices.dtype, "."));
      }
      if (sparseIndices.rank > 2) {
        throw new Error("sparseIndices should be a scalar, vector, or matrix," + " but got shape ".concat(sparseIndices.shape, "."));
      }
      var numElems = sparseIndices.rank > 0 ? sparseIndices.shape[0] : 1;
      var numDims = sparseIndices.rank > 1 ? sparseIndices.shape[1] : 1;
      if (outputShape.length !== numDims) {
        throw new Error("outputShape has incorrect number of elements:," + " ".concat(outputShape.length, ", should be: ").concat(numDims, "."));
      }
      var numValues = sparseValues.size;
      if (!(sparseValues.rank === 0 || sparseValues.rank === 1 && numValues === numElems)) {
        throw new Error("sparseValues has incorrect shape " + "".concat(sparseValues.shape, ", should be [] or [").concat(numElems, "]"));
      }
      if (sparseValues.dtype !== defaultValues.dtype) {
        throw new Error("sparseValues.dtype must match defaultValues.dtype");
      }
    }
    function sparseToDense_(sparseIndices, sparseValues, outputShape, defaultValue) {
      if (defaultValue === void 0) {
        defaultValue = 0;
      }
      assertNonNegativeIntegerDimensions(outputShape);
      var $sparseIndices = convertToTensor(sparseIndices, "sparseIndices", "sparseToDense", "int32");
      var $sparseValues = convertToTensor(sparseValues, "sparseValues", "sparseToDense", "string_or_numeric");
      var $defaultValue = convertToTensor(defaultValue, "defaultValue", "sparseToDense", $sparseValues.dtype);
      validateInput($sparseIndices, $sparseValues, outputShape, $defaultValue);
      var inputs = {
        sparseIndices: $sparseIndices,
        sparseValues: $sparseValues,
        defaultValue: $defaultValue
      };
      var attrs = { outputShape };
      return ENGINE.runKernel(SparseToDense, inputs, attrs);
    }
    var sparseToDense = /* @__PURE__ */ op({ sparseToDense_ });
    function gatherND_(x, indices) {
      var $indices = convertToTensor(indices, "indices", "gatherND", "int32");
      var $x = convertToTensor(x, "x", "gatherND", "string_or_numeric");
      var inputs = { params: $x, indices: $indices };
      return ENGINE.runKernel(GatherNd, inputs);
    }
    var gatherND = /* @__PURE__ */ op({ gatherND_ });
    function getNoiseShape(x, noiseShape) {
      if (noiseShape == null) {
        return x.shape.slice();
      }
      if (arraysEqual(x.shape, noiseShape)) {
        return noiseShape;
      }
      if (x.shape.length === noiseShape.length) {
        var newDimension = [];
        for (var i = 0; i < x.shape.length; i++) {
          if (noiseShape[i] == null && x.shape[i] != null) {
            newDimension.push(x.shape[i]);
          } else {
            newDimension.push(noiseShape[i]);
          }
        }
        return newDimension;
      }
      return noiseShape;
    }
    function dropout_(x, rate, noiseShape, seed) {
      var $x = convertToTensor(x, "x", "dropout");
      assert($x.dtype === "float32", function() {
        return "x has to be a floating point tensor since it's going to be " + "scaled, but got a ".concat($x.dtype, " tensor instead.");
      });
      assert(rate >= 0 && rate < 1, function() {
        return "rate must be a float in the range [0, 1), but got ".concat(rate, ".");
      });
      if (rate === 0) {
        return x instanceof Tensor ? $x.clone() : $x;
      }
      var $noiseShape = getNoiseShape($x, noiseShape);
      var keepProb = 1 - rate;
      var multiplier = div(floor(add(randomUniform($noiseShape, 0, 1, "float32", seed), keepProb)), keepProb);
      return mul($x, multiplier);
    }
    var dropout = /* @__PURE__ */ op({ dropout_ });
    function enclosingPowerOfTwo(value) {
      return Math.floor(Math.pow(2, Math.ceil(Math.log(value) / Math.log(2))));
    }
    function cosineWindow(windowLength, a, b) {
      var even = 1 - windowLength % 2;
      var newValues = new Float32Array(windowLength);
      for (var i = 0; i < windowLength; ++i) {
        var cosArg = 2 * Math.PI * i / (windowLength + even - 1);
        newValues[i] = a - b * Math.cos(cosArg);
      }
      return tensor1d(newValues, "float32");
    }
    function inTopKAsync_(predictions, targets, k) {
      if (k === void 0) {
        k = 1;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $predictions, $targets, lastDim, predictionsVals, targetsVals, _a, batch, size, precision, b, offset, vals, valAndInd, i, i;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              $predictions = convertToTensor(predictions, "predictions", "inTopK");
              $targets = convertToTensor(targets, "targets", "inTopK");
              assert($predictions.rank > 1, function() {
                return "inTopK() expects the predictions to be of rank 2 or higher, " + "but got ".concat($predictions.rank);
              });
              assert($predictions.rank - 1 === $targets.rank, function() {
                return "predictions rank should be 1 larger than targets rank, but got predictions rank " + "".concat($predictions.rank, " and targets rank ").concat($targets.rank);
              });
              assertShapesMatch($predictions.shape.slice(0, $predictions.shape.length - 1), $targets.shape, "predictions's shape should be align with the targets' shape, except the last dimension.");
              lastDim = $predictions.shape[$predictions.shape.length - 1];
              assert(k > 0 && k <= lastDim, function() {
                return "'k' passed to inTopK() must be > 0 && <= the predictions last " + "dimension (".concat(lastDim, "), but got ").concat(k);
              });
              return [4, $predictions.data()];
            case 1:
              predictionsVals = _b.sent();
              return [4, $targets.data()];
            case 2:
              targetsVals = _b.sent();
              _a = __read([predictionsVals.length / lastDim, lastDim], 2), batch = _a[0], size = _a[1];
              precision = getTypedArrayFromDType("bool", batch);
              for (b = 0; b < batch; b++) {
                offset = b * size;
                vals = predictionsVals.subarray(offset, offset + size);
                valAndInd = [];
                for (i = 0; i < vals.length; i++) {
                  valAndInd.push({ value: vals[i], index: i });
                }
                valAndInd.sort(function(a, b2) {
                  return b2.value - a.value;
                });
                precision[b] = 0;
                for (i = 0; i < k; i++) {
                  if (valAndInd[i].index === targetsVals[b]) {
                    precision[b] = 1;
                    break;
                  }
                }
              }
              if (predictions !== $predictions) {
                $predictions.dispose();
              }
              if (targets !== $targets) {
                $targets.dispose();
              }
              return [2, tensor(precision, $targets.shape, "bool")];
          }
        });
      });
    }
    var inTopKAsync = inTopKAsync_;
    function conv2DBackpropFilter_(x, dy, filterShape, strides, pad2, dataFormat, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var x4D = x;
      if (x.rank === 3) {
        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
      }
      var dy4D = dy;
      if (dy4D.rank === 3) {
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in conv2dDerFilter: input must be rank 4, but got shape " + "".concat(x4D.shape, ".");
      });
      assert(dy4D.rank === 4, function() {
        return "Error in conv2dDerFilter: dy must be rank 4, but got shape " + "".concat(dy4D.shape, ".");
      });
      assert(filterShape.length === 4, function() {
        return "Error in conv2dDerFilter: filterShape must be length 4, but got " + "".concat(filterShape, ".");
      });
      var inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      var outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
      assert(inDepth === filterShape[2], function() {
        return "Error in conv2dDerFilter: depth of input ".concat(inDepth, ") must ") + "match input depth in filter (".concat(filterShape[2], ".");
      });
      assert(outDepth === filterShape[3], function() {
        return "Error in conv2dDerFilter: depth of dy (".concat(outDepth, ") must ") + "match output depth for filter (".concat(filterShape[3], ").");
      });
      checkPadOnDimRoundingMode("conv2dDerFilter", pad2, dimRoundingMode);
      var inputs = { x: x4D, dy: dy4D };
      var attrs = { strides, pad: pad2, dataFormat, dimRoundingMode, filterShape };
      return ENGINE.runKernel(Conv2DBackpropFilter, inputs, attrs);
    }
    var conv2DBackpropFilter = /* @__PURE__ */ op({ conv2DBackpropFilter_ });
    function getFusedDyActivation(dy, y, activation) {
      if (activation == null || activation === "linear") {
        return dy;
      }
      if (activation === "relu") {
        return mul(dy, step(y));
      }
      throw new Error("Cannot compute gradient for fused activation ".concat(activation, "."));
    }
    function getFusedBiasGradient(bias, dyActivation) {
      var res = dyActivation;
      var reduceAxes = getReductionAxes(bias.shape, dyActivation.shape);
      if (reduceAxes.length > 0) {
        res = sum(res, reduceAxes);
      }
      return reshape(res, bias.shape);
    }
    function applyActivation(x, activation, preluActivationWeights, leakyreluAlpha) {
      if (activation === "linear") {
        return x;
      } else if (activation === "relu") {
        return relu(x);
      } else if (activation === "elu") {
        return elu(x);
      } else if (activation === "relu6") {
        return relu6(x);
      } else if (activation === "prelu") {
        return prelu(x, preluActivationWeights);
      } else if (activation === "leakyrelu") {
        return leakyRelu(x, leakyreluAlpha);
      } else if (activation === "sigmoid") {
        return sigmoid(x);
      }
      throw new Error("Unknown fused activation ".concat(activation, "."));
    }
    var shouldFuse = function(gradientDepth, activation) {
      var gradientMode = gradientDepth > 0;
      return !gradientMode || activation === "linear";
    };
    function fusedConv2d_(_a) {
      var _b;
      var x = _a.x, filter = _a.filter, strides = _a.strides, pad2 = _a.pad, _c = _a.dataFormat, dataFormat = _c === void 0 ? "NHWC" : _c, _d = _a.dilations, dilations = _d === void 0 ? [1, 1] : _d, dimRoundingMode = _a.dimRoundingMode, bias = _a.bias, _e = _a.activation, activation = _e === void 0 ? "linear" : _e, preluActivationWeights = _a.preluActivationWeights, leakyreluAlpha = _a.leakyreluAlpha;
      activation = activation || "linear";
      if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
        assert(dataFormat === "NHWC", function() {
          return "Error in fused conv2d: got dataFormat of ".concat(dataFormat, " but ") + "only NHWC is currently supported for the case of gradient depth is 0 and the activation is not linear.";
        });
        var result = conv2d$1(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
        if (bias != null) {
          result = add(result, bias);
        }
        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
      }
      var $x = convertToTensor(x, "x", "conv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "conv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in fused conv2d: input must be rank 4, but got rank " + "".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in fused conv2d: filter must be rank 4, but got rank " + "".concat($filter.rank, ".");
      });
      checkPadOnDimRoundingMode("fused conv2d", pad2, dimRoundingMode);
      var inputChannels = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      assert($filter.shape[2] === inputChannels, function() {
        return "Error in conv2d: depth of input (".concat(inputChannels, ") must match ") + "input depth for filter ".concat($filter.shape[2], ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in conv2D: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var convInfo = computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad2, dimRoundingMode);
      var $bias;
      if (bias != null) {
        $bias = convertToTensor(bias, "bias", "fused conv2d");
        _b = __read(makeTypesMatch($bias, $x), 1), $bias = _b[0];
        if (dataFormat === "NHWC") {
          assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
        } else {
          assert($bias.shape.length <= 1, function() {
            return "Error in fused conv2d: only supports scalar or 1-D Tensor bias for NCHW format but got the bias of " + "rank-".concat($bias.shape.length, ".");
          });
          assert($bias.shape.length === 0 || $bias.shape[0] === convInfo.outChannels || $bias.shape[0] === 1, function() {
            return "Error in fused conv2d: bias shape (".concat($bias.shape, ") is not ") + "compatible with the number of output channels " + "(".concat(convInfo.outChannels, ")");
          });
        }
      }
      var $preluActivationWeights;
      if (preluActivationWeights != null) {
        var alphaShape_1 = preluActivationWeights.shape;
        assert(alphaShape_1.length <= 1 || alphaShape_1.length === 3, function() {
          return "Error in fused conv2d: only supports scalar, 1-D Tensor or 3-D Tensor PReLU activation weights but got a tensor of " + "rank-".concat(alphaShape_1.length, ".");
        });
        if (alphaShape_1.length === 1) {
          assert(alphaShape_1[0] === 1 || alphaShape_1[0] === convInfo.outChannels, function() {
            return "Error in fused conv2d: PReLU activation weights " + "(".concat(alphaShape_1, ") is not compatible with the number of output ") + "channels (".concat(convInfo.outChannels, ").");
          });
        } else if (alphaShape_1.length === 3) {
          try {
            assertAndGetBroadcastShape(alphaShape_1, convInfo.outShape);
          } catch (e) {
            var errMsg = "Error in fused conv2d: PReLU activation weights (".concat(alphaShape_1, ") ") + "is not compatible with the output shape of the conv2d " + "(".concat(convInfo.outShape, ").");
            throw Error(errMsg);
          }
        }
        $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused conv2d");
      }
      var grad = function(dy, saved) {
        assert(dataFormat === "NHWC", function() {
          return "Error in gradient of fused conv2D: got dataFormat of ".concat(dataFormat, " but only NHWC is currently supported.");
        });
        var _a2 = __read(saved, 4), $filter2 = _a2[0], x4D2 = _a2[1], y = _a2[2], $bias2 = _a2[3];
        var dyActivation = getFusedDyActivation(dy, y, activation);
        assert(tupleValuesAreOne(dilations), function() {
          return "Error in gradient of fused conv2D: dilation rates greater than 1 " + "are not yet supported in gradients. Got dilations '".concat(dilations, "'");
        });
        var xDer = conv2DBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2);
        var filterDer = conv2DBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2);
        var der = [xDer, filterDer];
        if ($bias2 != null) {
          var biasDer = getFusedBiasGradient($bias2, dyActivation);
          der.push(biasDer);
        }
        return der;
      };
      var inputs = {
        x: x4D,
        filter: $filter,
        bias: $bias,
        preluActivationWeights: $preluActivationWeights
      };
      var attrs = {
        strides,
        pad: pad2,
        dataFormat,
        dilations,
        dimRoundingMode,
        activation,
        leakyreluAlpha
      };
      if (bias == null) {
        var customOp = customGrad(function(x4D2, filter2, save) {
          var res = (
            // tslint:disable-next-line: no-unnecessary-type-assertion
            ENGINE.runKernel(FusedConv2D, inputs, attrs)
          );
          save([filter2, x4D2, res]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad };
        });
        return customOp(x4D, $filter);
      } else {
        var customOpWithBias = customGrad(function(x4D2, filter2, bias2, save) {
          var res = ENGINE.runKernel(FusedConv2D, inputs, attrs);
          save([filter2, x4D2, res, bias2]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad };
        });
        return customOpWithBias(x4D, $filter, $bias);
      }
    }
    var conv2d = /* @__PURE__ */ op({ fusedConv2d_ });
    function depthwiseConv2dNativeBackpropFilter_(x, dy, filterShape, strides, pad2, dilations, dimRoundingMode) {
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var x4D = x;
      if (x.rank === 3) {
        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
      }
      var dy4D = dy;
      if (dy4D.rank === 3) {
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
      }
      var inputs = { x: x4D, dy: dy4D };
      var attrs = { strides, pad: pad2, dimRoundingMode, dilations, filterShape };
      return ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter, inputs, attrs);
    }
    var depthwiseConv2dNativeBackpropFilter = op({ depthwiseConv2dNativeBackpropFilter_ });
    function depthwiseConv2dNativeBackpropInput_(xShape, dy, filter, strides, pad2, dilations, dimRoundingMode) {
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var dy4D = dy;
      var reshapedTo4D = false;
      if (dy.rank === 3) {
        reshapedTo4D = true;
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
      }
      var inputs = { dy: dy4D, filter };
      var attrs = { strides, pad: pad2, dimRoundingMode, dilations, inputShape: xShape };
      var res = (
        // tslint:disable-next-line: no-unnecessary-type-assertion
        ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput, inputs, attrs)
      );
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var depthwiseConv2dNativeBackpropInput = op({ depthwiseConv2dNativeBackpropInput_ });
    function fusedDepthwiseConv2d_(_a) {
      var _b;
      var x = _a.x, filter = _a.filter, strides = _a.strides, pad2 = _a.pad, _c = _a.dataFormat, dataFormat = _c === void 0 ? "NHWC" : _c, _d = _a.dilations, dilations = _d === void 0 ? [1, 1] : _d, dimRoundingMode = _a.dimRoundingMode, bias = _a.bias, _e = _a.activation, activation = _e === void 0 ? "linear" : _e, preluActivationWeights = _a.preluActivationWeights, leakyreluAlpha = _a.leakyreluAlpha;
      if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
        var result = depthwiseConv2d$1(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
        if (bias != null) {
          result = add(result, bias);
        }
        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
      }
      var $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in fused depthwiseConv2d: input must be rank 4, but got " + "rank ".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in fused depthwiseConv2d: filter must be rank 4, " + "but got rank ".concat($filter.rank, ".");
      });
      assert(x4D.shape[3] === $filter.shape[2], function() {
        return "Error in fused depthwiseConv2d: number of input channels " + "(".concat(x4D.shape[3], ") must match the inChannels dimension in ") + "filter ".concat($filter.shape[2], ".");
      });
      if (dilations == null) {
        dilations = [1, 1];
      }
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in fused depthwiseConv2d: Either strides or dilations must " + "be 1. Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      checkPadOnDimRoundingMode("fused depthwiseConv2d", pad2, dimRoundingMode);
      var convInfo = computeConv2DInfo(
        x4D.shape,
        $filter.shape,
        strides,
        dilations,
        pad2,
        dimRoundingMode,
        true
        /* depthwise */
      );
      var $bias;
      if (bias != null) {
        $bias = convertToTensor(bias, "bias", "fused conv2d");
        _b = __read(makeTypesMatch($bias, $x), 1), $bias = _b[0];
        assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
      }
      var $preluActivationWeights;
      if (preluActivationWeights != null) {
        $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused depthwiseConv2d");
      }
      var grad = function(dy, saved) {
        assert(tupleValuesAreOne(dilations), function() {
          return "Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations " + "'".concat(dilations, "'");
        });
        var _a2 = __read(saved, 4), $filter2 = _a2[0], x4D2 = _a2[1], y = _a2[2], bias2 = _a2[3];
        var dyActivation = getFusedDyActivation(dy, y, activation);
        var xDer = depthwiseConv2dNativeBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2, dilations, dimRoundingMode);
        var filterDer = depthwiseConv2dNativeBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2, dilations, dimRoundingMode);
        if (bias2 != null) {
          var biasDer = getFusedBiasGradient($bias, dyActivation);
          return [xDer, filterDer, biasDer];
        }
        return [xDer, filterDer];
      };
      var inputs = {
        x: x4D,
        filter: $filter,
        bias: $bias,
        preluActivationWeights: $preluActivationWeights
      };
      var attrs = {
        strides,
        pad: pad2,
        dataFormat,
        dilations,
        dimRoundingMode,
        activation,
        leakyreluAlpha
      };
      if (bias == null) {
        var customOp = customGrad(function(x4D2, filter2, save) {
          var res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
          save([filter2, x4D2, res]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad };
        });
        return customOp(x4D, $filter);
      } else {
        var customOpWithBias = customGrad(function(x4D2, filter2, bias2, save) {
          var res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
          save([filter2, x4D2, res, bias2]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad };
        });
        return customOpWithBias(x4D, $filter, $bias);
      }
    }
    var depthwiseConv2d = /* @__PURE__ */ op({ fusedDepthwiseConv2d_ });
    function fusedMatMul_(_a) {
      var _b, _c;
      var a = _a.a, b = _a.b, _d = _a.transposeA, transposeA = _d === void 0 ? false : _d, _e = _a.transposeB, transposeB = _e === void 0 ? false : _e, bias = _a.bias, _f = _a.activation, activation = _f === void 0 ? "linear" : _f, preluActivationWeights = _a.preluActivationWeights, _g = _a.leakyreluAlpha, leakyreluAlpha = _g === void 0 ? 0.2 : _g;
      if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
        var result = matMul$1(a, b, transposeA, transposeB);
        if (bias != null) {
          result = add(result, bias);
        }
        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
      }
      var $a = convertToTensor(a, "a", "fused matMul");
      var $b = convertToTensor(b, "b", "fused matMul");
      _b = __read(makeTypesMatch($a, $b), 2), $a = _b[0], $b = _b[1];
      var innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];
      var innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];
      var outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];
      var outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];
      var outerDimsA = $a.shape.slice(0, -2);
      var outerDimsB = $b.shape.slice(0, -2);
      var batchDimA = sizeFromShape(outerDimsA);
      var batchDimB = sizeFromShape(outerDimsB);
      assert(innerShapeA === innerShapeB, function() {
        return "Error in fused matMul: inner shapes (".concat(innerShapeA, ") and (") + "".concat(innerShapeB, ") of Tensors with shapes ").concat($a.shape, " and ") + "".concat($b.shape, " and transposeA=").concat(transposeA) + " and transposeB=".concat(transposeB, " must match.");
      });
      var outShapeOuterDims = assertAndGetBroadcastShape($a.shape.slice(0, -2), $b.shape.slice(0, -2));
      var outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
      var a3D = transposeA ? reshape($a, [batchDimA, innerShapeA, outerShapeA]) : reshape($a, [batchDimA, outerShapeA, innerShapeA]);
      var b3D = transposeB ? reshape($b, [batchDimB, outerShapeB, innerShapeB]) : reshape($b, [batchDimB, innerShapeB, outerShapeB]);
      var $bias;
      if (bias != null) {
        $bias = convertToTensor(bias, "bias", "fused matMul");
        _c = __read(makeTypesMatch($bias, $a), 1), $bias = _c[0];
        assertAndGetBroadcastShape(outShape, $bias.shape);
      }
      var $preluActivationWeights;
      if (preluActivationWeights != null) {
        $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused matMul");
      }
      var grad = function(dy, saved) {
        var _a2 = __read(saved, 4), a3D2 = _a2[0], b3D2 = _a2[1], y = _a2[2], $bias2 = _a2[3];
        var dyActivation = getFusedDyActivation(reshape(dy, y.shape), y, activation);
        var aDer;
        var bDer;
        if (!transposeA && !transposeB) {
          aDer = matMul$1(dyActivation, b3D2, false, true);
          bDer = matMul$1(a3D2, dyActivation, true, false);
        } else if (!transposeA && transposeB) {
          aDer = matMul$1(dyActivation, b3D2, false, false);
          bDer = matMul$1(dyActivation, a3D2, true, false);
        } else if (transposeA && !transposeB) {
          aDer = matMul$1(b3D2, dyActivation, false, true);
          bDer = matMul$1(a3D2, dyActivation, false, false);
        } else {
          aDer = matMul$1(b3D2, dyActivation, true, true);
          bDer = matMul$1(dyActivation, a3D2, true, true);
        }
        if (bias != null) {
          var biasDer = getFusedBiasGradient($bias2, dyActivation);
          return [aDer, bDer, biasDer];
        } else {
          return [aDer, bDer];
        }
      };
      var inputs = {
        a: a3D,
        b: b3D,
        bias: $bias,
        preluActivationWeights: $preluActivationWeights
      };
      var attrs = { transposeA, transposeB, activation, leakyreluAlpha };
      if (bias == null) {
        var customOp = customGrad(function(a3D2, b3D2, save) {
          var res = (
            // tslint:disable-next-line: no-unnecessary-type-assertion
            ENGINE.runKernel(_FusedMatMul, inputs, attrs)
          );
          save([a3D2, b3D2, res]);
          return { value: reshape(res, outShape), gradFunc: grad };
        });
        return customOp(a3D, b3D);
      } else {
        var customOpWithBias = customGrad(function(a3D2, b3D2, $bias2, save) {
          var res = (
            // tslint:disable-next-line: no-unnecessary-type-assertion
            ENGINE.runKernel(_FusedMatMul, inputs, attrs)
          );
          save([a3D2, b3D2, res, $bias2]);
          return { value: reshape(res, outShape), gradFunc: grad };
        });
        return customOpWithBias(a3D, b3D, $bias);
      }
    }
    var matMul = /* @__PURE__ */ op({ fusedMatMul_ });
    var fused_ops = {
      __proto__: null,
      conv2d,
      depthwiseConv2d,
      matMul
    };
    function hammingWindow_(windowLength) {
      return cosineWindow(windowLength, 0.54, 0.46);
    }
    var hammingWindow = /* @__PURE__ */ op({ hammingWindow_ });
    function hannWindow_(windowLength) {
      return cosineWindow(windowLength, 0.5, 0.5);
    }
    var hannWindow = /* @__PURE__ */ op({ hannWindow_ });
    function frame_(signal2, frameLength, frameStep, padEnd, padValue) {
      if (padEnd === void 0) {
        padEnd = false;
      }
      if (padValue === void 0) {
        padValue = 0;
      }
      var start = 0;
      var output = [];
      while (start + frameLength <= signal2.size) {
        output.push(slice(signal2, start, frameLength));
        start += frameStep;
      }
      if (padEnd) {
        while (start < signal2.size) {
          var padLen = start + frameLength - signal2.size;
          var pad2 = concat([
            slice(signal2, start, frameLength - padLen),
            fill([padLen], padValue)
          ]);
          output.push(pad2);
          start += frameStep;
        }
      }
      if (output.length === 0) {
        return tensor2d([], [0, frameLength]);
      }
      return reshape(concat(output), [output.length, frameLength]);
    }
    var frame = /* @__PURE__ */ op({ frame_ });
    function stft_(signal2, frameLength, frameStep, fftLength, windowFn) {
      if (windowFn === void 0) {
        windowFn = hannWindow;
      }
      if (fftLength == null) {
        fftLength = enclosingPowerOfTwo(frameLength);
      }
      var framedSignal = frame(signal2, frameLength, frameStep);
      var windowedSignal = mul(framedSignal, windowFn(frameLength));
      return rfft(windowedSignal, fftLength);
    }
    var stft = /* @__PURE__ */ op({ stft_ });
    function cropAndResize_(image2, boxes, boxInd, cropSize, method, extrapolationValue) {
      if (method === void 0) {
        method = "bilinear";
      }
      if (extrapolationValue === void 0) {
        extrapolationValue = 0;
      }
      var $image = convertToTensor(image2, "image", "cropAndResize");
      var $boxes = convertToTensor(boxes, "boxes", "cropAndResize", "float32");
      var $boxInd = convertToTensor(boxInd, "boxInd", "cropAndResize", "int32");
      var numBoxes = $boxes.shape[0];
      assert($image.rank === 4, function() {
        return "Error in cropAndResize: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      assert($boxes.rank === 2 && $boxes.shape[1] === 4, function() {
        return "Error in cropAndResize: boxes must be have size [".concat(numBoxes, ",4] ") + "but had shape ".concat($boxes.shape, ".");
      });
      assert($boxInd.rank === 1 && $boxInd.shape[0] === numBoxes, function() {
        return "Error in cropAndResize: boxInd must be have size [".concat(numBoxes, "] ") + "but had shape ".concat($boxes.shape, ".");
      });
      assert(cropSize.length === 2, function() {
        return "Error in cropAndResize: cropSize must be of length 2, but got " + "length ".concat(cropSize.length, ".");
      });
      assert(cropSize[0] >= 1 && cropSize[1] >= 1, function() {
        return "cropSize must be atleast [1,1], but was ".concat(cropSize);
      });
      assert(method === "bilinear" || method === "nearest", function() {
        return "method must be bilinear or nearest, but was ".concat(method);
      });
      var inputs = { image: $image, boxes: $boxes, boxInd: $boxInd };
      var attrs = { method, extrapolationValue, cropSize };
      var res = ENGINE.runKernel(CropAndResize, inputs, attrs);
      return res;
    }
    var cropAndResize = /* @__PURE__ */ op({ cropAndResize_ });
    function flipLeftRight_(image2) {
      var $image = convertToTensor(image2, "image", "flipLeftRight", "float32");
      assert($image.rank === 4, function() {
        return "Error in flipLeftRight: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      var inputs = { image: $image };
      var res = ENGINE.runKernel(FlipLeftRight, inputs, {});
      return res;
    }
    var flipLeftRight = /* @__PURE__ */ op({ flipLeftRight_ });
    function grayscaleToRGB_(image2) {
      var $image = convertToTensor(image2, "image", "grayscaleToRGB");
      var lastDimsIdx = $image.rank - 1;
      var lastDims = $image.shape[lastDimsIdx];
      assert($image.rank >= 2, function() {
        return "Error in grayscaleToRGB: images must be at least rank 2, " + "but got rank ".concat($image.rank, ".");
      });
      assert(lastDims === 1, function() {
        return "Error in grayscaleToRGB: last dimension of a grayscale image " + "should be size 1, but got size ".concat(lastDims, ".");
      });
      var reps = new Array($image.rank);
      reps.fill(1, 0, lastDimsIdx);
      reps[lastDimsIdx] = 3;
      return tile($image, reps);
    }
    var grayscaleToRGB = /* @__PURE__ */ op({ grayscaleToRGB_ });
    function rgbToGrayscale_(image2) {
      var $image = convertToTensor(image2, "image", "RGBToGrayscale");
      var lastDimsIdx = $image.rank - 1;
      var lastDims = $image.shape[lastDimsIdx];
      assert($image.rank >= 2, function() {
        return "Error in RGBToGrayscale: images must be at least rank 2, " + "but got rank ".concat($image.rank, ".");
      });
      assert(lastDims === 3, function() {
        return "Error in RGBToGrayscale: last dimension of an RGB image " + "should be size 3, but got size ".concat(lastDims, ".");
      });
      var origDtype = $image.dtype;
      var fltImage = cast($image, "float32");
      var rgbWeights = tensor1d([0.2989, 0.587, 0.114]);
      var grayFloat;
      switch ($image.rank) {
        case 2:
          grayFloat = einsum("ij,j->i", fltImage, rgbWeights);
          break;
        case 3:
          grayFloat = einsum("ijk,k->ij", fltImage, rgbWeights);
          break;
        case 4:
          grayFloat = einsum("ijkl,l->ijk", fltImage, rgbWeights);
          break;
        case 5:
          grayFloat = einsum("ijklm,m->ijkl", fltImage, rgbWeights);
          break;
        case 6:
          grayFloat = einsum("ijklmn,n->ijklm", fltImage, rgbWeights);
          break;
        default:
          throw new Error("Not a valid tensor rank.");
      }
      grayFloat = expandDims(grayFloat, -1);
      return cast(grayFloat, origDtype);
    }
    var rgbToGrayscale = /* @__PURE__ */ op({ rgbToGrayscale_ });
    function rotateWithOffset_(image2, radians, fillValue, center) {
      if (fillValue === void 0) {
        fillValue = 0;
      }
      if (center === void 0) {
        center = 0.5;
      }
      var $image = convertToTensor(image2, "image", "rotateWithOffset", "float32");
      assert($image.rank === 4, function() {
        return "Error in rotateWithOffset: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      var inputs = { image: $image };
      var attrs = { radians, fillValue, center };
      var res = ENGINE.runKernel(RotateWithOffset, inputs, attrs);
      return res;
    }
    var rotateWithOffset = /* @__PURE__ */ op({ rotateWithOffset_ });
    function nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      if (iouThreshold == null) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold == null) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (softNmsSigma == null) {
        softNmsSigma = 0;
      }
      var numBoxes = boxes.shape[0];
      maxOutputSize = Math.min(maxOutputSize, numBoxes);
      assert(0 <= iouThreshold && iouThreshold <= 1, function() {
        return "iouThreshold must be in [0, 1], but was '".concat(iouThreshold, "'");
      });
      assert(boxes.rank === 2, function() {
        return "boxes must be a 2D tensor, but was of rank '".concat(boxes.rank, "'");
      });
      assert(boxes.shape[1] === 4, function() {
        return "boxes must have 4 columns, but 2nd dimension was ".concat(boxes.shape[1]);
      });
      assert(scores.rank === 1, function() {
        return "scores must be a 1D tensor";
      });
      assert(scores.shape[0] === numBoxes, function() {
        return "scores has incompatible shape with boxes. Expected ".concat(numBoxes, ", ") + "but was ".concat(scores.shape[0]);
      });
      assert(0 <= softNmsSigma && softNmsSigma <= 1, function() {
        return "softNmsSigma must be in [0, 1], but was '".concat(softNmsSigma, "'");
      });
      return { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
    }
    function nonMaxSuppression_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      var $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression", "float32");
      var $scores = convertToTensor(scores, "scores", "nonMaxSuppression", "float32");
      var inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
      maxOutputSize = inputs.maxOutputSize;
      iouThreshold = inputs.iouThreshold;
      scoreThreshold = inputs.scoreThreshold;
      var attrs = { maxOutputSize, iouThreshold, scoreThreshold };
      return ENGINE.runKernel(NonMaxSuppressionV3, { boxes: $boxes, scores: $scores }, attrs);
    }
    var nonMaxSuppression = /* @__PURE__ */ op({ nonMaxSuppression_ });
    function binaryInsert(arr, element, comparator) {
      var index = binarySearch(arr, element, comparator);
      var insertionPoint = index < 0 ? -(index + 1) : index;
      arr.splice(insertionPoint, 0, element);
    }
    function binarySearch(arr, target, comparator) {
      return binarySearch_(arr, target, comparator || defaultComparator);
    }
    function defaultComparator(a, b) {
      return a > b ? 1 : a < b ? -1 : 0;
    }
    function binarySearch_(arr, target, comparator) {
      var left = 0;
      var right = arr.length;
      var middle = 0;
      var found = false;
      while (left < right) {
        middle = left + (right - left >>> 1);
        var compareResult = comparator(target, arr[middle]);
        if (compareResult > 0) {
          left = middle + 1;
        } else {
          right = middle;
          found = !compareResult;
        }
      }
      return found ? left : -left - 1;
    }
    function nonMaxSuppressionV3Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
      return nonMaxSuppressionImpl_(
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        0
        /* softNmsSigma */
      );
    }
    function nonMaxSuppressionV4Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
      return nonMaxSuppressionImpl_(
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        0,
        false,
        padToMaxOutputSize,
        true
        /* returnValidOutputs */
      );
    }
    function nonMaxSuppressionV5Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      return nonMaxSuppressionImpl_(
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        softNmsSigma,
        true
        /* returnScoresTensor */
      );
    }
    function nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor, padToMaxOutputSize, returnValidOutputs) {
      if (returnScoresTensor === void 0) {
        returnScoresTensor = false;
      }
      if (padToMaxOutputSize === void 0) {
        padToMaxOutputSize = false;
      }
      if (returnValidOutputs === void 0) {
        returnValidOutputs = false;
      }
      var candidates = [];
      for (var i = 0; i < scores.length; i++) {
        if (scores[i] > scoreThreshold) {
          candidates.push({ score: scores[i], boxIndex: i, suppressBeginIndex: 0 });
        }
      }
      candidates.sort(ascendingComparator);
      var scale = softNmsSigma > 0 ? -0.5 / softNmsSigma : 0;
      var selectedIndices = [];
      var selectedScores = [];
      while (selectedIndices.length < maxOutputSize && candidates.length > 0) {
        var candidate = candidates.pop();
        var originalScore = candidate.score, boxIndex = candidate.boxIndex, suppressBeginIndex = candidate.suppressBeginIndex;
        if (originalScore < scoreThreshold) {
          break;
        }
        var ignoreCandidate = false;
        for (var j = selectedIndices.length - 1; j >= suppressBeginIndex; --j) {
          var iou = intersectionOverUnion(boxes, boxIndex, selectedIndices[j]);
          if (iou >= iouThreshold) {
            ignoreCandidate = true;
            break;
          }
          candidate.score = candidate.score * suppressWeight(iouThreshold, scale, iou);
          if (candidate.score <= scoreThreshold) {
            break;
          }
        }
        candidate.suppressBeginIndex = selectedIndices.length;
        if (!ignoreCandidate) {
          if (candidate.score === originalScore) {
            selectedIndices.push(boxIndex);
            selectedScores.push(candidate.score);
          } else if (candidate.score > scoreThreshold) {
            binaryInsert(candidates, candidate, ascendingComparator);
          }
        }
      }
      var validOutputs = selectedIndices.length;
      var elemsToPad = maxOutputSize - validOutputs;
      if (padToMaxOutputSize && elemsToPad > 0) {
        selectedIndices.push.apply(selectedIndices, __spreadArray([], __read(new Array(elemsToPad).fill(0)), false));
        selectedScores.push.apply(selectedScores, __spreadArray([], __read(new Array(elemsToPad).fill(0)), false));
      }
      var result = { selectedIndices };
      if (returnScoresTensor) {
        result["selectedScores"] = selectedScores;
      }
      if (returnValidOutputs) {
        result["validOutputs"] = validOutputs;
      }
      return result;
    }
    function intersectionOverUnion(boxes, i, j) {
      var iCoord = boxes.subarray(i * 4, i * 4 + 4);
      var jCoord = boxes.subarray(j * 4, j * 4 + 4);
      var yminI = Math.min(iCoord[0], iCoord[2]);
      var xminI = Math.min(iCoord[1], iCoord[3]);
      var ymaxI = Math.max(iCoord[0], iCoord[2]);
      var xmaxI = Math.max(iCoord[1], iCoord[3]);
      var yminJ = Math.min(jCoord[0], jCoord[2]);
      var xminJ = Math.min(jCoord[1], jCoord[3]);
      var ymaxJ = Math.max(jCoord[0], jCoord[2]);
      var xmaxJ = Math.max(jCoord[1], jCoord[3]);
      var areaI = (ymaxI - yminI) * (xmaxI - xminI);
      var areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);
      if (areaI <= 0 || areaJ <= 0) {
        return 0;
      }
      var intersectionYmin = Math.max(yminI, yminJ);
      var intersectionXmin = Math.max(xminI, xminJ);
      var intersectionYmax = Math.min(ymaxI, ymaxJ);
      var intersectionXmax = Math.min(xmaxI, xmaxJ);
      var intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0) * Math.max(intersectionXmax - intersectionXmin, 0);
      return intersectionArea / (areaI + areaJ - intersectionArea);
    }
    function suppressWeight(iouThreshold, scale, iou) {
      var weight = Math.exp(scale * iou * iou);
      return iou <= iouThreshold ? weight : 0;
    }
    function ascendingComparator(c1, c2) {
      return c1.score - c2.score || c1.score === c2.score && c2.boxIndex - c1.boxIndex;
    }
    function nonMaxSuppressionAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $boxes, $scores, inputs, boxesAndScores, boxesVals, scoresVals, selectedIndices;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
              $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
              inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
              maxOutputSize = inputs.maxOutputSize;
              iouThreshold = inputs.iouThreshold;
              scoreThreshold = inputs.scoreThreshold;
              return [4, Promise.all([$boxes.data(), $scores.data()])];
            case 1:
              boxesAndScores = _a.sent();
              boxesVals = boxesAndScores[0];
              scoresVals = boxesAndScores[1];
              selectedIndices = nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold).selectedIndices;
              if ($boxes !== boxes) {
                $boxes.dispose();
              }
              if ($scores !== scores) {
                $scores.dispose();
              }
              return [2, tensor1d(selectedIndices, "int32")];
          }
        });
      });
    }
    var nonMaxSuppressionAsync = nonMaxSuppressionAsync_;
    function nonMaxSuppressionWithScore_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (softNmsSigma === void 0) {
        softNmsSigma = 0;
      }
      var $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
      var $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
      var params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
      maxOutputSize = params.maxOutputSize;
      iouThreshold = params.iouThreshold;
      scoreThreshold = params.scoreThreshold;
      softNmsSigma = params.softNmsSigma;
      var inputs = { boxes: $boxes, scores: $scores };
      var attrs = { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
      var result = ENGINE.runKernel(NonMaxSuppressionV5, inputs, attrs);
      return { selectedIndices: result[0], selectedScores: result[1] };
    }
    var nonMaxSuppressionWithScore = /* @__PURE__ */ op({ nonMaxSuppressionWithScore_ });
    function nonMaxSuppressionWithScoreAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (softNmsSigma === void 0) {
        softNmsSigma = 0;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $boxes, $scores, params, boxesAndScores, boxesVals, scoresVals, _a, selectedIndices, selectedScores;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
              $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
              params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
              maxOutputSize = params.maxOutputSize;
              iouThreshold = params.iouThreshold;
              scoreThreshold = params.scoreThreshold;
              softNmsSigma = params.softNmsSigma;
              return [4, Promise.all([$boxes.data(), $scores.data()])];
            case 1:
              boxesAndScores = _b.sent();
              boxesVals = boxesAndScores[0];
              scoresVals = boxesAndScores[1];
              _a = nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma), selectedIndices = _a.selectedIndices, selectedScores = _a.selectedScores;
              if ($boxes !== boxes) {
                $boxes.dispose();
              }
              if ($scores !== scores) {
                $scores.dispose();
              }
              return [2, {
                selectedIndices: tensor1d(selectedIndices, "int32"),
                selectedScores: tensor1d(selectedScores)
              }];
          }
        });
      });
    }
    var nonMaxSuppressionWithScoreAsync = nonMaxSuppressionWithScoreAsync_;
    function nonMaxSuppressionPadded_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (padToMaxOutputSize === void 0) {
        padToMaxOutputSize = false;
      }
      var $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
      var $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
      var params = nonMaxSuppSanityCheck(
        $boxes,
        $scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        null
        /* softNmsSigma */
      );
      var $maxOutputSize = params.maxOutputSize;
      var $iouThreshold = params.iouThreshold;
      var $scoreThreshold = params.scoreThreshold;
      var inputs = { boxes: $boxes, scores: $scores };
      var attrs = {
        maxOutputSize: $maxOutputSize,
        iouThreshold: $iouThreshold,
        scoreThreshold: $scoreThreshold,
        padToMaxOutputSize
      };
      var result = ENGINE.runKernel(NonMaxSuppressionV4, inputs, attrs);
      return { selectedIndices: result[0], validOutputs: result[1] };
    }
    var nonMaxSuppressionPadded = /* @__PURE__ */ op({ nonMaxSuppressionPadded_ });
    function nonMaxSuppressionPaddedAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (padToMaxOutputSize === void 0) {
        padToMaxOutputSize = false;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $boxes, $scores, params, $maxOutputSize, $iouThreshold, $scoreThreshold, _a, boxesVals, scoresVals, _b, selectedIndices, validOutputs;
        return __generator(this, function(_c) {
          switch (_c.label) {
            case 0:
              $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
              $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
              params = nonMaxSuppSanityCheck(
                $boxes,
                $scores,
                maxOutputSize,
                iouThreshold,
                scoreThreshold,
                null
                /* softNmsSigma */
              );
              $maxOutputSize = params.maxOutputSize;
              $iouThreshold = params.iouThreshold;
              $scoreThreshold = params.scoreThreshold;
              return [4, Promise.all([$boxes.data(), $scores.data()])];
            case 1:
              _a = __read.apply(void 0, [_c.sent(), 2]), boxesVals = _a[0], scoresVals = _a[1];
              _b = nonMaxSuppressionV4Impl(boxesVals, scoresVals, $maxOutputSize, $iouThreshold, $scoreThreshold, padToMaxOutputSize), selectedIndices = _b.selectedIndices, validOutputs = _b.validOutputs;
              if ($boxes !== boxes) {
                $boxes.dispose();
              }
              if ($scores !== scores) {
                $scores.dispose();
              }
              return [2, {
                selectedIndices: tensor1d(selectedIndices, "int32"),
                validOutputs: scalar(validOutputs, "int32")
              }];
          }
        });
      });
    }
    var nonMaxSuppressionPaddedAsync = nonMaxSuppressionPaddedAsync_;
    function resizeBilinear_(images, size, alignCorners, halfPixelCenters) {
      if (alignCorners === void 0) {
        alignCorners = false;
      }
      if (halfPixelCenters === void 0) {
        halfPixelCenters = false;
      }
      var $images = convertToTensor(images, "images", "resizeBilinear");
      assert($images.rank === 3 || $images.rank === 4, function() {
        return "Error in resizeBilinear: x must be rank 3 or 4, but got " + "rank ".concat($images.rank, ".");
      });
      assert(size.length === 2, function() {
        return "Error in resizeBilinear: new shape must 2D, but got shape " + "".concat(size, ".");
      });
      assert(halfPixelCenters === false || alignCorners === false, function() {
        return "Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.";
      });
      var batchImages = $images;
      var reshapedTo4D = false;
      if ($images.rank === 3) {
        reshapedTo4D = true;
        batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
      }
      __read(size, 0);
      var inputs = { images: batchImages };
      var attrs = { alignCorners, halfPixelCenters, size };
      var res = ENGINE.runKernel(ResizeBilinear, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var resizeBilinear = /* @__PURE__ */ op({ resizeBilinear_ });
    function resizeNearestNeighbor_(images, size, alignCorners, halfPixelCenters) {
      if (alignCorners === void 0) {
        alignCorners = false;
      }
      if (halfPixelCenters === void 0) {
        halfPixelCenters = false;
      }
      var $images = convertToTensor(images, "images", "resizeNearestNeighbor");
      assert($images.rank === 3 || $images.rank === 4, function() {
        return "Error in resizeNearestNeighbor: x must be rank 3 or 4, but got " + "rank ".concat($images.rank, ".");
      });
      assert(size.length === 2, function() {
        return "Error in resizeNearestNeighbor: new shape must 2D, but got shape " + "".concat(size, ".");
      });
      assert($images.dtype === "float32" || $images.dtype === "int32", function() {
        return "`images` must have `int32` or `float32` as dtype";
      });
      assert(halfPixelCenters === false || alignCorners === false, function() {
        return "Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.";
      });
      var batchImages = $images;
      var reshapedTo4D = false;
      if ($images.rank === 3) {
        reshapedTo4D = true;
        batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
      }
      __read(size, 0);
      var inputs = { images: batchImages };
      var attrs = { alignCorners, halfPixelCenters, size };
      var res = ENGINE.runKernel(ResizeNearestNeighbor, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var resizeNearestNeighbor = /* @__PURE__ */ op({ resizeNearestNeighbor_ });
    function threshold_(image2, method, inverted, threshValue) {
      var _a;
      if (method === void 0) {
        method = "binary";
      }
      if (inverted === void 0) {
        inverted = false;
      }
      if (threshValue === void 0) {
        threshValue = 0.5;
      }
      var $image = convertToTensor(image2, "image", "threshold");
      var RED_INTENCITY_COEF = 0.2989;
      var GREEN_INTENCITY_COEF = 0.587;
      var BLUE_INTENCITY_COEF = 0.114;
      var totalPixelsInImage = $image.shape[0] * $image.shape[1];
      var $threshold = mul(tensor1d([threshValue]), 255);
      var r, g, b, grayscale;
      assert($image.rank === 3, function() {
        return "Error in threshold: image must be rank 3," + "but got rank ".concat($image.rank, ".");
      });
      assert($image.shape[2] === 3 || $image.shape[2] === 1, function() {
        return "Error in threshold: image color channel must be equal to 3 or 1" + "but got ".concat($image.shape[2], ".");
      });
      assert($image.dtype === "int32" || $image.dtype === "float32", function() {
        return "Error in dtype: image dtype must be int32 or float32," + "but got dtype ".concat($image.dtype, ".");
      });
      assert(method === "otsu" || method === "binary", function() {
        return "Method must be binary or otsu, but was ".concat(method);
      });
      if ($image.shape[2] === 3) {
        _a = __read(split$1($image, [1, 1, 1], -1), 3), r = _a[0], g = _a[1], b = _a[2];
        var $r = mul(r, RED_INTENCITY_COEF);
        var $g = mul(g, GREEN_INTENCITY_COEF);
        var $b = mul(b, BLUE_INTENCITY_COEF);
        grayscale = add(add($r, $g), $b);
      } else {
        grayscale = image2;
      }
      if (method === "otsu") {
        var $histogram = bincount(cast(round(grayscale), "int32"), tensor([]), 256);
        $threshold = otsu($histogram, totalPixelsInImage);
      }
      var invCondition = inverted ? lessEqual(grayscale, $threshold) : greater(grayscale, $threshold);
      var result = cast(mul(invCondition, 255), "int32");
      return result;
    }
    function otsu(histogram, total) {
      var bestThresh = tensor1d([-1]);
      var bestInBetVar = tensor1d([0]);
      var cInBetVar = tensor1d([0]);
      var classFirst, classSecond, meanFirst, meanSec, weightForeground, weightBack;
      for (var index = 0; index < histogram.size - 1; index++) {
        classFirst = slice(histogram, 0, index + 1);
        classSecond = slice(histogram, index + 1);
        weightForeground = div(sum(classFirst), total);
        weightBack = div(sum(classSecond), total);
        var meanFirstDivA = sum(mul(classFirst, range(0, classFirst.size)));
        meanFirst = div(meanFirstDivA, sum(classFirst));
        var meanSecFill = fill(classSecond.shape, classFirst.size);
        var meanSecAdd = add(range(0, classSecond.size), meanSecFill);
        var meanSecMul = mul(classSecond, meanSecAdd);
        meanSec = div(sum(meanSecMul), sum(classSecond));
        var cInBetVarSubA = sub(meanFirst, meanSec);
        var cInBetVarSubB = sub(meanFirst, meanSec);
        var cInBetVarMul = mul(weightForeground, weightBack);
        cInBetVar = mul(mul(cInBetVarMul, cInBetVarSubA), cInBetVarSubB);
        var condition = greater(cInBetVar, bestInBetVar);
        bestInBetVar = where(condition, cInBetVar, bestInBetVar);
        bestThresh = where(condition, tensor1d([index]), bestThresh);
      }
      return bestThresh;
    }
    var threshold = /* @__PURE__ */ op({ threshold_ });
    function transform_(image2, transforms, interpolation, fillMode, fillValue, outputShape) {
      if (interpolation === void 0) {
        interpolation = "nearest";
      }
      if (fillMode === void 0) {
        fillMode = "constant";
      }
      if (fillValue === void 0) {
        fillValue = 0;
      }
      var $image = convertToTensor(image2, "image", "transform", "float32");
      var $transforms = convertToTensor(transforms, "transforms", "transform", "float32");
      assert($image.rank === 4, function() {
        return "Error in transform: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      assert($transforms.rank === 2 && ($transforms.shape[0] === $image.shape[0] || $transforms.shape[0] === 1) && $transforms.shape[1] === 8, function() {
        return "Error in transform: Input transform should be batch x 8 or 1 x 8";
      });
      assert(outputShape == null || outputShape.length === 2, function() {
        return "Error in transform: outputShape must be [height, width] or null, " + "but got ".concat(outputShape, ".");
      });
      var inputs = { image: $image, transforms: $transforms };
      var attrs = { interpolation, fillMode, fillValue, outputShape };
      return ENGINE.runKernel(Transform, inputs, attrs);
    }
    var transform = /* @__PURE__ */ op({ transform_ });
    function bandPart_(a, numLower, numUpper) {
      var $a = convertToTensor(a, "a", "bandPart");
      assert($a.rank >= 2, function() {
        return "bandPart(): Rank must be at least 2, got ".concat($a.rank, ".");
      });
      var shape = $a.shape;
      var _a = __read($a.shape.slice(-2), 2), M = _a[0], N = _a[1];
      var $numLower;
      var $numUpper;
      if (typeof numLower === "number") {
        assert(numLower % 1 === 0, function() {
          return "bandPart(): numLower must be an integer, got ".concat(numLower, ".");
        });
        assert(numLower <= M, function() {
          return "bandPart(): numLower (".concat(numLower, ")") + " must not be greater than the number of rows (".concat(M, ").");
        });
        $numLower = convertToTensor(numLower < 0 ? M : numLower, "numLower", "bandPart");
      } else {
        assert(numLower.dtype === "int32", function() {
          return "bandPart(): numLower's dtype must be an int32.";
        });
        $numLower = where(less(numLower, 0), M, minimum(numLower, M));
      }
      if (typeof numUpper === "number") {
        assert(numUpper % 1 === 0, function() {
          return "bandPart(): numUpper must be an integer, got ".concat(numUpper, ".");
        });
        assert(numUpper <= N, function() {
          return "bandPart(): numUpper (".concat(numUpper, ")") + " must not be greater than the number of columns (".concat(N, ").");
        });
        $numUpper = convertToTensor(numUpper < 0 ? N : numUpper, "numUpper", "bandPart");
      } else {
        assert(numUpper.dtype === "int32", function() {
          return "bandPart(): numUpper's dtype must be an int32.";
        });
        $numUpper = where(less(numUpper, 0), N, minimum(numUpper, N));
      }
      var i = reshape(range(0, M, 1, "int32"), [-1, 1]);
      var j = range(0, N, 1, "int32");
      var ij = sub(i, j);
      var inBand = logicalAnd(lessEqual(ij, $numLower), greaterEqual(ij, neg($numUpper)));
      var zero = zeros([M, N], $a.dtype);
      return reshape(stack(unstack(reshape($a, [-1, M, N])).map(function(mat) {
        return where(inBand, mat, zero);
      })), shape);
    }
    var bandPart = /* @__PURE__ */ op({ bandPart_ });
    function gramSchmidt_(xs) {
      var inputIsTensor2D;
      if (Array.isArray(xs)) {
        inputIsTensor2D = false;
        assert(xs != null && xs.length > 0, function() {
          return "Gram-Schmidt process: input must not be null, undefined, or empty";
        });
        var dim_1 = xs[0].shape[0];
        var _loop_1 = function(i2) {
          assert(xs[i2].shape[0] === dim_1, function() {
            return "Gram-Schmidt: Non-unique lengths found in the input vectors: " + "(".concat(xs[i2].shape[0], " vs. ").concat(dim_1, ")");
          });
        };
        for (var i = 1; i < xs.length; ++i) {
          _loop_1(i);
        }
      } else {
        inputIsTensor2D = true;
        xs = split$1(xs, xs.shape[0], 0).map(function(x) {
          return squeeze(x, [0]);
        });
      }
      assert(xs.length <= xs[0].shape[0], function() {
        return "Gram-Schmidt: Number of vectors (".concat(xs.length, ") exceeds ") + "number of dimensions (".concat(xs[0].shape[0], ").");
      });
      var ys = [];
      var xs1d = xs;
      var _loop_2 = function(i2) {
        ys.push(ENGINE.tidy(function() {
          var x = xs1d[i2];
          if (i2 > 0) {
            for (var j = 0; j < i2; ++j) {
              var proj = mul(sum(mul(ys[j], x)), ys[j]);
              x = sub(x, proj);
            }
          }
          return div(x, norm(x, "euclidean"));
        }));
      };
      for (var i = 0; i < xs.length; ++i) {
        _loop_2(i);
      }
      if (inputIsTensor2D) {
        return stack(ys, 0);
      } else {
        return ys;
      }
    }
    var gramSchmidt = /* @__PURE__ */ op({ gramSchmidt_ });
    function qr_(x, fullMatrices) {
      if (fullMatrices === void 0) {
        fullMatrices = false;
      }
      assert(x.rank >= 2, function() {
        return "qr() requires input tensor to have a rank >= 2, but got rank ".concat(x.rank);
      });
      if (x.rank === 2) {
        return qr2d(x, fullMatrices);
      } else {
        var outerDimsProd = x.shape.slice(0, x.shape.length - 2).reduce(function(value, prev) {
          return value * prev;
        });
        var x2ds = unstack(reshape(x, [
          outerDimsProd,
          x.shape[x.shape.length - 2],
          x.shape[x.shape.length - 1]
        ]), 0);
        var q2ds_1 = [];
        var r2ds_1 = [];
        x2ds.forEach(function(x2d) {
          var _a = __read(qr2d(x2d, fullMatrices), 2), q2d = _a[0], r2d = _a[1];
          q2ds_1.push(q2d);
          r2ds_1.push(r2d);
        });
        var q = reshape(stack(q2ds_1, 0), x.shape);
        var r = reshape(stack(r2ds_1, 0), x.shape);
        return [q, r];
      }
    }
    function qr2d(x, fullMatrices) {
      if (fullMatrices === void 0) {
        fullMatrices = false;
      }
      return ENGINE.tidy(function() {
        assert(x.shape.length === 2, function() {
          return "qr2d() requires a 2D Tensor, but got a ".concat(x.shape.length, "D Tensor.");
        });
        var m = x.shape[0];
        var n = x.shape[1];
        var q = eye(m);
        var r = clone(x);
        var one2D = tensor2d([[1]], [1, 1]);
        var w = clone(one2D);
        var iters = m >= n ? n : m;
        var _loop_1 = function(j2) {
          var _a;
          var rTemp = r;
          var wTemp = w;
          var qTemp = q;
          _a = __read(ENGINE.tidy(function() {
            var rjEnd1 = slice(r, [j2, j2], [m - j2, 1]);
            var normX = norm(rjEnd1);
            var rjj = slice(r, [j2, j2], [1, 1]);
            var s = where(greater(rjj, 0), tensor2d([[-1]]), tensor2d([[1]]));
            var u1 = sub(rjj, mul(s, normX));
            var wPre = div(rjEnd1, u1);
            if (wPre.shape[0] === 1) {
              w = clone(one2D);
            } else {
              w = concat([
                one2D,
                slice(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]])
              ], 0);
            }
            var tau = neg(div(matMul$1(s, u1), normX));
            var rjEndAll = slice(r, [j2, 0], [m - j2, n]);
            var tauTimesW = mul(tau, w);
            var wT = transpose(w);
            if (j2 === 0) {
              r = sub(rjEndAll, matMul$1(tauTimesW, matMul$1(wT, rjEndAll)));
            } else {
              var rTimesTau = sub(rjEndAll, matMul$1(tauTimesW, matMul$1(wT, rjEndAll)));
              r = concat([slice(r, [0, 0], [j2, n]), rTimesTau], 0);
            }
            var tawTimesWT = transpose(tauTimesW);
            var qAllJEnd = slice(q, [0, j2], [m, q.shape[1] - j2]);
            if (j2 === 0) {
              q = sub(qAllJEnd, matMul$1(matMul$1(qAllJEnd, w), tawTimesWT));
            } else {
              var qTimesTau = sub(qAllJEnd, matMul$1(matMul$1(qAllJEnd, w), tawTimesWT));
              q = concat([slice(q, [0, 0], [m, j2]), qTimesTau], 1);
            }
            return [w, r, q];
          }), 3), w = _a[0], r = _a[1], q = _a[2];
          dispose([rTemp, wTemp, qTemp]);
        };
        for (var j = 0; j < iters; ++j) {
          _loop_1(j);
        }
        if (!fullMatrices && m > n) {
          q = slice(q, [0, 0], [m, n]);
          r = slice(r, [0, 0], [n, n]);
        }
        return [q, r];
      });
    }
    var qr = /* @__PURE__ */ op({ qr_ });
    var Reduction;
    (function(Reduction2) {
      Reduction2[Reduction2["NONE"] = 0] = "NONE";
      Reduction2[Reduction2["MEAN"] = 1] = "MEAN";
      Reduction2[Reduction2["SUM"] = 2] = "SUM";
      Reduction2[Reduction2["SUM_BY_NONZERO_WEIGHTS"] = 3] = "SUM_BY_NONZERO_WEIGHTS";
    })(Reduction || (Reduction = {}));
    function computeWeightedLoss_(losses2, weights, reduction2) {
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $losses = convertToTensor(losses2, "losses", "computeWeightedLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "computeWeightedLoss");
      }
      var weightedLoss = $weights == null ? $losses : mul($losses, $weights);
      if (reduction2 === Reduction.NONE) {
        return weightedLoss;
      }
      if (reduction2 === Reduction.SUM) {
        return sum(weightedLoss);
      }
      if (reduction2 === Reduction.MEAN) {
        if ($weights == null) {
          return mean(weightedLoss);
        } else {
          var broadcastFactor = $losses.size / $weights.size;
          var result = div(sum(weightedLoss), sum($weights));
          return broadcastFactor > 1 ? div(result, scalar(broadcastFactor)) : result;
        }
      }
      if (reduction2 === Reduction.SUM_BY_NONZERO_WEIGHTS) {
        if ($weights == null) {
          return div(sum(weightedLoss), scalar($losses.size));
        } else {
          var broadcastedWeights = mul($weights, ones($losses.shape));
          var numNonZeros = cast(sum(notEqual(broadcastedWeights, scalar(0))), "float32");
          return div(sum(weightedLoss), numNonZeros);
        }
      }
      throw Error("Unknown reduction: ".concat(reduction2));
    }
    var computeWeightedLoss = /* @__PURE__ */ op({ computeWeightedLoss_ });
    function absoluteDifference_(labels, predictions, weights, reduction2) {
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "absoluteDifference");
      var $predictions = convertToTensor(predictions, "predictions", "absoluteDifference");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "absoluteDifference");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in absoluteDifference: ");
      var losses2 = abs(sub($labels, $predictions));
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var absoluteDifference = /* @__PURE__ */ op({ absoluteDifference_ });
    function cosineDistance_(labels, predictions, axis, weights, reduction2) {
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "cosineDistance");
      var $predictions = convertToTensor(predictions, "predictions", "cosineDistance");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "cosineDistance");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in cosineDistance: ");
      var one = scalar(1);
      var losses2 = sub(one, sum(mul($labels, $predictions), axis, true));
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var cosineDistance = /* @__PURE__ */ op({ cosineDistance_ });
    function hingeLoss_(labels, predictions, weights, reduction2) {
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "hingeLoss");
      var $predictions = convertToTensor(predictions, "predictions", "hingeLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "hingeLoss");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in hingeLoss: ");
      var one = scalar(1);
      $labels = sub(mul(scalar(2), $labels), one);
      var losses2 = relu(sub(one, mul($labels, $predictions)));
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var hingeLoss = /* @__PURE__ */ op({ hingeLoss_ });
    function huberLoss_(labels, predictions, weights, delta, reduction2) {
      if (delta === void 0) {
        delta = 1;
      }
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "huberLoss");
      var $predictions = convertToTensor(predictions, "predictions", "huberLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "huberLoss");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in huberLoss: ");
      var deltaScalar = scalar(delta);
      var error = abs(sub($predictions, $labels));
      var quadratic = minimum(error, deltaScalar);
      var linear = sub(error, quadratic);
      var losses2 = add(mul(scalar(0.5), square(quadratic)), mul(deltaScalar, linear));
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var huberLoss = /* @__PURE__ */ op({ huberLoss_ });
    function logLoss_(labels, predictions, weights, epsilon, reduction2) {
      if (epsilon === void 0) {
        epsilon = 1e-7;
      }
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "logLoss");
      var $predictions = convertToTensor(predictions, "predictions", "logLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "logLoss");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in logLoss: ");
      var one = scalar(1);
      var epsilonScalar = scalar(epsilon);
      var l1 = neg(mul($labels, log(add($predictions, epsilonScalar))));
      var l2 = mul(sub(one, $labels), log(add(sub(one, $predictions), epsilonScalar)));
      var losses2 = sub(l1, l2);
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var logLoss = /* @__PURE__ */ op({ logLoss_ });
    function meanSquaredError_(labels, predictions, weights, reduction2) {
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "meanSquaredError");
      var $predictions = convertToTensor(predictions, "predictions", "meanSquaredError");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "meanSquaredError");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in meanSquaredError: ");
      var losses2 = squaredDifference($labels, $predictions);
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var meanSquaredError = /* @__PURE__ */ op({ meanSquaredError_ });
    function sigmoidCrossEntropyWithLogits_(labels, logits) {
      var $labels = convertToTensor(labels, "labels", "sigmoidCrossEntropyWithLogits");
      var $logits = convertToTensor(logits, "logits", "sigmoidCrossEntropyWithLogits");
      assertShapesMatch($labels.shape, $logits.shape, "Error in sigmoidCrossEntropyWithLogits: ");
      var maxOutput = relu($logits);
      var outputXTarget = mul($logits, $labels);
      var sigmoidOutput = log1p(exp(neg(abs($logits))));
      return add(sub(maxOutput, outputXTarget), sigmoidOutput);
    }
    function sigmoidCrossEntropy_(multiClassLabels, logits, weights, labelSmoothing, reduction2) {
      if (labelSmoothing === void 0) {
        labelSmoothing = 0;
      }
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $multiClassLabels = convertToTensor(multiClassLabels, "multiClassLabels", "sigmoidCrossEntropy");
      var $logits = convertToTensor(logits, "logits", "sigmoidCrossEntropy");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "sigmoidCrossEntropy");
      }
      assertShapesMatch($multiClassLabels.shape, $logits.shape, "Error in sigmoidCrossEntropy: ");
      if (labelSmoothing > 0) {
        var labelSmoothingScalar = scalar(labelSmoothing);
        var one = scalar(1);
        var half = scalar(0.5);
        $multiClassLabels = add(mul($multiClassLabels, sub(one, labelSmoothingScalar)), mul(half, labelSmoothingScalar));
      }
      var losses2 = sigmoidCrossEntropyWithLogits_($multiClassLabels, $logits);
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var sigmoidCrossEntropy = /* @__PURE__ */ op({ sigmoidCrossEntropy_ });
    function softmaxCrossEntropyWithLogits_(labels, logits, dim) {
      if (dim === void 0) {
        dim = -1;
      }
      if (dim === -1) {
        dim = logits.rank - 1;
      }
      if (dim !== logits.rank - 1) {
        throw Error("Softmax cross entropy along a non-last dimension is not yet " + "supported. Labels / logits was rank ".concat(logits.rank, " ") + "and dim was ".concat(dim));
      }
      var customOp = customGrad(function(labels2, logits2, save) {
        var keepDims = true;
        var lse = logSumExp(logits2, [dim], keepDims);
        var logResult = sub(cast(logits2, "float32"), lse);
        save([labels2, logResult]);
        var costVector = neg(mul(logResult, labels2));
        var value = sum(costVector, [dim]);
        var gradFunc = function(dy, saved) {
          var _a = __read(saved, 2), labels3 = _a[0], logResult2 = _a[1];
          var dyShape = expandShapeToKeepDim(dy.shape, [dim]);
          return [
            mul(reshape(dy, dyShape), sub(cast(labels3, "float32"), exp(logResult2))),
            mul(reshape(dy, dyShape), sub(exp(logResult2), cast(labels3, "float32")))
          ];
        };
        return { value, gradFunc };
      });
      return customOp(labels, logits);
    }
    function softmaxCrossEntropy_(onehotLabels, logits, weights, labelSmoothing, reduction2) {
      if (labelSmoothing === void 0) {
        labelSmoothing = 0;
      }
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $onehotLabels = convertToTensor(onehotLabels, "onehotLabels", "softmaxCrossEntropy");
      var $logits = convertToTensor(logits, "logits", "softmaxCrossEntropy");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "softmaxCrossEntropy");
      }
      assertShapesMatch($onehotLabels.shape, $logits.shape, "Error in softmaxCrossEntropy: ");
      if (labelSmoothing > 0) {
        var labelSmoothingScalar = scalar(labelSmoothing);
        var one = scalar(1);
        var numClasses = scalar($onehotLabels.shape[1]);
        $onehotLabels = add(mul($onehotLabels, sub(one, labelSmoothingScalar)), div(labelSmoothingScalar, numClasses));
      }
      var losses2 = softmaxCrossEntropyWithLogits_($onehotLabels, $logits);
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var softmaxCrossEntropy = /* @__PURE__ */ op({ softmaxCrossEntropy_ });
    function sparseFillEmptyRows_(indices, values, denseShape, defaultValue) {
      var $indices = convertToTensor(indices, "indices", "sparseFillEmptyRows", "int32");
      var $values = convertToTensor(values, "values", "sparseFillEmptyRows");
      var $denseShape = convertToTensor(denseShape, "denseShape", "sparseFillEmptyRows", "int32");
      var $defaultValue = convertToTensor(defaultValue, "defaultValue", "sparseFillEmptyRows", $values.dtype);
      if ($indices.rank !== 2) {
        throw new Error("Indices should be Tensor2D but received shape\n        ".concat($indices.shape));
      }
      if ($values.rank !== 1) {
        throw new Error("Values should be Tensor1D but received shape ".concat($values.shape));
      }
      if ($denseShape.rank !== 1) {
        throw new Error("Dense shape should be Tensor1D but received shape ".concat($denseShape.shape));
      }
      if ($defaultValue.rank !== 0) {
        throw new Error("Default value should be a scalar but received shape ".concat($defaultValue.shape));
      }
      var inputs = {
        indices: $indices,
        values: $values,
        denseShape: $denseShape,
        defaultValue: $defaultValue
      };
      var result = ENGINE.runKernel(SparseFillEmptyRows, inputs);
      return {
        outputIndices: result[0],
        outputValues: result[1],
        emptyRowIndicator: result[2],
        reverseIndexMap: result[3]
      };
    }
    var sparseFillEmptyRows = /* @__PURE__ */ op({ sparseFillEmptyRows_ });
    function sparseReshape_(inputIndices, inputShape, newShape) {
      var $inputIndices = convertToTensor(inputIndices, "inputIndices", "sparseReshape", "int32");
      var $inputShape = convertToTensor(inputShape, "inputShape", "sparseReshape", "int32");
      var $newShape = convertToTensor(newShape, "newShape", "sparseReshape", "int32");
      if ($inputIndices.rank !== 2) {
        throw new Error("Input indices should be Tensor2D but received shape\n        ".concat($inputIndices.shape));
      }
      if ($inputShape.rank !== 1) {
        throw new Error("Input shape should be Tensor1D but received shape ".concat($inputShape.shape));
      }
      if ($newShape.rank !== 1) {
        throw new Error("New shape should be Tensor1D but received shape ".concat($newShape.shape));
      }
      var inputs = {
        inputIndices: $inputIndices,
        inputShape: $inputShape,
        newShape: $newShape
      };
      var result = ENGINE.runKernel(SparseReshape, inputs);
      return { outputIndices: result[0], outputShape: result[1] };
    }
    var sparseReshape = /* @__PURE__ */ op({ sparseReshape_ });
    function sparseSegmentMean_(data, indices, segmentIds) {
      var $data = convertToTensor(data, "data", "sparseSegmentMean");
      var $indices = convertToTensor(indices, "indices", "sparseSegmentMean", "int32");
      var $segmentIds = convertToTensor(segmentIds, "segmentIds", "sparseSegmentMean", "int32");
      if ($data.rank < 1) {
        throw new Error("Data should be at least 1 dimensional but received scalar");
      }
      if ($indices.rank !== 1) {
        throw new Error("Indices should be Tensor1D but received shape\n          ".concat($indices.shape));
      }
      if ($segmentIds.rank !== 1) {
        throw new Error("Segment ids should be Tensor1D but received shape\n          ".concat($segmentIds.shape));
      }
      var inputs = {
        data: $data,
        indices: $indices,
        segmentIds: $segmentIds
      };
      return ENGINE.runKernel(SparseSegmentMean, inputs);
    }
    var sparseSegmentMean = /* @__PURE__ */ op({ sparseSegmentMean_ });
    function sparseSegmentSum_(data, indices, segmentIds) {
      var $data = convertToTensor(data, "data", "sparseSegmentSum");
      var $indices = convertToTensor(indices, "indices", "sparseSegmentSum", "int32");
      var $segmentIds = convertToTensor(segmentIds, "segmentIds", "sparseSegmentSum", "int32");
      if ($data.rank < 1) {
        throw new Error("Data should be at least 1 dimensional but received scalar");
      }
      if ($indices.rank !== 1) {
        throw new Error("Indices should be Tensor1D but received shape\n         ".concat($indices.shape));
      }
      if ($segmentIds.rank !== 1) {
        throw new Error("Segment ids should be Tensor1D but received shape\n         ".concat($segmentIds.shape));
      }
      var inputs = {
        data: $data,
        indices: $indices,
        segmentIds: $segmentIds
      };
      return ENGINE.runKernel(SparseSegmentSum, inputs);
    }
    var sparseSegmentSum = /* @__PURE__ */ op({ sparseSegmentSum_ });
    function stringNGrams_(data, dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences) {
      var $data = convertToTensor(data, "data", "stringNGrams", "string");
      if ($data.dtype !== "string") {
        throw new Error("Data must be of datatype string");
      }
      if ($data.shape.length !== 1) {
        throw new Error("Data must be a vector, saw: ".concat($data.shape));
      }
      var $dataSplits = convertToTensor(dataSplits, "dataSplits", "stringNGrams");
      if ($dataSplits.dtype !== "int32") {
        throw new Error("Data splits must be of datatype int32");
      }
      var attrs = {
        separator,
        nGramWidths,
        leftPad,
        rightPad: rightPad2,
        padWidth,
        preserveShortSequences
      };
      var inputs = { data: $data, dataSplits: $dataSplits };
      var result = ENGINE.runKernel(StringNGrams, inputs, attrs);
      return { nGrams: result[0], nGramsSplits: result[1] };
    }
    var stringNGrams = /* @__PURE__ */ op({ stringNGrams_ });
    function stringSplit_(input, delimiter, skipEmpty) {
      if (skipEmpty === void 0) {
        skipEmpty = true;
      }
      var $input = convertToTensor(input, "input", "stringSplit", "string");
      var $delimiter = convertToTensor(delimiter, "delimiter", "stringSplit", "string");
      if ($input.rank !== 1) {
        throw new Error("Input should be Tensor1D but received shape ".concat($input.shape));
      }
      if ($delimiter.rank !== 0) {
        throw new Error("Delimiter should be a scalar but received shape ".concat($delimiter.shape));
      }
      var attrs = { skipEmpty };
      var inputs = { input: $input, delimiter: $delimiter };
      var result = ENGINE.runKernel(StringSplit, inputs, attrs);
      return { indices: result[0], values: result[1], shape: result[2] };
    }
    var stringSplit = /* @__PURE__ */ op({ stringSplit_ });
    function stringToHashBucketFast_(input, numBuckets) {
      var $input = convertToTensor(input, "input", "stringToHashBucketFast", "string");
      var attrs = { numBuckets };
      if (numBuckets <= 0) {
        throw new Error("Number of buckets must be at least 1");
      }
      var inputs = { input: $input };
      return ENGINE.runKernel(StringToHashBucketFast, inputs, attrs);
    }
    var stringToHashBucketFast = /* @__PURE__ */ op({ stringToHashBucketFast_ });
    function staticRegexReplace_(input, pattern, rewrite, replaceGlobal) {
      if (replaceGlobal === void 0) {
        replaceGlobal = true;
      }
      var $input = convertToTensor(input, "input", "staticRegexReplace", "string");
      var attrs = { pattern, rewrite, replaceGlobal };
      return ENGINE.runKernel(StaticRegexReplace, { x: $input }, attrs);
    }
    var staticRegexReplace = /* @__PURE__ */ op({ staticRegexReplace_ });
    var spectral = {
      fft,
      ifft,
      rfft,
      irfft
    };
    var signal = {
      hammingWindow,
      hannWindow,
      frame,
      stft
    };
    var image = {
      flipLeftRight,
      grayscaleToRGB,
      resizeNearestNeighbor,
      resizeBilinear,
      rgbToGrayscale,
      rotateWithOffset,
      cropAndResize,
      nonMaxSuppression,
      nonMaxSuppressionAsync,
      nonMaxSuppressionWithScore,
      nonMaxSuppressionWithScoreAsync,
      nonMaxSuppressionPadded,
      nonMaxSuppressionPaddedAsync,
      threshold,
      transform
    };
    var linalg = {
      bandPart,
      gramSchmidt,
      qr
    };
    var losses = {
      absoluteDifference,
      computeWeightedLoss,
      cosineDistance,
      hingeLoss,
      huberLoss,
      logLoss,
      meanSquaredError,
      sigmoidCrossEntropy,
      softmaxCrossEntropy
    };
    var sparse = {
      sparseFillEmptyRows,
      sparseReshape,
      sparseSegmentMean,
      sparseSegmentSum
    };
    var string = {
      stringNGrams,
      stringSplit,
      stringToHashBucketFast,
      staticRegexReplace
    };
    var tfOps = {
      __proto__: null,
      OP_SCOPE_SUFFIX,
      abs,
      acos,
      acosh,
      add,
      addN,
      all,
      any,
      argMax,
      argMin,
      asin,
      asinh,
      atan,
      atan2,
      atanh,
      avgPool,
      avgPool3d,
      basicLSTMCell,
      batchNorm,
      batchNorm2d,
      batchNorm3d,
      batchNorm4d,
      batchToSpaceND,
      bincount,
      bitwiseAnd,
      booleanMaskAsync,
      broadcastArgs,
      broadcastTo,
      buffer,
      cast,
      ceil,
      clipByValue,
      clone,
      complex,
      concat,
      concat1d,
      concat2d,
      concat3d,
      concat4d,
      conv1d,
      conv2d: conv2d$1,
      conv2dTranspose,
      conv3d,
      conv3dTranspose,
      cos,
      cosh,
      cosineWindow,
      cumprod,
      cumsum,
      denseBincount,
      depthToSpace,
      depthwiseConv2d: depthwiseConv2d$1,
      diag,
      dilation2d,
      div,
      divNoNan,
      dot,
      dropout,
      einsum,
      elu,
      enclosingPowerOfTwo,
      ensureShape,
      equal,
      erf,
      euclideanNorm,
      exp,
      expandDims,
      expm1,
      eye,
      fft,
      fill,
      floor,
      floorDiv,
      fused: fused_ops,
      gather,
      gatherND,
      greater,
      greaterEqual,
      ifft,
      imag,
      image,
      inTopKAsync,
      irfft,
      isFinite: isFinite$1,
      isInf,
      isNaN: isNaN$1,
      leakyRelu,
      less,
      lessEqual,
      linalg,
      linspace,
      localResponseNormalization,
      log,
      log1p,
      logSigmoid,
      logSoftmax,
      logSumExp,
      logicalAnd,
      logicalNot,
      logicalOr,
      logicalXor,
      losses,
      lowerBound,
      matMul: matMul$1,
      max,
      maxPool,
      maxPool3d,
      maxPoolWithArgmax,
      maximum,
      mean,
      meshgrid,
      min,
      minimum,
      mirrorPad,
      mod,
      moments,
      movingAverage,
      mul,
      multiRNNCell,
      multinomial,
      neg,
      norm,
      notEqual,
      oneHot,
      ones,
      onesLike,
      op,
      outerProduct,
      pad,
      pad1d,
      pad2d,
      pad3d,
      pad4d,
      pool,
      pow,
      prelu,
      print,
      prod,
      raggedGather,
      raggedRange,
      raggedTensorToTensor,
      rand,
      randomGamma,
      randomNormal,
      randomStandardNormal,
      randomUniform,
      randomUniformInt,
      range,
      real,
      reciprocal,
      relu,
      relu6,
      reshape,
      reverse,
      reverse1d,
      reverse2d,
      reverse3d,
      reverse4d,
      rfft,
      round,
      rsqrt,
      scalar,
      scatterND,
      searchSorted,
      selu,
      separableConv2d,
      setdiff1dAsync,
      sigmoid,
      sign,
      signal,
      sin,
      sinh,
      slice,
      slice1d,
      slice2d,
      slice3d,
      slice4d,
      softmax,
      softplus,
      spaceToBatchND,
      sparse,
      sparseToDense,
      spectral,
      split: split$1,
      sqrt,
      square,
      squaredDifference,
      squeeze,
      stack,
      step,
      stridedSlice,
      string,
      sub,
      sum,
      tan,
      tanh,
      tensor,
      tensor1d,
      tensor2d,
      tensor3d,
      tensor4d,
      tensor5d,
      tensor6d,
      tensorScatterUpdate,
      tile,
      topk,
      transpose,
      truncatedNormal,
      unique,
      unsortedSegmentSum,
      unstack,
      upperBound,
      variable,
      where,
      whereAsync,
      zeros,
      zerosLike
    };
    var executeOp$k = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "BiasAdd":
        case "AddV2":
        case "Add": {
          return [ops.add(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "AddN": {
          return [ops.addN(getParamValue("tensors", node, tensorMap, context))];
        }
        case "FloorMod":
        case "Mod":
          return [ops.mod(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        case "Mul":
          return [ops.mul(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        case "RealDiv":
        case "Div": {
          return [ops.div(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "DivNoNan": {
          return [ops.divNoNan(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "FloorDiv": {
          return [ops.floorDiv(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "Sub": {
          return [ops.sub(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "Minimum": {
          return [ops.minimum(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "Maximum": {
          return [ops.maximum(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "Pow": {
          return [ops.pow(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "SquaredDifference": {
          return [ops.squaredDifference(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$j = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "Abs":
        case "ComplexAbs":
          return [ops.abs(getParamValue("x", node, tensorMap, context))];
        case "Acos":
          return [ops.acos(getParamValue("x", node, tensorMap, context))];
        case "Acosh":
          return [ops.acosh(getParamValue("x", node, tensorMap, context))];
        case "Asin":
          return [ops.asin(getParamValue("x", node, tensorMap, context))];
        case "Asinh":
          return [ops.asinh(getParamValue("x", node, tensorMap, context))];
        case "Atan":
          return [ops.atan(getParamValue("x", node, tensorMap, context))];
        case "Atan2":
          return [ops.atan2(getParamValue("x", node, tensorMap, context), getParamValue("y", node, tensorMap, context))];
        case "Atanh":
          return [ops.atanh(getParamValue("x", node, tensorMap, context))];
        case "Ceil":
          return [ops.ceil(getParamValue("x", node, tensorMap, context))];
        case "Complex":
          return [ops.complex(getParamValue("real", node, tensorMap, context), getParamValue("imag", node, tensorMap, context))];
        case "Cos":
          return [ops.cos(getParamValue("x", node, tensorMap, context))];
        case "Cosh":
          return [ops.cosh(getParamValue("x", node, tensorMap, context))];
        case "Elu":
          return [ops.elu(getParamValue("x", node, tensorMap, context))];
        case "Erf":
          return [ops.erf(getParamValue("x", node, tensorMap, context))];
        case "Exp":
          return [ops.exp(getParamValue("x", node, tensorMap, context))];
        case "Expm1": {
          return [ops.expm1(getParamValue("x", node, tensorMap, context))];
        }
        case "Floor":
          return [ops.floor(getParamValue("x", node, tensorMap, context))];
        case "Log":
          return [ops.log(getParamValue("x", node, tensorMap, context))];
        case "Log1p": {
          return [ops.log1p(getParamValue("x", node, tensorMap, context))];
        }
        case "Imag":
          return [ops.imag(getParamValue("x", node, tensorMap, context))];
        case "Neg":
          return [ops.neg(getParamValue("x", node, tensorMap, context))];
        case "Reciprocal": {
          return [ops.reciprocal(getParamValue("x", node, tensorMap, context))];
        }
        case "Real":
          return [ops.real(getParamValue("x", node, tensorMap, context))];
        case "Relu":
          return [ops.relu(getParamValue("x", node, tensorMap, context))];
        case "Round": {
          return [ops.round(getParamValue("x", node, tensorMap, context))];
        }
        case "Selu":
          return [ops.selu(getParamValue("x", node, tensorMap, context))];
        case "Sigmoid":
          return [ops.sigmoid(getParamValue("x", node, tensorMap, context))];
        case "Sin":
          return [ops.sin(getParamValue("x", node, tensorMap, context))];
        case "Sign": {
          return [ops.sign(getParamValue("x", node, tensorMap, context))];
        }
        case "Sinh": {
          return [ops.sinh(getParamValue("x", node, tensorMap, context))];
        }
        case "Softplus": {
          return [ops.softplus(getParamValue("x", node, tensorMap, context))];
        }
        case "Sqrt": {
          return [ops.sqrt(getParamValue("x", node, tensorMap, context))];
        }
        case "Square": {
          return [ops.square(getParamValue("x", node, tensorMap, context))];
        }
        case "Tanh": {
          return [ops.tanh(getParamValue("x", node, tensorMap, context))];
        }
        case "Tan":
          return [ops.tan(getParamValue("x", node, tensorMap, context))];
        case "ClipByValue":
          return [ops.clipByValue(getParamValue("x", node, tensorMap, context), getParamValue("clipValueMin", node, tensorMap, context), getParamValue("clipValueMax", node, tensorMap, context))];
        case "Relu6":
          return [ops.relu6(getParamValue("x", node, tensorMap, context))];
        case "Rsqrt":
          return [ops.rsqrt(getTensor(node.inputNames[0], tensorMap, context))];
        case "LeakyRelu":
          return [ops.leakyRelu(getParamValue("x", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context))];
        case "Prelu":
          return [ops.prelu(getParamValue("x", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context))];
        case "IsNan":
          return [ops.isNaN(getTensor(node.inputNames[0], tensorMap, context))];
        case "IsInf":
          return [ops.isInf(getTensor(node.inputNames[0], tensorMap, context))];
        case "IsFinite":
          return [ops.isFinite(getTensor(node.inputNames[0], tensorMap, context))];
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    function assertShapesMatchAllowUndefinedSize(shapeA, shapeB, errorMessagePrefix) {
      if (errorMessagePrefix === void 0) {
        errorMessagePrefix = "";
      }
      if (typeof shapeA === "number" || typeof shapeB === "number") {
        return;
      }
      tfc.util.assert(shapeA.length === shapeB.length, function() {
        return errorMessagePrefix + " Shapes ".concat(shapeA, " and ").concat(shapeB, " must match");
      });
      for (var i = 0; i < shapeA.length; i++) {
        var dim0 = shapeA[i];
        var dim1 = shapeB[i];
        tfc.util.assert(dim0 < 0 || dim1 < 0 || dim0 === dim1, function() {
          return errorMessagePrefix + " Shapes ".concat(shapeA, " and ").concat(shapeB, " must match");
        });
      }
    }
    function fullDefinedShape(elementShape) {
      if (typeof elementShape === "number" || elementShape.some(function(dim) {
        return dim < 0;
      })) {
        return false;
      }
      return true;
    }
    function inferElementShape(listElementShape, tensors, elementShape) {
      var partialShape = mergeElementShape(listElementShape, elementShape);
      var notfullDefinedShape = !fullDefinedShape(partialShape);
      if (notfullDefinedShape && tensors.length === 0) {
        throw new Error("Tried to calculate elements of an empty list" + " with non-fully-defined elementShape: ".concat(partialShape));
      }
      if (notfullDefinedShape) {
        tensors.forEach(function(tensor2) {
          partialShape = mergeElementShape(tensor2.shape, partialShape);
        });
      }
      if (!fullDefinedShape(partialShape)) {
        throw new Error("Non-fully-defined elementShape: ".concat(partialShape));
      }
      return partialShape;
    }
    function mergeElementShape(elementShapeA, elementShapeB) {
      if (typeof elementShapeA === "number") {
        return elementShapeB;
      }
      if (typeof elementShapeB === "number") {
        return elementShapeA;
      }
      if (elementShapeA.length !== elementShapeB.length) {
        throw new Error("Incompatible ranks during merge: ".concat(elementShapeA, " vs. ").concat(elementShapeB));
      }
      var result = [];
      for (var i = 0; i < elementShapeA.length; ++i) {
        var dim0 = elementShapeA[i];
        var dim1 = elementShapeB[i];
        if (dim0 >= 0 && dim1 >= 0 && dim0 !== dim1) {
          throw new Error("Incompatible shape during merge: ".concat(elementShapeA, " vs. ").concat(elementShapeB));
        }
        result[i] = dim0 >= 0 ? dim0 : dim1;
      }
      return result;
    }
    var TensorArray = (
      /** @class */
      function() {
        function TensorArray2(name, dtype, maxSize, elementShape, identicalElementShapes, dynamicSize, clearAfterRead) {
          this.name = name;
          this.dtype = dtype;
          this.maxSize = maxSize;
          this.elementShape = elementShape;
          this.identicalElementShapes = identicalElementShapes;
          this.dynamicSize = dynamicSize;
          this.clearAfterRead = clearAfterRead;
          this.tensors = [];
          this.closed_ = false;
          this.idTensor = tfc.scalar(0);
          tfc.keep(this.idTensor);
        }
        Object.defineProperty(TensorArray2.prototype, "id", {
          get: function() {
            return this.idTensor.id;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(TensorArray2.prototype, "closed", {
          get: function() {
            return this.closed_;
          },
          enumerable: false,
          configurable: true
        });
        TensorArray2.prototype.clearAndClose = function(keepIds) {
          this.tensors.forEach(function(tensor2) {
            if (keepIds == null || !keepIds.has(tensor2.tensor.id)) {
              tensor2.tensor.dispose();
            }
          });
          this.tensors = [];
          this.closed_ = true;
          this.idTensor.dispose();
        };
        TensorArray2.prototype.size = function() {
          return this.tensors.length;
        };
        TensorArray2.prototype.read = function(index) {
          if (this.closed_) {
            throw new Error("TensorArray ".concat(this.name, " has already been closed."));
          }
          if (index < 0 || index >= this.size()) {
            throw new Error("Tried to read from index ".concat(index, ", but array size is: ").concat(this.size()));
          }
          var tensorWithState = this.tensors[index];
          if (tensorWithState.cleared) {
            throw new Error("TensorArray ".concat(this.name, ": Could not read index ").concat(index, " twice because it was cleared after a previous read ") + "(perhaps try setting clear_after_read = false?).");
          }
          if (this.clearAfterRead) {
            tensorWithState.cleared = true;
          }
          tensorWithState.read = true;
          return tensorWithState.tensor;
        };
        TensorArray2.prototype.readMany = function(indices) {
          var _this = this;
          return indices.map(function(index) {
            return _this.read(index);
          });
        };
        TensorArray2.prototype.write = function(index, tensor2) {
          if (this.closed_) {
            throw new Error("TensorArray ".concat(this.name, " has already been closed."));
          }
          if (index < 0 || !this.dynamicSize && index >= this.maxSize) {
            throw new Error("Tried to write to index ".concat(index, ", but array is not resizeable and size is: ").concat(this.maxSize));
          }
          var t = this.tensors[index] || {};
          if (tensor2.dtype !== this.dtype) {
            throw new Error("TensorArray ".concat(this.name, ": Could not write to TensorArray index ").concat(index, ",\n          because the value dtype is ").concat(tensor2.dtype, ", but TensorArray dtype is ").concat(this.dtype, "."));
          }
          if (this.size() === 0 && (this.elementShape == null || this.elementShape.length === 0)) {
            this.elementShape = tensor2.shape;
          }
          assertShapesMatchAllowUndefinedSize(this.elementShape, tensor2.shape, "TensorArray ".concat(this.name, ": Could not write to TensorArray index ").concat(index, "."));
          if (t.read) {
            throw new Error("TensorArray ".concat(this.name, ": Could not write to TensorArray index ").concat(index, ", because it has already been read."));
          }
          if (t.written) {
            throw new Error("TensorArray ".concat(this.name, ": Could not write to TensorArray index ").concat(index, ", because it has already been written."));
          }
          t.tensor = tensor2;
          tfc.keep(tensor2);
          t.written = true;
          this.tensors[index] = t;
        };
        TensorArray2.prototype.writeMany = function(indices, tensors) {
          var _this = this;
          if (indices.length !== tensors.length) {
            throw new Error("TensorArray ".concat(this.name, ": could not write multiple tensors,") + "because the index size: ".concat(indices.length, " is not the same as tensors size: ").concat(tensors.length, "."));
          }
          indices.forEach(function(i, index) {
            return _this.write(i, tensors[index]);
          });
        };
        TensorArray2.prototype.gather = function(indices, dtype) {
          if (!!dtype && dtype !== this.dtype) {
            throw new Error("TensorArray dtype is ".concat(this.dtype, " but gather requested dtype ").concat(dtype));
          }
          if (!indices) {
            indices = [];
            for (var i = 0; i < this.size(); i++) {
              indices.push(i);
            }
          } else {
            indices = indices.slice(0, this.size());
          }
          if (indices.length === 0) {
            return tfc.tensor([], [0].concat(this.elementShape));
          }
          var tensors = this.readMany(indices);
          assertShapesMatchAllowUndefinedSize(this.elementShape, tensors[0].shape, "TensorArray shape mismatch: ");
          return tfc.stack(tensors, 0);
        };
        TensorArray2.prototype.concat = function(dtype) {
          if (!!dtype && dtype !== this.dtype) {
            throw new Error("TensorArray dtype is ".concat(this.dtype, " but concat requested dtype ").concat(dtype));
          }
          if (this.size() === 0) {
            return tfc.tensor([], [0].concat(this.elementShape));
          }
          var indices = [];
          for (var i = 0; i < this.size(); i++) {
            indices.push(i);
          }
          var tensors = this.readMany(indices);
          assertShapesMatchAllowUndefinedSize(this.elementShape, tensors[0].shape, "TensorArray shape mismatch: tensor array shape (".concat(this.elementShape, ") vs first tensor shape (").concat(tensors[0].shape, ")"));
          return tfc.concat(tensors, 0);
        };
        TensorArray2.prototype.scatter = function(indices, tensor2) {
          if (tensor2.dtype !== this.dtype) {
            throw new Error("TensorArray dtype is ".concat(this.dtype, " but tensor has dtype ").concat(tensor2.dtype));
          }
          if (indices.length !== tensor2.shape[0]) {
            throw new Error("Expected len(indices) == tensor.shape[0], but saw: ".concat(indices.length, " vs. ").concat(tensor2.shape[0]));
          }
          var maxIndex = Math.max.apply(Math, __spreadArray([], __read(indices), false));
          if (!this.dynamicSize && maxIndex >= this.maxSize) {
            throw new Error("Max index must be < array size (".concat(maxIndex, "  vs. ").concat(this.maxSize, ")"));
          }
          this.writeMany(indices, tfc.unstack(tensor2, 0));
        };
        TensorArray2.prototype.split = function(length, tensor2) {
          var _this = this;
          if (tensor2.dtype !== this.dtype) {
            throw new Error("TensorArray dtype is ".concat(this.dtype, " but tensor has dtype ").concat(tensor2.dtype));
          }
          var totalLength = 0;
          var cumulativeLengths = length.map(function(len) {
            totalLength += len;
            return totalLength;
          });
          if (totalLength !== tensor2.shape[0]) {
            throw new Error("Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ".concat(totalLength, ", and tensor's shape is: ").concat(tensor2.shape));
          }
          if (!this.dynamicSize && length.length !== this.maxSize) {
            throw new Error("TensorArray's size is not equal to the size of lengths (".concat(this.maxSize, " vs. ").concat(length.length, "), ") + "and the TensorArray is not marked as dynamically resizeable");
          }
          var elementPerRow = totalLength === 0 ? 0 : tensor2.size / totalLength;
          var tensors = [];
          tfc.tidy(function() {
            tensor2 = tfc.reshape(tensor2, [1, totalLength, elementPerRow]);
            for (var i2 = 0; i2 < length.length; ++i2) {
              var previousLength = i2 === 0 ? 0 : cumulativeLengths[i2 - 1];
              var indices_1 = [0, previousLength, 0];
              var sizes = [1, length[i2], elementPerRow];
              tensors[i2] = tfc.reshape(tfc.slice(tensor2, indices_1, sizes), _this.elementShape);
            }
            return tensors;
          });
          var indices = [];
          for (var i = 0; i < length.length; i++) {
            indices[i] = i;
          }
          this.writeMany(indices, tensors);
        };
        return TensorArray2;
      }()
    );
    var TensorList = (
      /** @class */
      function() {
        function TensorList2(tensors, elementShape, elementDtype, maxNumElements) {
          if (maxNumElements === void 0) {
            maxNumElements = -1;
          }
          this.tensors = tensors;
          this.elementShape = elementShape;
          this.elementDtype = elementDtype;
          if (tensors != null) {
            tensors.forEach(function(tensor2) {
              if (elementDtype !== tensor2.dtype) {
                throw new Error("Invalid data types; op elements ".concat(elementDtype, ", but list elements ").concat(tensor2.dtype));
              }
              assertShapesMatchAllowUndefinedSize(elementShape, tensor2.shape, "TensorList shape mismatch: ");
              tfc.keep(tensor2);
            });
          }
          this.idTensor = tfc.scalar(0);
          this.maxNumElements = maxNumElements;
          tfc.keep(this.idTensor);
        }
        Object.defineProperty(TensorList2.prototype, "id", {
          get: function() {
            return this.idTensor.id;
          },
          enumerable: false,
          configurable: true
        });
        TensorList2.prototype.copy = function() {
          return new TensorList2(__spreadArray([], __read(this.tensors), false), this.elementShape, this.elementDtype);
        };
        TensorList2.prototype.clearAndClose = function(keepIds) {
          this.tensors.forEach(function(tensor2) {
            if (keepIds == null || !keepIds.has(tensor2.id)) {
              tensor2.dispose();
            }
          });
          this.tensors.length = 0;
          this.idTensor.dispose();
        };
        TensorList2.prototype.size = function() {
          return this.tensors.length;
        };
        TensorList2.prototype.stack = function(elementShape, elementDtype, numElements) {
          var _this = this;
          if (numElements === void 0) {
            numElements = -1;
          }
          if (elementDtype !== this.elementDtype) {
            throw new Error("Invalid data types; op elements ".concat(elementDtype, ", but list elements ").concat(this.elementDtype));
          }
          if (numElements !== -1 && this.tensors.length !== numElements) {
            throw new Error("Operation expected a list with ".concat(numElements, " elements but got a list with ").concat(this.tensors.length, " elements."));
          }
          assertShapesMatchAllowUndefinedSize(elementShape, this.elementShape, "TensorList shape mismatch: ");
          var outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          return tfc.tidy(function() {
            var reshapedTensors = _this.tensors.map(function(tensor2) {
              return tfc.reshape(tensor2, outputElementShape);
            });
            return tfc.stack(reshapedTensors, 0);
          });
        };
        TensorList2.prototype.popBack = function(elementShape, elementDtype) {
          if (elementDtype !== this.elementDtype) {
            throw new Error("Invalid data types; op elements ".concat(elementDtype, ", but list elements ").concat(this.elementDtype));
          }
          if (this.size() === 0) {
            throw new Error("Trying to pop from an empty list.");
          }
          var outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          var tensor2 = this.tensors.pop();
          tensor2.kept = false;
          assertShapesMatchAllowUndefinedSize(tensor2.shape, elementShape, "TensorList shape mismatch: ");
          return tfc.reshape(tensor2, outputElementShape);
        };
        TensorList2.prototype.pushBack = function(tensor2) {
          if (tensor2.dtype !== this.elementDtype) {
            throw new Error("Invalid data types; op elements ".concat(tensor2.dtype, ", but list elements ").concat(this.elementDtype));
          }
          assertShapesMatchAllowUndefinedSize(tensor2.shape, this.elementShape, "TensorList shape mismatch: ");
          if (this.maxNumElements === this.size()) {
            throw new Error("Trying to push element into a full list.");
          }
          tfc.keep(tensor2);
          this.tensors.push(tensor2);
        };
        TensorList2.prototype.resize = function(size) {
          if (size < 0) {
            throw new Error("TensorListResize expects size to be non-negative. Got: ".concat(size));
          }
          if (this.maxNumElements !== -1 && size > this.maxNumElements) {
            throw new Error("TensorListResize input size ".concat(size, " is greater maxNumElement ").concat(this.maxNumElements, "."));
          }
          var destTensorList = new TensorList2([], this.elementShape, this.elementDtype, this.maxNumElements);
          destTensorList.tensors.length = size;
          for (var i = 0; i < Math.min(this.tensors.length, size); ++i) {
            destTensorList.tensors[i] = this.tensors[i];
          }
          return destTensorList;
        };
        TensorList2.prototype.getItem = function(elementIndex, elementShape, elementDtype) {
          if (elementDtype !== this.elementDtype) {
            throw new Error("Invalid data types; op elements ".concat(elementDtype, ", but list elements ").concat(this.elementDtype));
          }
          if (elementIndex < 0 || elementIndex > this.tensors.length) {
            throw new Error("Trying to access element ".concat(elementIndex, " in a list with ").concat(this.tensors.length, " elements."));
          }
          if (this.tensors[elementIndex] == null) {
            throw new Error("element at index ".concat(elementIndex, " is null."));
          }
          assertShapesMatchAllowUndefinedSize(this.tensors[elementIndex].shape, elementShape, "TensorList shape mismatch: ");
          var outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          return tfc.reshape(this.tensors[elementIndex], outputElementShape);
        };
        TensorList2.prototype.setItem = function(elementIndex, tensor2) {
          if (tensor2.dtype !== this.elementDtype) {
            throw new Error("Invalid data types; op elements ".concat(tensor2.dtype, ", but list elements ").concat(this.elementDtype));
          }
          if (elementIndex < 0 || this.maxNumElements !== -1 && elementIndex >= this.maxNumElements) {
            throw new Error("Trying to set element ".concat(elementIndex, " in a list with max ").concat(this.maxNumElements, " elements."));
          }
          assertShapesMatchAllowUndefinedSize(this.elementShape, tensor2.shape, "TensorList shape mismatch: ");
          tfc.keep(tensor2);
          if (this.tensors[elementIndex] != null) {
            this.tensors[elementIndex].kept = false;
          }
          this.tensors[elementIndex] = tensor2;
        };
        TensorList2.prototype.gather = function(indices, elementDtype, elementShape) {
          var _this = this;
          if (elementDtype !== this.elementDtype) {
            throw new Error("Invalid data types; op elements ".concat(elementDtype, ", but list elements ").concat(this.elementDtype));
          }
          assertShapesMatchAllowUndefinedSize(this.elementShape, elementShape, "TensorList shape mismatch: ");
          indices = indices.slice(0, this.size());
          var outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          if (indices.length === 0) {
            return tfc.tensor([], [0].concat(outputElementShape));
          }
          return tfc.tidy(function() {
            var tensors = indices.map(function(i) {
              return tfc.reshape(_this.tensors[i], outputElementShape);
            });
            return tfc.stack(tensors, 0);
          });
        };
        TensorList2.prototype.concat = function(elementDtype, elementShape) {
          var _this = this;
          if (!!elementDtype && elementDtype !== this.elementDtype) {
            throw new Error("TensorList dtype is ".concat(this.elementDtype, " but concat requested dtype ").concat(elementDtype));
          }
          assertShapesMatchAllowUndefinedSize(this.elementShape, elementShape, "TensorList shape mismatch: ");
          var outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          if (this.size() === 0) {
            return tfc.tensor([], [0].concat(outputElementShape));
          }
          return tfc.tidy(function() {
            var tensors = _this.tensors.map(function(t) {
              return tfc.reshape(t, outputElementShape);
            });
            return tfc.concat(tensors, 0);
          });
        };
        return TensorList2;
      }()
    );
    function fromTensor(tensor2, elementShape, elementDtype) {
      var dtype = tensor2.dtype;
      if (tensor2.shape.length < 1) {
        throw new Error("Tensor must be at least a vector, but saw shape: ".concat(tensor2.shape));
      }
      if (tensor2.dtype !== elementDtype) {
        throw new Error("Invalid data types; op elements ".concat(tensor2.dtype, ", but list elements ").concat(elementDtype));
      }
      var tensorElementShape = tensor2.shape.slice(1);
      assertShapesMatchAllowUndefinedSize(tensorElementShape, elementShape, "TensorList shape mismatch: ");
      var tensorList = tfc.unstack(tensor2);
      return new TensorList(tensorList, elementShape, dtype);
    }
    function reserve(elementShape, elementDtype, numElements, maxNumElements) {
      return new TensorList([], elementShape, elementDtype, maxNumElements);
    }
    function scatter(tensor2, indices, elementShape, numElements) {
      if (indices.length !== tensor2.shape[0]) {
        throw new Error("Expected len(indices) == tensor.shape[0], but saw: ".concat(indices.length, " vs. ").concat(tensor2.shape[0]));
      }
      var maxIndex = Math.max.apply(Math, __spreadArray([], __read(indices), false));
      if (numElements != null && numElements !== -1 && maxIndex >= numElements) {
        throw new Error("Max index must be < array size (".concat(maxIndex, "  vs. ").concat(numElements, ")"));
      }
      var list = new TensorList([], elementShape, tensor2.dtype, numElements);
      var tensors = tfc.unstack(tensor2, 0);
      indices.forEach(function(value, index) {
        list.setItem(value, tensors[index]);
      });
      return list;
    }
    function split(tensor2, length, elementShape) {
      var totalLength = 0;
      var cumulativeLengths = length.map(function(len) {
        totalLength += len;
        return totalLength;
      });
      if (totalLength !== tensor2.shape[0]) {
        throw new Error("Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ".concat(totalLength, ", and tensor's shape is: ").concat(tensor2.shape));
      }
      var shapeWithoutFirstDim = tensor2.shape.slice(1);
      var outputElementShape = mergeElementShape(shapeWithoutFirstDim, elementShape);
      var elementPerRow = totalLength === 0 ? 0 : tensor2.size / totalLength;
      var tensors = tfc.tidy(function() {
        var tensors2 = [];
        tensor2 = tfc.reshape(tensor2, [1, totalLength, elementPerRow]);
        for (var i2 = 0; i2 < length.length; ++i2) {
          var previousLength = i2 === 0 ? 0 : cumulativeLengths[i2 - 1];
          var indices = [0, previousLength, 0];
          var sizes = [1, length[i2], elementPerRow];
          tensors2[i2] = tfc.reshape(tfc.slice(tensor2, indices, sizes), outputElementShape);
        }
        tensor2.dispose();
        return tensors2;
      });
      var list = new TensorList([], elementShape, tensor2.dtype, length.length);
      for (var i = 0; i < tensors.length; i++) {
        list.setItem(i, tensors[i]);
      }
      return list;
    }
    var executeOp$i = function(node, tensorMap, context) {
      return __awaiter(void 0, void 0, void 0, function() {
        var _a, thenFunc, elseFunc, cond, args, condValue, bodyFunc, condFunc, args, condResult, argIds_1, condValue, result, _loop_1, pred, pred, data, inputName, data, frameId, data, data, data, size, dtype, elementShape, dynamicSize, clearAfterRead, identicalElementShapes, name, tensorArray, id, index, writeTensor, writeTensorArray, readId, readIndex, readTensorArray, gatherId, gatherIndices, gatherDtype, gatherTensorArray, scatterId, scatterIndices, scatterTensor, scatterTensorArray, concatId, concatTensorArray, concatDtype, splitId, splitTensor, lengths, splitTensorArray, sizeId, sizeTensorArray, closeId, closeTensorArray, idTensor, index, writeTensor, tensorList, idTensor, readIndex, elementShape, elementDType, tensorList, scatterIndices, scatterTensor, elementShape, numElements, tensorList, elementShape, elementDtype, numElementsParam, numElements, maxNumElements, tensorList, gatherId, gatherIndices, elementShape, elementDtype, tensorList, idTensor, elementShape, elementDtype, numElements, tensorList, tensor2, elementShape, elementDtype, tensorList, concatId, tensorList, concatDtype, elementShape, idTensor, writeTensor, tensorList, idTensor, elementShape, elementDType, tensorList, splitTensor, elementShape, lengths, tensorList, idTensor, tensorList, idTensor, size, srcTensorList, destTensorList;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              _a = node.op;
              switch (_a) {
                case "If":
                  return [3, 1];
                case "StatelessIf":
                  return [3, 1];
                case "While":
                  return [3, 3];
                case "StatelessWhile":
                  return [3, 3];
                case "LoopCond":
                  return [3, 9];
                case "Switch":
                  return [3, 10];
                case "Merge":
                  return [3, 12];
                case "Enter":
                  return [3, 13];
                case "Exit":
                  return [3, 14];
                case "NextIteration":
                  return [3, 15];
                case "TensorArrayV3":
                  return [3, 16];
                case "TensorArrayWriteV3":
                  return [3, 17];
                case "TensorArrayReadV3":
                  return [3, 18];
                case "TensorArrayGatherV3":
                  return [3, 19];
                case "TensorArrayScatterV3":
                  return [3, 20];
                case "TensorArrayConcatV3":
                  return [3, 21];
                case "TensorArraySplitV3":
                  return [3, 22];
                case "TensorArraySizeV3":
                  return [3, 23];
                case "TensorArrayCloseV3":
                  return [3, 24];
                case "TensorListSetItem":
                  return [3, 25];
                case "TensorListGetItem":
                  return [3, 26];
                case "TensorListScatterV2":
                  return [3, 27];
                case "TensorListScatter":
                  return [3, 27];
                case "TensorListReserve":
                  return [3, 28];
                case "EmptyTensorList":
                  return [3, 28];
                case "TensorListGather":
                  return [3, 29];
                case "TensorListStack":
                  return [3, 30];
                case "TensorListFromTensor":
                  return [3, 31];
                case "TensorListConcat":
                  return [3, 32];
                case "TensorListConcatV2":
                  return [3, 32];
                case "TensorListPushBack":
                  return [3, 33];
                case "TensorListPopBack":
                  return [3, 34];
                case "TensorListSplit":
                  return [3, 35];
                case "TensorListLength":
                  return [3, 36];
                case "TensorListResize":
                  return [3, 37];
              }
              return [3, 38];
            case 1:
              thenFunc = getParamValue("thenBranch", node, tensorMap, context);
              elseFunc = getParamValue("elseBranch", node, tensorMap, context);
              cond = getParamValue("cond", node, tensorMap, context);
              args = getParamValue("args", node, tensorMap, context);
              return [4, cond.data()];
            case 2:
              condValue = _b.sent();
              if (condValue[0]) {
                return [2, context.functionMap[thenFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap)];
              } else {
                return [2, context.functionMap[elseFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap)];
              }
            case 3:
              bodyFunc = getParamValue("body", node, tensorMap, context);
              condFunc = getParamValue("cond", node, tensorMap, context);
              args = getParamValue("args", node, tensorMap, context);
              return [4, context.functionMap[condFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap)];
            case 4:
              condResult = _b.sent();
              argIds_1 = args.map(function(tensor3) {
                return tensor3.id;
              });
              return [4, condResult[0].data()];
            case 5:
              condValue = _b.sent();
              condResult.forEach(function(tensor3) {
                if (!tensor3.kept && argIds_1.indexOf(tensor3.id) === -1) {
                  tensor3.dispose();
                }
              });
              result = args;
              _loop_1 = function() {
                var origResult, resultIds, condResult_1;
                return __generator(this, function(_c) {
                  switch (_c.label) {
                    case 0:
                      origResult = result;
                      return [4, context.functionMap[bodyFunc].executeFunctionAsync(result, context.tensorArrayMap, context.tensorListMap)];
                    case 1:
                      result = _c.sent();
                      resultIds = result.map(function(tensor3) {
                        return tensor3.id;
                      });
                      origResult.forEach(function(tensor3) {
                        if (!tensor3.kept && argIds_1.indexOf(tensor3.id) === -1 && resultIds.indexOf(tensor3.id) === -1) {
                          tensor3.dispose();
                        }
                      });
                      return [4, context.functionMap[condFunc].executeFunctionAsync(result, context.tensorArrayMap, context.tensorListMap)];
                    case 2:
                      condResult_1 = _c.sent();
                      return [4, condResult_1[0].data()];
                    case 3:
                      condValue = _c.sent();
                      condResult_1.forEach(function(tensor3) {
                        if (!tensor3.kept && argIds_1.indexOf(tensor3.id) === -1 && resultIds.indexOf(tensor3.id) === -1) {
                          tensor3.dispose();
                        }
                      });
                      return [
                        2
                        /*return*/
                      ];
                  }
                });
              };
              _b.label = 6;
            case 6:
              if (!condValue[0])
                return [3, 8];
              return [5, _loop_1()];
            case 7:
              _b.sent();
              return [3, 6];
            case 8:
              return [2, result];
            case 9: {
              pred = getParamValue("pred", node, tensorMap, context);
              return [2, [cloneTensor(pred)]];
            }
            case 10:
              pred = getParamValue("pred", node, tensorMap, context);
              data = getParamValue("data", node, tensorMap, context);
              if (!data.kept) {
                data = cloneTensor(data);
              }
              return [4, pred.data()];
            case 11:
              return [2, _b.sent()[0] ? [void 0, data] : [data, void 0]];
            case 12: {
              inputName = node.inputNames.find(function(name2) {
                return getTensor(name2, tensorMap, context) !== void 0;
              });
              if (inputName) {
                data = getTensor(inputName, tensorMap, context);
                return [2, [cloneTensor(data)]];
              }
              return [2, void 0];
            }
            case 13: {
              frameId = getParamValue("frameName", node, tensorMap, context);
              data = getParamValue("tensor", node, tensorMap, context);
              context.enterFrame(frameId);
              return [2, [cloneTensor(data)]];
            }
            case 14: {
              data = getParamValue("tensor", node, tensorMap, context);
              context.exitFrame();
              return [2, [cloneTensor(data)]];
            }
            case 15: {
              data = getParamValue("tensor", node, tensorMap, context);
              context.nextIteration();
              return [2, [cloneTensor(data)]];
            }
            case 16: {
              size = getParamValue("size", node, tensorMap, context);
              dtype = getParamValue("dtype", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              dynamicSize = getParamValue("dynamicSize", node, tensorMap, context);
              clearAfterRead = getParamValue("clearAfterRead", node, tensorMap, context);
              identicalElementShapes = getParamValue("identicalElementShapes", node, tensorMap, context);
              name = getParamValue("name", node, tensorMap, context);
              tensorArray = new TensorArray(name, dtype, size, elementShape, identicalElementShapes, dynamicSize, clearAfterRead);
              context.addTensorArray(tensorArray);
              return [2, [tensorArray.idTensor, tfc.scalar(1)]];
            }
            case 17: {
              id = getParamValue("tensorArrayId", node, tensorMap, context);
              index = getParamValue("index", node, tensorMap, context);
              writeTensor = getParamValue("tensor", node, tensorMap, context);
              writeTensorArray = context.getTensorArray(id.id);
              writeTensorArray.write(index, writeTensor);
              return [2, [writeTensorArray.idTensor]];
            }
            case 18: {
              readId = getParamValue("tensorArrayId", node, tensorMap, context);
              readIndex = getParamValue("index", node, tensorMap, context);
              readTensorArray = context.getTensorArray(readId.id);
              return [2, [readTensorArray.read(readIndex)]];
            }
            case 19: {
              gatherId = getParamValue("tensorArrayId", node, tensorMap, context);
              gatherIndices = getParamValue("indices", node, tensorMap, context);
              gatherDtype = getParamValue("dtype", node, tensorMap, context);
              gatherTensorArray = context.getTensorArray(gatherId.id);
              return [2, [gatherTensorArray.gather(gatherIndices, gatherDtype)]];
            }
            case 20: {
              scatterId = getParamValue("tensorArrayId", node, tensorMap, context);
              scatterIndices = getParamValue("indices", node, tensorMap, context);
              scatterTensor = getParamValue("tensor", node, tensorMap, context);
              scatterTensorArray = context.getTensorArray(scatterId.id);
              scatterTensorArray.scatter(scatterIndices, scatterTensor);
              return [2, [scatterTensorArray.idTensor]];
            }
            case 21: {
              concatId = getParamValue("tensorArrayId", node, tensorMap, context);
              concatTensorArray = context.getTensorArray(concatId.id);
              concatDtype = getParamValue("dtype", node, tensorMap, context);
              return [2, [concatTensorArray.concat(concatDtype)]];
            }
            case 22: {
              splitId = getParamValue("tensorArrayId", node, tensorMap, context);
              splitTensor = getParamValue("tensor", node, tensorMap, context);
              lengths = getParamValue("lengths", node, tensorMap, context);
              splitTensorArray = context.getTensorArray(splitId.id);
              splitTensorArray.split(lengths, splitTensor);
              return [2, [splitTensorArray.idTensor]];
            }
            case 23: {
              sizeId = getParamValue("tensorArrayId", node, tensorMap, context);
              sizeTensorArray = context.getTensorArray(sizeId.id);
              return [2, [tfc.scalar(sizeTensorArray.size(), "int32")]];
            }
            case 24: {
              closeId = getParamValue("tensorArrayId", node, tensorMap, context);
              closeTensorArray = context.getTensorArray(closeId.id);
              closeTensorArray.clearAndClose();
              return [2, [closeTensorArray.idTensor]];
            }
            case 25: {
              idTensor = getParamValue("tensorListId", node, tensorMap, context);
              index = getParamValue("index", node, tensorMap, context);
              writeTensor = getParamValue("tensor", node, tensorMap, context);
              tensorList = context.getTensorList(idTensor.id);
              tensorList.setItem(index, writeTensor);
              return [2, [tensorList.idTensor]];
            }
            case 26: {
              idTensor = getParamValue("tensorListId", node, tensorMap, context);
              readIndex = getParamValue("index", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              elementDType = getParamValue("elementDType", node, tensorMap, context);
              tensorList = context.getTensorList(idTensor.id);
              return [2, [tensorList.getItem(readIndex, elementShape, elementDType)]];
            }
            case 27: {
              scatterIndices = getParamValue("indices", node, tensorMap, context);
              scatterTensor = getParamValue("tensor", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              numElements = getParamValue("numElements", node, tensorMap, context);
              tensorList = scatter(scatterTensor, scatterIndices, elementShape, numElements);
              context.addTensorList(tensorList);
              return [2, [tensorList.idTensor]];
            }
            case 28: {
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              elementDtype = getParamValue("elementDType", node, tensorMap, context);
              numElementsParam = void 0;
              if (node.op === "TensorListReserve") {
                numElementsParam = "numElements";
              } else {
                numElementsParam = "maxNumElements";
              }
              numElements = getParamValue(numElementsParam, node, tensorMap, context);
              maxNumElements = node.op === "TensorListReserve" ? -1 : numElements;
              tensorList = reserve(elementShape, elementDtype, numElements, maxNumElements);
              context.addTensorList(tensorList);
              return [2, [tensorList.idTensor]];
            }
            case 29: {
              gatherId = getParamValue("tensorListId", node, tensorMap, context);
              gatherIndices = getParamValue("indices", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              elementDtype = getParamValue("elementDType", node, tensorMap, context);
              tensorList = context.getTensorList(gatherId.id);
              return [2, [tensorList.gather(gatherIndices, elementDtype, elementShape)]];
            }
            case 30: {
              idTensor = getParamValue("tensorListId", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              elementDtype = getParamValue("elementDType", node, tensorMap, context);
              numElements = getParamValue("numElements", node, tensorMap, context);
              tensorList = context.getTensorList(idTensor.id);
              return [2, [tensorList.stack(elementShape, elementDtype, numElements)]];
            }
            case 31: {
              tensor2 = getParamValue("tensor", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              elementDtype = getParamValue("elementDType", node, tensorMap, context);
              tensorList = fromTensor(tensor2, elementShape, elementDtype);
              context.addTensorList(tensorList);
              return [2, [tensorList.idTensor]];
            }
            case 32: {
              concatId = getParamValue("tensorListId", node, tensorMap, context);
              tensorList = context.getTensorList(concatId.id);
              concatDtype = getParamValue("dtype", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              return [2, [tensorList.concat(concatDtype, elementShape)]];
            }
            case 33: {
              idTensor = getParamValue("tensorListId", node, tensorMap, context);
              writeTensor = getParamValue("tensor", node, tensorMap, context);
              tensorList = context.getTensorList(idTensor.id);
              tensorList.pushBack(writeTensor);
              return [2, [tensorList.idTensor]];
            }
            case 34: {
              idTensor = getParamValue("tensorListId", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              elementDType = getParamValue("elementDType", node, tensorMap, context);
              tensorList = context.getTensorList(idTensor.id);
              return [2, [tensorList.popBack(elementShape, elementDType)]];
            }
            case 35: {
              splitTensor = getParamValue("tensor", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              lengths = getParamValue("lengths", node, tensorMap, context);
              tensorList = split(splitTensor, lengths, elementShape);
              context.addTensorList(tensorList);
              return [2, [tensorList.idTensor]];
            }
            case 36: {
              idTensor = getParamValue("tensorListId", node, tensorMap, context);
              tensorList = context.getTensorList(idTensor.id);
              return [2, [tfc.scalar(tensorList.size(), "int32")]];
            }
            case 37: {
              idTensor = getParamValue("tensorListId", node, tensorMap, context);
              size = getParamValue("size", node, tensorMap, context);
              srcTensorList = context.getTensorList(idTensor.id);
              destTensorList = srcTensorList.resize(size);
              context.addTensorList(destTensorList);
              return [2, [destTensorList.idTensor]];
            }
            case 38:
              throw TypeError("Node type ".concat(node.op, " is not implemented"));
          }
        });
      });
    };
    function fusedConvAndDepthWiseParams(node, tensorMap, context) {
      var _a = __read(getParamValue("fusedOps", node, tensorMap, context), 2), extraOp = _a[0], activationFunc = _a[1];
      var isBiasAdd = extraOp === "biasadd";
      var noBiasAdd = !isBiasAdd;
      var isPrelu = activationFunc === "prelu";
      var isBatchNorm = extraOp === "fusedbatchnorm";
      var numArgs = getParamValue("numArgs", node, tensorMap, context);
      if (isBiasAdd) {
        if (isPrelu && numArgs !== 2) {
          throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
        }
        if (!isPrelu && isBiasAdd && numArgs !== 1) {
          throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.");
        }
      }
      if (isBatchNorm) {
        throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported");
      }
      var stride = getParamValue("strides", node, tensorMap, context);
      var pad2 = getPadding(node, tensorMap, context);
      var dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
      var dilations = getParamValue("dilations", node, tensorMap, context);
      var _b = __read(getParamValue("args", node, tensorMap, context), 2), biasArg = _b[0], preluArg = _b[1];
      if (noBiasAdd) {
        preluArg = biasArg;
        biasArg = void 0;
      }
      var leakyreluAlpha = getParamValue("leakyreluAlpha", node, tensorMap, context);
      return {
        stride,
        pad: pad2,
        dataFormat,
        dilations,
        biasArg,
        preluArg,
        activationFunc,
        leakyreluAlpha
      };
    }
    var executeOp$h = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "Conv1D": {
          var stride = getParamValue("stride", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
          var dilation = getParamValue("dilation", node, tensorMap, context);
          return [ops.conv1d(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), stride, pad2, dataFormat, dilation)];
        }
        case "Conv2D": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getPadding(node, tensorMap, context);
          var dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
          var dilations = getParamValue("dilations", node, tensorMap, context);
          return [ops.conv2d(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2]], pad2, dataFormat, [dilations[1], dilations[2]])];
        }
        case "_FusedConv2D": {
          var _a = fusedConvAndDepthWiseParams(node, tensorMap, context), stride = _a.stride, pad2 = _a.pad, dataFormat = _a.dataFormat, dilations = _a.dilations, biasArg = _a.biasArg, preluArg = _a.preluArg, activationFunc = _a.activationFunc, leakyreluAlpha = _a.leakyreluAlpha;
          return [ops.fused.conv2d({
            x: getParamValue("x", node, tensorMap, context),
            filter: getParamValue("filter", node, tensorMap, context),
            strides: [stride[1], stride[2]],
            pad: pad2,
            dataFormat,
            dilations: [dilations[1], dilations[2]],
            bias: biasArg,
            activation: activationFunc,
            preluActivationWeights: preluArg,
            leakyreluAlpha
          })];
        }
        case "FusedDepthwiseConv2dNative": {
          var _b = fusedConvAndDepthWiseParams(node, tensorMap, context), stride = _b.stride, pad2 = _b.pad, dataFormat = _b.dataFormat, dilations = _b.dilations, biasArg = _b.biasArg, preluArg = _b.preluArg, activationFunc = _b.activationFunc, leakyreluAlpha = _b.leakyreluAlpha;
          return [ops.fused.depthwiseConv2d({
            x: getParamValue("x", node, tensorMap, context),
            filter: getParamValue("filter", node, tensorMap, context),
            strides: [stride[1], stride[2]],
            pad: pad2,
            dataFormat,
            dilations: [dilations[1], dilations[2]],
            bias: biasArg,
            activation: activationFunc,
            preluActivationWeights: preluArg,
            leakyreluAlpha
          })];
        }
        case "Conv2DBackpropInput":
        case "Conv2dTranspose": {
          var shape = getParamValue("outputShape", node, tensorMap, context);
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getPadding(node, tensorMap, context);
          return [ops.conv2dTranspose(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), shape, [stride[1], stride[2]], pad2)];
        }
        case "DepthwiseConv2dNative":
        case "DepthwiseConv2d": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getPadding(node, tensorMap, context);
          var dilations = getParamValue("dilations", node, tensorMap, context);
          var dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
          return [ops.depthwiseConv2d(getParamValue("input", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2]], pad2, dataFormat, [dilations[1], dilations[2]])];
        }
        case "Conv3D": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
          var dilations = getParamValue("dilations", node, tensorMap, context);
          return [ops.conv3d(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2], stride[3]], pad2, dataFormat, [dilations[1], dilations[2], dilations[3]])];
        }
        case "AvgPool": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var kernelSize = getParamValue("kernelSize", node, tensorMap, context);
          return [ops.avgPool(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad2)];
        }
        case "MaxPool": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var kernelSize = getParamValue("kernelSize", node, tensorMap, context);
          return [ops.maxPool(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad2)];
        }
        case "MaxPoolWithArgmax": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var kernelSize = getParamValue("kernelSize", node, tensorMap, context);
          var includeBatchInIndex = getParamValue("includeBatchInIndex", node, tensorMap, context);
          var _c = ops.maxPoolWithArgmax(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad2, includeBatchInIndex), result = _c.result, indexes = _c.indexes;
          return [result, indexes];
        }
        case "AvgPool3D": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var kernelSize = getParamValue("kernelSize", node, tensorMap, context);
          return [ops.avgPool3d(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2], kernelSize[3]], [stride[1], stride[2], stride[3]], pad2)];
        }
        case "MaxPool3D": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var kernelSize = getParamValue("kernelSize", node, tensorMap, context);
          return [ops.maxPool3d(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2], kernelSize[3]], [stride[1], stride[2], stride[3]], pad2)];
        }
        case "Dilation2D": {
          var strides = getParamValue("strides", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var dilations = getParamValue("dilations", node, tensorMap, context);
          var strideHeight = strides[1];
          var strideWidth = strides[2];
          var dilationHeight = dilations[1];
          var dilationWidth = dilations[2];
          return [ops.dilation2d(
            getParamValue("x", node, tensorMap, context),
            getParamValue("filter", node, tensorMap, context),
            [strideHeight, strideWidth],
            pad2,
            [dilationHeight, dilationWidth],
            "NHWC"
            /* dataFormat */
          )];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$g = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "Fill": {
          var shape = getParamValue("shape", node, tensorMap, context);
          var dtype = getParamValue("dtype", node, tensorMap, context);
          var value = getParamValue("value", node, tensorMap, context);
          return [ops.fill(shape, value, dtype)];
        }
        case "LinSpace": {
          var start = getParamValue("start", node, tensorMap, context);
          var stop = getParamValue("stop", node, tensorMap, context);
          var num = getParamValue("num", node, tensorMap, context);
          return [ops.linspace(start, stop, num)];
        }
        case "Multinomial": {
          var logits = getParamValue("logits", node, tensorMap, context);
          var numSamples = getParamValue("numSamples", node, tensorMap, context);
          var seed = getParamValue("seed", node, tensorMap, context);
          return [ops.multinomial(logits, numSamples, seed)];
        }
        case "OneHot": {
          var indices = getParamValue("indices", node, tensorMap, context);
          var depth = getParamValue("depth", node, tensorMap, context);
          var onValue = getParamValue("onValue", node, tensorMap, context);
          var offValue = getParamValue("offValue", node, tensorMap, context);
          var dtype = getParamValue("dtype", node, tensorMap, context);
          return [ops.oneHot(indices, depth, onValue, offValue, dtype)];
        }
        case "Ones": {
          return [ops.ones(getParamValue("shape", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
        }
        case "OnesLike": {
          return [ops.onesLike(getParamValue("x", node, tensorMap, context))];
        }
        case "RandomStandardNormal": {
          return [ops.randomStandardNormal(getParamValue("shape", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context), getParamValue("seed", node, tensorMap, context))];
        }
        case "RandomUniform": {
          return [ops.randomUniform(
            // tslint:disable-next-line:no-any
            getParamValue("shape", node, tensorMap, context),
            getParamValue("minval", node, tensorMap, context),
            getParamValue("maxval", node, tensorMap, context),
            getParamValue("dtype", node, tensorMap, context)
          )];
        }
        case "RandomUniformInt": {
          return [ops.randomUniformInt(getParamValue("shape", node, tensorMap, context), getParamValue("minval", node, tensorMap, context), getParamValue("maxval", node, tensorMap, context), getParamValue("seed", node, tensorMap, context))];
        }
        case "Range": {
          var start = getParamValue("start", node, tensorMap, context);
          var stop = getParamValue("stop", node, tensorMap, context);
          var step2 = getParamValue("step", node, tensorMap, context);
          return [ops.range(start, stop, step2, getParamValue("dtype", node, tensorMap, context))];
        }
        case "TruncatedNormal": {
          var shape = getParamValue("shape", node, tensorMap, context);
          var mean2 = getParamValue("mean", node, tensorMap, context);
          var stdDev = getParamValue("stdDev", node, tensorMap, context);
          var seed = getParamValue("seed", node, tensorMap, context);
          return [ops.truncatedNormal(shape, mean2, stdDev, getParamValue("dtype", node, tensorMap, context), seed)];
        }
        case "Zeros": {
          return [ops.zeros(getParamValue("shape", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
        }
        case "ZerosLike": {
          return [ops.zerosLike(getParamValue("x", node, tensorMap, context))];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    function nmsParams(node, tensorMap, context) {
      var boxes = getParamValue("boxes", node, tensorMap, context);
      var scores = getParamValue("scores", node, tensorMap, context);
      var maxOutputSize = getParamValue("maxOutputSize", node, tensorMap, context);
      var iouThreshold = getParamValue("iouThreshold", node, tensorMap, context);
      var scoreThreshold = getParamValue("scoreThreshold", node, tensorMap, context);
      var softNmsSigma = getParamValue("softNmsSigma", node, tensorMap, context);
      return {
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        softNmsSigma
      };
    }
    var executeOp$f = function(node, tensorMap, context, resourceManager, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      return __awaiter(void 0, void 0, void 0, function() {
        var _a, _b, boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, result, _c, boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize, result, _d, boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, condition, result;
        return __generator(this, function(_e) {
          switch (_e.label) {
            case 0:
              _a = node.op;
              switch (_a) {
                case "NonMaxSuppressionV5":
                  return [3, 1];
                case "NonMaxSuppressionV4":
                  return [3, 3];
                case "NonMaxSuppressionV3":
                  return [3, 5];
                case "NonMaxSuppressionV2":
                  return [3, 5];
                case "Where":
                  return [3, 7];
                case "ListDiff":
                  return [3, 9];
              }
              return [3, 10];
            case 1:
              _b = nmsParams(node, tensorMap, context), boxes = _b.boxes, scores = _b.scores, maxOutputSize = _b.maxOutputSize, iouThreshold = _b.iouThreshold, scoreThreshold = _b.scoreThreshold, softNmsSigma = _b.softNmsSigma;
              return [4, ops.image.nonMaxSuppressionWithScoreAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma)];
            case 2:
              result = _e.sent();
              return [2, [result.selectedIndices, result.selectedScores]];
            case 3:
              _c = nmsParams(node, tensorMap, context), boxes = _c.boxes, scores = _c.scores, maxOutputSize = _c.maxOutputSize, iouThreshold = _c.iouThreshold, scoreThreshold = _c.scoreThreshold;
              padToMaxOutputSize = getParamValue("padToMaxOutputSize", node, tensorMap, context);
              return [4, ops.image.nonMaxSuppressionPaddedAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize)];
            case 4:
              result = _e.sent();
              return [2, [result.selectedIndices, result.validOutputs]];
            case 5:
              _d = nmsParams(node, tensorMap, context), boxes = _d.boxes, scores = _d.scores, maxOutputSize = _d.maxOutputSize, iouThreshold = _d.iouThreshold, scoreThreshold = _d.scoreThreshold;
              return [4, ops.image.nonMaxSuppressionAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold)];
            case 6:
              return [2, [_e.sent()]];
            case 7:
              condition = ops.cast(getParamValue("condition", node, tensorMap, context), "bool");
              return [4, ops.whereAsync(condition)];
            case 8:
              result = [_e.sent()];
              condition.dispose();
              return [2, result];
            case 9: {
              return [2, ops.setdiff1dAsync(getParamValue("x", node, tensorMap, context), getParamValue("y", node, tensorMap, context))];
            }
            case 10:
              throw TypeError("Node type ".concat(node.op, " is not implemented"));
          }
        });
      });
    };
    var executeOp$e = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "LowerBound": {
          var sortedSequence = getParamValue("sortedSequence", node, tensorMap, context);
          var values = getParamValue("values", node, tensorMap, context);
          return [ops.lowerBound(sortedSequence, values)];
        }
        case "TopKV2": {
          var x = getParamValue("x", node, tensorMap, context);
          var k = getParamValue("k", node, tensorMap, context);
          var sorted = getParamValue("sorted", node, tensorMap, context);
          var result = ops.topk(x, k, sorted);
          return [result.values, result.indices];
        }
        case "UpperBound": {
          var sortedSequence = getParamValue("sortedSequence", node, tensorMap, context);
          var values = getParamValue("values", node, tensorMap, context);
          return [ops.upperBound(sortedSequence, values)];
        }
        case "Unique": {
          var x = getParamValue("x", node, tensorMap, context);
          var result = ops.unique(x);
          return [result.values, result.indices];
        }
        case "UniqueV2": {
          var x = getParamValue("x", node, tensorMap, context);
          var axis = getParamValue("axis", node, tensorMap, context);
          var result = ops.unique(x, axis);
          return [result.values, result.indices];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$d = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "Const": {
          return tensorMap[node.name];
        }
        case "PlaceholderWithDefault":
          var def = getParamValue("default", node, tensorMap, context);
          return [getTensor(node.name, tensorMap, context) || def];
        case "Placeholder":
          return [getTensor(node.name, tensorMap, context)];
        case "Identity":
        case "StopGradient":
        case "FakeQuantWithMinMaxVars": {
          var data_1 = getParamValue("x", node, tensorMap, context);
          return [cloneTensor(data_1)];
        }
        case "IdentityN":
          return getParamValue("x", node, tensorMap, context).map(function(t) {
            return cloneTensor(t);
          });
        case "Snapshot":
          var snapshot = getParamValue("x", node, tensorMap, context);
          return [cloneTensor(snapshot)];
        case "Shape":
          return [ops.tensor1d(getParamValue("x", node, tensorMap, context).shape, "int32")];
        case "ShapeN":
          return getParamValue("x", node, tensorMap, context).map(function(t) {
            return ops.tensor1d(t.shape);
          });
        case "Size":
          return [ops.scalar(getParamValue("x", node, tensorMap, context).size, "int32")];
        case "Rank":
          return [ops.scalar(getParamValue("x", node, tensorMap, context).rank, "int32")];
        case "NoOp":
          return [ops.scalar(1)];
        case "Print":
          var input = getParamValue("x", node, tensorMap, context);
          var data = getParamValue("data", node, tensorMap, context);
          var message = getParamValue("message", node, tensorMap, context);
          var summarize = getParamValue("summarize", node, tensorMap, context);
          console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance.");
          console.log(message);
          for (var i = 0; i < data.length; i++) {
            console.log(Array.prototype.slice.call(data[i].dataSync()).slice(0, summarize));
          }
          return [input];
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var HashTable = (
      /** @class */
      function() {
        function HashTable2(keyDType, valueDType) {
          this.keyDType = keyDType;
          this.valueDType = valueDType;
          this.handle = tfc.scalar(0);
          this.tensorMap = /* @__PURE__ */ new Map();
          tfc.keep(this.handle);
        }
        Object.defineProperty(HashTable2.prototype, "id", {
          get: function() {
            return this.handle.id;
          },
          enumerable: false,
          configurable: true
        });
        HashTable2.prototype.clearAndClose = function() {
          this.tensorMap.forEach(function(value) {
            return value.dispose();
          });
          this.tensorMap.clear();
          this.handle.dispose();
        };
        HashTable2.prototype.size = function() {
          return this.tensorMap.size;
        };
        HashTable2.prototype.tensorSize = function() {
          return scalar(this.size(), "int32");
        };
        HashTable2.prototype.import = function(keys, values) {
          return __awaiter(this, void 0, void 0, function() {
            var $keys;
            var _this = this;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  this.checkKeyAndValueTensor(keys, values);
                  return [4, keys.data()];
                case 1:
                  $keys = _a.sent();
                  this.tensorMap.forEach(function(value) {
                    return value.dispose();
                  });
                  this.tensorMap.clear();
                  return [2, tfc.tidy(function() {
                    var $values = tfc.unstack(values);
                    var keysLength = $keys.length;
                    var valuesLength = $values.length;
                    tfc.util.assert(keysLength === valuesLength, function() {
                      return "The number of elements doesn't match, keys has " + "".concat(keysLength, " elements, the values has ").concat(valuesLength, " ") + "elements.";
                    });
                    for (var i = 0; i < keysLength; i++) {
                      var key = $keys[i];
                      var value = $values[i];
                      tfc.keep(value);
                      _this.tensorMap.set(key, value);
                    }
                    return _this.handle;
                  })];
              }
            });
          });
        };
        HashTable2.prototype.find = function(keys, defaultValue) {
          return __awaiter(this, void 0, void 0, function() {
            var $keys;
            var _this = this;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  this.checkKeyAndValueTensor(keys, defaultValue);
                  return [4, keys.data()];
                case 1:
                  $keys = _a.sent();
                  return [2, tfc.tidy(function() {
                    var result = [];
                    for (var i = 0; i < $keys.length; i++) {
                      var key = $keys[i];
                      var value = _this.findWithDefault(key, defaultValue);
                      result.push(value);
                    }
                    return tfc.stack(result);
                  })];
              }
            });
          });
        };
        HashTable2.prototype.findWithDefault = function(key, defaultValue) {
          var result = this.tensorMap.get(key);
          return result != null ? result : defaultValue;
        };
        HashTable2.prototype.checkKeyAndValueTensor = function(key, value) {
          if (key.dtype !== this.keyDType) {
            throw new Error("Expect key dtype ".concat(this.keyDType, ", but got ") + "".concat(key.dtype));
          }
          if (value.dtype !== this.valueDType) {
            throw new Error("Expect value dtype ".concat(this.valueDType, ", but got ") + "".concat(value.dtype));
          }
        };
        return HashTable2;
      }()
    );
    var executeOp$c = function(node, tensorMap, context, resourceManager) {
      return __awaiter(void 0, void 0, void 0, function() {
        var _a, existingTableHandle, keyDType, valueDType, hashTable2, handle, keys, values, hashTable2, handle, keys, defaultValue, hashTable2, handle, hashTable2;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              _a = node.op;
              switch (_a) {
                case "HashTable":
                  return [3, 1];
                case "HashTableV2":
                  return [3, 1];
                case "InitializeTable":
                  return [3, 2];
                case "InitializeTableV2":
                  return [3, 2];
                case "LookupTableImport":
                  return [3, 2];
                case "LookupTableImportV2":
                  return [3, 2];
                case "LookupTableFind":
                  return [3, 4];
                case "LookupTableFindV2":
                  return [3, 4];
                case "LookupTableSize":
                  return [3, 6];
                case "LookupTableSizeV2":
                  return [3, 6];
              }
              return [3, 7];
            case 1: {
              existingTableHandle = resourceManager.getHashTableHandleByName(node.name);
              if (existingTableHandle != null) {
                return [2, [existingTableHandle]];
              } else {
                keyDType = getParamValue("keyDType", node, tensorMap, context);
                valueDType = getParamValue("valueDType", node, tensorMap, context);
                hashTable2 = new HashTable(keyDType, valueDType);
                resourceManager.addHashTable(node.name, hashTable2);
                return [2, [hashTable2.handle]];
              }
            }
            case 2:
              handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
              keys = getParamValue("keys", node, tensorMap, context);
              values = getParamValue("values", node, tensorMap, context);
              hashTable2 = resourceManager.getHashTableById(handle.id);
              return [4, hashTable2.import(keys, values)];
            case 3:
              return [2, [_b.sent()]];
            case 4:
              handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
              keys = getParamValue("keys", node, tensorMap, context);
              defaultValue = getParamValue("defaultValue", node, tensorMap, context);
              hashTable2 = resourceManager.getHashTableById(handle.id);
              return [4, hashTable2.find(keys, defaultValue)];
            case 5:
              return [2, [_b.sent()]];
            case 6: {
              handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
              hashTable2 = resourceManager.getHashTableById(handle.id);
              return [2, [hashTable2.tensorSize()]];
            }
            case 7:
              throw TypeError("Node type ".concat(node.op, " is not implemented"));
          }
        });
      });
    };
    var executeOp$b = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "ResizeBilinear": {
          var images = getParamValue("images", node, tensorMap, context);
          var size = getParamValue("size", node, tensorMap, context);
          var alignCorners = getParamValue("alignCorners", node, tensorMap, context);
          var halfPixelCenters = getParamValue("halfPixelCenters", node, tensorMap, context);
          return [ops.image.resizeBilinear(images, [size[0], size[1]], alignCorners, halfPixelCenters)];
        }
        case "ResizeNearestNeighbor": {
          var images = getParamValue("images", node, tensorMap, context);
          var size = getParamValue("size", node, tensorMap, context);
          var alignCorners = getParamValue("alignCorners", node, tensorMap, context);
          var halfPixelCenters = getParamValue("halfPixelCenters", node, tensorMap, context);
          return [ops.image.resizeNearestNeighbor(images, [size[0], size[1]], alignCorners, halfPixelCenters)];
        }
        case "CropAndResize": {
          var image2 = getParamValue("image", node, tensorMap, context);
          var boxes = getParamValue("boxes", node, tensorMap, context);
          var boxInd = getParamValue("boxInd", node, tensorMap, context);
          var cropSize = getParamValue("cropSize", node, tensorMap, context);
          var method = getParamValue("method", node, tensorMap, context);
          var extrapolationValue = getParamValue("extrapolationValue", node, tensorMap, context);
          return [ops.image.cropAndResize(image2, boxes, boxInd, cropSize, method, extrapolationValue)];
        }
        case "ImageProjectiveTransformV3": {
          var images = getParamValue("images", node, tensorMap, context);
          var transforms = getParamValue("transforms", node, tensorMap, context);
          var outputShape = getParamValue("outputShape", node, tensorMap, context);
          var fillValue = getParamValue("fillValue", node, tensorMap, context);
          var interpolation = getParamValue("interpolation", node, tensorMap, context);
          var fillMode = getParamValue("fillMode", node, tensorMap, context);
          return [ops.image.transform(images, transforms, interpolation.toLowerCase(), fillMode.toLowerCase(), fillValue, outputShape)];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$a = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "Equal": {
          return [ops.equal(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "NotEqual": {
          return [ops.notEqual(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "Greater": {
          return [ops.greater(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "GreaterEqual": {
          return [ops.greaterEqual(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "Less": {
          return [ops.less(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "LessEqual": {
          return [ops.lessEqual(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "LogicalAnd": {
          return [ops.logicalAnd(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "LogicalNot": {
          return [ops.logicalNot(getParamValue("a", node, tensorMap, context))];
        }
        case "LogicalOr": {
          return [ops.logicalOr(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "Select":
        case "SelectV2": {
          return [ops.where(getParamValue("condition", node, tensorMap, context), getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "BitwiseAnd": {
          return [ops.bitwiseAnd(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$9 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "BatchMatMul":
        case "BatchMatMulV2":
        case "MatMul":
          return [ops.matMul(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context), getParamValue("transposeA", node, tensorMap, context), getParamValue("transposeB", node, tensorMap, context))];
        case "Einsum":
          return [ops.einsum.apply(ops, __spreadArray([getParamValue("equation", node, tensorMap, context)], __read(getParamValue("tensors", node, tensorMap, context)), false))];
        case "Transpose":
          return [ops.transpose(getParamValue("x", node, tensorMap, context), getParamValue("perm", node, tensorMap, context))];
        case "_FusedMatMul":
          var _a = __read(getParamValue("fusedOps", node, tensorMap, context), 2), extraOp = _a[0], activationFunc = _a[1];
          var isBiasAdd = extraOp === "biasadd";
          var isPrelu = activationFunc === "prelu";
          var numArgs = getParamValue("numArgs", node, tensorMap, context);
          var leakyreluAlpha = getParamValue("leakyreluAlpha", node, tensorMap, context);
          if (isBiasAdd) {
            if (isPrelu && numArgs !== 2) {
              throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
            }
            if (!isPrelu && numArgs !== 1) {
              throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.");
            }
          }
          var _b = __read(getParamValue("args", node, tensorMap, context), 2), biasArg = _b[0], preluArg = _b[1];
          return [ops.fused.matMul({
            a: getParamValue("a", node, tensorMap, context),
            b: getParamValue("b", node, tensorMap, context),
            transposeA: getParamValue("transposeA", node, tensorMap, context),
            transposeB: getParamValue("transposeB", node, tensorMap, context),
            bias: biasArg,
            activation: activationFunc,
            preluActivationWeights: preluArg,
            leakyreluAlpha
          })];
        case "MatrixBandPart":
          return [ops.linalg.bandPart(getParamValue("a", node, tensorMap, context), getParamValue("numLower", node, tensorMap, context), getParamValue("numUpper", node, tensorMap, context))];
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$8 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "EuclideanNorm":
          return [ops.euclideanNorm(getParamValue("x", node, tensorMap, context), getParamValue("axis", node, tensorMap, context), getParamValue("keepDims", node, tensorMap, context))];
        case "FusedBatchNorm":
        case "FusedBatchNormV2": {
          return [ops.batchNorm(getParamValue("x", node, tensorMap, context), getParamValue("mean", node, tensorMap, context), getParamValue("variance", node, tensorMap, context), getParamValue("offset", node, tensorMap, context), getParamValue("scale", node, tensorMap, context), getParamValue("epsilon", node, tensorMap, context))];
        }
        case "FusedBatchNormV3": {
          return [ops.batchNorm(getParamValue("x", node, tensorMap, context), getParamValue("mean", node, tensorMap, context), getParamValue("variance", node, tensorMap, context), getParamValue("offset", node, tensorMap, context), getParamValue("scale", node, tensorMap, context), getParamValue("epsilon", node, tensorMap, context))];
        }
        case "LRN": {
          return [ops.localResponseNormalization(getParamValue("x", node, tensorMap, context), getParamValue("radius", node, tensorMap, context), getParamValue("bias", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context), getParamValue("beta", node, tensorMap, context))];
        }
        case "Softmax": {
          return [ops.softmax(getParamValue("x", node, tensorMap, context))];
        }
        case "LogSoftmax": {
          return [ops.logSoftmax(getParamValue("x", node, tensorMap, context))];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$7 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "RaggedGather": {
          var _a = ops.raggedGather(getParamValue("paramsNestedSplits", node, tensorMap, context), getParamValue("paramsDenseValues", node, tensorMap, context), getParamValue("indices", node, tensorMap, context), getParamValue("outputRaggedRank", node, tensorMap, context)), outputNestedSplits = _a.outputNestedSplits, outputDenseValues = _a.outputDenseValues;
          return outputNestedSplits.concat(outputDenseValues);
        }
        case "RaggedRange": {
          var _b = ops.raggedRange(getParamValue("starts", node, tensorMap, context), getParamValue("limits", node, tensorMap, context), getParamValue("splits", node, tensorMap, context)), rtNestedSplits = _b.rtNestedSplits, rtDenseValues = _b.rtDenseValues;
          return [rtNestedSplits, rtDenseValues];
        }
        case "RaggedTensorToTensor": {
          return [ops.raggedTensorToTensor(getParamValue("shape", node, tensorMap, context), getParamValue("values", node, tensorMap, context), getParamValue("defaultValue", node, tensorMap, context), getParamValue("rowPartitionTensors", node, tensorMap, context), getParamValue("rowPartitionTypes", node, tensorMap, context))];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$6 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "Max": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var keepDims = getParamValue("keepDims", node, tensorMap, context);
          return [ops.max(getParamValue("x", node, tensorMap, context), axis, keepDims)];
        }
        case "Mean": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var keepDims = getParamValue("keepDims", node, tensorMap, context);
          return [ops.mean(getParamValue("x", node, tensorMap, context), axis, keepDims)];
        }
        case "Min": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var keepDims = getParamValue("keepDims", node, tensorMap, context);
          return [ops.min(getParamValue("x", node, tensorMap, context), axis, keepDims)];
        }
        case "Sum": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var keepDims = getParamValue("keepDims", node, tensorMap, context);
          return [ops.sum(getParamValue("x", node, tensorMap, context), axis, keepDims)];
        }
        case "All": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var keepDims = getParamValue("keepDims", node, tensorMap, context);
          return [ops.all(getParamValue("x", node, tensorMap, context), axis, keepDims)];
        }
        case "Any": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var keepDims = getParamValue("keepDims", node, tensorMap, context);
          return [ops.any(getParamValue("x", node, tensorMap, context), axis, keepDims)];
        }
        case "ArgMax": {
          var axis = getParamValue("axis", node, tensorMap, context);
          return [ops.argMax(getParamValue("x", node, tensorMap, context), axis)];
        }
        case "ArgMin": {
          var axis = getParamValue("axis", node, tensorMap, context);
          return [ops.argMin(getParamValue("x", node, tensorMap, context), axis)];
        }
        case "Prod": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var keepDims = getParamValue("keepDims", node, tensorMap, context);
          return [ops.prod(getParamValue("x", node, tensorMap, context), axis, keepDims)];
        }
        case "Cumprod": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var exclusive = getParamValue("exclusive", node, tensorMap, context);
          var reverse2 = getParamValue("reverse", node, tensorMap, context);
          return [ops.cumprod(getParamValue("x", node, tensorMap, context), axis, exclusive, reverse2)];
        }
        case "Cumsum": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var exclusive = getParamValue("exclusive", node, tensorMap, context);
          var reverse2 = getParamValue("reverse", node, tensorMap, context);
          return [ops.cumsum(getParamValue("x", node, tensorMap, context), axis, exclusive, reverse2)];
        }
        case "Bincount":
          var x = getParamValue("x", node, tensorMap, context);
          var weights = getParamValue("weights", node, tensorMap, context);
          var size = getParamValue("size", node, tensorMap, context);
          return [ops.bincount(x, weights, size)];
        case "DenseBincount": {
          var x_1 = getParamValue("x", node, tensorMap, context);
          var weights_1 = getParamValue("weights", node, tensorMap, context);
          var size_1 = getParamValue("size", node, tensorMap, context);
          var binaryOutput = getParamValue("binaryOutput", node, tensorMap, context);
          return [ops.denseBincount(x_1, weights_1, size_1, binaryOutput)];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$5 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "ConcatV2":
        case "Concat": {
          var n = getParamValue("n", node, tensorMap, context);
          var axis = getParamValue("axis", node, tensorMap, context);
          var inputs = getParamValue("tensors", node, tensorMap, context);
          inputs = inputs.slice(0, n);
          return [ops.concat(inputs, axis)];
        }
        case "Gather": {
          var input = getParamValue("x", node, tensorMap, context);
          var indices = getParamValue("indices", node, tensorMap, context);
          return [ops.gather(input, ops.cast(indices, "int32"), 0)];
        }
        case "GatherV2": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var batchDims = getParamValue("batchDims", node, tensorMap, context);
          var input = getParamValue("x", node, tensorMap, context);
          var indices = getParamValue("indices", node, tensorMap, context);
          return [ops.gather(input, ops.cast(indices, "int32"), axis, batchDims)];
        }
        case "Reverse": {
          var dims = getParamValue("dims", node, tensorMap, context);
          var axis = [];
          for (var i = 0; i < dims.length; i++) {
            if (dims[i]) {
              axis.push(i);
            }
          }
          var input = getParamValue("x", node, tensorMap, context);
          return [ops.reverse(input, axis)];
        }
        case "ReverseV2": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var input = getParamValue("x", node, tensorMap, context);
          return [ops.reverse(input, axis)];
        }
        case "Slice": {
          var begin = getParamValue("begin", node, tensorMap, context);
          var size = getParamValue("size", node, tensorMap, context);
          return [ops.slice(getParamValue("x", node, tensorMap, context), begin, size)];
        }
        case "StridedSlice": {
          var begin = getParamValue("begin", node, tensorMap, context);
          var end = getParamValue("end", node, tensorMap, context);
          var strides = getParamValue("strides", node, tensorMap, context);
          var beginMask = getParamValue("beginMask", node, tensorMap, context);
          var endMask = getParamValue("endMask", node, tensorMap, context);
          var ellipsisMask = getParamValue("ellipsisMask", node, tensorMap, context);
          var newAxisMask = getParamValue("newAxisMask", node, tensorMap, context);
          var shrinkAxisMask = getParamValue("shrinkAxisMask", node, tensorMap, context);
          var tensor2 = getParamValue("x", node, tensorMap, context);
          return [ops.stridedSlice(tensor2, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask)];
        }
        case "Pack": {
          return tfc.tidy(function() {
            var axis2 = getParamValue("axis", node, tensorMap, context);
            var tensors = getParamValue("tensors", node, tensorMap, context);
            var shape2 = tensors[0].shape;
            var squeezedShape = ops.squeeze(tensors[0]).shape;
            var mapped = tensors.map(function(tensor3) {
              var sameShape = tfc.util.arraysEqual(tensor3.shape, shape2);
              if (!sameShape && !tfc.util.arraysEqual(ops.squeeze(tensor3).shape, squeezedShape)) {
                throw new Error("the input tensors shape does not match");
              }
              return sameShape ? tensor3 : ops.reshape(tensor3, shape2);
            });
            return [ops.stack(mapped, axis2)];
          });
        }
        case "Unpack": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var tensor2 = getParamValue("tensor", node, tensorMap, context);
          return ops.unstack(tensor2, axis);
        }
        case "Tile": {
          var reps = getParamValue("reps", node, tensorMap, context);
          return [ops.tile(getParamValue("x", node, tensorMap, context), reps)];
        }
        case "Split":
        case "SplitV": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var numOrSizeSplits = getParamValue("numOrSizeSplits", node, tensorMap, context);
          var tensor2 = getParamValue("x", node, tensorMap, context);
          return ops.split(tensor2, numOrSizeSplits, axis);
        }
        case "ScatterNd": {
          var indices = getParamValue("indices", node, tensorMap, context);
          var values = getParamValue("values", node, tensorMap, context);
          var shape = getParamValue("shape", node, tensorMap, context);
          return [ops.scatterND(indices, values, shape)];
        }
        case "GatherNd": {
          var x = getParamValue("x", node, tensorMap, context);
          var indices = getParamValue("indices", node, tensorMap, context);
          return [ops.gatherND(x, indices)];
        }
        case "SparseToDense": {
          var indices = getParamValue("sparseIndices", node, tensorMap, context);
          var shape = getParamValue("outputShape", node, tensorMap, context);
          var sparseValues = getParamValue("sparseValues", node, tensorMap, context);
          var defaultValue = getParamValue("defaultValue", node, tensorMap, context);
          return [ops.sparseToDense(indices, sparseValues, shape, sparseValues.dtype === defaultValue.dtype ? defaultValue : ops.cast(defaultValue, sparseValues.dtype))];
        }
        case "TensorScatterUpdate": {
          var indices = getParamValue("indices", node, tensorMap, context);
          var values = getParamValue("values", node, tensorMap, context);
          var tensor2 = getParamValue("tensor", node, tensorMap, context);
          return [ops.tensorScatterUpdate(tensor2, indices, values)];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$4 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "SparseFillEmptyRows": {
          var _a = ops.sparse.sparseFillEmptyRows(getParamValue("indices", node, tensorMap, context), getParamValue("values", node, tensorMap, context), getParamValue("denseShape", node, tensorMap, context), getParamValue("defaultValue", node, tensorMap, context)), outputIndices = _a.outputIndices, outputValues = _a.outputValues, emptyRowIndicator = _a.emptyRowIndicator, reverseIndexMap = _a.reverseIndexMap;
          return [
            outputIndices,
            outputValues,
            emptyRowIndicator,
            reverseIndexMap
          ];
        }
        case "SparseReshape": {
          var _b = ops.sparse.sparseReshape(getParamValue("inputIndices", node, tensorMap, context), getParamValue("inputShape", node, tensorMap, context), getParamValue("newShape", node, tensorMap, context)), outputIndices = _b.outputIndices, outputShape = _b.outputShape;
          return [outputIndices, outputShape];
        }
        case "SparseSegmentMean": {
          var outputData = ops.sparse.sparseSegmentMean(getParamValue("data", node, tensorMap, context), getParamValue("indices", node, tensorMap, context), getParamValue("segmentIds", node, tensorMap, context));
          return [outputData];
        }
        case "SparseSegmentSum": {
          var outputData = ops.sparse.sparseSegmentSum(getParamValue("data", node, tensorMap, context), getParamValue("indices", node, tensorMap, context), getParamValue("segmentIds", node, tensorMap, context));
          return [outputData];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$3 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "FFT": {
          return [ops.fft(getParamValue("x", node, tensorMap, context))];
        }
        case "IFFT": {
          return [ops.ifft(getParamValue("x", node, tensorMap, context))];
        }
        case "RFFT": {
          return [ops.rfft(getParamValue("x", node, tensorMap, context))];
        }
        case "IRFFT": {
          return [ops.irfft(getParamValue("x", node, tensorMap, context))];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$2 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "StaticRegexReplace": {
          return [ops.string.staticRegexReplace(getParamValue("input", node, tensorMap, context), getParamValue("pattern", node, tensorMap, context), getParamValue("rewrite", node, tensorMap, context), getParamValue("replaceGlobal", node, tensorMap, context))];
        }
        case "StringNGrams": {
          var _a = ops.string.stringNGrams(getParamValue("data", node, tensorMap, context), getParamValue("dataSplits", node, tensorMap, context), getParamValue("separator", node, tensorMap, context), getParamValue("nGramWidths", node, tensorMap, context), getParamValue("leftPad", node, tensorMap, context), getParamValue("rightPad", node, tensorMap, context), getParamValue("padWidth", node, tensorMap, context), getParamValue("preserveShortSequences", node, tensorMap, context)), nGrams = _a.nGrams, nGramsSplits = _a.nGramsSplits;
          return [nGrams, nGramsSplits];
        }
        case "StringSplit": {
          var _b = ops.string.stringSplit(getParamValue("input", node, tensorMap, context), getParamValue("delimiter", node, tensorMap, context), getParamValue("skipEmpty", node, tensorMap, context)), indices = _b.indices, values = _b.values, shape = _b.shape;
          return [indices, values, shape];
        }
        case "StringToHashBucketFast": {
          var output = ops.string.stringToHashBucketFast(getParamValue("input", node, tensorMap, context), getParamValue("numBuckets", node, tensorMap, context));
          return [output];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$1 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "Cast": {
          return [ops.cast(getParamValue("x", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
        }
        case "ExpandDims": {
          var axis = getParamValue("axis", node, tensorMap, context);
          return [ops.expandDims(getParamValue("x", node, tensorMap, context), axis)];
        }
        case "Squeeze": {
          var axis = getParamValue("axis", node, tensorMap, context);
          return [ops.squeeze(getParamValue("x", node, tensorMap, context), axis)];
        }
        case "Reshape": {
          return [ops.reshape(getParamValue("x", node, tensorMap, context), getParamValue("shape", node, tensorMap, context))];
        }
        case "EnsureShape": {
          return [ops.ensureShape(getParamValue("x", node, tensorMap, context), getParamValue("shape", node, tensorMap, context))];
        }
        case "MirrorPad": {
          return [ops.mirrorPad(getParamValue("x", node, tensorMap, context), getParamValue("padding", node, tensorMap, context), getParamValue("mode", node, tensorMap, context))];
        }
        case "PadV2":
        case "Pad": {
          return [ops.pad(getParamValue("x", node, tensorMap, context), getParamValue("padding", node, tensorMap, context), getParamValue("constantValue", node, tensorMap, context))];
        }
        case "SpaceToBatchND": {
          var blockShape = getParamValue("blockShape", node, tensorMap, context);
          var paddings = getParamValue("paddings", node, tensorMap, context);
          return [ops.spaceToBatchND(getParamValue("x", node, tensorMap, context), blockShape, paddings)];
        }
        case "BatchToSpaceND": {
          var blockShape = getParamValue("blockShape", node, tensorMap, context);
          var crops = getParamValue("crops", node, tensorMap, context);
          return [ops.batchToSpaceND(getParamValue("x", node, tensorMap, context), blockShape, crops)];
        }
        case "DepthToSpace": {
          var blockSize = getParamValue("blockSize", node, tensorMap, context);
          var dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
          return [ops.depthToSpace(getParamValue("x", node, tensorMap, context), blockSize, dataFormat)];
        }
        case "BroadcastTo": {
          return [ops.broadcastTo(getParamValue("x", node, tensorMap, context), getParamValue("shape", node, tensorMap, context))];
        }
        case "BroadcastArgs": {
          return [ops.broadcastArgs(getParamValue("s0", node, tensorMap, context), getParamValue("s1", node, tensorMap, context))];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    function executeOp(node, tensorMap, context, resourceManager, tidy2) {
      if (tidy2 === void 0) {
        tidy2 = tfc__namespace.tidy;
      }
      var value = function(node2, tensorMap2, context2) {
        switch (node2.category) {
          case "arithmetic":
            return tidy2(function() {
              return executeOp$k(node2, tensorMap2, context2);
            });
          case "basic_math":
            return tidy2(function() {
              return executeOp$j(node2, tensorMap2, context2);
            });
          case "control":
            return executeOp$i(node2, tensorMap2, context2);
          case "convolution":
            return tidy2(function() {
              return executeOp$h(node2, tensorMap2, context2);
            });
          case "creation":
            return tidy2(function() {
              return executeOp$g(node2, tensorMap2, context2);
            });
          case "dynamic":
            return executeOp$f(node2, tensorMap2, context2);
          case "evaluation":
            return tidy2(function() {
              return executeOp$e(node2, tensorMap2, context2);
            });
          case "image":
            return tidy2(function() {
              return executeOp$b(node2, tensorMap2, context2);
            });
          case "graph":
            return tidy2(function() {
              return executeOp$d(node2, tensorMap2, context2);
            });
          case "logical":
            return tidy2(function() {
              return executeOp$a(node2, tensorMap2, context2);
            });
          case "matrices":
            return tidy2(function() {
              return executeOp$9(node2, tensorMap2, context2);
            });
          case "normalization":
            return tidy2(function() {
              return executeOp$8(node2, tensorMap2, context2);
            });
          case "ragged":
            return tidy2(function() {
              return executeOp$7(node2, tensorMap2, context2);
            });
          case "reduction":
            return tidy2(function() {
              return executeOp$6(node2, tensorMap2, context2);
            });
          case "slice_join":
            return tidy2(function() {
              return executeOp$5(node2, tensorMap2, context2);
            });
          case "sparse":
            return tidy2(function() {
              return executeOp$4(node2, tensorMap2, context2);
            });
          case "spectral":
            return tidy2(function() {
              return executeOp$3(node2, tensorMap2, context2);
            });
          case "string":
            return tidy2(function() {
              return executeOp$2(node2, tensorMap2, context2);
            });
          case "transformation":
            return tidy2(function() {
              return executeOp$1(node2, tensorMap2, context2);
            });
          case "hash_table":
            return executeOp$c(node2, tensorMap2, context2, resourceManager);
          case "custom":
            var opMapper = getRegisteredOp(node2.op);
            if (opMapper && opMapper.customExecutor) {
              return opMapper.customExecutor(new NodeValueImpl(node2, tensorMap2, context2));
            } else {
              throw TypeError("Custom op ".concat(node2.op, " is not registered."));
            }
          default:
            throw TypeError("Unknown op '".concat(node2.op, "'. File an issue at ") + "https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()");
        }
      }(node, tensorMap, context);
      if (tfc__namespace.util.isPromise(value)) {
        return value.then(function(data) {
          return [].concat(data);
        });
      }
      return [].concat(value);
    }
    var ExecutionContext = (
      /** @class */
      function() {
        function ExecutionContext2(weightMap, tensorArrayMap, tensorListMap, functionMap, parseNodeNameCache) {
          if (weightMap === void 0) {
            weightMap = {};
          }
          if (tensorArrayMap === void 0) {
            tensorArrayMap = {};
          }
          if (tensorListMap === void 0) {
            tensorListMap = {};
          }
          if (functionMap === void 0) {
            functionMap = {};
          }
          this.weightMap = weightMap;
          this.tensorArrayMap = tensorArrayMap;
          this.tensorListMap = tensorListMap;
          this.functionMap = functionMap;
          this.parseNodeNameCache = parseNodeNameCache;
          this.rootContext = { id: 0, frameName: "", iterationId: 0 };
          this.contexts = [this.rootContext];
          this.lastId = 0;
          this.generateCurrentContextIds();
        }
        ExecutionContext2.prototype.newFrame = function(id, frameName) {
          return { id, frameName, iterationId: 0 };
        };
        Object.defineProperty(ExecutionContext2.prototype, "currentContext", {
          get: function() {
            return this.contexts;
          },
          /**
           * Set the current context
           * @param contexts: ExecutionContextInfo[] the current path of execution
           * frames
           */
          set: function(contexts) {
            if (this.contexts !== contexts) {
              this.contexts = contexts;
              this.generateCurrentContextIds();
            }
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(ExecutionContext2.prototype, "currentContextId", {
          /**
           * Returns the current context in string format.
           */
          get: function() {
            return this._currentContextIds[0];
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(ExecutionContext2.prototype, "currentContextIds", {
          /**
           * Returns the current context and all parent contexts in string format.
           * This allow access to the nodes in the current and parent frames.
           */
          get: function() {
            return this._currentContextIds;
          },
          enumerable: false,
          configurable: true
        });
        ExecutionContext2.prototype.generateCurrentContextIds = function() {
          var names = [];
          for (var i = 0; i < this.contexts.length - 1; i++) {
            var contexts = this.contexts.slice(0, this.contexts.length - i);
            names.push(this.contextIdforContexts(contexts));
          }
          names.push("");
          this._currentContextIds = names;
        };
        ExecutionContext2.prototype.contextIdforContexts = function(contexts) {
          return contexts ? contexts.map(function(context) {
            return context.id === 0 && context.iterationId === 0 ? "" : "".concat(context.frameName, "-").concat(context.iterationId);
          }).join("/") : "";
        };
        ExecutionContext2.prototype.enterFrame = function(frameId) {
          if (this.contexts) {
            this.lastId++;
            this.contexts = this.contexts.slice();
            this.contexts.push(this.newFrame(this.lastId, frameId));
            this._currentContextIds.unshift(this.contextIdforContexts(this.contexts));
          }
        };
        ExecutionContext2.prototype.exitFrame = function() {
          if (this.contexts && this.contexts.length > 1) {
            this.contexts = this.contexts.slice();
            this.contexts.splice(-1);
            this.currentContextIds.shift();
          } else {
            throw new Error("Cannot exit frame, the context is empty");
          }
        };
        ExecutionContext2.prototype.nextIteration = function() {
          if (this.contexts && this.contexts.length > 0) {
            this.contexts = this.contexts.slice();
            this.lastId++;
            var context = Object.assign({}, this.contexts[this.contexts.length - 1]);
            context.iterationId += 1;
            context.id = this.lastId;
            this.contexts.splice(-1, 1, context);
            this._currentContextIds.splice(0, 1, this.contextIdforContexts(this.contexts));
          } else {
            throw new Error("Cannot increase frame iteration, the context is empty");
          }
        };
        ExecutionContext2.prototype.getWeight = function(name) {
          return this.weightMap[name];
        };
        ExecutionContext2.prototype.addTensorArray = function(tensorArray) {
          this.tensorArrayMap[tensorArray.id] = tensorArray;
        };
        ExecutionContext2.prototype.getTensorArray = function(id) {
          return this.tensorArrayMap[id];
        };
        ExecutionContext2.prototype.addTensorList = function(tensorList) {
          this.tensorListMap[tensorList.id] = tensorList;
        };
        ExecutionContext2.prototype.getTensorList = function(id) {
          return this.tensorListMap[id];
        };
        ExecutionContext2.prototype.dispose = function(keepIds) {
          for (var key in this.tensorArrayMap) {
            this.tensorArrayMap[key].clearAndClose(keepIds);
          }
          for (var key in this.tensorListMap) {
            this.tensorListMap[key].clearAndClose(keepIds);
          }
        };
        return ExecutionContext2;
      }()
    );
    function getExecutionSubgraph(inputs, outputs, weightMap, initNodes) {
      var usedNodes = /* @__PURE__ */ new Set();
      var missingInputs = [];
      var dynamicNode = null;
      var syncInputs = null;
      var seen = /* @__PURE__ */ new Set();
      var inputNodeNames = new Set(Object.keys(inputs).map(function(name) {
        return parseNodeName(name)[0];
      }));
      initNodes = initNodes || [];
      var initNodeNames = new Set(initNodes.map(function(node2) {
        return parseNodeName(node2.name)[0];
      }));
      var frontier = __spreadArray([], __read(outputs), false);
      while (frontier.length > 0) {
        var node = frontier.pop();
        if (isControlFlow(node) || isDynamicShape(node) || isHashTable(node)) {
          if (dynamicNode == null) {
            dynamicNode = node;
            syncInputs = dynamicNode.children.map(function(child) {
              return child.name;
            }).filter(function(name) {
              return usedNodes.has(name);
            });
          }
        }
        usedNodes.add(node.name);
        if (weightMap[node.name] != null) {
          continue;
        }
        if (inputNodeNames.has(node.name)) {
          continue;
        }
        if (initNodeNames.has(node.name)) {
          continue;
        }
        if (node.inputs.length === 0) {
          missingInputs.push(node.name);
          continue;
        }
        node.inputs.forEach(function(input) {
          if (seen.has(input.name)) {
            return;
          }
          seen.add(input.name);
          frontier.push(input);
        });
      }
      return { inputs, outputs, usedNodes, missingInputs, dynamicNode, syncInputs };
    }
    function getNodesInTopologicalOrder(graph2, executionInfo) {
      var e_1, _a, e_2, _b, e_3, _c;
      var usedNodes = executionInfo.usedNodes, inputs = executionInfo.inputs;
      var inputNodes = Object.keys(inputs).map(function(name) {
        return parseNodeName(name)[0];
      }).map(function(name) {
        return graph2.nodes[name];
      });
      var initNodes = graph2.initNodes || [];
      var isUsed = function(node2) {
        return usedNodes.has(typeof node2 === "string" ? node2 : node2.name);
      };
      function unique2(nodes) {
        return __spreadArray([], __read(new Map(nodes.map(function(node2) {
          return [node2.name, node2];
        })).values()), false);
      }
      var predefinedNodes = unique2(__spreadArray(__spreadArray(__spreadArray([], __read(inputNodes), false), __read(graph2.weights), false), __read(initNodes), false)).filter(isUsed);
      var allNodes = unique2(__spreadArray(__spreadArray([], __read(predefinedNodes), false), __read(Object.values(graph2.nodes)), false)).filter(isUsed);
      var nameToNode = new Map(allNodes.map(function(node2) {
        return [node2.name, node2];
      }));
      var inCounts = {};
      try {
        for (var allNodes_1 = __values(allNodes), allNodes_1_1 = allNodes_1.next(); !allNodes_1_1.done; allNodes_1_1 = allNodes_1.next()) {
          var node = allNodes_1_1.value;
          inCounts[node.name] = inCounts[node.name] || 0;
          try {
            for (var _d = (e_2 = void 0, __values(node.children)), _e = _d.next(); !_e.done; _e = _d.next()) {
              var child = _e.value;
              if (!isUsed(child)) {
                inCounts[child.name] = Number.POSITIVE_INFINITY;
              }
              inCounts[child.name] = (inCounts[child.name] || 0) + 1;
            }
          } catch (e_2_1) {
            e_2 = { error: e_2_1 };
          } finally {
            try {
              if (_e && !_e.done && (_b = _d.return))
                _b.call(_d);
            } finally {
              if (e_2)
                throw e_2.error;
            }
          }
        }
      } catch (e_1_1) {
        e_1 = { error: e_1_1 };
      } finally {
        try {
          if (allNodes_1_1 && !allNodes_1_1.done && (_a = allNodes_1.return))
            _a.call(allNodes_1);
        } finally {
          if (e_1)
            throw e_1.error;
        }
      }
      var frontier = Object.entries(inCounts).filter(function(_a2) {
        var _b2 = __read(_a2, 2), inCount = _b2[1];
        return inCount === 0;
      }).map(function(_a2) {
        var _b2 = __read(_a2, 1), name = _b2[0];
        return name;
      });
      var orderedNodeNames = __spreadArray([], __read(frontier), false);
      while (frontier.length > 0) {
        var nodeName = frontier.pop();
        var node = nameToNode.get(nodeName);
        try {
          for (var _f = (e_3 = void 0, __values(node.children.filter(isUsed))), _g = _f.next(); !_g.done; _g = _f.next()) {
            var child = _g.value;
            if (--inCounts[child.name] === 0) {
              orderedNodeNames.push(child.name);
              frontier.push(child.name);
            }
          }
        } catch (e_3_1) {
          e_3 = { error: e_3_1 };
        } finally {
          try {
            if (_g && !_g.done && (_c = _f.return))
              _c.call(_f);
          } finally {
            if (e_3)
              throw e_3.error;
          }
        }
      }
      var orderedNodes = orderedNodeNames.map(function(name) {
        return nameToNode.get(name);
      });
      var filteredOrderedNodes = filterPredefinedReachableNodes(orderedNodes, predefinedNodes);
      validateNodesExecutionOrder(filteredOrderedNodes, predefinedNodes);
      return filteredOrderedNodes;
    }
    function filterPredefinedReachableNodes(orderedNodes, predefinedNodes) {
      var e_4, _a;
      var nameToNode = new Map(orderedNodes.map(function(node2) {
        return [node2.name, node2];
      }));
      var stack2 = predefinedNodes.map(function(node2) {
        return node2.name;
      });
      var predefinedReachableNodeNames = new Set(stack2);
      while (stack2.length > 0) {
        var nodeName = stack2.pop();
        var node = nameToNode.get(nodeName);
        try {
          for (var _b = (e_4 = void 0, __values(node.children)), _c = _b.next(); !_c.done; _c = _b.next()) {
            var child = _c.value;
            if (!nameToNode.has(child.name) || predefinedReachableNodeNames.has(child.name)) {
              continue;
            }
            predefinedReachableNodeNames.add(child.name);
            stack2.push(child.name);
          }
        } catch (e_4_1) {
          e_4 = { error: e_4_1 };
        } finally {
          try {
            if (_c && !_c.done && (_a = _b.return))
              _a.call(_b);
          } finally {
            if (e_4)
              throw e_4.error;
          }
        }
      }
      var filteredOrderedNodes = orderedNodes.filter(function(node2) {
        return predefinedReachableNodeNames.has(node2.name);
      });
      return filteredOrderedNodes;
    }
    var NodesExecutionOrderError = (
      /** @class */
      function(_super) {
        __extends(NodesExecutionOrderError2, _super);
        function NodesExecutionOrderError2(message) {
          return _super.call(this, "NodesExecutionOrderError: ".concat(message)) || this;
        }
        return NodesExecutionOrderError2;
      }(Error)
    );
    function validateNodesExecutionOrder(orderedNodes, predefinedNodes) {
      var e_5, _a, e_6, _b, e_7, _c;
      var nodeNameToOrder = new Map(orderedNodes.map(function(node2, order) {
        return [node2.name, order];
      }));
      var predefinedNodeNames = new Set(predefinedNodes.map(function(node2) {
        return node2.name;
      }));
      var isPredefined = function(node2) {
        return predefinedNodeNames.has(typeof node2 === "string" ? node2 : node2.name);
      };
      var willBeExecutedNodeNames = new Set(orderedNodes.map(function(node2) {
        return node2.name;
      }));
      var willBeExecuted = function(node2) {
        return willBeExecutedNodeNames.has(typeof node2 === "string" ? node2 : node2.name);
      };
      try {
        for (var orderedNodes_1 = __values(orderedNodes), orderedNodes_1_1 = orderedNodes_1.next(); !orderedNodes_1_1.done; orderedNodes_1_1 = orderedNodes_1.next()) {
          var node = orderedNodes_1_1.value;
          try {
            for (var _d = (e_6 = void 0, __values(node.children.filter(willBeExecuted))), _e = _d.next(); !_e.done; _e = _d.next()) {
              var child = _e.value;
              if (!nodeNameToOrder.has(child.name)) {
                throw new NodesExecutionOrderError("Child ".concat(child.name, " of node ").concat(node.name, " is unreachable."));
              }
              if (nodeNameToOrder.get(node.name) > nodeNameToOrder.get(child.name)) {
                throw new NodesExecutionOrderError("Node ".concat(node.name, " is scheduled to run after its child ").concat(child.name, "."));
              }
            }
          } catch (e_6_1) {
            e_6 = { error: e_6_1 };
          } finally {
            try {
              if (_e && !_e.done && (_b = _d.return))
                _b.call(_d);
            } finally {
              if (e_6)
                throw e_6.error;
            }
          }
          if (!isPredefined(node)) {
            try {
              for (var _f = (e_7 = void 0, __values(node.inputs)), _g = _f.next(); !_g.done; _g = _f.next()) {
                var input = _g.value;
                if (!nodeNameToOrder.has(input.name)) {
                  throw new NodesExecutionOrderError("Input ".concat(input.name, " of node ").concat(node.name, " is unreachable."));
                }
                if (nodeNameToOrder.get(input.name) > nodeNameToOrder.get(node.name)) {
                  throw new NodesExecutionOrderError("Node ".concat(node.name, " is scheduled to run before its input ").concat(input.name, "."));
                }
              }
            } catch (e_7_1) {
              e_7 = { error: e_7_1 };
            } finally {
              try {
                if (_g && !_g.done && (_c = _f.return))
                  _c.call(_f);
              } finally {
                if (e_7)
                  throw e_7.error;
              }
            }
          }
        }
      } catch (e_5_1) {
        e_5 = { error: e_5_1 };
      } finally {
        try {
          if (orderedNodes_1_1 && !orderedNodes_1_1.done && (_a = orderedNodes_1.return))
            _a.call(orderedNodes_1);
        } finally {
          if (e_5)
            throw e_5.error;
        }
      }
    }
    function getNodeLiveUntilMap(orderedNodes) {
      var nodeNameToOrder = new Map(orderedNodes.map(function(node2, order) {
        return [node2.name, order];
      }));
      var INF_LIFE = Number.MAX_SAFE_INTEGER;
      var selfLifespans = orderedNodes.map(function(node2, nodeOrder2) {
        return isControlFlow(node2) ? INF_LIFE : nodeOrder2;
      });
      var getSelfLifeSpan = function(node2) {
        var selfLife = selfLifespans[nodeNameToOrder.get(node2.name)];
        if (selfLife == null) {
          return -1;
        }
        return selfLife;
      };
      var liveUntilOrders = orderedNodes.map(function(node2, nodeOrder2) {
        return node2.children.map(getSelfLifeSpan).reduce(function(a, b) {
          return Math.max(a, b);
        }, selfLifespans[nodeOrder2]);
      });
      var liveUntilMap = /* @__PURE__ */ new Map();
      for (var nodeOrder = 0; nodeOrder < orderedNodes.length; ++nodeOrder) {
        var liveUntilOrder = liveUntilOrders[nodeOrder];
        if (liveUntilOrder === INF_LIFE) {
          continue;
        }
        var node = orderedNodes[nodeOrder];
        var liveUntilNode = orderedNodes[liveUntilOrder];
        if (!liveUntilMap.has(liveUntilNode.name)) {
          liveUntilMap.set(liveUntilNode.name, []);
        }
        liveUntilMap.get(liveUntilNode.name).push(node);
      }
      return liveUntilMap;
    }
    var CONTROL_FLOW_OPS = /* @__PURE__ */ new Set([
      "Switch",
      "Merge",
      "Enter",
      "Exit",
      "NextIteration",
      "StatelessIf",
      "StatelessWhile",
      "if",
      "While"
    ]);
    var DYNAMIC_SHAPE_OPS = /* @__PURE__ */ new Set([
      "NonMaxSuppressionV2",
      "NonMaxSuppressionV3",
      "NonMaxSuppressionV5",
      "Where"
    ]);
    var HASH_TABLE_OPS = /* @__PURE__ */ new Set([
      "HashTable",
      "HashTableV2",
      "LookupTableImport",
      "LookupTableImportV2",
      "LookupTableFind",
      "LookupTableFindV2",
      "LookupTableSize",
      "LookupTableSizeV2"
    ]);
    function isControlFlow(node) {
      return CONTROL_FLOW_OPS.has(node.op);
    }
    function isDynamicShape(node) {
      return DYNAMIC_SHAPE_OPS.has(node.op);
    }
    function isHashTable(node) {
      return HASH_TABLE_OPS.has(node.op);
    }
    var GraphExecutor = (
      /** @class */
      function() {
        function GraphExecutor2(graph2, parent) {
          var _this = this;
          this.graph = graph2;
          this.parent = parent;
          this.compiledMap = /* @__PURE__ */ new Map();
          this.parseNodeNameCache = /* @__PURE__ */ new Map();
          this._weightMap = {};
          this.SEPARATOR = ",";
          this._functions = {};
          this._functionExecutorMap = {};
          this.keepIntermediateTensors = false;
          this._outputs = graph2.outputs;
          this._inputs = graph2.inputs;
          this._initNodes = graph2.initNodes;
          this._signature = graph2.signature;
          this._functions = graph2.functions;
          if (graph2.functions != null) {
            Object.keys(graph2.functions).forEach(function(name) {
              _this._functionExecutorMap[name] = new GraphExecutor2(graph2.functions[name], _this);
            });
          }
        }
        Object.defineProperty(GraphExecutor2.prototype, "weightIds", {
          get: function() {
            return this.parent ? this.parent.weightIds : this._weightIds;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "functionExecutorMap", {
          get: function() {
            return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "weightMap", {
          get: function() {
            return this.parent ? this.parent.weightMap : this._weightMap;
          },
          set: function(weightMap) {
            var weightIds = Object.keys(weightMap).map(function(key) {
              return weightMap[key].map(function(tensor2) {
                return tensor2.id;
              });
            });
            this._weightIds = [].concat.apply([], __spreadArray([], __read(weightIds), false));
            this._weightMap = weightMap;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "resourceManager", {
          /**
           * Set `ResourceManager` shared by executors of a model.
           * @param resourceManager: `ResourceManager` of the `GraphModel`.
           */
          set: function(resourceManager) {
            this._resourceManager = resourceManager;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "inputs", {
          get: function() {
            return this._inputs.map(function(node) {
              return {
                name: node.name,
                shape: node.attrParams["shape"] ? node.attrParams["shape"].value : void 0,
                dtype: node.attrParams["dtype"] ? node.attrParams["dtype"].value : void 0
              };
            });
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "outputs", {
          get: function() {
            return this._outputs.map(function(node) {
              return {
                name: node.name,
                shape: node.attrParams["shape"] ? node.attrParams["shape"].value : void 0,
                dtype: node.attrParams["dtype"] ? node.attrParams["dtype"].value : void 0
              };
            });
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "inputNodes", {
          get: function() {
            return this._inputs.map(function(node) {
              return node.signatureKey || node.name;
            });
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "outputNodes", {
          get: function() {
            return this._outputs.map(function(node) {
              var name = node.signatureKey || node.name;
              return node.defaultOutput ? "".concat(name, ":").concat(node.defaultOutput) : name;
            });
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "functions", {
          get: function() {
            var _this = this;
            return Object.keys(this._functions).reduce(function(map, key) {
              map[key] = _this._functions[key].signature;
              return map;
            }, {});
          },
          enumerable: false,
          configurable: true
        });
        GraphExecutor2.prototype.getCompilationKey = function(inputs, outputs) {
          var sortedInputs = inputs.map(function(node) {
            return node.name;
          }).sort();
          var sortedOutputs = outputs.map(function(node) {
            return node.name;
          }).sort();
          return sortedInputs.join(this.SEPARATOR) + "--" + sortedOutputs.join(this.SEPARATOR);
        };
        GraphExecutor2.prototype.compile = function(inputs, outputs) {
          var executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);
          var missingInputs = executionInfo.missingInputs, dynamicNode = executionInfo.dynamicNode, syncInputs = executionInfo.syncInputs;
          if (dynamicNode != null) {
            throw new Error("This execution contains the node '".concat(dynamicNode.name, "', which has ") + "the dynamic op '".concat(dynamicNode.op, "'. Please use ") + "model.executeAsync() instead. Alternatively, to avoid the " + "dynamic ops, specify the inputs [".concat(syncInputs, "]"));
          }
          if (missingInputs.length > 0) {
            var outNames = outputs.map(function(n) {
              return n.name;
            });
            var inNames = Object.keys(inputs);
            throw new Error("Cannot compute the outputs [".concat(outNames, "] from the provided inputs ") + "[".concat(inNames, "]. Missing the following inputs: [").concat(missingInputs, "]"));
          }
          var orderedNodes = getNodesInTopologicalOrder(this.graph, executionInfo);
          var nodeLiveUntilMap = getNodeLiveUntilMap(orderedNodes);
          return { orderedNodes, nodeLiveUntilMap };
        };
        GraphExecutor2.prototype.cloneAndKeepTensor = function(tensor2) {
          if (tensor2 == null) {
            return null;
          }
          var clone2 = tensor2.clone();
          tfc.keep(clone2);
          return clone2;
        };
        GraphExecutor2.prototype.cloneTensorList = function(tensors) {
          var _this = this;
          if (!tensors) {
            return null;
          }
          var clonedTensor = tensors.map(function(tensor2) {
            return _this.cloneAndKeepTensor(tensor2);
          });
          return clonedTensor;
        };
        GraphExecutor2.prototype.cloneTensorMap = function(tensorsMap) {
          var _this = this;
          return Object.fromEntries(Object.entries(tensorsMap).map(function(_c) {
            var _d = __read(_c, 2), name = _d[0], tensorsList = _d[1];
            return [name, _this.cloneTensorList(tensorsList)];
          }));
        };
        GraphExecutor2.prototype.execute = function(inputs, outputs) {
          var _this = this;
          this.disposeIntermediateTensors();
          inputs = this.mapInputs(inputs);
          var names = Object.keys(inputs).sort();
          this.checkInputs(inputs);
          this.checkInputShapeAndType(inputs);
          outputs = this.mapOutputs(outputs);
          this.checkOutputs(outputs);
          var inputNodes = names.map(function(name) {
            return _this.graph.nodes[parseNodeName(name)[0]];
          });
          var outputNodeNames = outputs.map(function(name) {
            return parseNodeName(name)[0];
          });
          var outputNodeNameSet = new Set(outputNodeNames);
          var outputNodes = outputNodeNames.map(function(name) {
            return _this.graph.nodes[name];
          });
          if (outputNodes.length === 0) {
            outputNodes = this._outputs;
          }
          var compilationKey = this.getCompilationKey(inputNodes, outputNodes);
          var compilation = this.compiledMap.get(compilationKey);
          if (compilation == null) {
            compilation = this.compile(inputs, outputNodes);
            this.compiledMap.set(compilationKey, compilation);
          }
          try {
            this.keepIntermediateTensors = tfc.env().getBool("KEEP_INTERMEDIATE_TENSORS");
          } catch (e) {
            this.keepIntermediateTensors = false;
            console.warn(e.message);
          }
          var tensorArrayMap = {};
          var tensorListMap = {};
          return tfc.tidy(function() {
            var e_1, _c;
            var context = new ExecutionContext(_this.weightMap, tensorArrayMap, tensorListMap, _this.functionExecutorMap, _this.parseNodeNameCache);
            var tensorsMap = Object.assign({}, _this.weightMap);
            if (_this.keepIntermediateTensors) {
              _this.clonedTensorsMap = _this.cloneTensorMap(_this.weightMap);
            }
            Object.keys(inputs).forEach(function(name) {
              var _c2 = __read(parseNodeName(name, context), 2), nodeName = _c2[0], index = _c2[1];
              var tensors2 = [];
              tensors2[index] = inputs[name];
              tensorsMap[nodeName] = tensors2;
              if (_this.keepIntermediateTensors) {
                _this.clonedTensorsMap[nodeName] = _this.cloneTensorList(tensors2);
              }
            });
            var tensorsToKeep = _this.getFrozenTensorIds(tensorsMap);
            var orderedNodes = compilation.orderedNodes, nodeLiveUntilMap = compilation.nodeLiveUntilMap;
            try {
              for (var orderedNodes_1 = __values(orderedNodes), orderedNodes_1_1 = orderedNodes_1.next(); !orderedNodes_1_1.done; orderedNodes_1_1 = orderedNodes_1.next()) {
                var node = orderedNodes_1_1.value;
                if (tensorsMap[node.name]) {
                  continue;
                }
                var tensors = executeOp(node, tensorsMap, context, _this._resourceManager);
                if (tfc.util.isPromise(tensors)) {
                  throw new Error("The execution of the op '".concat(node.op, "' returned a promise. ") + "Please use model.executeAsync() instead.");
                }
                tensorsMap[node.name] = tensors;
                if (_this.keepIntermediateTensors) {
                  _this.clonedTensorsMap[node.name] = _this.cloneTensorList(tensors);
                }
                _this.checkTensorForDisposalWithNodeLiveUntilInfo(node, tensorsMap, context, tensorsToKeep, outputNodeNameSet, nodeLiveUntilMap.get(node.name));
              }
            } catch (e_1_1) {
              e_1 = { error: e_1_1 };
            } finally {
              try {
                if (orderedNodes_1_1 && !orderedNodes_1_1.done && (_c = orderedNodes_1.return))
                  _c.call(orderedNodes_1);
              } finally {
                if (e_1)
                  throw e_1.error;
              }
            }
            if (_this.parent == null) {
              context.dispose(tensorsToKeep);
            }
            return outputs.map(function(name) {
              return getTensor(name, tensorsMap, context);
            });
          });
        };
        GraphExecutor2.prototype.getFrozenTensorIds = function(tensorMap) {
          var ids = [].concat.apply([], Object.keys(tensorMap).map(function(key) {
            return tensorMap[key];
          }).map(function(tensors) {
            return tensors.map(function(tensor2) {
              return tensor2.id;
            });
          }));
          return new Set(ids);
        };
        GraphExecutor2.prototype.checkTensorForDisposal = function(nodeName, node, tensorMap, context, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount) {
          var e_2, _c, e_3, _d, e_4, _e;
          if (isControlFlow(node) || outputNodeNameSet.has(nodeName)) {
            return;
          }
          try {
            for (var _f = __values(tensorMap[nodeName]), _g = _f.next(); !_g.done; _g = _f.next()) {
              var tensor2 = _g.value;
              if (tensor2 == null) {
                continue;
              }
              intermediateTensorConsumerCount[tensor2.id] = (intermediateTensorConsumerCount[tensor2.id] || 0) + node.children.length;
            }
          } catch (e_2_1) {
            e_2 = { error: e_2_1 };
          } finally {
            try {
              if (_g && !_g.done && (_c = _f.return))
                _c.call(_f);
            } finally {
              if (e_2)
                throw e_2.error;
            }
          }
          try {
            for (var _h = __values(node.inputs), _j = _h.next(); !_j.done; _j = _h.next()) {
              var input = _j.value;
              if (isControlFlow(input)) {
                continue;
              }
              var tensors = getTensorsForCurrentContext(input.name, tensorMap, context);
              if (tensors == null) {
                continue;
              }
              try {
                for (var tensors_1 = (e_4 = void 0, __values(tensors)), tensors_1_1 = tensors_1.next(); !tensors_1_1.done; tensors_1_1 = tensors_1.next()) {
                  var tensor2 = tensors_1_1.value;
                  if (!tensor2 || tensor2.kept || tensorsToKeep.has(tensor2.id)) {
                    continue;
                  }
                  var count = intermediateTensorConsumerCount[tensor2.id];
                  if (count === 1) {
                    tensor2.dispose();
                    delete intermediateTensorConsumerCount[tensor2.id];
                  } else if (count != null) {
                    intermediateTensorConsumerCount[tensor2.id]--;
                  }
                }
              } catch (e_4_1) {
                e_4 = { error: e_4_1 };
              } finally {
                try {
                  if (tensors_1_1 && !tensors_1_1.done && (_e = tensors_1.return))
                    _e.call(tensors_1);
                } finally {
                  if (e_4)
                    throw e_4.error;
                }
              }
            }
          } catch (e_3_1) {
            e_3 = { error: e_3_1 };
          } finally {
            try {
              if (_j && !_j.done && (_d = _h.return))
                _d.call(_h);
            } finally {
              if (e_3)
                throw e_3.error;
            }
          }
        };
        GraphExecutor2.prototype.checkTensorForDisposalWithNodeLiveUntilInfo = function(node, tensorMap, context, tensorsToKeep, outputNodeNameSet, liveUntilNodes) {
          var e_5, _c, e_6, _d;
          function isNonDisposableNode(node2) {
            return isControlFlow(node2) || outputNodeNameSet.has(node2.name);
          }
          if (isControlFlow(node) || liveUntilNodes == null) {
            return;
          }
          try {
            for (var liveUntilNodes_1 = __values(liveUntilNodes), liveUntilNodes_1_1 = liveUntilNodes_1.next(); !liveUntilNodes_1_1.done; liveUntilNodes_1_1 = liveUntilNodes_1.next()) {
              var nodeToDispose = liveUntilNodes_1_1.value;
              if (isNonDisposableNode(nodeToDispose)) {
                continue;
              }
              var tensors = getTensorsForCurrentContext(nodeToDispose.name, tensorMap, context);
              try {
                for (var tensors_2 = (e_6 = void 0, __values(tensors)), tensors_2_1 = tensors_2.next(); !tensors_2_1.done; tensors_2_1 = tensors_2.next()) {
                  var tensor2 = tensors_2_1.value;
                  if (!tensor2 || tensor2.kept || tensorsToKeep.has(tensor2.id)) {
                    continue;
                  }
                  tensor2.dispose();
                }
              } catch (e_6_1) {
                e_6 = { error: e_6_1 };
              } finally {
                try {
                  if (tensors_2_1 && !tensors_2_1.done && (_d = tensors_2.return))
                    _d.call(tensors_2);
                } finally {
                  if (e_6)
                    throw e_6.error;
                }
              }
            }
          } catch (e_5_1) {
            e_5 = { error: e_5_1 };
          } finally {
            try {
              if (liveUntilNodes_1_1 && !liveUntilNodes_1_1.done && (_c = liveUntilNodes_1.return))
                _c.call(liveUntilNodes_1);
            } finally {
              if (e_5)
                throw e_5.error;
            }
          }
        };
        GraphExecutor2.prototype.executeAsync = function(inputs, outputs) {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_c) {
              return [2, this._executeAsync(inputs, outputs)];
            });
          });
        };
        GraphExecutor2.prototype.disposeIntermediateTensors = function() {
          if (!this.clonedTensorsMap) {
            return;
          }
          Object.values(this.clonedTensorsMap).forEach(function(tensorsList) {
            var e_7, _c;
            try {
              for (var tensorsList_1 = __values(tensorsList), tensorsList_1_1 = tensorsList_1.next(); !tensorsList_1_1.done; tensorsList_1_1 = tensorsList_1.next()) {
                var tensor2 = tensorsList_1_1.value;
                if (tensor2 && !tensor2.isDisposed) {
                  tensor2.dispose();
                }
              }
            } catch (e_7_1) {
              e_7 = { error: e_7_1 };
            } finally {
              try {
                if (tensorsList_1_1 && !tensorsList_1_1.done && (_c = tensorsList_1.return))
                  _c.call(tensorsList_1);
              } finally {
                if (e_7)
                  throw e_7.error;
              }
            }
          });
          this.clonedTensorsMap = null;
        };
        GraphExecutor2.prototype.getIntermediateTensors = function() {
          return this.clonedTensorsMap;
        };
        GraphExecutor2.prototype._executeAsync = function(inputs, outputs, isFunctionExecution, tensorArrayMap, tensorListMap) {
          if (isFunctionExecution === void 0) {
            isFunctionExecution = false;
          }
          if (tensorArrayMap === void 0) {
            tensorArrayMap = {};
          }
          if (tensorListMap === void 0) {
            tensorListMap = {};
          }
          return __awaiter(this, void 0, void 0, function() {
            var context, tensorsMap, results, outputIds, inputIds, keepIds;
            return __generator(this, function(_c) {
              switch (_c.label) {
                case 0:
                  this.disposeIntermediateTensors();
                  if (!isFunctionExecution) {
                    inputs = this.mapInputs(inputs);
                    this.checkInputs(inputs);
                    this.checkInputShapeAndType(inputs);
                    outputs = this.mapOutputs(outputs);
                    this.checkOutputs(outputs);
                  }
                  try {
                    this.keepIntermediateTensors = tfc.env().getBool("KEEP_INTERMEDIATE_TENSORS");
                  } catch (e) {
                    this.keepIntermediateTensors = false;
                    console.warn(e.message);
                  }
                  context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap, this.parseNodeNameCache);
                  if (this.keepIntermediateTensors) {
                    this.clonedTensorsMap = this.cloneTensorMap(this.weightMap);
                  }
                  return [4, this.executeWithControlFlow(inputs, context, outputs, isFunctionExecution)];
                case 1:
                  tensorsMap = _c.sent();
                  results = outputs.map(function(name) {
                    return getTensor(name, tensorsMap, context);
                  });
                  outputIds = results.map(function(t) {
                    return t.id;
                  });
                  inputIds = Object.keys(inputs).map(function(name) {
                    return inputs[name].id;
                  });
                  keepIds = new Set(__spreadArray(__spreadArray(__spreadArray([], __read(outputIds), false), __read(inputIds), false), __read(this.weightIds), false));
                  Object.values(tensorsMap).forEach(function(tensorsList) {
                    tensorsList.forEach(function(tensor2) {
                      if (tensor2 && !tensor2.isDisposed && !keepIds.has(tensor2.id)) {
                        tensor2.dispose();
                      }
                    });
                  });
                  if (this.parent == null) {
                    context.dispose(keepIds);
                  }
                  return [2, results];
              }
            });
          });
        };
        GraphExecutor2.prototype.executeFunctionAsync = function(inputs, tensorArrayMap, tensorListMap) {
          return __awaiter(this, void 0, void 0, function() {
            var mappedInputs;
            var _this = this;
            return __generator(this, function(_c) {
              mappedInputs = inputs.reduce(function(map, tensor2, index) {
                map[_this.inputs[index].name] = tensor2;
                return map;
              }, {});
              return [2, this._executeAsync(mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap)];
            });
          });
        };
        GraphExecutor2.prototype.executeWithControlFlow = function(inputs, context, outputNames, isFunctionExecution) {
          return __awaiter(this, void 0, void 0, function() {
            var names, inputNodes, outputNodeNames, outputNodeNameSet, outputNodes, _c, usedNodes, missingInputs, dynamicNode, syncInputs, stack2, tensorsMap, intermediateTensorConsumerCount, tensorsToKeep, added, promises, missingOutputs, alternativeMsg;
            var _this = this;
            return __generator(this, function(_d) {
              switch (_d.label) {
                case 0:
                  names = Object.keys(inputs);
                  inputNodes = names.map(function(name) {
                    return _this.graph.nodes[parseNodeName(name)[0]];
                  });
                  outputNodeNames = outputNames.map(function(name) {
                    return parseNodeName(name)[0];
                  });
                  outputNodeNameSet = new Set(outputNodeNames);
                  outputNodes = outputNodeNames.map(function(name) {
                    return _this.graph.nodes[name];
                  });
                  if (outputNodes.length === 0) {
                    outputNodes = this._outputs;
                  }
                  _c = getExecutionSubgraph(inputs, outputNodes, this.weightMap, this._initNodes), usedNodes = _c.usedNodes, missingInputs = _c.missingInputs, dynamicNode = _c.dynamicNode, syncInputs = _c.syncInputs;
                  stack2 = __spreadArray(__spreadArray(__spreadArray([], __read(inputNodes), false), __read(this.graph.weights), false), __read(this._initNodes || []), false).map(function(node) {
                    return { node, contexts: context.currentContext };
                  });
                  tensorsMap = Object.assign({}, this.weightMap);
                  Object.keys(inputs).forEach(function(name) {
                    var _c2 = __read(parseNodeName(name), 2), nodeName = _c2[0], index = _c2[1];
                    var tensors = [];
                    tensors[index] = inputs[name];
                    tensorsMap[nodeName] = tensors;
                  });
                  intermediateTensorConsumerCount = {};
                  tensorsToKeep = this.getFrozenTensorIds(tensorsMap);
                  added = {};
                  _d.label = 1;
                case 1:
                  if (!(stack2.length > 0))
                    return [3, 3];
                  promises = this.processStack(inputNodes, stack2, context, tensorsMap, added, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount, usedNodes);
                  return [4, Promise.all(promises)];
                case 2:
                  _d.sent();
                  return [3, 1];
                case 3:
                  if (dynamicNode == null && !isFunctionExecution) {
                    console.warn("This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.");
                  }
                  missingOutputs = outputNodes.filter(function(node) {
                    return !isControlFlow(node) && !getTensor(node.name, tensorsMap, context);
                  }).map(function(node) {
                    return node.name;
                  });
                  if (missingOutputs.length > 0) {
                    alternativeMsg = "";
                    if (dynamicNode != null) {
                      alternativeMsg = "Alternatively, to avoid the dynamic ops, use model.execute() " + "and specify the inputs [".concat(syncInputs, "]");
                    }
                    throw new Error("Cannot compute the outputs [".concat(missingOutputs, "] from the provided ") + "inputs [".concat(names, "]. Consider providing the following inputs: ") + "[".concat(missingInputs, "]. ").concat(alternativeMsg));
                  }
                  return [2, tensorsMap];
              }
            });
          });
        };
        GraphExecutor2.prototype.processStack = function(inputNodes, stack2, context, tensorMap, added, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount, usedNodes) {
          var _this = this;
          var promises = [];
          var _loop_1 = function() {
            var _c, _d;
            var item = stack2.pop();
            context.currentContext = item.contexts;
            var nodeName = "";
            if (item.node.op === "Enter" && getParamValue("isConstant", item.node, tensorMap, context)) {
              _c = __read(getNodeNameAndIndex(item.node.name, context), 1), nodeName = _c[0];
            }
            if (tensorMap[item.node.name] == null) {
              var tensors = executeOp(item.node, tensorMap, context, this_1._resourceManager);
              if (!nodeName) {
                _d = __read(getNodeNameAndIndex(item.node.name, context), 1), nodeName = _d[0];
              }
              var currentContext_1 = context.currentContext;
              if (tfc.util.isPromise(tensors)) {
                promises.push(tensors.then(function(t) {
                  tensorMap[nodeName] = t;
                  if (_this.keepIntermediateTensors) {
                    _this.clonedTensorsMap[nodeName] = _this.cloneTensorList(t);
                  }
                  context.currentContext = currentContext_1;
                  _this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount);
                  _this.processChildNodes(item.node, stack2, context, tensorMap, added, usedNodes);
                  return t;
                }));
              } else {
                tensorMap[nodeName] = tensors;
                if (this_1.keepIntermediateTensors) {
                  this_1.clonedTensorsMap[nodeName] = this_1.cloneTensorList(tensors);
                }
                this_1.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount);
                this_1.processChildNodes(item.node, stack2, context, tensorMap, added, usedNodes);
              }
            } else {
              this_1.processChildNodes(item.node, stack2, context, tensorMap, added, usedNodes);
            }
          };
          var this_1 = this;
          while (stack2.length > 0) {
            _loop_1();
          }
          return promises;
        };
        GraphExecutor2.prototype.processChildNodes = function(node, stack2, context, tensorMap, added, usedNodes) {
          node.children.forEach(function(childNode) {
            var _c = __read(getNodeNameAndIndex(childNode.name, context), 1), nodeName = _c[0];
            if (added[nodeName] || !usedNodes.has(childNode.name)) {
              return;
            }
            if (childNode.op === "Merge") {
              if (childNode.inputNames.some(function(name) {
                return !!getTensor(name, tensorMap, context);
              })) {
                added[nodeName] = true;
                stack2.push({ contexts: context.currentContext, node: childNode });
              }
            } else if (childNode.inputNames.every(function(name) {
              return !!getTensor(name, tensorMap, context);
            })) {
              added[nodeName] = true;
              stack2.push({ contexts: context.currentContext, node: childNode });
            }
          });
        };
        GraphExecutor2.prototype.dispose = function() {
          var _this = this;
          Object.keys(this.weightMap).forEach(function(key) {
            return _this.weightMap[key].forEach(function(tensor2) {
              return tensor2.dispose();
            });
          });
        };
        GraphExecutor2.prototype.checkInputShapeAndType = function(inputs) {
          var _this = this;
          Object.keys(inputs).forEach(function(name) {
            var input = inputs[name];
            var _c = __read(parseNodeName(name), 1), nodeName = _c[0];
            var node = _this.graph.nodes[nodeName];
            if (node.attrParams["shape"] && node.attrParams["shape"].value) {
              var shape_1 = node.attrParams["shape"].value;
              var match = shape_1.length === input.shape.length && input.shape.every(function(dim, index) {
                return shape_1[index] === -1 || shape_1[index] === dim;
              });
              tfc.util.assert(match, function() {
                return "The shape of dict['".concat(node.name, "'] provided in ") + "model.execute(dict) must be [".concat(shape_1, "], but was ") + "[".concat(input.shape, "]");
              });
            }
            if (node.attrParams["dtype"] && node.attrParams["dtype"].value) {
              tfc.util.assert(input.dtype === node.attrParams["dtype"].value, function() {
                return "The dtype of dict['".concat(node.name, "'] provided in ") + "model.execute(dict) must be " + "".concat(node.attrParams["dtype"].value, ", but was ").concat(input.dtype);
              });
            }
          });
        };
        GraphExecutor2.prototype.mapInputs = function(inputs) {
          var _a, _b;
          var result = {};
          for (var inputName in inputs) {
            var tensor2 = (_b = (_a = this._signature) === null || _a === void 0 ? void 0 : _a.inputs) === null || _b === void 0 ? void 0 : _b[inputName];
            if (tensor2 != null) {
              result[tensor2.name] = inputs[inputName];
            } else {
              result[inputName] = inputs[inputName];
            }
          }
          return result;
        };
        GraphExecutor2.prototype.checkInputs = function(inputs) {
          var _this = this;
          var notInGraph = Object.keys(inputs).filter(function(name) {
            var _c = __read(parseNodeName(name), 1), nodeName = _c[0];
            return _this.graph.nodes[nodeName] == null;
          });
          if (notInGraph.length > 0) {
            throw new Error("The dict provided in model.execute(dict) has " + "keys: [".concat(notInGraph, "] that are not part of graph"));
          }
        };
        GraphExecutor2.prototype.mapOutputs = function(outputs) {
          var _this = this;
          return outputs.map(function(name) {
            var _a, _b;
            var tensor2 = (_b = (_a = _this._signature) === null || _a === void 0 ? void 0 : _a.outputs) === null || _b === void 0 ? void 0 : _b[name];
            if (tensor2 != null) {
              return tensor2.name;
            }
            return name;
          }, {});
        };
        GraphExecutor2.prototype.checkOutputs = function(outputs) {
          var _this = this;
          outputs.forEach(function(name) {
            var _c = __read(parseNodeName(name), 1), normalizedName = _c[0];
            if (!_this.graph.nodes[normalizedName]) {
              throw new Error("The output '".concat(name, "' is not found in the graph"));
            }
          });
        };
        return GraphExecutor2;
      }()
    );
    var ResourceManager = (
      /** @class */
      function() {
        function ResourceManager2(hashTableNameToHandle, hashTableMap) {
          if (hashTableNameToHandle === void 0) {
            hashTableNameToHandle = {};
          }
          if (hashTableMap === void 0) {
            hashTableMap = {};
          }
          this.hashTableNameToHandle = hashTableNameToHandle;
          this.hashTableMap = hashTableMap;
        }
        ResourceManager2.prototype.addHashTable = function(name, hashTable2) {
          this.hashTableNameToHandle[name] = hashTable2.handle;
          this.hashTableMap[hashTable2.id] = hashTable2;
        };
        ResourceManager2.prototype.getHashTableHandleByName = function(name) {
          return this.hashTableNameToHandle[name];
        };
        ResourceManager2.prototype.getHashTableById = function(id) {
          return this.hashTableMap[id];
        };
        ResourceManager2.prototype.dispose = function() {
          for (var key in this.hashTableMap) {
            this.hashTableMap[key].clearAndClose();
            delete this.hashTableMap[key];
          }
          for (var name in this.hashTableNameToHandle) {
            this.hashTableNameToHandle[name].dispose();
            delete this.hashTableNameToHandle[name];
          }
        };
        return ResourceManager2;
      }()
    );
    var DTYPE_VALUE_SIZE_MAP = {
      "float32": 4,
      "float16": 2,
      "int32": 4,
      "uint16": 2,
      "uint8": 1,
      "bool": 1,
      "complex64": 8
    };
    var NUM_BYTES_STRING_LENGTH = 4;
    function getWeightBytelengthAsync(spec, slice2) {
      return __awaiter(this, void 0, void 0, function() {
        var size, bytesPerValue, quantization, byteLength, i, _a, _b, _c;
        return __generator(this, function(_d) {
          switch (_d.label) {
            case 0:
              size = sizeFromShape(spec.shape);
              if (!("quantization" in spec))
                return [3, 1];
              quantization = spec.quantization;
              bytesPerValue = DTYPE_VALUE_SIZE_MAP[quantization.dtype];
              return [3, 7];
            case 1:
              if (!(spec.dtype === "string"))
                return [3, 6];
              byteLength = 0;
              i = 0;
              _d.label = 2;
            case 2:
              if (!(i < size))
                return [3, 5];
              _a = byteLength;
              _b = NUM_BYTES_STRING_LENGTH;
              _c = Uint32Array.bind;
              return [4, slice2(byteLength, byteLength + NUM_BYTES_STRING_LENGTH)];
            case 3:
              byteLength = _a + (_b + new (_c.apply(Uint32Array, [void 0, _d.sent()]))()[0]);
              _d.label = 4;
            case 4:
              i++;
              return [3, 2];
            case 5:
              return [2, byteLength];
            case 6:
              bytesPerValue = DTYPE_VALUE_SIZE_MAP[spec.dtype];
              _d.label = 7;
            case 7:
              return [2, size * bytesPerValue];
          }
        });
      });
    }
    function decodeWeight(spec, byteBuffer) {
      var name = spec.name;
      var dtype = spec.dtype;
      var shape = spec.shape;
      var size = sizeFromShape(shape);
      var values;
      var offset = 0;
      if ("quantization" in spec) {
        var quantization = spec.quantization;
        if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
          if (!("min" in quantization && "scale" in quantization)) {
            throw new Error("Weight ".concat(spec.name, " with quantization ").concat(quantization.dtype, " ") + "doesn't have corresponding metadata min and scale.");
          }
        } else if (quantization.dtype === "float16") {
          if (dtype !== "float32") {
            throw new Error("Weight ".concat(spec.name, " is quantized with ").concat(quantization.dtype, " ") + "which only supports weights of type float32 not ".concat(dtype, "."));
          }
        } else {
          throw new Error("Weight ".concat(spec.name, " has unknown ") + "quantization dtype ".concat(quantization.dtype, ". ") + "Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.");
        }
        var quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];
        var quantizedArray = quantization.dtype === "uint8" ? new Uint8Array(byteBuffer) : new Uint16Array(byteBuffer);
        if (dtype === "float32") {
          if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
            values = new Float32Array(quantizedArray.length);
            for (var i = 0; i < quantizedArray.length; i++) {
              var v = quantizedArray[i];
              values[i] = v * quantization.scale + quantization.min;
            }
          } else if (quantization.dtype === "float16") {
            var float16Decode = getFloat16Decoder();
            values = float16Decode(quantizedArray);
          } else {
            throw new Error("Unsupported quantization type ".concat(quantization.dtype, " ") + "for weight type float32.");
          }
        } else if (dtype === "int32") {
          if (quantization.dtype !== "uint8" && quantization.dtype !== "uint16") {
            throw new Error("Unsupported quantization type ".concat(quantization.dtype, " ") + "for weight type int32.");
          }
          values = new Int32Array(quantizedArray.length);
          for (var i = 0; i < quantizedArray.length; i++) {
            var v = quantizedArray[i];
            values[i] = Math.round(v * quantization.scale + quantization.min);
          }
        } else {
          throw new Error("Unsupported dtype in weight '".concat(name, "': ").concat(dtype));
        }
        offset += size * quantizationSizeFactor;
      } else if (dtype === "string") {
        var size_1 = sizeFromShape(spec.shape);
        values = [];
        for (var i = 0; i < size_1; i++) {
          var byteLength = new Uint32Array(byteBuffer.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];
          offset += NUM_BYTES_STRING_LENGTH;
          var bytes = new Uint8Array(byteBuffer.slice(offset, offset + byteLength));
          values.push(bytes);
          offset += byteLength;
        }
      } else {
        var dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];
        if (dtype === "float32") {
          values = new Float32Array(byteBuffer);
        } else if (dtype === "int32") {
          values = new Int32Array(byteBuffer);
        } else if (dtype === "bool") {
          values = new Uint8Array(byteBuffer);
        } else if (dtype === "complex64") {
          values = new Float32Array(byteBuffer);
          var real2 = new Float32Array(values.length / 2);
          var image2 = new Float32Array(values.length / 2);
          for (var i = 0; i < real2.length; i++) {
            real2[i] = values[i * 2];
            image2[i] = values[i * 2 + 1];
          }
          var realTensor = tensor(real2, shape, "float32");
          var imageTensor = tensor(image2, shape, "float32");
          var complexTensor = complex(realTensor, imageTensor);
          realTensor.dispose();
          imageTensor.dispose();
          return complexTensor;
        } else {
          throw new Error("Unsupported dtype in weight '".concat(name, "': ").concat(dtype));
        }
        offset += size * dtypeFactor;
      }
      return tensor(values, shape, dtype);
    }
    function readToLength(reader, initialData, length) {
      return __awaiter(this, void 0, void 0, function() {
        var data, _a, done, value, missing, newData;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              data = new Uint8Array(initialData);
              _b.label = 1;
            case 1:
              if (!(data.byteLength < length))
                return [3, 3];
              return [4, reader.read()];
            case 2:
              _a = _b.sent(), done = _a.done, value = _a.value;
              if (done && value == null) {
                missing = length - data.byteLength;
                throw new Error("Reader is done but ".concat(missing, " bytes are still expected"));
              }
              newData = new Uint8Array(data.length + value.byteLength);
              newData.set(data, 0);
              newData.set(new Uint8Array(value), data.length);
              data = newData;
              return [3, 1];
            case 3:
              return [2, data.buffer];
          }
        });
      });
    }
    function decodeWeightsStream(weightStream, specs) {
      return __awaiter(this, void 0, void 0, function() {
        var tensors, reader, data, specs_2, specs_2_1, spec, byteLength, tensorData, weightTensor, b, e_2_1;
        var e_2, _a;
        var _this = this;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              tensors = {};
              reader = weightStream.getReader();
              data = new ArrayBuffer(0);
              _b.label = 1;
            case 1:
              _b.trys.push([1, 7, 8, 9]);
              specs_2 = __values(specs), specs_2_1 = specs_2.next();
              _b.label = 2;
            case 2:
              if (!!specs_2_1.done)
                return [3, 6];
              spec = specs_2_1.value;
              return [4, getWeightBytelengthAsync(spec, function(start, end) {
                return __awaiter(_this, void 0, void 0, function() {
                  return __generator(this, function(_a2) {
                    switch (_a2.label) {
                      case 0:
                        return [4, readToLength(reader, data, end)];
                      case 1:
                        data = _a2.sent();
                        return [2, data.slice(start, end)];
                    }
                  });
                });
              })];
            case 3:
              byteLength = _b.sent();
              return [4, readToLength(reader, data, byteLength)];
            case 4:
              data = _b.sent();
              tensorData = data.slice(0, byteLength);
              data = data.slice(byteLength);
              weightTensor = decodeWeight(spec, tensorData);
              tensors[spec.name] = weightTensor;
              if (getBackend() === "webgpu") {
                b = backend();
                if ("uploadToGPU" in b && sizeFromShape(weightTensor.shape) >= env().get("WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD")) {
                  b.uploadToGPU(weightTensor.dataId);
                }
              }
              _b.label = 5;
            case 5:
              specs_2_1 = specs_2.next();
              return [3, 2];
            case 6:
              return [3, 9];
            case 7:
              e_2_1 = _b.sent();
              e_2 = { error: e_2_1 };
              return [3, 9];
            case 8:
              try {
                if (specs_2_1 && !specs_2_1.done && (_a = specs_2.return))
                  _a.call(specs_2);
              } finally {
                if (e_2)
                  throw e_2.error;
              }
              return [
                7
                /*endfinally*/
              ];
            case 9:
              return [2, tensors];
          }
        });
      });
    }
    function computeFloat16MantisaTable() {
      var convertMantissa = function(i2) {
        var m = i2 << 13;
        var e = 0;
        while ((m & 8388608) === 0) {
          e -= 8388608;
          m <<= 1;
        }
        m &= ~8388608;
        e += 947912704;
        return m | e;
      };
      var mantisaTable = new Uint32Array(2048);
      mantisaTable[0] = 0;
      for (var i = 1; i < 1024; i++) {
        mantisaTable[i] = convertMantissa(i);
      }
      for (var i = 1024; i < 2048; i++) {
        mantisaTable[i] = 939524096 + (i - 1024 << 13);
      }
      return mantisaTable;
    }
    function computeFloat16ExponentTable() {
      var exponentTable = new Uint32Array(64);
      exponentTable[0] = 0;
      exponentTable[31] = 1199570944;
      exponentTable[32] = 2147483648;
      exponentTable[63] = 3347054592;
      for (var i = 1; i < 31; i++) {
        exponentTable[i] = i << 23;
      }
      for (var i = 33; i < 63; i++) {
        exponentTable[i] = 2147483648 + (i - 32 << 23);
      }
      return exponentTable;
    }
    function computeFloat16OffsetTable() {
      var offsetTable = new Uint32Array(64);
      for (var i = 0; i < 64; i++) {
        offsetTable[i] = 1024;
      }
      offsetTable[0] = offsetTable[32] = 0;
      return offsetTable;
    }
    function getFloat16Decoder() {
      var mantisaTable = computeFloat16MantisaTable();
      var exponentTable = computeFloat16ExponentTable();
      var offsetTable = computeFloat16OffsetTable();
      return function(quantizedArray) {
        var buffer2 = new ArrayBuffer(4 * quantizedArray.length);
        var bufferUint32View = new Uint32Array(buffer2);
        for (var index = 0; index < quantizedArray.length; index++) {
          var float16Bits = quantizedArray[index];
          var float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 1023)] + exponentTable[float16Bits >> 10];
          bufferUint32View[index] = float32Bits;
        }
        return new Float32Array(buffer2);
      };
    }
    var TFHUB_SEARCH_PARAM = "?tfjs-format=file";
    var DEFAULT_MODEL_NAME = "model.json";
    var GraphModel = (
      /** @class */
      function() {
        function GraphModel2(modelUrl, loadOptions, tfio) {
          if (loadOptions === void 0) {
            loadOptions = {};
          }
          if (tfio === void 0) {
            tfio = tfc.io;
          }
          this.modelUrl = modelUrl;
          this.loadOptions = loadOptions;
          this.version = "n/a";
          this.io = tfio;
          if (loadOptions == null) {
            this.loadOptions = {};
          }
          this.resourceManager = new ResourceManager();
        }
        Object.defineProperty(GraphModel2.prototype, "modelVersion", {
          // Returns the version information for the tensorflow model GraphDef.
          get: function() {
            return this.version;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "inputNodes", {
          get: function() {
            return this.executor.inputNodes;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "outputNodes", {
          get: function() {
            return this.executor.outputNodes;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "inputs", {
          get: function() {
            return this.executor.inputs;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "outputs", {
          get: function() {
            return this.executor.outputs;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "weights", {
          get: function() {
            return this.executor.weightMap;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "metadata", {
          get: function() {
            return this.artifacts.userDefinedMetadata;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "modelSignature", {
          get: function() {
            return this.signature;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "modelStructuredOutputKeys", {
          get: function() {
            return this.structuredOutputKeys;
          },
          enumerable: false,
          configurable: true
        });
        GraphModel2.prototype.findIOHandler = function() {
          var path = this.modelUrl;
          if (path.load != null) {
            this.handler = path;
          } else if (this.loadOptions.requestInit != null) {
            this.handler = this.io.browserHTTPRequest(path, this.loadOptions);
          } else {
            var handlers = this.io.getLoadHandlers(path, this.loadOptions);
            if (handlers.length === 0) {
              handlers.push(this.io.browserHTTPRequest(path, this.loadOptions));
            } else if (handlers.length > 1) {
              throw new Error("Found more than one (".concat(handlers.length, ") load handlers for ") + "URL '".concat([path], "'"));
            }
            this.handler = handlers[0];
          }
        };
        GraphModel2.prototype.load = function() {
          var _this = this;
          this.findIOHandler();
          if (this.handler.load == null) {
            throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
          }
          var loadResult = this.handler.load();
          if (tfc.util.isPromise(loadResult)) {
            return loadResult.then(function(artifacts) {
              if (artifacts.getWeightStream == null) {
                return _this.loadSync(artifacts);
              }
              return _this.loadStreaming(artifacts);
            });
          }
          return this.loadSync(loadResult);
        };
        GraphModel2.prototype.loadSync = function(artifacts) {
          var weightMap = this.io.decodeWeights(artifacts.weightData, artifacts.weightSpecs);
          return this.loadWithWeightMap(artifacts, weightMap);
        };
        GraphModel2.prototype.loadStreaming = function(artifacts) {
          return __awaiter(this, void 0, void 0, function() {
            var weightMap;
            return __generator(this, function(_d) {
              switch (_d.label) {
                case 0:
                  if (artifacts.getWeightStream == null) {
                    throw new Error("Model artifacts missing streamWeights function");
                  }
                  return [4, decodeWeightsStream(artifacts.getWeightStream(), artifacts.weightSpecs)];
                case 1:
                  weightMap = _d.sent();
                  return [2, this.loadWithWeightMap(artifacts, weightMap)];
              }
            });
          });
        };
        GraphModel2.prototype.loadWithWeightMap = function(artifacts, weightMap) {
          this.artifacts = artifacts;
          var graph2 = this.artifacts.modelTopology;
          var signature = this.artifacts.signature;
          if (this.artifacts.userDefinedMetadata != null) {
            var metadata = this.artifacts.userDefinedMetadata;
            if (metadata.signature != null) {
              signature = metadata.signature;
            }
            if (metadata.structuredOutputKeys != null) {
              this.structuredOutputKeys = metadata.structuredOutputKeys;
            }
          }
          this.signature = signature;
          this.version = "".concat(graph2.versions.producer, ".").concat(graph2.versions.minConsumer);
          this.executor = new GraphExecutor(OperationMapper.Instance.transformGraph(graph2, this.signature));
          this.executor.weightMap = this.convertTensorMapToTensorsMap(weightMap);
          this.executor.resourceManager = this.resourceManager;
          if (artifacts.modelInitializer != null && artifacts.modelInitializer.node != null) {
            var initializer = OperationMapper.Instance.transformGraph(artifacts.modelInitializer);
            this.initializer = new GraphExecutor(initializer);
            this.initializer.weightMap = this.executor.weightMap;
            this.initializer.resourceManager = this.resourceManager;
            this.initializerSignature = artifacts.initializerSignature;
          }
          return true;
        };
        GraphModel2.prototype.save = function(handlerOrURL, config) {
          return __awaiter(this, void 0, void 0, function() {
            var handlers;
            return __generator(this, function(_d) {
              if (typeof handlerOrURL === "string") {
                handlers = this.io.getSaveHandlers(handlerOrURL);
                if (handlers.length === 0) {
                  throw new Error("Cannot find any save handlers for URL '".concat(handlerOrURL, "'"));
                } else if (handlers.length > 1) {
                  throw new Error("Found more than one (".concat(handlers.length, ") save handlers for ") + "URL '".concat(handlerOrURL, "'"));
                }
                handlerOrURL = handlers[0];
              }
              if (handlerOrURL.save == null) {
                throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
              }
              return [2, handlerOrURL.save(this.artifacts)];
            });
          });
        };
        GraphModel2.prototype.addStructuredOutputNames = function(outputTensors) {
          var _this = this;
          if (this.structuredOutputKeys) {
            var outputTensorsArray = outputTensors instanceof tfc.Tensor ? [outputTensors] : outputTensors;
            var outputTensorMap_1 = {};
            outputTensorsArray.forEach(function(outputTensor, i) {
              return outputTensorMap_1[_this.structuredOutputKeys[i]] = outputTensor;
            });
            return outputTensorMap_1;
          }
          return outputTensors;
        };
        GraphModel2.prototype.predict = function(inputs, config) {
          var outputTensors = this.execute(inputs, this.outputNodes);
          return this.addStructuredOutputNames(outputTensors);
        };
        GraphModel2.prototype.predictAsync = function(inputs, config) {
          return __awaiter(this, void 0, void 0, function() {
            var outputTensors;
            return __generator(this, function(_d) {
              switch (_d.label) {
                case 0:
                  return [4, this.executeAsync(inputs, this.outputNodes)];
                case 1:
                  outputTensors = _d.sent();
                  return [2, this.addStructuredOutputNames(outputTensors)];
              }
            });
          });
        };
        GraphModel2.prototype.normalizeInputs = function(inputs) {
          var _this = this;
          var _a;
          if (!(inputs instanceof tfc.Tensor) && !Array.isArray(inputs)) {
            var signatureInputs = (_a = this.signature) === null || _a === void 0 ? void 0 : _a.inputs;
            if (signatureInputs != null) {
              for (var input in signatureInputs) {
                var tensor2 = signatureInputs[input];
                if (tensor2.resourceId != null) {
                  inputs[input] = this.resourceIdToCapturedInput[tensor2.resourceId];
                }
              }
            }
            return inputs;
          }
          inputs = Array.isArray(inputs) ? inputs : [inputs];
          var numCapturedInputs = Object.keys(this.resourceIdToCapturedInput).length;
          if (inputs.length + numCapturedInputs !== this.inputNodes.length) {
            throw new Error("Input tensor count mismatch, the graph model has ".concat(this.inputNodes.length - numCapturedInputs, " non-resource placeholders, while there are ").concat(inputs.length, " input tensors provided."));
          }
          var inputIndex = 0;
          return this.inputNodes.reduce(function(map, inputName) {
            var _a2, _b, _c;
            var resourceId = (_c = (_b = (_a2 = _this.signature) === null || _a2 === void 0 ? void 0 : _a2.inputs) === null || _b === void 0 ? void 0 : _b[inputName]) === null || _c === void 0 ? void 0 : _c.resourceId;
            if (resourceId != null) {
              map[inputName] = _this.resourceIdToCapturedInput[resourceId];
            } else {
              map[inputName] = inputs[inputIndex++];
            }
            return map;
          }, {});
        };
        GraphModel2.prototype.normalizeOutputs = function(outputs) {
          outputs = outputs || this.outputNodes;
          return !Array.isArray(outputs) ? [outputs] : outputs;
        };
        GraphModel2.prototype.executeInitializerGraph = function() {
          if (this.initializer == null) {
            return [];
          }
          if (this.initializerSignature == null) {
            return this.initializer.execute({}, []);
          } else {
            return this.initializer.execute({}, Object.keys(this.initializerSignature.outputs));
          }
        };
        GraphModel2.prototype.executeInitializerGraphAsync = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_d) {
              if (this.initializer == null) {
                return [2, []];
              }
              if (this.initializerSignature == null) {
                return [2, this.initializer.executeAsync({}, [])];
              } else {
                return [2, this.initializer.executeAsync({}, Object.keys(this.initializerSignature.outputs))];
              }
            });
          });
        };
        GraphModel2.prototype.setResourceIdToCapturedInput = function(outputs) {
          this.resourceIdToCapturedInput = {};
          if (this.initializerSignature) {
            var signatureOutputs = this.initializerSignature.outputs;
            var outputNames = Object.keys(signatureOutputs);
            for (var i = 0; i < outputNames.length; i++) {
              var outputName = outputNames[i];
              var tensorInfo = signatureOutputs[outputName];
              this.resourceIdToCapturedInput[tensorInfo.resourceId] = outputs[i];
            }
          }
        };
        GraphModel2.prototype.execute = function(inputs, outputs) {
          if (this.resourceIdToCapturedInput == null) {
            this.setResourceIdToCapturedInput(this.executeInitializerGraph());
          }
          inputs = this.normalizeInputs(inputs);
          outputs = this.normalizeOutputs(outputs);
          var result = this.executor.execute(inputs, outputs);
          return result.length > 1 ? result : result[0];
        };
        GraphModel2.prototype.executeAsync = function(inputs, outputs) {
          return __awaiter(this, void 0, void 0, function() {
            var _d, result;
            return __generator(this, function(_e) {
              switch (_e.label) {
                case 0:
                  if (!(this.resourceIdToCapturedInput == null))
                    return [3, 2];
                  _d = this.setResourceIdToCapturedInput;
                  return [4, this.executeInitializerGraphAsync()];
                case 1:
                  _d.apply(this, [_e.sent()]);
                  _e.label = 2;
                case 2:
                  inputs = this.normalizeInputs(inputs);
                  outputs = this.normalizeOutputs(outputs);
                  return [4, this.executor.executeAsync(inputs, outputs)];
                case 3:
                  result = _e.sent();
                  return [2, result.length > 1 ? result : result[0]];
              }
            });
          });
        };
        GraphModel2.prototype.getIntermediateTensors = function() {
          return this.executor.getIntermediateTensors();
        };
        GraphModel2.prototype.disposeIntermediateTensors = function() {
          this.executor.disposeIntermediateTensors();
        };
        GraphModel2.prototype.convertTensorMapToTensorsMap = function(map) {
          return Object.keys(map).reduce(function(newMap, key) {
            newMap[key] = [map[key]];
            return newMap;
          }, {});
        };
        GraphModel2.prototype.dispose = function() {
          this.executor.dispose();
          if (this.initializer) {
            this.initializer.dispose();
            if (this.resourceIdToCapturedInput) {
              tfc.dispose(this.resourceIdToCapturedInput);
            }
          }
          this.resourceManager.dispose();
        };
        return GraphModel2;
      }()
    );
    function loadGraphModel(modelUrl, options, tfio) {
      if (options === void 0) {
        options = {};
      }
      if (tfio === void 0) {
        tfio = tfc.io;
      }
      return __awaiter(this, void 0, void 0, function() {
        var model;
        return __generator(this, function(_d) {
          switch (_d.label) {
            case 0:
              if (modelUrl == null) {
                throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");
              }
              if (options == null) {
                options = {};
              }
              if (options.fromTFHub && typeof modelUrl === "string") {
                modelUrl = getTFHubUrl(modelUrl);
              }
              model = new GraphModel(modelUrl, options, tfio);
              return [4, model.load()];
            case 1:
              _d.sent();
              return [2, model];
          }
        });
      });
    }
    function loadGraphModelSync(modelSource) {
      if (modelSource == null) {
        throw new Error("modelUrl in loadGraphModelSync() cannot be null. Please provide model artifacts or an IOHandler that loads the model");
      }
      var ioHandler;
      if (modelSource instanceof Array) {
        var _d = __read(modelSource, 2), modelJSON = _d[0], weights = _d[1];
        if (!modelJSON) {
          throw new Error("modelJSON must be the first element of the array");
        }
        if (!weights || !(weights instanceof ArrayBuffer)) {
          throw new Error("An ArrayBuffer of weights must be the second element of the array");
        }
        if (!("modelTopology" in modelJSON)) {
          throw new Error("Model JSON is missing 'modelTopology'");
        }
        if (!("weightsManifest" in modelJSON)) {
          throw new Error("Model JSON is missing 'weightsManifest'");
        }
        var weightSpecs = tfc.io.getWeightSpecs(modelJSON.weightsManifest);
        var modelArtifacts = tfc.io.getModelArtifactsForJSONSync(modelJSON, weightSpecs, weights);
        ioHandler = tfc.io.fromMemorySync(modelArtifacts);
      } else if ("load" in modelSource) {
        ioHandler = modelSource;
      } else if ("modelTopology" in modelSource && "weightSpecs" in modelSource && "weightData" in modelSource) {
        ioHandler = tfc.io.fromMemorySync(modelSource);
      } else {
        throw new Error("Unknown model format");
      }
      var model = new GraphModel(ioHandler);
      model.load();
      return model;
    }
    function getTFHubUrl(modelUrl) {
      if (!modelUrl.endsWith("/")) {
        modelUrl = modelUrl + "/";
      }
      return "".concat(modelUrl).concat(DEFAULT_MODEL_NAME).concat(TFHUB_SEARCH_PARAM);
    }
    var version = "4.15.0";
    exports.GraphModel = GraphModel;
    exports.deregisterOp = deregisterOp;
    exports.loadGraphModel = loadGraphModel;
    exports.loadGraphModelSync = loadGraphModelSync;
    exports.registerOp = registerOp;
    exports.version_converter = version;
  }
});

// node_modules/@tensorflow-models/coco-ssd/dist/coco-ssd.node.js
var require_coco_ssd_node = __commonJS({
  "node_modules/@tensorflow-models/coco-ssd/dist/coco-ssd.node.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    var tfconv = require_tf_converter_node();
    var tf = require_tf_core_node();
    function __awaiter(thisArg, _arguments, P, generator) {
      function adopt(value) {
        return value instanceof P ? value : new P(function(resolve) {
          resolve(value);
        });
      }
      return new (P || (P = Promise))(function(resolve, reject) {
        function fulfilled(value) {
          try {
            step(generator.next(value));
          } catch (e) {
            reject(e);
          }
        }
        function rejected(value) {
          try {
            step(generator["throw"](value));
          } catch (e) {
            reject(e);
          }
        }
        function step(result) {
          result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
      });
    }
    function __generator(thisArg, body) {
      var _ = { label: 0, sent: function() {
        if (t[0] & 1)
          throw t[1];
        return t[1];
      }, trys: [], ops: [] }, f, y, t, g;
      return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
      }), g;
      function verb(n) {
        return function(v) {
          return step([n, v]);
        };
      }
      function step(op) {
        if (f)
          throw new TypeError("Generator is already executing.");
        while (_)
          try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done)
              return t;
            if (y = 0, t)
              op = [op[0] & 2, t.value];
            switch (op[0]) {
              case 0:
              case 1:
                t = op;
                break;
              case 4:
                _.label++;
                return { value: op[1], done: false };
              case 5:
                _.label++;
                y = op[1];
                op = [0];
                continue;
              case 7:
                op = _.ops.pop();
                _.trys.pop();
                continue;
              default:
                if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {
                  _ = 0;
                  continue;
                }
                if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {
                  _.label = op[1];
                  break;
                }
                if (op[0] === 6 && _.label < t[1]) {
                  _.label = t[1];
                  t = op;
                  break;
                }
                if (t && _.label < t[2]) {
                  _.label = t[2];
                  _.ops.push(op);
                  break;
                }
                if (t[2])
                  _.ops.pop();
                _.trys.pop();
                continue;
            }
            op = body.call(thisArg, _);
          } catch (e) {
            op = [6, e];
            y = 0;
          } finally {
            f = t = 0;
          }
        if (op[0] & 5)
          throw op[1];
        return { value: op[0] ? op[1] : void 0, done: true };
      }
    }
    var CLASSES = {
      1: {
        name: "/m/01g317",
        id: 1,
        displayName: "person"
      },
      2: {
        name: "/m/0199g",
        id: 2,
        displayName: "bicycle"
      },
      3: {
        name: "/m/0k4j",
        id: 3,
        displayName: "car"
      },
      4: {
        name: "/m/04_sv",
        id: 4,
        displayName: "motorcycle"
      },
      5: {
        name: "/m/05czz6l",
        id: 5,
        displayName: "airplane"
      },
      6: {
        name: "/m/01bjv",
        id: 6,
        displayName: "bus"
      },
      7: {
        name: "/m/07jdr",
        id: 7,
        displayName: "train"
      },
      8: {
        name: "/m/07r04",
        id: 8,
        displayName: "truck"
      },
      9: {
        name: "/m/019jd",
        id: 9,
        displayName: "boat"
      },
      10: {
        name: "/m/015qff",
        id: 10,
        displayName: "traffic light"
      },
      11: {
        name: "/m/01pns0",
        id: 11,
        displayName: "fire hydrant"
      },
      13: {
        name: "/m/02pv19",
        id: 13,
        displayName: "stop sign"
      },
      14: {
        name: "/m/015qbp",
        id: 14,
        displayName: "parking meter"
      },
      15: {
        name: "/m/0cvnqh",
        id: 15,
        displayName: "bench"
      },
      16: {
        name: "/m/015p6",
        id: 16,
        displayName: "bird"
      },
      17: {
        name: "/m/01yrx",
        id: 17,
        displayName: "cat"
      },
      18: {
        name: "/m/0bt9lr",
        id: 18,
        displayName: "dog"
      },
      19: {
        name: "/m/03k3r",
        id: 19,
        displayName: "horse"
      },
      20: {
        name: "/m/07bgp",
        id: 20,
        displayName: "sheep"
      },
      21: {
        name: "/m/01xq0k1",
        id: 21,
        displayName: "cow"
      },
      22: {
        name: "/m/0bwd_0j",
        id: 22,
        displayName: "elephant"
      },
      23: {
        name: "/m/01dws",
        id: 23,
        displayName: "bear"
      },
      24: {
        name: "/m/0898b",
        id: 24,
        displayName: "zebra"
      },
      25: {
        name: "/m/03bk1",
        id: 25,
        displayName: "giraffe"
      },
      27: {
        name: "/m/01940j",
        id: 27,
        displayName: "backpack"
      },
      28: {
        name: "/m/0hnnb",
        id: 28,
        displayName: "umbrella"
      },
      31: {
        name: "/m/080hkjn",
        id: 31,
        displayName: "handbag"
      },
      32: {
        name: "/m/01rkbr",
        id: 32,
        displayName: "tie"
      },
      33: {
        name: "/m/01s55n",
        id: 33,
        displayName: "suitcase"
      },
      34: {
        name: "/m/02wmf",
        id: 34,
        displayName: "frisbee"
      },
      35: {
        name: "/m/071p9",
        id: 35,
        displayName: "skis"
      },
      36: {
        name: "/m/06__v",
        id: 36,
        displayName: "snowboard"
      },
      37: {
        name: "/m/018xm",
        id: 37,
        displayName: "sports ball"
      },
      38: {
        name: "/m/02zt3",
        id: 38,
        displayName: "kite"
      },
      39: {
        name: "/m/03g8mr",
        id: 39,
        displayName: "baseball bat"
      },
      40: {
        name: "/m/03grzl",
        id: 40,
        displayName: "baseball glove"
      },
      41: {
        name: "/m/06_fw",
        id: 41,
        displayName: "skateboard"
      },
      42: {
        name: "/m/019w40",
        id: 42,
        displayName: "surfboard"
      },
      43: {
        name: "/m/0dv9c",
        id: 43,
        displayName: "tennis racket"
      },
      44: {
        name: "/m/04dr76w",
        id: 44,
        displayName: "bottle"
      },
      46: {
        name: "/m/09tvcd",
        id: 46,
        displayName: "wine glass"
      },
      47: {
        name: "/m/08gqpm",
        id: 47,
        displayName: "cup"
      },
      48: {
        name: "/m/0dt3t",
        id: 48,
        displayName: "fork"
      },
      49: {
        name: "/m/04ctx",
        id: 49,
        displayName: "knife"
      },
      50: {
        name: "/m/0cmx8",
        id: 50,
        displayName: "spoon"
      },
      51: {
        name: "/m/04kkgm",
        id: 51,
        displayName: "bowl"
      },
      52: {
        name: "/m/09qck",
        id: 52,
        displayName: "banana"
      },
      53: {
        name: "/m/014j1m",
        id: 53,
        displayName: "apple"
      },
      54: {
        name: "/m/0l515",
        id: 54,
        displayName: "sandwich"
      },
      55: {
        name: "/m/0cyhj_",
        id: 55,
        displayName: "orange"
      },
      56: {
        name: "/m/0hkxq",
        id: 56,
        displayName: "broccoli"
      },
      57: {
        name: "/m/0fj52s",
        id: 57,
        displayName: "carrot"
      },
      58: {
        name: "/m/01b9xk",
        id: 58,
        displayName: "hot dog"
      },
      59: {
        name: "/m/0663v",
        id: 59,
        displayName: "pizza"
      },
      60: {
        name: "/m/0jy4k",
        id: 60,
        displayName: "donut"
      },
      61: {
        name: "/m/0fszt",
        id: 61,
        displayName: "cake"
      },
      62: {
        name: "/m/01mzpv",
        id: 62,
        displayName: "chair"
      },
      63: {
        name: "/m/02crq1",
        id: 63,
        displayName: "couch"
      },
      64: {
        name: "/m/03fp41",
        id: 64,
        displayName: "potted plant"
      },
      65: {
        name: "/m/03ssj5",
        id: 65,
        displayName: "bed"
      },
      67: {
        name: "/m/04bcr3",
        id: 67,
        displayName: "dining table"
      },
      70: {
        name: "/m/09g1w",
        id: 70,
        displayName: "toilet"
      },
      72: {
        name: "/m/07c52",
        id: 72,
        displayName: "tv"
      },
      73: {
        name: "/m/01c648",
        id: 73,
        displayName: "laptop"
      },
      74: {
        name: "/m/020lf",
        id: 74,
        displayName: "mouse"
      },
      75: {
        name: "/m/0qjjc",
        id: 75,
        displayName: "remote"
      },
      76: {
        name: "/m/01m2v",
        id: 76,
        displayName: "keyboard"
      },
      77: {
        name: "/m/050k8",
        id: 77,
        displayName: "cell phone"
      },
      78: {
        name: "/m/0fx9l",
        id: 78,
        displayName: "microwave"
      },
      79: {
        name: "/m/029bxz",
        id: 79,
        displayName: "oven"
      },
      80: {
        name: "/m/01k6s3",
        id: 80,
        displayName: "toaster"
      },
      81: {
        name: "/m/0130jx",
        id: 81,
        displayName: "sink"
      },
      82: {
        name: "/m/040b_t",
        id: 82,
        displayName: "refrigerator"
      },
      84: {
        name: "/m/0bt_c3",
        id: 84,
        displayName: "book"
      },
      85: {
        name: "/m/01x3z",
        id: 85,
        displayName: "clock"
      },
      86: {
        name: "/m/02s195",
        id: 86,
        displayName: "vase"
      },
      87: {
        name: "/m/01lsmm",
        id: 87,
        displayName: "scissors"
      },
      88: {
        name: "/m/0kmg4",
        id: 88,
        displayName: "teddy bear"
      },
      89: {
        name: "/m/03wvsk",
        id: 89,
        displayName: "hair drier"
      },
      90: {
        name: "/m/012xff",
        id: 90,
        displayName: "toothbrush"
      }
    };
    var version = "2.2.3";
    var BASE_PATH = "https://storage.googleapis.com/tfjs-models/savedmodel/";
    function load(config) {
      if (config === void 0) {
        config = {};
      }
      return __awaiter(this, void 0, void 0, function() {
        var base, modelUrl, objectDetection;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              if (tf == null) {
                throw new Error("Cannot find TensorFlow.js. If you are using a <script> tag, please also include @tensorflow/tfjs on the page before using this model.");
              }
              base = config.base || "lite_mobilenet_v2";
              modelUrl = config.modelUrl;
              if (["mobilenet_v1", "mobilenet_v2", "lite_mobilenet_v2"].indexOf(base) === -1) {
                throw new Error("ObjectDetection constructed with invalid base model " + "".concat(base, ". Valid names are 'mobilenet_v1',") + " 'mobilenet_v2' and 'lite_mobilenet_v2'.");
              }
              objectDetection = new ObjectDetection(base, modelUrl);
              return [4, objectDetection.load()];
            case 1:
              _a.sent();
              return [2, objectDetection];
          }
        });
      });
    }
    var ObjectDetection = (
      /** @class */
      function() {
        function ObjectDetection2(base, modelUrl) {
          this.modelPath = modelUrl || "".concat(BASE_PATH).concat(this.getPrefix(base), "/model.json");
        }
        ObjectDetection2.prototype.getPrefix = function(base) {
          return base === "lite_mobilenet_v2" ? "ssd".concat(base) : "ssd_".concat(base);
        };
        ObjectDetection2.prototype.load = function() {
          return __awaiter(this, void 0, void 0, function() {
            var _a, zeroTensor, result;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  _a = this;
                  return [4, tfconv.loadGraphModel(this.modelPath)];
                case 1:
                  _a.model = _b.sent();
                  zeroTensor = tf.zeros([1, 300, 300, 3], "int32");
                  return [4, this.model.executeAsync(zeroTensor)];
                case 2:
                  result = _b.sent();
                  return [4, Promise.all(result.map(function(t) {
                    return t.data();
                  }))];
                case 3:
                  _b.sent();
                  result.map(function(t) {
                    return t.dispose();
                  });
                  zeroTensor.dispose();
                  return [
                    2
                    /*return*/
                  ];
              }
            });
          });
        };
        ObjectDetection2.prototype.infer = function(img, maxNumBoxes, minScore) {
          return __awaiter(this, void 0, void 0, function() {
            var batched, height, width, result, scores, boxes, _a, maxScores, classes, prevBackend, indexTensor, indexes;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  batched = tf.tidy(function() {
                    if (!(img instanceof tf.Tensor)) {
                      img = tf.browser.fromPixels(img);
                    }
                    return tf.expandDims(img);
                  });
                  height = batched.shape[1];
                  width = batched.shape[2];
                  return [4, this.model.executeAsync(batched)];
                case 1:
                  result = _b.sent();
                  scores = result[0].dataSync();
                  boxes = result[1].dataSync();
                  batched.dispose();
                  tf.dispose(result);
                  _a = this.calculateMaxScores(scores, result[0].shape[1], result[0].shape[2]), maxScores = _a[0], classes = _a[1];
                  prevBackend = tf.getBackend();
                  if (tf.getBackend() === "webgl") {
                    tf.setBackend("cpu");
                  }
                  indexTensor = tf.tidy(function() {
                    var boxes2 = tf.tensor2d(boxes, [result[1].shape[1], result[1].shape[3]]);
                    return tf.image.nonMaxSuppression(boxes2, maxScores, maxNumBoxes, minScore, minScore);
                  });
                  indexes = indexTensor.dataSync();
                  indexTensor.dispose();
                  if (prevBackend !== tf.getBackend()) {
                    tf.setBackend(prevBackend);
                  }
                  return [2, this.buildDetectedObjects(width, height, boxes, maxScores, indexes, classes)];
              }
            });
          });
        };
        ObjectDetection2.prototype.buildDetectedObjects = function(width, height, boxes, scores, indexes, classes) {
          var count = indexes.length;
          var objects = [];
          for (var i = 0; i < count; i++) {
            var bbox = [];
            for (var j = 0; j < 4; j++) {
              bbox[j] = boxes[indexes[i] * 4 + j];
            }
            var minY = bbox[0] * height;
            var minX = bbox[1] * width;
            var maxY = bbox[2] * height;
            var maxX = bbox[3] * width;
            bbox[0] = minX;
            bbox[1] = minY;
            bbox[2] = maxX - minX;
            bbox[3] = maxY - minY;
            objects.push({
              bbox,
              class: CLASSES[classes[indexes[i]] + 1].displayName,
              score: scores[indexes[i]]
            });
          }
          return objects;
        };
        ObjectDetection2.prototype.calculateMaxScores = function(scores, numBoxes, numClasses) {
          var maxes = [];
          var classes = [];
          for (var i = 0; i < numBoxes; i++) {
            var max = Number.MIN_VALUE;
            var index = -1;
            for (var j = 0; j < numClasses; j++) {
              if (scores[i * numClasses + j] > max) {
                max = scores[i * numClasses + j];
                index = j;
              }
            }
            maxes[i] = max;
            classes[i] = index;
          }
          return [maxes, classes];
        };
        ObjectDetection2.prototype.detect = function(img, maxNumBoxes, minScore) {
          if (maxNumBoxes === void 0) {
            maxNumBoxes = 20;
          }
          if (minScore === void 0) {
            minScore = 0.5;
          }
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              return [2, this.infer(img, maxNumBoxes, minScore)];
            });
          });
        };
        ObjectDetection2.prototype.dispose = function() {
          if (this.model != null) {
            this.model.dispose();
          }
        };
        return ObjectDetection2;
      }()
    );
    exports.ObjectDetection = ObjectDetection;
    exports.load = load;
    exports.version = version;
  }
});

// src/content/blockList.js
var blockList = [
  "0006666.net",
  "0310love.com",
  "081xxx.com",
  "1001truyen.blogspot.com",
  "102model.com",
  "1116666.net",
  "116almet.ru",
  "123porn.com",
  "123sex.top",
  "12hdem.com",
  "1phimsex.vip",
  "1pondohd.com",
  "2089.vntopg88.live",
  "210vn.net",
  "247live.mobi",
  "24hchudu.com",
  "24hphimsex.com",
  "2jav.net",
  "2ola.pro",
  "303cc.xyz",
  "3jvos6.st-sy.com",
  "3xhay.pro",
  "3xhd.me",
  "3xphimsex.com",
  "3xsex.net",
  "3xtop.pro",
  "3xvn.pro",
  "444live.link",
  "51sexygirl.xyz",
  "567live.online",
  "567live.win",
  "567liveapp.net",
  "567lives.com",
  "567lives.top",
  "567livestop.com",
  "567livewin.com",
  "5sex.maulon.pro",
  "6666.net",
  "6789live.com",
  "7776666.net",
  "7sex.org",
  "820mm.live",
  "825mm.live",
  "836mm.live",
  "8886666.net",
  "9996666.net",
  "999live.app",
  "999live.pro",
  "9lxx.com",
  "9xlove.xyz",
  "adultepic.com",
  "alkux.com",
  "allx.tube",
  "alogai24.xyz",
  "alogaidep.xyz",
  "alogaigoi.com",
  "alogirlxinh.com",
  "alohang.xyz",
  "alohi.xyz",
  "aloyeu.com",
  "amurz.com",
  "anhgainude.com",
  "anhgaisexy.com",
  "anhgaixinh.us",
  "anhjavdep.blogspot.com",
  "anhlondep.xyz",
  "anhmodel.com",
  "anhnude.org",
  "anhphimsex.com",
  "anhsex.day",
  "anhsex18.biz",
  "anhsex18.com",
  "anhsex18.net",
  "anhsex18.top",
  "anhsexjav.xyz",
  "anhsexvip.me",
  "anhsexvip.net",
  "anhsexy69.com",
  "anhvl.net",
  "anhx.net",
  "antonstepanok.com",
  "app567lives.com",
  "appchichlive.top",
  "appgaixinh.com",
  "apphotlive.biz",
  "applive.vn",
  "applives.top",
  "appliveshow.com",
  "appmmlive.com",
  "argylesecurity.com",
  "automarket43.ru",
  "avhd.mobi",
  "b2branked.com",
  "badtopsex.com",
  "bantinh.xyz",
  "bb11.live",
  "bblive.org",
  "bblive17.vip",
  "bblive6.vip",
  "bemup.biz",
  "bimxinh.com",
  "bimxinh.net",
  "biphim18.com",
  "blog.applive.vn",
  "blogtruyensex.com",
  "boy18tube.com",
  "boybamien.com",
  "boymoviedome.com",
  "boyngon.com",
  "bucac.net",
  "buoito.vip",
  "buom.tv",
  "buomdep.pro",
  "buomsex.com",
  "buomxinh.org",
  "bupbetinhduc.co",
  "bupnhau.com",
  "callboy247.com",
  "callboyvn.net",
  "catewalk.com",
  "cavekiemdinh.xyz",
  "caysex.net",
  "cbhentai.one",
  "cbhentai.xyz",
  "cd-taxi.com",
  "cdn.manhwa24hs.com",
  "cdn2.seaporn.net",
  "changtrai.net",
  "chanheo.com",
  "chanrau.cc",
  "checkerfc.xyz",
  "checkerviet.bid",
  "checkerviet.fun",
  "checkerviet.one",
  "checkgaigoi.cc",
  "checkgaigoi.co",
  "checkgaigoi.info",
  "checkgaigoi.one",
  "checkgaigoi.tv",
  "checkgaigoi.us",
  "checkgaigoi.xyz",
  "checkgaiviet.com",
  "checkgaiviet.pro",
  "checkgaiviet.us",
  "chennhau.net",
  "chiasegaidep.xyz",
  "chich.club",
  "chich.live",
  "chich.mobi",
  "chich.pro",
  "chich.xyz",
  "chich3x.net",
  "chichchichchich.com",
  "chichgaixinh.com",
  "chichlive.biz",
  "chichlive.club",
  "chichlive.com",
  "chichlive.info",
  "chichlive.live",
  "chichlive.mobi",
  "chichlive.top",
  "chichlive.tumblr.com",
  "chichlivehd.online",
  "chichlivemobi.contently.com",
  "chigaicodon.xyz",
  "chim18.xyz",
  "chimlon.net",
  "chinababe.net",
  "chogai.net",
  "chogai.xyz",
  "choidangcap.net",
  "choidangcap.org",
  "choidangcap.pro",
  "choidangcap.us",
  "choiemdi.com",
  "choigai.xyz",
  "choigaigoi.com",
  "choitrai.com",
  "choitrai.net",
  "chuoito.com",
  "clip-sex.biz",
  "clip3xxx.com",
  "clipcave.xyz",
  "clipchich.com",
  "clipdit.xyz",
  "clipfull.xyz",
  "clipgai.xyz",
  "clipgai2k.xyz",
  "clipgaicave.xyz",
  "clipgaidep.com",
  "clipgaigoi.xyz",
  "clipgaingon.xyz",
  "clipgaixinh.xyz",
  "cliphang.xyz",
  "cliphangdep.xyz",
  "cliphot-vn.com",
  "cliphot.biz",
  "cliphot.cc",
  "cliphot.live",
  "cliphot.lol",
  "cliphot.me",
  "cliphot.net",
  "cliphot.online",
  "cliphot.space",
  "cliphot69.cc",
  "cliphot69.org",
  "cliphot69.win",
  "cliphotne.com",
  "cliphotqua.com",
  "cliphotvn.com",
  "cliphotvn.org",
  "cliphubs.com",
  "clipkhoe.xyz",
  "clipkhoehang.xyz",
  "clipnong.blog",
  "clipnong.club",
  "clipnong.co",
  "clipnong.com",
  "clipnong.live",
  "clipnong.lol",
  "clipnong.me",
  "clipnong.mobi",
  "clipnong.online",
  "clipnong.video",
  "clipnong.xyz",
  "clipnong18.com",
  "clipnong24h.com",
  "clipnongmobi.com",
  "clipquaylen.net",
  "clipscandal.xyz",
  "clipsex.cam",
  "clipsex.link",
  "clipsex.mobi",
  "clipsex.top",
  "clipsex.video",
  "clipsex.xxx",
  "clipsex1.com",
  "clipsex3x.net",
  "clipsex69.com",
  "clipsexhay.org",
  "clipsexhay.pro",
  "clipsexhot.org",
  "clipsexmoi.com",
  "clipsexnhatban.top",
  "clipsextop.com",
  "clipsextv.net",
  "clipsexviet.live",
  "clipsexviet.top",
  "clipsexviet.xyz",
  "clipsexvn.me",
  "clipsexvn.net",
  "clipsexvn.org",
  "clipsexx.net",
  "clipshowhang.xyz",
  "cliptrongngay.com",
  "clipviet69.net",
  "clipvietnam18.com",
  "clipxxx.tv",
  "cocomicz.com",
  "cogaixinh.live",
  "cogiaothao69.com",
  "coiphimsex.club",
  "coiphimsex.me",
  "coiphimsex.org",
  "coiphimsex.pro",
  "coisex.biz",
  "coithienthai.com",
  "comics24hd.net",
  "comics24hx.com",
  "comicz.co",
  "condau.net",
  "contrinh.net",
  "cphimsex.pro",
  "crownlive.net",
  "cuongsex.com",
  "cutexinh.com",
  "cutrai.net",
  "cwow.org",
  "dam18.me",
  "dam18.pro",
  "dam18.xyz",
  "dam3x.info",
  "dam69.biz",
  "dam69.cc",
  "dam69.com",
  "dam69.me",
  "dam69.org",
  "dam69.pro",
  "dam69.tv",
  "dam69.vip",
  "dam69.xyz",
  "dam69z.com",
  "damchim.com",
  "damchim1.com",
  "damlon.net",
  "damlon.xyz",
  "damvc.vip",
  "damvlerz.com",
  "damvodoi.com",
  "danchoihot.com",
  "daoxinh.bio",
  "demnay.com",
  "dep3x.pro",
  "diendanjav.com",
  "ditdu.com",
  "ditem.sbs",
  "ditgai.club",
  "ditgai.info",
  "ditgai.net",
  "ditgai.pro",
  "ditgai.xyz",
  "ditgaidep.com",
  "ditgaixinh.com",
  "ditgaixinh.me",
  "dithay.net",
  "ditme.biz",
  "ditme.info",
  "ditme88.com",
  "ditngon.com",
  "ditnhau.cc",
  "ditnhau.club",
  "ditnhau.cyou",
  "ditnhau.icu",
  "ditnhau.info",
  "ditnhau.live",
  "ditnhau.online",
  "ditnhau.org",
  "ditnhau.pw",
  "ditnhau.vip",
  "ditnhau.xyz",
  "ditnhauko.net",
  "ditnhauvietnam.com",
  "ditnhauz.com",
  "ditnhauz.net",
  "dl.bb11.live",
  "dmhentai.net",
  "dmsex.net",
  "doctruyen14x.com",
  "doctruyennguoilonhay.blogspot.com",
  "doctruyennguoilonvl.wordpress.com",
  "dokatehnik.ru",
  "donggai.pro",
  "dongtoico.co",
  "dongtoico.com",
  "dongtoico.info",
  "dongtoico.live",
  "dongtoico.tv",
  "dongtoico.us",
  "dongtrai.com",
  "dp568phim.com",
  "dphimsex.cc",
  "dualeotruyen1s.com",
  "dualeotruyen24h.com",
  "dualeotruyen3s.com",
  "dualeotruyenzz.com",
  "duccai.com",
  "duccai.xyz",
  "dutrai.com",
  "emdau.pro",
  "emgai.net",
  "emgaixinh.one",
  "emmiu.art",
  "emodayne.live",
  "emodayne.one",
  "emphequa.com",
  "emtien2k1.live",
  "emxinh.art",
  "emxinh.click",
  "emxinh.live",
  "ephimsex.net",
  "erotic-hentai.com",
  "etinhyeu.com",
  "faggai.pro",
  "fanpay.org",
  "fap18.net",
  "file.dp568phim.com",
  "file.mm1cloud.com",
  "film18.pro",
  "filmseksbaru.blogspot.com",
  "fimsex.org",
  "fimsex.vip",
  "fimsexmoi.com",
  "fullphim.pro",
  "gai18.net",
  "gai18.pw",
  "gai35.com",
  "gai3s.net",
  "gai3x.com",
  "gaicaocap.link",
  "gaicaocap.xyz",
  "gaichanh.co",
  "gaidam.click",
  "gaidam.host",
  "gaidam.in",
  "gaidam.link",
  "gaidam.org",
  "gaidam.pro",
  "gaidam.site",
  "gaidam3x.com",
  "gaidamxx.xyz",
  "gaidamxxx.xyz",
  "gaidanang.click",
  "gaidanang.fun",
  "gaidanang.in",
  "gaidanang.link",
  "gaidep.pro",
  "gaidephanoi.xyz",
  "gaidepvietnam.com",
  "gaidepvip.xyz",
  "gaidepvn.xyz",
  "gaidikhach.xyz",
  "gaigoi.app",
  "gaigoi.icu",
  "gaigoi.link",
  "gaigoi.live",
  "gaigoi18.biz",
  "gaigoi18.site",
  "gaigoi24h.net",
  "gaigoi33.xyz",
  "gaigoi9.com",
  "gaigoialo.com",
  "gaigoiangiang.xyz",
  "gaigoiaz.xyz",
  "gaigoibaclieu.xyz",
  "gaigoibentre.xyz",
  "gaigoibienhoadongnai.xyz",
  "gaigoicamau.xyz",
  "gaigoicantho.xyz",
  "gaigoicave.xyz",
  "gaigoidalat.xyz",
  "gaigoidanang.link",
  "gaigoidanang.net",
  "gaigoidanang.xyz",
  "gaigoidananghot.com",
  "gaigoidananghot.net",
  "gaigoidananghot.xyz",
  "gaigoidep.info",
  "gaigoidep.org",
  "gaigoidep.pro",
  "gaigoidep.site",
  "gaigoidep.xyz",
  "gaigoidongthap.xyz",
  "gaigoigiare.com",
  "gaigoihaiphong.gonevis.com",
  "gaigoihanoi.icu",
  "gaigoihanoi.info",
  "gaigoihanoi.net",
  "gaigoihanoi.one",
  "gaigoihanoi.pro",
  "gaigoihanoivip.com",
  "gaigoihanoivip.vncns.com",
  "gaigoihaugiang.xyz",
  "gaigoihn.com",
  "gaigoihue.link",
  "gaigoihue.live",
  "gaigoihue.net",
  "gaigoihue.xyz",
  "gaigoihuekiemdinh.xyz",
  "gaigoikiemdinh.click",
  "gaigoikiemdinh.com",
  "gaigoikiemdinh.fun",
  "gaigoikiemdinh.link",
  "gaigoikiemdinh.live",
  "gaigoikiemdinh.net",
  "gaigoikiemdinh.vip",
  "gaigoikiemdinh1.xyz",
  "gaigoikiengiang.xyz",
  "gaigoilauxanh.us",
  "gaigoilauxanh.xyz",
  "gaigoilongan.xyz",
  "gaigoimientay.xyz",
  "gaigoinhatrang.com",
  "gaigoinhatrang.link",
  "gaigoinhatrang.xyz",
  "gaigoionline.click",
  "gaigoionline.info",
  "gaigoionline.link",
  "gaigoionline.live",
  "gaigoionline.xyz",
  "gaigoipho.xyz",
  "gaigoisaigon.xyz",
  "gaigoisinhvien.xyz",
  "gaigoisoctrang.xyz",
  "gaigoitayninh.xyz",
  "gaigoitelegram.xyz",
  "gaigoitiengiang.xyz",
  "gaigoitop.xyz",
  "gaigoituoi17.xyz",
  "gaigoituoi18.fun",
  "gaigoituoi18.link",
  "gaigoituoi18.xyz",
  "gaigoiviet.info",
  "gaigoivinhlong.xyz",
  "gaigoivip.info",
  "gaigoivip.live",
  "gaigoivip.org",
  "gaigoivip.pro",
  "gaigoivip.site",
  "gaigoivn.club",
  "gaigoixinh.me",
  "gaigoixx.xyz",
  "gaigu.to",
  "gaigu.xyz",
  "gaigu1.tv",
  "gaigu6.tv",
  "gaigu7.tv",
  "gaigu8.tv",
  "gaigutv.net",
  "gaigutv.org",
  "gaigutv.top",
  "gaigutv.vip",
  "gaihongdao.xyz",
  "gaikhoehang.com",
  "gaikiemdinh.fun",
  "gaikiemdinh.link",
  "gaikiemdinh.live",
  "gaikiemdinh.net",
  "gaikiemdinh.org",
  "gaikiemdinh.site",
  "gaikiemdinh1.xyz",
  "gaikiemdinhx.xyz",
  "gailauxanh.xyz",
  "gailondep.net",
  "gailove.com",
  "gaimassagetainha.vipvn.net",
  "gaimup.click",
  "gaimup.lol",
  "gaimup.net",
  "gaimup.shop",
  "gaimup.site",
  "gaimup.xyz",
  "gaingon.lol",
  "gaingonlive.com",
  "gainviewers.com",
  "gaionline.xyz",
  "gaisex.me",
  "gaisex.net",
  "gaisex.top",
  "gaithudam.org",
  "gaito.life",
  "gaito.xyz",
  "gaitop.click",
  "gaitop.link",
  "gaitop.me",
  "gaitredep.top",
  "gaituoi18.xyz",
  "gaituyenchon.link",
  "gaituyenchon.xyz",
  "gaivietdo.com",
  "gaivip.art",
  "gaivip.lol",
  "gaivip.mom",
  "gaixinh.app",
  "gaixinh.art",
  "gaixinh.biz",
  "gaixinh.cyou",
  "gaixinh.me",
  "gaixinh.photo",
  "gaixinh.sex",
  "gaixinh.space",
  "gaixinh.us",
  "gaixinh.vipvn.net",
  "gaixinh18.info",
  "gaixinh18.zalovn.net",
  "gaixinh24h.xyz",
  "gaixinh2k.xyz",
  "gaixinh365.com",
  "gaixinh365.net",
  "gaixinhanoi.xyz",
  "gaixinhcaocap.top",
  "gaixinhchandai.com",
  "gaixinhgiare.com",
  "gaixinhhenho.com",
  "gaixinhkhoehang.com",
  "gaixinhonline.com",
  "gaixinhshowhang.online",
  "gaixinhthudam.net",
  "gay3x.top",
  "gay3x.tv",
  "gayhd.tv",
  "gaysex69.net",
  "ggvn.xyz",
  "ghepdoi.site",
  "girl3x.xyz",
  "girlkiemdinh.link",
  "girlkiemdinh.xyz",
  "girlxinhblog.com",
  "girlxinhcaocap.com",
  "girlxinhxinh.com",
  "gockhuat.net",
  "gocquaytay.com",
  "goctoi.xyz",
  "goigai2k.xyz",
  "goigai3m.xyz",
  "goigaicaocap.xyz",
  "goikieu.org",
  "gvnvh18.com",
  "gwweb.xyz",
  "hangdep.co",
  "hangdep.xyz",
  "hangdep18.com",
  "hangkhung.club",
  "hangngon.pro",
  "hangto.club",
  "hardcore3000.com",
  "hay3x.tv",
  "hay3x.vip",
  "hay69.top",
  "hay88.me",
  "hayhaynhat.com",
  "hayjav.com",
  "hayphimsex.net",
  "haysex.net",
  "haysex.xyz",
  "hayvkl.xyz",
  "hayvl.pro",
  "hdgay.net",
  "hdlove.at",
  "hdvietsubmoi.com",
  "hdxjav.xyz",
  "hdxx.sex",
  "hdxx.tv",
  "hdxxxx.org",
  "hencb.top",
  "henho.cucvui.com",
  "henho.us",
  "henho.vip",
  "henho247.xyz",
  "henho24az.xyz",
  "henho24h.com",
  "henho2k.xyz",
  "henho3mien.com",
  "henhoaz.xyz",
  "henhogai.xyz",
  "henhozalo.com",
  "hentai24h.org",
  "hentai789.cc",
  "hentai88.vip",
  "hentaiaz.net",
  "hentaicb.top",
  "hentaicb.xyz",
  "hentaihub.pro",
  "hentaimanhwa.net",
  "hentaimoi.com",
  "hentaipro.tv",
  "hentaisub.live",
  "hentaivip.biz",
  "hentaivip.pro",
  "hentaivl.tv",
  "hentaivl.vip",
  "hentaivlv.com",
  "hentaivlz.com",
  "hentaivn.autos",
  "hentaivn.cc",
  "hentaivn.com",
  "hentaivn.de",
  "hentaivn.fun",
  "hentaivn.info",
  "hentaivn.la",
  "hentaivn.life",
  "hentaivn.moe",
  "hentaivn.online",
  "hentaivn.run",
  "hentaivn.team",
  "hentaivn.tv",
  "hentaivnn.net",
  "hentaivnpro.net",
  "hentaivnvip.com",
  "hentaivv1.com",
  "hentaivvz.com",
  "hentaiz.cc",
  "hentaiz.in",
  "hentaiz.mobi",
  "hentaiz.vip",
  "hentaizz.net",
  "heo3x.club",
  "heo3x.info",
  "heo3x.net",
  "heo3x.top",
  "heo3xx.com",
  "heo68.biz",
  "heo68.pro",
  "heo68.xyz",
  "heo69.cc",
  "heo69.com",
  "heo69.icu",
  "heo69.info",
  "heo69.link",
  "heo69.me",
  "heo69.org",
  "heo69.top",
  "heo699.sbs",
  "heo88.net",
  "heodam.biz",
  "heodam.net",
  "heodam.pro",
  "heodem.com",
  "heodem.info",
  "heodem.plus",
  "heodem.vip",
  "heodemz.net",
  "heodemz.org",
  "heohay.com",
  "heohd.com",
  "heomup.net",
  "heotop1.net",
  "heotv.net",
  "heoviet.com",
  "heovl.cc",
  "heovl.com",
  "heovl.fun",
  "heovl.io",
  "heovl.live",
  "heovl.me",
  "heovl.net",
  "heovl.tv",
  "heovl1.com",
  "heovl1.net",
  "heozz.net",
  "heyzo.pro",
  "hhentai.net",
  "hihisex.biz",
  "hihisex.pro",
  "hihisex.vip",
  "hinhgai.com",
  "hinhgaixinh.org",
  "hinhkhieudam.com",
  "hinhxes.com",
  "hisex.cc",
  "hisex.pro",
  "hisex.xyz",
  "hlxx.pro",
  "hoidam.vip",
  "home.tuoi69vn.com",
  "hongbiencang.com",
  "hotlive.win",
  "hqthaiporn.com",
  "htvncdn.net",
  "hungtinh.net",
  "i-xnxx.com",
  "i1.hhentai.net",
  "i3.hentaivn.tv",
  "i3.hhentai.net",
  "i998.co",
  "icehdv.com",
  "img.hentaivv1.com",
  "img.heozz.net",
  "img.phimkk.vip",
  "img.phimloz.tv",
  "img.phimtxx.net",
  "info.xnxx.gold",
  "ishg.xyz",
  "japanhdv.biz",
  "jav-hay.com",
  "jav-phim.com",
  "jav.ffmgu.ru",
  "jav.markets",
  "jav2.pro",
  "jav2022.top",
  "jav2k.net",
  "jav678.me",
  "jav6789.com",
  "jav69.tube",
  "jav789.tv",
  "jav99.biz",
  "javabc.com",
  "javbiz.net",
  "javdemz.com",
  "javdep.com",
  "javdep.me",
  "javdep.net",
  "javdep.pro",
  "javdit.com",
  "javdm.org",
  "javfinder.la",
  "javfinder.li",
  "javgg.me",
  "javgiga.com",
  "javhay.asia",
  "javhay.club",
  "javhay.co",
  "javhay.cyou",
  "javhay.media",
  "javhay.one",
  "javhay.online",
  "javhay.org",
  "javhay.site",
  "javhay.store",
  "javhay.xxx",
  "javhaytop.net",
  "javhayz.cc",
  "javhayz.com",
  "javhd-porn.net",
  "javhd-stream.com",
  "javhd-vn.com",
  "javhd-vn.xyz",
  "javhd.ai",
  "javhd.best",
  "javhd.bio",
  "javhd.charity",
  "javhd.contact",
  "javhd.im",
  "javhd.lol",
  "javhd.moe",
  "javhd.news",
  "javhd.ninja",
  "javhd.page",
  "javhd.services",
  "javhd.tech",
  "javhd.video",
  "javhd.ws",
  "javhdhay.me",
  "javhdhayz.com",
  "javhdhayz.net",
  "javhdkhongche.com",
  "javhdpro.org",
  "javhdvd.net",
  "javhiv.com",
  "javhiv.one",
  "javhiv.xyz",
  "javhotvietsub.com",
  "javkhongche.net",
  "javlxx.com",
  "javmienphi.com",
  "javmienphi.live",
  "javmienphi.net",
  "javmienphi.org",
  "javmienphi.xyz",
  "javmoi.org",
  "javne.net",
  "javnhat.club",
  "javnhatban.me",
  "javnhatban.net",
  "javnhatban.pro",
  "javnhe.org",
  "javnoi.xyz",
  "javnong.cc",
  "javnong.top",
  "javnong.xyz",
  "javphe.cc",
  "javphe.info",
  "javphim.cam",
  "javphim.co",
  "javphim.com",
  "javphim.cyou",
  "javphim.lol",
  "javphim.net",
  "javphim.org",
  "javphim.site",
  "javphim.space",
  "javphim.xyz",
  "javphimsex.pro",
  "javphimx.net",
  "javpho.net",
  "javphot.net",
  "javphoz.com",
  "javpro.biz",
  "javsex.cc",
  "javsub.biz",
  "javsub.cc",
  "javsub.co",
  "javsub.in",
  "javsub.live",
  "javsub.mobi",
  "javsub.one",
  "javsub.online",
  "javsub.wiki",
  "javsub.xyz",
  "javsubmoi.net",
  "javsubz.com",
  "javtop1.biz",
  "javtop1.com",
  "javtop1.org",
  "javtop1.pro",
  "javtop1.xyz",
  "javtopvn.com",
  "javtopxx.com",
  "javuz.com",
  "javviet.me",
  "javviet.tv",
  "javvietnam.net",
  "javvietsub.biz",
  "javvietsub.city",
  "javvietsub.me",
  "javvn.me",
  "javvn.online",
  "javvn.org",
  "javx.me",
  "javxem.com",
  "javxxx.org",
  "javxxx.vip",
  "jizzbay.com",
  "jpxnx.com",
  "jpxnx.ink",
  "ka25.ru",
  "kenh3x.net",
  "kenh3x.xxx",
  "kenh4.com",
  "kenhdammy.com",
  "kenhjav.pro",
  "kenhporn.xyz",
  "kenhsex.net",
  "kenhvitamin.com",
  "kenxxx.com",
  "ketban24h.xyz",
  "ketdoi.net",
  "khattinh.pro",
  "khattinh.tech",
  "khieudam.club",
  "khoailac.net",
  "khoanhgaixinh.com",
  "khoanhnguoinoitieng.blogspot.com",
  "khohieu.com",
  "khongche.click",
  "khongche.net",
  "khongche.us",
  "khophim1080.com",
  "khophim18.com",
  "khophimhay.pro",
  "khophimsex.co",
  "khosex.me",
  "khosex.net",
  "khotruyenhay.wordpress.com",
  "khotruyensexy.blogspot.com",
  "khotruyentranhx.com",
  "khotruyenvn.com",
  "khugai.com",
  "kichdam.me",
  "kichduc.biz",
  "kichduc.cc",
  "kichduc.to",
  "kichduc.vip",
  "kieunuvadaigia.link",
  "kieunuvadaigia.live",
  "kieunuvadaigia.xyz",
  "kieunuviet.xyz",
  "kphimsex.xyz",
  "ktv.bio",
  "kute3x.net",
  "kynu.live",
  "kynudanang.link",
  "kynudanang.xyz",
  "kynudep.com",
  "kynukiemdinh.fun",
  "kynukiemdinh.link",
  "kynukiemdinh.net",
  "kynukiemdinhx.xyz",
  "kynuviet.net",
  "lala69.com",
  "laugai.net",
  "lauxanh.me",
  "lauxanh.one",
  "lauxanhthiendia.com",
  "laysogaigoi.com",
  "lenlut.info",
  "lenlut.net",
  "linh2k.live",
  "linkclipsex.com",
  "linkclipsex.xyz",
  "linksex.live",
  "linksex.me",
  "linksex.pro",
  "live.mm1cloud.com",
  "live.sexviet88.pro",
  "live18.online",
  "live2k.lol",
  "livechich.com",
  "loandam.net",
  "loanluan.top",
  "loanluanx.com",
  "loclipnong.com",
  "lon2k.com",
  "lon88.com",
  "lon88.sex",
  "lon88.vip",
  "lon88.ws",
  "londam.net",
  "londam.pro",
  "londep.city",
  "londep.org",
  "londep18.xyz",
  "londepz.com",
  "longai.xyz",
  "longaiviet.info",
  "longaixinh.com",
  "lonkk.net",
  "lonmup.vip",
  "lonsex.net",
  "lonto.club",
  "lonto.vip",
  "lonto18.com",
  "lontv.cc",
  "lontv.co",
  "lontv.mobi",
  "lontv.tv",
  "lonxnxx.com",
  "lovejav.net",
  "lutcan.net",
  "luyensex.club",
  "m-vlxx.com",
  "m.1116666.net",
  "m.cd-taxi.com",
  "m.clipviet69.net",
  "m.conheo3x.com",
  "m.hentaiaz.net",
  "m.heyzo.biz",
  "m.phe3x.xyz",
  "m.phimsexhay.cc",
  "m.phimsexsub.co",
  "m.sexhayvc.biz",
  "m.sexsub.xyz",
  "m.sexzz.me",
  "m.taianhsex.com",
  "m.viet69.chat",
  "m.viet69.tech",
  "m.vlxxvietsub.net",
  "m.xvietsub.tv",
  "m.youtubecliphot.link",
  "manggaigoi.info",
  "manhwa24h.com",
  "manhwa24hs.com",
  "manhwa24hz.com",
  "manhwavn.com",
  "manquynh.com",
  "manquynh.net",
  "manquynh1.com",
  "massagebinhduong.vipvn.net",
  "massagegayhcm.110.vn",
  "massagetannoi24h.com",
  "massageviet.net",
  "massagevungtau.com",
  "massagex.org",
  "mattrinh.net",
  "maulon.pro",
  "mb.phimsexvip.cc",
  "mbbg-binhduong.blogspot.com",
  "mbbg.cc",
  "mbbg.club",
  "mbbg.info",
  "mbbg.live",
  "mbbg.org",
  "mbbg.pro",
  "mbbg.tv",
  "mbbg.vip",
  "mbbg.xyz",
  "mbbgvietnam.me",
  "megaidep.link",
  "megaidep.online",
  "megaidep.xyz",
  "megaidep1.xyz",
  "megaidepx.link",
  "megaxh.com",
  "mekiep.pro",
  "mephimsex.com",
  "mesex.pro",
  "mhuu6.wiki",
  "migraine-aura.com",
  "milive.fun",
  "minosa68.com",
  "miuxinh.art",
  "mlem.live",
  "mm.mm1cloud.com",
  "mm1cloud.com",
  "mm819.me",
  "mmlive.link",
  "mmlive.live",
  "mmlive.one",
  "mmlive.plus",
  "mmlive1.com",
  "mmliveapp.club",
  "mmliveapp.top",
  "mmliveapptop.com",
  "mobiblog.bio",
  "mobiblog.cc",
  "mobiblog.io",
  "mobiblog.net",
  "mobiblog.us",
  "mobiblog.vip",
  "modelviet.us",
  "moihay.com",
  "moonlive.club",
  "moto88.fun",
  "mphimsex.me",
  "mphimsex.pro",
  "mphimsex.xyz",
  "mtbshop.ru",
  "mtruyen18.com",
  "mup.sex",
  "mupxx.net",
  "mvhay.xyz",
  "myhotlive.tv",
  "mymeyeu.xyz",
  "nangdau.top",
  "nenvl.net",
  "newsexwap.com",
  "ngamgai.click",
  "ngamgai.live",
  "ngamgai.lol",
  "ngamgai.online",
  "ngamgai.pics",
  "ngamgai.xyz",
  "nganhsex.net",
  "ngaytho.me",
  "ngonvl.com",
  "nguoilon.top",
  "nguoithuong.xyz",
  "nhatkimaymua.com",
  "nhentaivn.com",
  "nhomdich.com",
  "nudeok.com",
  "nudeok.live",
  "nudeok.pro",
  "nudephim.com",
  "nudevietnam.com",
  "nungvc.vip",
  "nungvl.net",
  "nuotvl.com",
  "nv89w.top",
  "okne.net",
  "olaphim.org",
  "ongtrumtraigoi.com",
  "opjav.com",
  "pfile.name",
  "phang.pro",
  "phang3x.com",
  "phatrinh.org",
  "phe3x.xyz",
  "phe69.com",
  "pheloi.com",
  "phesex.pro",
  "phesex.vip",
  "phevkl.com",
  "phevkl.me",
  "phevklz.com",
  "phichthu.club",
  "phim-heo.cc",
  "phim-heo.com",
  "phim-heo.pro",
  "phim-jav.vip",
  "phim-javhd.biz",
  "phim-javhd.com",
  "phim-javhd.pro",
  "phim-sec.net",
  "phim-sec.one",
  "phim-sec.pro",
  "phim-set-hay.pro",
  "phim-set.me",
  "phim-set.pro",
  "phim-sex-hay.me",
  "phim-sex-hay.net",
  "phim-sex-khong-che.com",
  "phim-sex-moi.net",
  "phim-sex.co",
  "phim-sex.live",
  "phim-sex.tv",
  "phim-sexhay.pro",
  "phim-sexhd.biz",
  "phim-sexmoi.pro",
  "phim-x.me",
  "phim-xes.pro",
  "phim-xnxx.me",
  "phim-xnxx.pro",
  "phim-xnxx.xyz",
  "phim-xxx.me",
  "phim-xxx.xyz",
  "phim.damvodoi.com",
  "phim.javhay.asia",
  "phim.sex68.link",
  "phim.sexmyhd.com",
  "phim.sexvn.one",
  "phim.vl9x.net",
  "phim.vuasex.co",
  "phim18.co",
  "phim18.online",
  "phim18hd.co",
  "phim18hd.com",
  "phim18hd.info",
  "phim18hd.net",
  "phim18hd.org",
  "phim18hdo.com",
  "phim18hot.com",
  "phim18k.com",
  "phim18vn.biz",
  "phim18vn.com",
  "phim18vn.net",
  "phim18x.net",
  "phim24h.pro",
  "phim2k.org",
  "phim3xhay.com",
  "phim3xhd.pro",
  "phim69.info",
  "phim7789.com",
  "phim85.com",
  "phima1.com",
  "phimbx.co",
  "phimbx.vip",
  "phimc3.net",
  "phimcave.com",
  "phimcave.top",
  "phimche.top",
  "phimchichnhau.com",
  "phimconheo.cc",
  "phimconheo.cyou",
  "phimconheo.info",
  "phimconheo.pro",
  "phimconheo.xyz",
  "phimconlon.net",
  "phimdemz.com",
  "phimdenz.com",
  "phimdit.pro",
  "phimditnhau.cc",
  "phimditnhau.club",
  "phimditnhau.co",
  "phimditnhau.icu",
  "phimditnhau.info",
  "phimditnhau.one",
  "phimditnhau.top",
  "phimditnhau.xyz",
  "phimditvl.com",
  "phimdot.vip",
  "phimex.me",
  "phimfull.pro",
  "phimgaixinh.top",
  "phimhanquoc18.com",
  "phimhay.pro",
  "phimhay3x.pro",
  "phimhay789.com",
  "phimhay789.win",
  "phimhd.sex",
  "phimhdhay.pro",
  "phimhdsex.com",
  "phimhentai.biz",
  "phimhentai.cyou",
  "phimhentai.pro",
  "phimhentai.xyz",
  "phimheo.biz",
  "phimheo.club",
  "phimheo.cyou",
  "phimheo.fun",
  "phimheo.life",
  "phimheo.me",
  "phimheo.mobi",
  "phimheo.net",
  "phimheo.one",
  "phimheo.online",
  "phimheo.plus",
  "phimheo.video",
  "phimheo.wiki",
  "phimheo69.plus",
  "phimheo789.com",
  "phimheohay.pro",
  "phimheoplus.net",
  "phimheosex.cc",
  "phimheosex.net",
  "phimheovietnam.cc",
  "phimheovietnam.com",
  "phimheovietnam.info",
  "phimheovietnam.xyz",
  "phimheovip.com",
  "phimheovl.net",
  "phimheovn.biz",
  "phimheovn.cc",
  "phimheoxx.com",
  "phimheoz.com",
  "phimheoz.org",
  "phimheoz.pro",
  "phimheoz.tv",
  "phimhiepdam.me",
  "phimhiepdam.top",
  "phimhinh.top",
  "phimii.net",
  "phimixxx.com",
  "phimjav.club",
  "phimjav.net",
  "phimjav.plus",
  "phimjav.xxx",
  "phimjav.xyz",
  "phimjavhd.net",
  "phimjavhd.pro",
  "phimjavnhat.top",
  "phimjavsex.me",
  "phimkhongche.com",
  "phimkk.com",
  "phimkk.me",
  "phimkk.net",
  "phimkk.vip",
  "phimkk.ws",
  "phimll.net",
  "phimloanluan.me",
  "phimloanluan.net",
  "phimloanluan.org",
  "phimlon.net",
  "phimlon.pro",
  "phimlon.xyz",
  "phimlop.com",
  "phimloz.co",
  "phimloz.info",
  "phimloz.net",
  "phimloz.pro",
  "phimloz.to",
  "phimloz.tv",
  "phimloz.ws",
  "phimmup.com",
  "phimmup.net",
  "phimnguoilon.biz",
  "phimnguoilon.cc",
  "phimnguoilon.info",
  "phimnguoilon.online",
  "phimnguoilon.top",
  "phimnguoilon.xyz",
  "phimolsex.pro",
  "phimonline.click",
  "phimphicong.xyz",
  "phimporn.pro",
  "phims3x.net",
  "phimsd.org",
  "phimsdx.org",
  "phimse.pro",
  "phimse.xyz",
  "phimsec-hay.net",
  "phimsec.cc",
  "phimsec.cyou",
  "phimsec.icu",
  "phimsec.info",
  "phimsec.live",
  "phimsec.one",
  "phimsec.org",
  "phimsec.pro",
  "phimsec.to",
  "phimsec.vip",
  "phimsec1.pro",
  "phimsec69.me",
  "phimsec7.top",
  "phimsecc.net",
  "phimsech.top",
  "phimsechay.pro",
  "phimsecmoi.net",
  "phimsecmy.net",
  "phimsecnhat.cyou",
  "phimsecvietnam.net",
  "phimsecvietnam.pro",
  "phimsecvl.com",
  "phimsehay.com",
  "phimsenhat.top",
  "phimset.cc",
  "phimset.cyou",
  "phimset.live",
  "phimset.me",
  "phimset.mobi",
  "phimset.net",
  "phimset.one",
  "phimset.plus",
  "phimset.pro",
  "phimset.sex",
  "phimset.top",
  "phimset.tube",
  "phimset.wtf",
  "phimset69.net",
  "phimsetmoi.net",
  "phimsetnhat.top",
  "phimsettre.net",
  "phimsex-com.pro",
  "phimsex-ditnhau.pro",
  "phimsex-hanquoc.net",
  "phimsex-hay.me",
  "phimsex-japan.pro",
  "phimsex-jav.com",
  "phimsex-jav.net",
  "phimsex-khongche.pro",
  "phimsex-loanluan.pro",
  "phimsex-my.net",
  "phimsex-nhatban.me",
  "phimsex-nhatban.pro",
  "phimsex-trungquoc.com",
  "phimsex-vlxx.vip",
  "phimsex-vn.com",
  "phimsex-xxx.pro",
  "phimsex-xxx.xyz",
  "phimsex.casa",
  "phimsex.icu",
  "phimsex.id",
  "phimsex.live",
  "phimsex.mom",
  "phimsex.name",
  "phimsex.root-shop.ru",
  "phimsex.run",
  "phimsex.sex",
  "phimsex.space",
  "phimsex.top",
  "phimsex.vc",
  "phimsex.watch",
  "phimsex1.club",
  "phimsex1.net",
  "phimsex102.net",
  "phimsex1080.com",
  "phimsex123.net",
  "phimsex14.net",
  "phimsex15.com",
  "phimsex17.com",
  "phimsex18.pro",
  "phimsex18.top",
  "phimsex19.com",
  "phimsex2022.org",
  "phimsex21.xyz",
  "phimsex29.net",
  "phimsex2k.biz",
  "phimsex2k.pro",
  "phimsex3d.com",
  "phimsex3s.pro",
  "phimsex3x.tv",
  "phimsex47.club",
  "phimsex4k.me",
  "phimsex4k.pro",
  "phimsex55.net",
  "phimsex5sao.com",
  "phimsex678.pro",
  "phimsex69.biz",
  "phimsex69.cc",
  "phimsex69.co",
  "phimsex69.icu",
  "phimsex69.info",
  "phimsex69.me",
  "phimsex69.one",
  "phimsex69.pro",
  "phimsex69.top",
  "phimsex720.asia",
  "phimsex789.me",
  "phimsex789.pro",
  "phimsex888.com",
  "phimsex8k.net",
  "phimsex99.co",
  "phimsex99.net",
  "phimsex99.org",
  "phimsexanime.top",
  "phimsexasian.net",
  "phimsexaumy.pro",
  "phimsexav.org",
  "phimsexbcs.org",
  "phimsexc.net",
  "phimsexcap3.xyz",
  "phimsexcave.pro",
  "phimsexchaua.com",
  "phimsexchaua.pro",
  "phimsexchauau.club",
  "phimsexchauau.net",
  "phimsexchauau247.xyz",
  "phimsexchina.club",
  "phimsexchina.com",
  "phimsexchina.net",
  "phimsexchina.pro",
  "phimsexchina.top",
  "phimsexchina.tv",
  "phimsexchina.xyz",
  "phimsexcom.com",
  "phimsexcom.me",
  "phimsexcom.net",
  "phimsexcom.pro",
  "phimsexcotrang.org",
  "phimsexcotrang.top",
  "phimsexdam.cc",
  "phimsexdam.net",
  "phimsexdam.top",
  "phimsexday.pro",
  "phimsexdep.net",
  "phimsexdep.pro",
  "phimsexdit.pro",
  "phimsexdit.top",
  "phimsexditnhau.com",
  "phimsexditnhau.info",
  "phimsexditnhau.net",
  "phimsexditnhau.pro",
  "phimsexditnhau.xyz",
  "phimsexditnhauhay.pro",
  "phimsexdj.com",
  "phimsexdoc.org",
  "phimsexdongtinh.net",
  "phimsexdongtinh.top",
  "phimsexdongtinh.xyz",
  "phimsexdongvat.com",
  "phimsexfullhd.net",
  "phimsexgai.net",
  "phimsexgaidep.net",
  "phimsexgaingon.com",
  "phimsexgaixinh.biz",
  "phimsexgaixinh.me",
  "phimsexgaixinh.org",
  "phimsexgay.info",
  "phimsexgay.me",
  "phimsexgay.net",
  "phimsexgay.org",
  "phimsexgaynhatban.top",
  "phimsexhan.cc",
  "phimsexhan.com",
  "phimsexhan.me",
  "phimsexhan.net",
  "phimsexhan.org",
  "phimsexhan.pro",
  "phimsexhan.top",
  "phimsexhan.xxx",
  "phimsexhanquoc.club",
  "phimsexhanquoc.co",
  "phimsexhanquoc.info",
  "phimsexhanquoc.live",
  "phimsexhanquoc.me",
  "phimsexhanquoc.mobi",
  "phimsexhanquoc.org",
  "phimsexhanquoc.site",
  "phimsexhanquoc.vip",
  "phimsexhanquoc.xyz",
  "phimsexhay.asia",
  "phimsexhay.biz",
  "phimsexhay.club",
  "phimsexhay.co",
  "phimsexhay.com",
  "phimsexhay.fun",
  "phimsexhay.icu",
  "phimsexhay.in",
  "phimsexhay.io",
  "phimsexhay.life",
  "phimsexhay.me",
  "phimsexhay.monster",
  "phimsexhay.one",
  "phimsexhay.online",
  "phimsexhay.plus",
  "phimsexhay.pro",
  "phimsexhay.store",
  "phimsexhay.studio",
  "phimsexhay.top",
  "phimsexhay.tube",
  "phimsexhay.video",
  "phimsexhay123.com",
  "phimsexhay3x.com",
  "phimsexhay669.com",
  "phimsexhay669.net",
  "phimsexhay69.net",
  "phimsexhaymoi.com",
  "phimsexhaynhatban.cyou",
  "phimsexhaynhatban.top",
  "phimsexhayvl.com",
  "phimsexhayy.com",
  "phimsexhd.club",
  "phimsexhd.cyou",
  "phimsexhd.live",
  "phimsexhd.nl",
  "phimsexhd.one",
  "phimsexhd.online",
  "phimsexhd.org",
  "phimsexhd.tube",
  "phimsexhd.video",
  "phimsexhd123.net",
  "phimsexhd2k.com",
  "phimsexhd69.pro",
  "phimsexhentai.me",
  "phimsexhentai.org",
  "phimsexhentai.top",
  "phimsexheo.com",
  "phimsexheo.net",
  "phimsexheo.pro",
  "phimsexhiepdam.com",
  "phimsexhiepdam.net",
  "phimsexhiepdam.pro",
  "phimsexhiepdam.xyz",
  "phimsexhihi.cc",
  "phimsexhocsinh.net",
  "phimsexhocsinh.top",
  "phimsexhocsinhnhatban.top",
  "phimsexhot.biz",
  "phimsexhot.club",
  "phimsexhot.info",
  "phimsexhot.xyz",
  "phimsexjapan.me",
  "phimsexjav.club",
  "phimsexjav.info",
  "phimsexjav.mobi",
  "phimsexjav.net",
  "phimsexjav.org",
  "phimsexjavhd.biz",
  "phimsexjavhd.blogspot.com",
  "phimsexjavhd.com",
  "phimsexjavhd.net",
  "phimsexjavhd.pro",
  "phimsexkhongche.biz",
  "phimsexkhongche.cc",
  "phimsexkhongche.cfd",
  "phimsexkhongche.club",
  "phimsexkhongche.co",
  "phimsexkhongche.com",
  "phimsexkhongche.info",
  "phimsexkhongche.me",
  "phimsexkhongche.net",
  "phimsexkhongche.org",
  "phimsexkhongche.pro",
  "phimsexkhongche.top",
  "phimsexkhongche.xyz",
  "phimsexkhongche69.com",
  "phimsexkoche.me",
  "phimsexkoche.net",
  "phimsexkoche.top",
  "phimsexkoche.xyz",
  "phimsexkorea.com",
  "phimsexlao.net",
  "phimsexlauxanh.pro",
  "phimsexlauxanh.vip",
  "phimsexll.me",
  "phimsexloanluan.biz",
  "phimsexloanluan.cc",
  "phimsexloanluan.info",
  "phimsexloanluan.mobi",
  "phimsexloanluan.org",
  "phimsexloanluan.pro",
  "phimsexloanluan.wtf",
  "phimsexloanluan.xyz",
  "phimsexlon.net",
  "phimsexmoi.biz",
  "phimsexmoi.club",
  "phimsexmoi.co",
  "phimsexmoi.info",
  "phimsexmoi.me",
  "phimsexmoi.one",
  "phimsexmoi.online",
  "phimsexmoi.us",
  "phimsexmoi.xyz",
  "phimsexmoi69.com",
  "phimsexmoi69.net",
  "phimsexmois.com",
  "phimsexmv.pro",
  "phimsexmy.biz",
  "phimsexmy.club",
  "phimsexmy.info",
  "phimsexmy.link",
  "phimsexmy.live",
  "phimsexmy.one",
  "phimsexmy.video",
  "phimsexmy.vip",
  "phimsexmy.xyz",
  "phimsexmy123.com",
  "phimsexmy99.com",
  "phimsexmyhay.com",
  "phimsexne.net",
  "phimsexnet.xyz",
  "phimsexngon.one",
  "phimsexnguoilon.top",
  "phimsexnhanh.club",
  "phimsexnhanh.me",
  "phimsexnhanh.online",
  "phimsexnhanh.plus",
  "phimsexnhanh.xyz",
  "phimsexnhanhvl.pro",
  "phimsexnhat.club",
  "phimsexnhat.tv",
  "phimsexnhat.vip",
  "phimsexnhatban.cc",
  "phimsexnhatban.club",
  "phimsexnhatban.info",
  "phimsexnhatban.live",
  "phimsexnhatban.monster",
  "phimsexnhatban.net",
  "phimsexnhatban.one",
  "phimsexnhatban.xyz",
  "phimsexnhatban99.com",
  "phimsexnhatbangaixinh.top",
  "phimsexnhatbanmoi.top",
  "phimsexnhatbanmoinhat.top",
  "phimsexnhathay.pro",
  "phimsexnhathaynhat.top",
  "phimsexnhatmoinhat.top",
  "phimsexok.vip",
  "phimsexol.pro",
  "phimsexonl.net",
  "phimsexonline.org",
  "phimsexonlines.com",
  "phimsexphap.net",
  "phimsexphe.com",
  "phimsexporn.tv",
  "phimsexpro.info",
  "phimsexpro.me",
  "phimsexs.net",
  "phimsexsh.com",
  "phimsexsub.cc",
  "phimsexsub.club",
  "phimsexsub.co",
  "phimsexsub.cyou",
  "phimsexsub.info",
  "phimsexsub.link",
  "phimsexsub.online",
  "phimsexsub.plus",
  "phimsexsub.pro",
  "phimsexsub.pw",
  "phimsexsub.sex",
  "phimsexsub.vip",
  "phimsexsub69.net",
  "phimsexsubxxx.com",
  "phimsext.me",
  "phimsext.net",
  "phimsextapthe.com",
  "phimsextau.pro",
  "phimsextc.com",
  "phimsextc.me",
  "phimsexteen.net",
  "phimsexteen.pro",
  "phimsexthailan.com",
  "phimsexthailan.net",
  "phimsexthu.biz",
  "phimsexthu.site",
  "phimsexthudam.com",
  "phimsextile.com",
  "phimsextinhduc.com",
  "phimsextop.pro",
  "phimsextop1.com",
  "phimsextop1.me",
  "phimsextoy.pro",
  "phimsextq.com",
  "phimsextq.pro",
  "phimsextrung.net",
  "phimsextrungquoc.org",
  "phimsextuoi18.net",
  "phimsextv.top",
  "phimsexvanphong.com",
  "phimsexvideos.top",
  "phimsexviet.info",
  "phimsexviet.one",
  "phimsexviet.xxx",
  "phimsexviet.xyz",
  "phimsexviet789.com",
  "phimsexviethd.net",
  "phimsexvietmoi.com",
  "phimsexvietmoi.net",
  "phimsexvietnam.club",
  "phimsexvietnam.live",
  "phimsexvietnam.me",
  "phimsexvietnam.org",
  "phimsexvietnam.vip",
  "phimsexvietsub.asia",
  "phimsexvietsub.club",
  "phimsexvietsub.cyou",
  "phimsexvietsub.site",
  "phimsexvietsub.vip",
  "phimsexvip.cc",
  "phimsexvip.mobi",
  "phimsexvip.online",
  "phimsexvip.pro",
  "phimsexvip.top",
  "phimsexvip.vip",
  "phimsexvkl.cc",
  "phimsexvkl.me",
  "phimsexvkl.net",
  "phimsexvl.biz",
  "phimsexvl.mobi",
  "phimsexvlxx.com",
  "phimsexvlxx.pro",
  "phimsexvn.one",
  "phimsexvn.xxx",
  "phimsexvn1.com",
  "phimsexvp.com",
  "phimsexvungtrom.com",
  "phimsexvuto.pro",
  "phimsexxl.com",
  "phimsexxnxx.net",
  "phimsexxx.me",
  "phimsexxx.pro",
  "phimsexxxx.monster",
  "phimsexxxx.xyz",
  "phimsexy.cyou",
  "phimsexy.info",
  "phimsexy.org",
  "phimsexy.pro",
  "phimsexy.top",
  "phimsexyz.pro",
  "phimsexz.biz",
  "phimsexz.cc",
  "phimsexz.club",
  "phimsexz.plus",
  "phimsexz.vip",
  "phimsexzz.net",
  "phimsez.pro",
  "phimsez.top",
  "phimssex.net",
  "phimtcc.com",
  "phimthudam.top",
  "phimtop.pro",
  "phimtop1.pro",
  "phimtrantrui.com",
  "phimtxx.com",
  "phimtxx.net",
  "phimtz.com",
  "phimvideosxxx.monster",
  "phimvideoxxx.top",
  "phimvip.biz",
  "phimvlxx.link",
  "phimvlxx.net",
  "phimvnxx.com",
  "phimvv.net",
  "phimx.cc",
  "phimx.xyz",
  "phimx69.com",
  "phimx69.net",
  "phimxec.me",
  "phimxec.net",
  "phimxec.pro",
  "phimxec.top",
  "phimxech.top",
  "phimxem.top",
  "phimxes.cc",
  "phimxes.click",
  "phimxes.org",
  "phimxes.top",
  "phimxes.video",
  "phimxesvn.com",
  "phimxesvn.pro",
  "phimxet.me",
  "phimxet.pro",
  "phimxet.to",
  "phimxet.top",
  "phimxet.tv",
  "phimxetviet.info",
  "phimxex.pro",
  "phimxhay.pro",
  "phimxhd.me",
  "phimxhd.net",
  "phimxlxx.com",
  "phimxnxx.pro",
  "phimxvideos1.pro",
  "phimxviet.pro",
  "phimxx.cc",
  "phimxx.monster",
  "phimxx.top",
  "phimxx.tube",
  "phimxx.xyz",
  "phimxxhd.me",
  "phimxxnx.net",
  "phimxxx.asia",
  "phimxxx.io",
  "phimxxx.link",
  "phimxxx.live",
  "phimxxx.lol",
  "phimxxx.mobi",
  "phimxxx.monster",
  "phimxxx.one",
  "phimxxx.red",
  "phimxxx.sex",
  "phimxxx.site",
  "phimxxx.to",
  "phimxxx.top",
  "phimxxx.tube",
  "phimxxx.us",
  "phimxxx.win",
  "phimxxx.xxx",
  "phimxxx.xyz",
  "phimxxx69.com",
  "phimxxxhay.com",
  "phimxxxmoi.com",
  "phimxxxtube.com",
  "phimxxxviet.net",
  "phimxxxvn.me",
  "phimxxxx.me",
  "phimxxxx.net",
  "phimyy.com",
  "phimyy.me",
  "phimyy.vip",
  "phimyz.com",
  "phodem.link",
  "phodem.xyz",
  "phodendo.xyz",
  "phogaigoi.link",
  "phogaigoi.live",
  "phogaigoi.xyz",
  "phogaigoi1.xyz",
  "phogaikiemdinh.fun",
  "phogaikiemdinh.link",
  "phogaikiemdinh.live",
  "phogaikiemdinh.xyz",
  "phogaikiemdinh1.xyz",
  "photocinenews.com",
  "phunucodon.cc",
  "phym18.com",
  "phym18.tube",
  "phymjavhd.com",
  "phymsex.pro",
  "pimsex.pro",
  "play.kichduc.to",
  "play.kphim.cc",
  "play3x.xyz",
  "player.vlxxtv.info",
  "playvdphe3x.xyz",
  "porn-vn.com",
  "porn.phimonline.click",
  "porn.work",
  "porn123.xyz",
  "porn789.net",
  "pornaz.net",
  "pornhat.pro",
  "pornhubf.com",
  "pornox.me",
  "pornpic.org",
  "pornzo.net",
  "pphimsex.com",
  "pphimsex.me",
  "q.sextop1.life",
  "qh88vn.live",
  "qq801.me",
  "qq892.live",
  "qqlive.cc",
  "qqlives.app",
  "quatvn.cc",
  "quatvn.club",
  "quatvn.net",
  "quaylen.me",
  "quaylen.org",
  "quaytay.net",
  "qydykq.com",
  "raiseyourhandnow.com",
  "rap3x.net",
  "rauheoz.com",
  "rauvn.net",
  "reviewxx.net",
  "ribaysteak.ru",
  "rphang.online",
  "rphangcdn.com",
  "rphangs.net",
  "rphangx.com",
  "rphangx.me",
  "rphangx.net",
  "rphangx.tv",
  "s.phimsexvip.cc",
  "s.vnchich.net",
  "s.yeusex.org",
  "s3xua.com",
  "s3xvn.com",
  "s666.tv",
  "s666tv.com",
  "sacduc.one",
  "sayhentai.me",
  "sayhentai.vip",
  "scorchin.com",
  "se69.fun",
  "seaporn.net",
  "sec-nhat.com",
  "sechay.net",
  "secphim.com",
  "secviet.net",
  "secvn.net",
  "sethay.com",
  "sex-com.pro",
  "sex-hay.org",
  "sex-hayhd.com",
  "sex-hd.co",
  "sex-hd.pro",
  "sex-heo.xyz",
  "sex-jav.pro",
  "sex-jav.xyz",
  "sex-lon.me",
  "sex-moi.pro",
  "sex-ngon.net",
  "sex-nhanh.pro",
  "sex-nhat.com",
  "sex-phim.net",
  "sex-sub.com",
  "sex-sub.xyz",
  "sex-top1.pro",
  "sex-viet-nam.net",
  "sex-viet.pro",
  "sex-xxx.me",
  "sex.2ola.pro",
  "sex.viet69.tech",
  "sex.vip",
  "sex.vl9x.pro",
  "sex.xcudem.com",
  "sex1.pro",
  "sex1.vl9x.net",
  "sex102.net",
  "sex1080.net",
  "sex11.net",
  "sex123.biz",
  "sex123.pro",
  "sex18t.com",
  "sex1x.net",
  "sex2.pro",
  "sex2022.net",
  "sex2030.net",
  "sex21.vip",
  "sex2k.me",
  "sex2k.org",
  "sex3.vip",
  "sex33.net",
  "sex333.xyz",
  "sex33x.net",
  "sex369.net",
  "sex39.net",
  "sex3x.info",
  "sex3x.pro",
  "sex3x.tv",
  "sex3xhay.pro",
  "sex3xhd.pro",
  "sex3xmoi.pro",
  "sex3xtop1.pro",
  "sex44k.com",
  "sex4k.pro",
  "sex66.net",
  "sex6688.link",
  "sex678.me",
  "sex6789.me",
  "sex68.link",
  "sex69.me",
  "sex69.to",
  "sex69.tv",
  "sex699.net",
  "sex888.pro",
  "sex888.tv",
  "sex89.net",
  "sex8x.com",
  "sex9.2ola.pro",
  "sex99.me",
  "sex9x.pro",
  "sexanh.com",
  "sexanime.info",
  "sexanime.net",
  "sexanime.pro",
  "sexau.org",
  "sexau.xyz",
  "sexaumy.com",
  "sexbattu.com",
  "sexc.it",
  "sexcap3.net",
  "sexchauau.biz",
  "sexchauau.club",
  "sexchauau.co",
  "sexchauau.mobi",
  "sexchich.com",
  "sexchich.net",
  "sexchich.pro",
  "sexchina.biz",
  "sexchina.cc",
  "sexcogiao.com",
  "sexcotrang.com",
  "sexcotrang.net",
  "sexcotrang.top",
  "sexcuto.info",
  "sexcuto.net",
  "sexdacbiet.pro",
  "sexdam.me",
  "sexdam.pro",
  "sexdam.tube",
  "sexdam3x.com",
  "sexdam3x.net",
  "sexdam69.net",
  "sexdamvl.com",
  "sexdate.nl",
  "sexdcm.com",
  "sexdem.cc",
  "sexdem.pro",
  "sexdem.us",
  "sexdep.biz",
  "sexdep.pro",
  "sexdep.tv",
  "sexdep.xyz",
  "sexdeptv.net",
  "sexdiary.cc",
  "sexdiary.pro",
  "sexdiaryx.net",
  "sexdiaryz.com",
  "sexdiaryz.fun",
  "sexdiaryz.pro",
  "sexdiaryz.us",
  "sexdiaryz.xyz",
  "sexdit.me",
  "sexdit3x.com",
  "sexdit3x.net",
  "sexditnhau.cc",
  "sexditnhau.info",
  "sexditnhau.live",
  "sexditnhau.me",
  "sexditnhau.net",
  "sexditnhau.org",
  "sexditnhau.pro",
  "sexdong.top",
  "sexdotz.com",
  "sexdu.net",
  "sexf8.com",
  "sexfree.club",
  "sexfull-hd.com",
  "sexfull.me",
  "sexfullhd.me",
  "sexfullhd.pro",
  "sexgai.pro",
  "sexgai.tube",
  "sexgai.us",
  "sexgaidam.com",
  "sexgaidep.net",
  "sexgaii.net",
  "sexgaixinh.biz",
  "sexgaixinh.me",
  "sexgaixinh.org",
  "sexgaixinh.pro",
  "sexgaixinh.site",
  "sexgay.tv",
  "sexhai.com",
  "sexhan.top",
  "sexhanquoc.net",
  "sexhapdan.com",
  "sexhay.biz",
  "sexhay.vip",
  "sexhay123.com",
  "sexhay2k.com",
  "sexhay3x.com",
  "sexhay4k.com",
  "sexhay69.link",
  "sexhay69.mobi",
  "sexhay69.us",
  "sexhay99.com",
  "sexhaydam.com",
  "sexhaydam.net",
  "sexhayhanquoc.com",
  "sexhayhd.me",
  "sexhaynhat.pro",
  "sexhaynhatban.top",
  "sexhaynhi.pro",
  "sexhaypro.com",
  "sexhayvc.biz",
  "sexhayvc.com",
  "sexhayvl.net",
  "sexhayvl.org",
  "sexhayvn.club",
  "sexhayvtc.pro",
  "sexhayz.me",
  "sexhd.link",
  "sexhd.top",
  "sexhd1.pro",
  "sexhd3x.com",
  "sexhd4k.com",
  "sexhd69.net",
  "sexhdfull.pro",
  "sexhdhay.com",
  "sexhdhay.me",
  "sexhdhay.vip",
  "sexhdmoi.net",
  "sexhdo.pro",
  "sexhdonline.net",
  "sexhdpro.com",
  "sexhds.com",
  "sexhdv.me",
  "sexhdvn.club",
  "sexhdvn.vip",
  "sexhdx.net",
  "sexhdx.xyz",
  "sexhdxnxx.pro",
  "sexheo.pro",
  "sexheo.xyz",
  "sexheo69.net",
  "sexheodem.com",
  "sexhi88.com",
  "sexhiep.net",
  "sexhihi.day",
  "sexhihi.info",
  "sexhihi.me",
  "sexhihi.plus",
  "sexhihi.pro",
  "sexhihi.tube",
  "sexhihi69.pro",
  "sexhihihi.net",
  "sexhihii.net",
  "sexhihiz.net",
  "sexhocsinh.top",
  "sexhome.pro",
  "sexhot.vip",
  "sexiezpix.com",
  "sexjav.cc",
  "sexjavhd.cc",
  "sexjavhd.me",
  "sexjavhd.org",
  "sexjavz.com",
  "sexkhongche.cyou",
  "sexkhongche.mobi",
  "sexkhongche5.cyou",
  "sexkhongchenhatban.top",
  "sexkoche.org",
  "sexkoche.pro",
  "sexktv.net",
  "sexlamtinh.com",
  "sexlauxanh.net",
  "sexlauxanh.pro",
  "sexlen.com",
  "sexlenlut.com",
  "sexliemlon.pro",
  "sexlo.net",
  "sexloanluan.cc",
  "sexloanluan.org",
  "sexloanluan.pro",
  "sexlol.me",
  "sexlon.pro",
  "sexlon.xyz",
  "sexlondep.pro",
  "sexmbbg.org",
  "sexmienphi.net",
  "sexmoi.buzz",
  "sexmoi.click",
  "sexmoi.co",
  "sexmoi.cyou",
  "sexmoi.info",
  "sexmoi.live",
  "sexmoi.online",
  "sexmoi.pro",
  "sexmoi.top",
  "sexmoi3x.co",
  "sexmoi3x.net",
  "sexmoi69.info",
  "sexmoi69.pro",
  "sexmoi69.xyz",
  "sexmoi88.net",
  "sexmoihay.com",
  "sexmoihay.pro",
  "sexmoihd.com",
  "sexmoii.top",
  "sexmoila.com",
  "sexmoilon.com",
  "sexmoinhat.com",
  "sexmoinhat.pro",
  "sexmoivl.com",
  "sexmuot.club",
  "sexmy.one",
  "sexmy.tv",
  "sexnao.net",
  "sexnet.club",
  "sexnet.me",
  "sexngan.com",
  "sexngon.org",
  "sexngon.pro",
  "sexngon69.com",
  "sexngon69.org",
  "sexngon69.pro",
  "sexngonz.com",
  "sexnguoilon.com",
  "sexnguoilon.one",
  "sexnguoithu.xyz",
  "sexnhanh.co",
  "sexnhanh69.pro",
  "sexnhanhz.net",
  "sexnhat.co",
  "sexnhat.me",
  "sexnhat69.pro",
  "sexnhatban.monster",
  "sexnhatbanhaynhat.top",
  "sexnhatbanvietsub.top",
  "sexnhatgaixinh.top",
  "sexnhathd.com",
  "sexnhathd.pro",
  "sexnhatkoche.top",
  "sexnhatmoinhat.top",
  "sexnhatpro.com",
  "sexnhe.club",
  "sexnhe.xyz",
  "sexnonghd.pro",
  "sexnung.net",
  "sexnunglon.pro",
  "sexnusinh.net",
  "sexnxx.pro",
  "sexphim-hd.pro",
  "sexphim.cc",
  "sexphim.club",
  "sexphim69.pro",
  "sexphimhd.pro",
  "sexphimhds.net",
  "sexphimjav.com",
  "sexphimmoi.pro",
  "sexphimtop.com",
  "sexphimtv.net",
  "sexphimvip.net",
  "sexphimx.pro",
  "sexphimxxx.pro",
  "sexphimz.com",
  "sexphimz.net",
  "sexphude.net",
  "sexplus.xyz",
  "sexpro.vip",
  "sexquaylen.me",
  "sexquaylen.org",
  "sexquaylen123.com",
  "sexsb.xyz",
  "sexshort.app",
  "sexshort.com",
  "sexso1.info",
  "sexso1.me",
  "sexso1.net",
  "sexso1.pro",
  "sexso1.top",
  "sexso1.xyz",
  "sexsoc.com",
  "sexsot.net",
  "sexsot.pro",
  "sexsub.one",
  "sexsub.tube",
  "sexsub.xyz",
  "sexsubjav.pro",
  "sexsubs.net",
  "sexsubvl.com",
  "sexsung.com",
  "sexsuong.net",
  "sext.pro",
  "sexthu.top",
  "sexthudam.pro",
  "sexthudam.top",
  "sextinh.me",
  "sextivi.vip",
  "sextop.live",
  "sextop.net",
  "sextop.rocks",
  "sextop.tv",
  "sextop1.app",
  "sextop1.best",
  "sextop1.bio",
  "sextop1.club",
  "sextop1.dev",
  "sextop1.fun",
  "sextop1.life",
  "sextop1.love",
  "sextop1.news",
  "sextop1.one",
  "sextop1.sex",
  "sextop1.video",
  "sextop1.win",
  "sextop10.pro",
  "sextop11.com",
  "sextop123.com",
  "sextop18.org",
  "sextop18.plus",
  "sextop1jav.net",
  "sextop1s.net",
  "sextop1x.com",
  "sextop3x.com",
  "sextop68.com",
  "sextopi.com",
  "sextopone.org",
  "sextopone.pro",
  "sextopvl.net",
  "sextopvl.tv",
  "sextot.com",
  "sextot.net",
  "sextoy.com",
  "sextq.xyz",
  "sextraxanh.com",
  "sextructuyen.com",
  "sextrung.me",
  "sextrung.top",
  "sextrungquoc.biz",
  "sextrungquoc.co",
  "sextrungquoc.mobi",
  "sextrungquoc.pro",
  "sextruyen.com",
  "sextub8k.com",
  "sextube3x.com",
  "sextubearea.com",
  "sextubefuck.pro",
  "sextubeporno.com",
  "sextusuong.com",
  "sextuyen.com",
  "sextuyen.pro",
  "sextv.me",
  "sextv2.pro",
  "sextvhay.net",
  "sexvcc.xyz",
  "sexvcl.pro",
  "sexvid.it",
  "sexvideo.asia",
  "sexviet.asia",
  "sexviet.cc",
  "sexviet.click",
  "sexviet.fun",
  "sexviet.info",
  "sexviet.live",
  "sexviet.mobi",
  "sexviet.net",
  "sexviet.online",
  "sexviet.sex",
  "sexviet.store",
  "sexviet.tube",
  "sexviet.uk",
  "sexviet.watch",
  "sexviet.ws",
  "sexviet.xweb.tv",
  "sexviet.xyz",
  "sexviet1.cc",
  "sexviet1.xyz",
  "sexviet102.co",
  "sexviet2k.com",
  "sexviet3x.pro",
  "sexviet69.biz",
  "sexviet69.info",
  "sexviet69.pro",
  "sexviet69.xyz",
  "sexviet88.cc",
  "sexviet88.com",
  "sexviet88.info",
  "sexviet88.me",
  "sexviet88.net",
  "sexviet88.top",
  "sexviet99.com",
  "sexviet99.tv",
  "sexviethay.com",
  "sexviethay.org",
  "sexviethd.co",
  "sexvietmoi.cc",
  "sexvietmoi.com",
  "sexvietmoi.info",
  "sexvietmoi.me",
  "sexvietmoi.net",
  "sexvietmoi.org",
  "sexvietmoi.pro",
  "sexvietnam.biz",
  "sexvietnam.cc",
  "sexvietnam.site",
  "sexvietnam.wtf",
  "sexvietnamhd.net",
  "sexvietnamnhanh.pro",
  "sexvietonline.org",
  "sexvietsub.mobi",
  "sexvietsub.today",
  "sexvietsub.vip",
  "sexvietsub123.com",
  "sexvietsub247.com",
  "sexvietsubz.com",
  "sexviett.com",
  "sexvietvip.net",
  "sexvietvl.com",
  "sexvietvl.net",
  "sexvietvl.pro",
  "sexvietvn.net",
  "sexvietx.net",
  "sexvietxxx.net",
  "sexvietz.co",
  "sexvietz.org",
  "sexvip.cc",
  "sexvip.vip",
  "sexvip1.com",
  "sexvip18.com",
  "sexvip88.com",
  "sexviphay.com",
  "sexvkl.me",
  "sexvkl.net",
  "sexvkl.tv",
  "sexvl.biz",
  "sexvl.tv",
  "sexvlxx.tv",
  "sexvlxxx.xyz",
  "sexvn.cc",
  "sexvn.cyou",
  "sexvn.icu",
  "sexvn.one",
  "sexvn.plus",
  "sexvn.pro",
  "sexvn.store",
  "sexvn.to",
  "sexvn.xyz",
  "sexvn.yeusex.org",
  "sexvn17.top",
  "sexvn3x.com",
  "sexvn69.com",
  "sexvn789.com",
  "sexvnhay.com",
  "sexvnhay.net",
  "sexvnx.co",
  "sexvnx.vip",
  "sexvtc.net",
  "sexvtv.xyz",
  "sexvtv1.pro",
  "sexvungtrom.org",
  "sexxinh.com",
  "sexxtrungquoc.com",
  "sexxy69.net",
  "sexz.top",
  "sexzig.xyz",
  "sexzz.me",
  "sgbb.pro",
  "showbuaz.net",
  "showgai.click",
  "showgai.pics",
  "showgai.xyz",
  "showgaidep.one",
  "showgaidep.xyz",
  "showhangnhanh.xyz",
  "showvip.one",
  "sieudamtv.com",
  "sieukhung.us",
  "sieukhungg.net",
  "sieukhungz.net",
  "sieukhungzz.net",
  "sieusexpro.com",
  "sieuthigai.cc",
  "sieuthitruyen.com",
  "sinhvienngon.biz",
  "socvl.net",
  "sodienthoaigai.com",
  "soigai.online",
  "songvedem.viwap.com",
  "sphimsex.me",
  "sphimsex.xyz",
  "ssieukhung.com",
  "st-sy.com",
  "static.htvncdn.net",
  "static.manhwa24h.com",
  "static.manhwa24hs.com",
  "subjav.live",
  "subjav.one",
  "subjav.org",
  "subjavhd.net",
  "subjavz.com",
  "sugababy.xyz",
  "sugarbabi.com",
  "swebcam.cam",
  "t.htvncdn.net",
  "taianhsex.com",
  "taiapplive.com",
  "taiappliveshow.blogspot.com",
  "taichichlive.xyz",
  "taihotlive.xyz",
  "taiphimsex.co",
  "taiphimsex.top",
  "taiphimsexnhatban.top",
  "taiqqlive.app",
  "taiqqlive.xyz",
  "taiqqliveapp.com",
  "tamilsex.desi",
  "tamsu9x.com",
  "tapchisex.click",
  "tapchisex.me",
  "teen17.pw",
  "teenlohang.com",
  "thanhdam.net",
  "thanhlau.tv",
  "thanhlau.xyz",
  "thao.live",
  "thegioianhdephd.blogspot.com",
  "thegioilucsac.com",
  "themchich.com",
  "theporndude.com",
  "theundergroundclub.net",
  "thichcu.com",
  "thichdit.com",
  "thichsex.net",
  "thichsex.pro",
  "thiendia.club",
  "thiendia.com",
  "thiendia.uk",
  "thiendia1.com",
  "thiendia88.org",
  "thiendia99.co",
  "thiendia99.net",
  "thiendiatruyen.com",
  "thienvadia.net",
  "thudam.pro",
  "thudam.vip",
  "thuongem.one",
  "timbaby.net",
  "timban24h.com",
  "timbanbonphuongaz.com",
  "timbangainhanh.com",
  "timbanhenho24h.xyz",
  "timbantinhvn.com",
  "timbantinhvn.xyz",
  "timmaybaybagia.net",
  "tinh1dem.club",
  "tinh69.com",
  "tinhduc.online",
  "tinhduc.org",
  "tinhmotdem.asia",
  "tintucgai.com",
  "tinwin.club",
  "titdam.tv",
  "tk66.app",
  "tk66.tv",
  "tk66vn.com",
  "tkaz.net",
  "top10jav.com",
  "top1sex.biz",
  "top1sex.cc",
  "top1sex.online",
  "top1sex.xyz",
  "top3x.cc",
  "top3x.tube",
  "top3x.vip",
  "top69.cc",
  "topapp.com.vn",
  "topapp.vin",
  "topapplive.com",
  "topbot.pro",
  "topg88.live",
  "topgaigoi.us",
  "topgaixinh.com",
  "topgaixinh.net",
  "topphim.pro",
  "topphimheo.com",
  "topphimsex.vip",
  "topsex1.pro",
  "topvlxx.com",
  "tphimsex.club",
  "trai18.com",
  "trai69.com",
  "traibao69.com",
  "traibaovip.com",
  "traicam.vn",
  "traidikhach.com",
  "traigym.com",
  "trainganh.com",
  "traingheo.com",
  "traipro.com",
  "traiviet.net",
  "traivip3mien.com",
  "traixitin.club",
  "trangxemsex.pro",
  "trangxx.com",
  "transbabe.net",
  "trendpornvids.com",
  "trinhtiet.net",
  "trumbamien.com",
  "trumsexviet.com",
  "trumsexviet.net",
  "trumsexviet.org",
  "trumtraibao.com",
  "trungquocsex.com",
  "trungquocsex.net",
  "truongsex.pro",
  "truyen-hentai.com",
  "truyen-sex.com",
  "truyen18.mobi",
  "truyen18.xyz",
  "truyen3.com",
  "truyen321.net",
  "truyen3x.vip",
  "truyenc.com",
  "truyenchu18.com",
  "truyenchu18.info",
  "truyencogiaothao.info",
  "truyendam.net",
  "truyendam.org",
  "truyendu.com",
  "truyengay.mobi",
  "truyengihay.net",
  "truyenhentai.blog.fc2.com",
  "truyenhentai.co",
  "truyenhentai.com",
  "truyenhentai.tv",
  "truyenhentai.xyz",
  "truyenheo.org",
  "truyenheta.com",
  "truyenkk1.com",
  "truyenkkz.com",
  "truyenmp3.net",
  "truyennghiemtuc.com",
  "truyennguoilon.info",
  "truyennung.com",
  "truyensac.net",
  "truyensec.net",
  "truyensex.cc",
  "truyensex.club",
  "truyensex.one",
  "truyensex.vip",
  "truyensex18.com",
  "truyensex69.net",
  "truyensex88.info",
  "truyensexaz.com",
  "truyensexhay.info",
  "truyensexhot.com",
  "truyensexmoi.net",
  "truyensextv.com",
  "truyensextv.me",
  "truyensexvip.com",
  "truyenteen.pro",
  "truyentinhduc.wordpress.com",
  "truyentranhgay.com",
  "truyentructuyen.com",
  "truyenvina.com",
  "truyenvkl.wordpress.com",
  "truyenvn.vip",
  "truyenwk.com",
  "truyenx365.com",
  "truyenxec.com",
  "truyenxx.com",
  "truyenxxx.com",
  "trymto.net",
  "ttk16.com",
  "tuntiensinh.com",
  "tuoi69.app",
  "tuoi69.biz",
  "tuoi69.click",
  "tuoi69.club",
  "tuoi69.com",
  "tuoi69.io",
  "tuoi69.life",
  "tuoi69.link",
  "tuoi69.live",
  "tuoi69.me",
  "tuoi69.net",
  "tuoi69.news",
  "tuoi69.one",
  "tuoi69.online",
  "tuoi69.site",
  "tuoi69.today",
  "tuoi69.vc",
  "tuoi69.video",
  "tuoi69.website",
  "tuoi69.xyz",
  "tuoi69vn.com",
  "tuoi69zz.com",
  "tuoilon.org",
  "tuoilon.pro",
  "tuoilontv.cc",
  "tuoilontv.org",
  "tuoinung.cc",
  "tuoinung.co",
  "tuoinung.com",
  "tuoinung69.com",
  "tuoiti.one",
  "tuoivl.com",
  "tut4k.net",
  "tut4k.xxx",
  "tuyensex3x.com",
  "tuyetpham.xyz",
  "twtgaixinh.com",
  "txxx.pics",
  "tzqctz.com",
  "umehentai.com",
  "up1.hhentai.net",
  "up2.hentaivn.tv",
  "vailonxx.com",
  "vaoxem.one",
  "vavporn.com",
  "vb9.biz",
  "venturefestbristolandbath.com",
  "vetmang.org",
  "vetmang.xyz",
  "vi.analespanol.com",
  "vi.filmssexegratuit.com",
  "vi.hairypornxxx.com",
  "vi.megaxh.com",
  "vi.pornoingyen.net",
  "vi.sexdansk.com",
  "vi.xhvid.com",
  "video8x.xyz",
  "videoaz.xyz",
  "videodikhach.xyz",
  "videogai.xyz",
  "videogaigoi.xyz",
  "videosexnhat.top",
  "videosexx.net",
  "viet.sex",
  "viet69.app",
  "viet69.asia",
  "viet69.cam",
  "viet69.cc",
  "viet69.co",
  "viet69.com",
  "viet69.day",
  "viet69.de",
  "viet69.dev",
  "viet69.fun",
  "viet69.gg",
  "viet69.io",
  "viet69.link",
  "viet69.love",
  "viet69.me",
  "viet69.net",
  "viet69.news",
  "viet69.online",
  "viet69.org",
  "viet69.page",
  "viet69.pro",
  "viet69.sex",
  "viet69.sh",
  "viet69.shop",
  "viet69.site",
  "viet69.social",
  "viet69.store",
  "viet69.studio",
  "viet69.tech",
  "viet69.to",
  "viet69.us",
  "viet69.vc",
  "viet69.video",
  "viet69x.com",
  "viet69xxx.com",
  "viet69z.com",
  "viet69zz.com",
  "vietclan.net",
  "vietfun.me",
  "vietsex.cam",
  "vietsex.info",
  "vietsex.io",
  "vietsex.me",
  "vietsex.org",
  "vietsex.us",
  "vietsubsex.com",
  "vietxinh.net",
  "vietxnxx.com",
  "vietxx.com",
  "vietxx.info",
  "vip3x.me",
  "vip9x.pro",
  "vipgai.net",
  "viplauxanh.net",
  "vipsex.one",
  "vipxnxx.com",
  "visitempire.ru",
  "vjav2.com",
  "vk103.com",
  "vkdam.me",
  "vkldkm.sextgem.com",
  "vl-truyen-sex.sextgem.com",
  "vl-xx.com",
  "vl18.net",
  "vl3x.cc",
  "vl3x.me",
  "vl3x.net",
  "vl4x.net",
  "vl88.biz",
  "vl88.pro",
  "vl9x.com",
  "vl9x.net",
  "vldit.me",
  "vldit.pro",
  "vlphimsex.co",
  "vlphimsex.net",
  "vlphimsex.org",
  "vlsex.pro",
  "vlsex1s.net",
  "vlsexhay.net",
  "vlsexhay.tv",
  "vlxhay.com",
  "vlxphim.com",
  "vlxphim.me",
  "vlxtop.net",
  "vlxx-phimsex.com",
  "vlxx-phimsex.pro",
  "vlxx-sex.pro",
  "vlxx.ac",
  "vlxx.ai",
  "vlxx.bet",
  "vlxx.bio",
  "vlxx.buzz",
  "vlxx.cc",
  "vlxx.chat",
  "vlxx.city",
  "vlxx.club",
  "vlxx.cm",
  "vlxx.contact",
  "vlxx.cyou",
  "vlxx.day",
  "vlxx.fan",
  "vlxx.fun",
  "vlxx.gay",
  "vlxx.homes",
  "vlxx.icu",
  "vlxx.info",
  "vlxx.io",
  "vlxx.kim",
  "vlxx.live",
  "vlxx.me",
  "vlxx.media",
  "vlxx.men",
  "vlxx.mobi",
  "vlxx.moe",
  "vlxx.network",
  "vlxx.pw",
  "vlxx.rocks",
  "vlxx.run",
  "vlxx.sbs",
  "vlxx.sex",
  "vlxx.space",
  "vlxx.store",
  "vlxx.studio",
  "vlxx.tips",
  "vlxx.today",
  "vlxx.tube",
  "vlxx.tv",
  "vlxx.uno",
  "vlxx.vip",
  "vlxx.wiki",
  "vlxx.win",
  "vlxx.ws",
  "vlxx.xyz",
  "vlxx1.me",
  "vlxx18.net",
  "vlxx24h.com",
  "vlxx24h.info",
  "vlxx24h.net",
  "vlxx3.pro",
  "vlxx69.net",
  "vlxx69.plus",
  "vlxx69.xyz",
  "vlxx8.com",
  "vlxx8.net",
  "vlxx9.com",
  "vlxxcom.net",
  "vlxxhd.net",
  "vlxxi.com",
  "vlxxjav.com",
  "vlxxphim.pro",
  "vlxxs.net",
  "vlxxsex.com",
  "vlxxsub.net",
  "vlxxtop.com",
  "vlxxtube.cc",
  "vlxxtube.com",
  "vlxxtube.net",
  "vlxxtv.info",
  "vlxxvc.com",
  "vlxxvideos.com",
  "vlxxvietnam.xyz",
  "vlxxvietsub.net",
  "vlxxvl.net",
  "vlxxvn.me",
  "vlxxvn.net",
  "vlxxx.sex",
  "vlxxx.vip",
  "vlxxx.xyz",
  "vlxxx69.com",
  "vlxxxyz.com",
  "vlxyz.co",
  "vlxyz.net",
  "vlxyz.org",
  "vlzz.net",
  "vn.avhd.mobi",
  "vn.dam69.tv",
  "vn.gaimup.net",
  "vn.hisex.pro",
  "vn.javbabe.net",
  "vn.phym18.com",
  "vn.sexgai.tube",
  "vn.sexnhanh.co",
  "vn.sexviet88.top",
  "vn.viet69.chat",
  "vn.vlxxtube.cc",
  "vn3x.me",
  "vnanchoi.ca",
  "vnchich.com",
  "vnchich.net",
  "vnditnhau.icu",
  "vnditnhau.info",
  "vnditnhau.xyz",
  "vnnmarket.com",
  "vnok.net",
  "vnphimsex.info",
  "vnshow.cc",
  "vntopg88.live",
  "vntopg88.vip",
  "vnxnxx.cc",
  "vnxnxx.pro",
  "vnxnxx.xyz",
  "vnxx.app",
  "vnxx.me",
  "vnxx.xyz",
  "vnxxx.biz",
  "vnxxx.org",
  "vnxxx.pro",
  "vnxxx.sex",
  "vnzb8.com",
  "voday.one",
  "vphimsex.net",
  "vpspt.ru",
  "vsporntube.com",
  "vuagaigoi.org",
  "vuasex.club",
  "vuasex.co",
  "vuatruyensex.com",
  "vui3x.cc",
  "vuianime.tv",
  "vuighe.net",
  "vuisex.net",
  "vznalvek.com",
  "w1.sextop1.life",
  "wap3xdep.sextgem.com",
  "wapsex.wordpress.com",
  "waptuoinoiloan.blogspot.com",
  "web.sexnhanh.co",
  "webchanrau.com",
  "webdoitruy.com",
  "webgioitinh.net",
  "webphimsex.co",
  "webphimsex.me",
  "webphimsex.org",
  "webphimsex.pro",
  "webphimsex.xyz",
  "websex.info",
  "websex.me",
  "websex.mx",
  "websex.one",
  "websex.pro",
  "websex.to",
  "websexhd.net",
  "websexnhanh.net",
  "websexvn.net",
  "webxemsex.pro",
  "webxxx.net",
  "welive18.net",
  "wowonlife.ru",
  "ww1.1pondohd.com",
  "ww1.chinababe.net",
  "ww1.heyzohd.com",
  "ww1.japanhdv.biz",
  "ww1.vlxx.bio",
  "ww1.vlxx.space",
  "ww1.vlxyz.org",
  "www.7776666.net",
  "www.8886666.net",
  "www.9996666.net",
  "www.anhsex18.biz",
  "www.anhsex18.com",
  "www.anhsex18.net",
  "www.anhsexvip.me",
  "www.phim18k.com",
  "www.phimsexcom.com",
  "www.phimsexs.net",
  "www.phimtrantrui.com",
  "www.s3xvn.com",
  "www.se69.fun",
  "www.sex21.vip",
  "www.sexf8.com",
  "www.sexphimhds.net",
  "www.sextopone.pro",
  "www.sexvip18.com",
  "www.thiendiatruyen.com",
  "www.vnzb8.com",
  "www.xamvn.club",
  "www.xamvn.top",
  "www.xnxx.gold",
  "www.xvideos98.xxx",
  "www.xxxphim.mobi",
  "www.yeuu.net",
  "wwwxxx.pro",
  "x-video-s.com",
  "x.phimsec1.pro",
  "x.phimsexsub.co",
  "x.phimsexsub.pw",
  "x.sextop1.life",
  "x3x.club",
  "xackup.com",
  "xamclip.me",
  "xamvn.club",
  "xamvn.pro",
  "xamvn.sh",
  "xamvn.today",
  "xamvn.top",
  "xamvn.us",
  "xcopen.com",
  "xem-jav.net",
  "xem-phim-sex.com",
  "xem-phim-sex.me",
  "xem-phimsex.com",
  "xem-sex.biz",
  "xem-sex.me",
  "xem-sex.net",
  "xem-sex.org",
  "xem-sex.pro",
  "xem-sex.xyz",
  "xem-xxx.pro",
  "xem.anhvl.net",
  "xem.sex33.net",
  "xem3x.me",
  "xem3x.vip",
  "xemanhnong.asia",
  "xemanhnong.net",
  "xemav.com",
  "xemdit.net",
  "xemditnhau.pro",
  "xemgaimocbuom.live",
  "xemhay.pro",
  "xemhdx.com",
  "xemjav.org",
  "xemlive.app",
  "xemlivehot.com",
  "xemlon.me",
  "xemphim-sex.me",
  "xemphim-sex.pro",
  "xemphimcap3.net",
  "xemphimcap3.org",
  "xemphimcapba.info",
  "xemphimgay.com",
  "xemphimheo.pro",
  "xemphimjav.net",
  "xemphimnguoilon.com",
  "xemphimsec.net",
  "xemphimsec.top",
  "xemphimset.me",
  "xemphimset.net",
  "xemphimset.pro",
  "xemphimset.xyz",
  "xemphimsex.live",
  "xemphimsex.one",
  "xemphimsex.onl",
  "xemphimsex.online",
  "xemphimsex.top",
  "xemphimsex.tv",
  "xemphimsex.vip",
  "xemphimsex.xyz",
  "xemphimsex1.com",
  "xemphimsexhay.pro",
  "xemphimsexx.me",
  "xemphimsexx.xyz",
  "xemphimx.pro",
  "xemphimxxx.me",
  "xemphimxxxhay.pro",
  "xemsec.net",
  "xemsec.pro",
  "xemsecmy.com",
  "xemset.me",
  "xemset.net",
  "xemset.pro",
  "xemsex.live",
  "xemsex.lol",
  "xemsex.one",
  "xemsex.online",
  "xemsex.org",
  "xemsex.pro",
  "xemsex.top",
  "xemsex.video",
  "xemsex.vip",
  "xemsex3x.com",
  "xemsex3x.net",
  "xemsex3x.pro",
  "xemsex69.vip",
  "xemsex99.com",
  "xemsexhay.me",
  "xemsexhay.org",
  "xemsexhd.com",
  "xemsexhd.info",
  "xemsexhd.live",
  "xemsexhd.me",
  "xemsexhd.pro",
  "xemsexmy.com",
  "xemsexnhanh.com",
  "xemsexnhat.pro",
  "xemsexphim.net",
  "xemsexpro.biz",
  "xemsexvip.me",
  "xemsexvip.net",
  "xemsexvip.pro",
  "xemsexvl.net",
  "xemsexvl.pro",
  "xemsexvn.com",
  "xemsexvn.me",
  "xemsexvn.tv",
  "xemsexx.me",
  "xemsexx.pro",
  "xemsexx.top",
  "xemsexxx.xyz",
  "xemsexz.pro",
  "xemshow.click",
  "xemshow.live",
  "xemsv.com",
  "xemtrai.top",
  "xemvlxx.me",
  "xemxx.info",
  "xemxx.org",
  "xemxxx.me",
  "xemxxx.org",
  "xemxxx.xyz",
  "xephimsex.com",
  "xexnhat.top",
  "xgaigoi.com",
  "xgaixinh.net",
  "xhdx.me",
  "xhdx.xyz",
  "xheo.net",
  "xhot.pro",
  "xhub.tv",
  "xinh1.com",
  "xinh66.com",
  "xinhclub.com",
  "xinhxinh.one",
  "xjavhay.com",
  "xltv.pro",
  "xmovies-xnxx.com",
  "xn--chch-6w5a.live",
  "xn--sexvitnam-zj7d.com",
  "xn-xx.me",
  "xn-xx.one",
  "xn-xx.pro",
  "xn-xx.xyz",
  "xn2x.top",
  "xn3x.net",
  "xn3x.pro",
  "xnxvn.org",
  "xnxx-com.net",
  "xnxx-moi.com",
  "xnxx-phim.com",
  "xnxx-phimsex.net",
  "xnxx-phimsex.pro",
  "xnxx-vlxx.com",
  "xnxx-vn.cc",
  "xnxx-vn.org",
  "xnxx-xvideos.vip",
  "xnxx-z.net",
  "xnxx.link",
  "xnxx11.net",
  "xnxx15.net",
  "xnxx2.info",
  "xnxx2.org",
  "xnxx2.pro",
  "xnxx2.vip",
  "xnxx2022.org",
  "xnxx4k.top",
  "xnxx55.net",
  "xnxx68.net",
  "xnxx7.biz",
  "xnxx98.tv",
  "xnxx99.xxx",
  "xnxxbb.com",
  "xnxxcc.com",
  "xnxxhay.top",
  "xnxxnew.sbs",
  "xnxxphe.com",
  "xnxxphim.me",
  "xnxxphim.xyz",
  "xnxxpro.net",
  "xnxxpro.xxx",
  "xnxxvc.com",
  "xnxxvcl.com",
  "xnxxvcl.net",
  "xnxxvidz.com",
  "xnxxviet.me",
  "xnxxvip.biz",
  "xnxxvl.net",
  "xnxxvn.club",
  "xnxxvn.co",
  "xnxxvn.online",
  "xnxxvn.org",
  "xnxxvn.top",
  "xnxxvn.vip",
  "xnxxvn.xxx",
  "xnxxvp.com",
  "xnxxyou.com",
  "xnxxzz.net",
  "xoac69.xyz",
  "xphe.net",
  "xphimsex.biz",
  "xphimsex.cc",
  "xphimsex.me",
  "xphimsex.pro",
  "xphimsex.top",
  "xphimsex.xyz",
  "xphimsexviet.com",
  "xsexdem.com",
  "xshopsex.com",
  "xsub.me",
  "xtop1.net",
  "xvideo-phimsex.net",
  "xvideo-phimsex.pro",
  "xvideo1.site",
  "xvideo98.com",
  "xvideos102.com",
  "xvideos21.xde.mx",
  "xvideos3x.net",
  "xvideos888.net",
  "xvideos98.pro",
  "xvideos98.xxx",
  "xvideosss.com",
  "xvideosviet.co",
  "xvideosviet.net",
  "xvideosviet.pro",
  "xvideosvn.co",
  "xvideosvn.live",
  "xvideosvn.org",
  "xvideosvn.pro",
  "xvideosvn.vip",
  "xvideosvn.xyz",
  "xvideosvn99.com",
  "xvideosz.co",
  "xvideosz.net",
  "xviet.sex",
  "xvietsub.com",
  "xx3x.me",
  "xxasian.net",
  "xxbase.org",
  "xxdam.net",
  "xxdem.pro",
  "xxdem.ws",
  "xxdem.xyz",
  "xxgai.org",
  "xxhd1.pro",
  "xxhot.sex",
  "xxjav.me",
  "xxlx.net",
  "xxngon.net",
  "xxnhanh.net",
  "xxnhanh.pro",
  "xxnhatz.com",
  "xxphap.net",
  "xxphe.cc",
  "xxphe.me",
  "xxphim.club",
  "xxphim.co",
  "xxphim.live",
  "xxphim.me",
  "xxphim.vin",
  "xxphim.vip",
  "xxphim.xyz",
  "xxphimsex.me",
  "xxphimsex.pro",
  "xxphimsex.vip",
  "xxpho.net",
  "xxtv.vip",
  "xxviet.net",
  "xxviet.top",
  "xxviet.tv",
  "xxviet.xyz",
  "xxvip.net",
  "xxx-hay.pro",
  "xxx-phim.com",
  "xxx.ditnhau.cc",
  "xxx3x.net",
  "xxx8.pro",
  "xxxdam.xyz",
  "xxxgaixinh.org",
  "xxxhay.biz",
  "xxxhay.buzz",
  "xxxhay.cc",
  "xxxhay.info",
  "xxxhay.org",
  "xxxhay.pro",
  "xxxhaynhat.net",
  "xxxhayz.com",
  "xxxmoi.com",
  "xxxmoi.pro",
  "xxxmoinhat.net",
  "xxxner.com",
  "xxxnhat.net",
  "xxxnhatban.cyou",
  "xxxphap.vip",
  "xxxphe.one",
  "xxxphe.pro",
  "xxxphim.biz",
  "xxxphim.me",
  "xxxphim.mobi",
  "xxxphim.top",
  "xxxphimheo.com",
  "xxxphimsex.pro",
  "xxxphimsexviet.com",
  "xxxphimxxx.com",
  "xxxphimz.com",
  "xxxv.us",
  "xxxviet.info",
  "xxxviet.me",
  "xxxviet.pro",
  "xxxviet.tv",
  "xxxvietnam.blog",
  "xxxvietnam.tv",
  "xxxvl.pro",
  "xxxvn.cc",
  "xxxvn.co",
  "xxxvn.live",
  "xxxvn.me",
  "xxxvn.plus",
  "xxxxinh.com",
  "xxxxvideo.uno",
  "xzx.mobi",
  "yeu3x.com",
  "yeuanh.site",
  "yeusex.me",
  "yeusex.net",
  "yeusex.one",
  "yeusex.org",
  "yeusex.pro",
  "yeutinhduc.com",
  "yeuu.net",
  "ynknc.com",
  "yo69.me",
  "yo69.one",
  "yo69.pro",
  "youtubecliphot.link",
  "youtubecliphot.net",
  "youtubecliphot.org",
  "youtubecliphot.xyz",
  "yphimsex.cc",
  "z.phimsexsub.co",
  "z88.one",
  "zanevski.ru",
  "zarabotokgroup.ru",
  "zhentai.tv",
  "zo3x.cc",
  "zo3x.top",
  "zohup.com",
  "zohup.net",
  "zoom.porn",
  "zoozoosexporn.com",
  "zphimsex.me",
  "zphimsex.pro",
  "zsex.lol",
  "zsex.pro",
  "zsexmoi.com",
  "zsexmoi.net"
];

// src/content/ignoreList.js
var ignoreList = [
  "google.com",
  "youtube.com",
  "drive.google.com",
  "docs.google.com",
  "quran.com",
  "islamqa.info"
];

// src/background/media-processor/remoteAnalyzer.js
var remoteAnalyzer = class {
  constructor(data) {
    this.data = data;
  }
  getCurrentTabHostName = async () => {
    const tabs = await chrome.tabs.query({ active: true });
    const { hostname } = new URL(tabs?.[0]?.url ?? "");
    return hostname;
  };
  analyze = async () => {
    let annotatedData;
    if (this.data.mediaUrl.startsWith(
      "https://images.safegaze.com/annotated_image/"
    )) {
      return {
        shouldMask: true,
        maskedUrl: this.data.mediaUrl
      };
    }
    try {
      let relativeFilePath = await this.relativeFilePath(this.data.mediaUrl);
      if (await this.urlExists(relativeFilePath)) {
        console.log("url exists");
        return {
          shouldMask: true,
          maskedUrl: relativeFilePath
        };
      }
    } catch (error) {
      console.log("Error checking if url exists");
      console.log(error);
    }
    try {
      annotatedData = await this.getAnnotatedMedia(this.data.mediaUrl);
    } catch (error) {
      console.log("Error getting annotated media");
      console.log(error);
      annotatedData = {
        success: false
      };
    }
    console.log(annotatedData);
    if (annotatedData.success === false || annotatedData.media.length <= 0 || annotatedData.media[0].success === false) {
      return {
        shouldMask: false,
        maskedUrl: null,
        invalidMedia: true
      };
    }
    let maskedUrl = annotatedData.media[0].processed_media_url;
    return {
      shouldMask: true,
      maskedUrl,
      activate: true
    };
  };
  getAnnotatedMedia = async (url) => {
    let myHeaders = new Headers();
    myHeaders.append("Content-Type", "application/json");
    let raw = JSON.stringify({
      media: [
        {
          media_url: url,
          media_type: "image",
          has_attachment: false
        }
      ]
    });
    let requestOptions = {
      method: "POST",
      headers: myHeaders,
      body: raw,
      redirect: "follow"
    };
    let response = await fetch(
      "https://api.safegaze.com/api/v1/analyze",
      requestOptions
    );
    let result = await response.json();
    console.log({
      request: {
        media: [
          {
            media_url: url,
            media_type: "image",
            has_attachment: false
          }
        ]
      },
      response: result
    });
    return result;
  };
  urlExists = async (url) => {
    const response = await fetch(url, {
      method: "HEAD",
      cache: "no-cache"
    }).catch(() => ({ ok: false }));
    return response.ok;
  };
  relativeFilePath = async (originalMediaUrl) => {
    const hash = await this.sha256(originalMediaUrl);
    let newUrl = `https://images.safegaze.com/annotated_image/${hash}/image.png`;
    return newUrl;
  };
  sha256 = async (str) => {
    try {
      const encoder = new TextEncoder();
      const data = encoder.encode(str);
      const hashBuffer = await crypto.subtle.digest("SHA-256", data);
      const hashArray = Array.from(new Uint8Array(hashBuffer));
      const hashHex = hashArray.map((byte) => byte.toString(16).padStart(2, "0")).join("");
      return hashHex;
    } catch (error) {
      return "";
    }
  };
};
var remoteAnalyzer_default = remoteAnalyzer;

// src/content/index.js
require_tf_backend_cpu_node();
require_tf_backend_webgl_node();
var cocoSsd = require_coco_ssd_node();
var hvf = {
  domObjectIndex: 0,
  interval: null,
  maxRenderItem: 1,
  ignoreImageSize: 40,
  getSettings: async function() {
    const waitTime = 5e3;
    return await new Promise((resolve, reject) => {
      const timeoutId = setTimeout(() => {
        reject(new Error("timeout"));
      }, waitTime);
      chrome.runtime.sendMessage({
        type: "getSettings",
        settingsKey: window.location.host ?? "power"
      }).then((value) => {
        clearTimeout(timeoutId);
        resolve(value);
      });
    });
  },
  getImageBase64: async function(imgUrl) {
    return await new Promise((resolve, reject) => {
      chrome.runtime.sendMessage({
        action: "CONVERT-IMAGE-TO-BASE64",
        imgUrl
      }).then((value) => {
        if (value?.complete) {
          resolve(value);
        }
      });
    });
  },
  is_scrolling: function() {
    return this.lastScrollTime && (/* @__PURE__ */ new Date()).getTime() < this.lastScrollTime + 500;
  },
  getUrlExtension: function(url) {
    if (!url) {
      return "";
    }
    return url.split(/[#?]/)[0].split(".").pop().trim().toLowerCase();
  },
  isDataSrcImage: function(imageSrc) {
    if (!imageSrc) {
      return;
    }
    const regex = /^data:image\/([a-zA-Z]+);base64,/;
    return regex.test(imageSrc);
  },
  openNewTabWithMessage() {
    chrome.tabs.create({ url: "about:blank" }, function(tab) {
      chrome.tabs.sendMessage(tab.id, { message: "Hello from content.js!" });
    });
  },
  // detect images
  async objectDetection(img) {
    try {
      const model = await cocoSsd.load();
      const predictions = await model.detect(img);
      const foundPerson = predictions.find((pred) => pred.class === "person");
      return !!foundPerson;
    } catch (error) {
      console.log("error on detecting image", error);
      return false;
    }
  },
  async imageURLToBase64(url) {
    try {
      const imageUrlWithCors = `${url}`;
      const response = await fetch(imageUrlWithCors, {
        method: "GET",
        // POST, PUT, DELETE, etc.
        headers: {
          // the content type header value is usually auto-set
          // depending on the request body
          "Content-Type": "application/json;charset=UTF-8",
          "X-Requested-With": "XMLHttpRequest"
        }
      });
      const blob = await response.blob();
      const reader = new FileReader();
      return new Promise((resolve, reject) => {
        reader.onloadend = () => {
          resolve(reader.result);
        };
        reader.onerror = reject;
        reader.readAsDataURL(blob);
      });
    } catch (error) {
      console.error("Error converting image to base64:", error);
      throw error;
    }
  },
  // Initialize the extension
  init: async function() {
    try {
      console.log("init function called");
      const power = await this.getSettings();
      if (!power) {
        document.body.classList.add("hvf-extension-power-off");
        document.body.classList.add("hvf-show-website");
        return;
      }
      const domain = window.location.hostname.replace("www.", "");
      if (blockList.includes(domain)) {
        console.log("blocking the domain", domain);
        chrome.runtime.sendMessage({ message: "openNewTab" });
        document.body.classList.add("hvf-extension-power-off");
        return;
      }
      document.body.classList.add("hvf-show-website");
      if (ignoreList.includes(domain)) {
        console.log(`Ignoring this domain ${domain}`);
        document.body.classList.add("hvf-extension-power-off");
        return;
      }
      document.body.classList.add("hvf-extension-loaded");
      setTimeout(() => {
        this.triggerScanning();
        this.receiveMedia();
      }, 1e3);
      window.addEventListener(
        "load",
        () => {
          this.listenUrlUpdate();
        },
        false
      );
    } catch (error) {
      if (!document.querySelector("body").classList.contains("hvf-extension-loaded") && !document.querySelector("body").classList.contains("hvf-extension-power-off")) {
        console.log("initial load failed!");
        document.body.classList.add("hvf-show-website");
        document.body.classList.add("hvf-extension-power-off");
      }
    }
  },
  isElementInViewport: function(el) {
    let rect = el.getBoundingClientRect();
    let result = rect.top >= 0 && rect.left >= 0 && rect.bottom <= (window.innerHeight || document.documentElement.clientHeight) && rect.right <= (window.innerWidth || document.documentElement.clientWidth);
    return result;
  },
  throttleWaiting: false,
  // Initially, we're not waiting
  throttle: function(callback, limit) {
    return function() {
      if (!this.throttleWaiting) {
        try {
          callback.apply(this, arguments);
        } catch (error) {
          console.log("Error executing callback in throttle");
          console.log(error);
        }
        this.throttleWaiting = true;
        setTimeout(function() {
          this.throttleWaiting = false;
        }, limit);
      }
    };
  },
  triggerScanning: function() {
    this.throttle(this.sendMedia(), 1e3);
  },
  removeUnUsedLoader() {
    document.querySelectorAll(`.hvf-loader`).forEach((loader) => {
      const domIdFromLoader = loader.getAttribute("data-dom-id");
      const findDomFromLoader = document.querySelector(`.${domIdFromLoader}`);
      if (!findDomFromLoader) {
        loader.remove();
      }
    });
  },
  addImageLoader(media) {
    if (media.classList.contains("hvf-multi-time-analyzing") || media.classList.contains("hvf-invalid")) {
      return;
    }
    const hvgLoader = document.querySelector(
      ".hvf-loader-id-" + this.domObjectIndex
    );
    media.setAttribute(
      "data-loader-id",
      `hvf-loader-id-${this.domObjectIndex}`
    );
    const { top, left, width, height } = media.getBoundingClientRect();
    if (top > 0 && left > 0 && width > 0 && height > 0 && !media.querySelector("[class^=hvf-dom-]")?.length) {
      if (!hvgLoader?.length) {
        document.body.insertAdjacentHTML(
          "beforeend",
          `<div data-dom-id="hvf-dom-id-${this.domObjectIndex}" style="width: ${width}px; height: ${height}px; top: ${top}px; left: ${left}px;" class="lds-ring hvf-loader hvf-loader-id-${this.domObjectIndex}"><div></div><div></div><div></div><div></div></div>`
        );
      } else {
        if (hvgLoader?.length) {
          hvgLoader.style.width = `${width}px`;
          hvgLoader.style.height = `${height}px`;
          hvgLoader.style.top = `${top}px`;
          hvgLoader.style.left = `${left}px`;
          hvgLoader.style.display = "flex";
        }
      }
    }
  },
  movePositionOfLoader() {
    document.querySelectorAll(`.hvf-loader:not(.hvf-analyzed-loader-el)`).forEach((loader) => {
      const domIdFromLoader = loader.getAttribute("data-dom-id");
      const findDomFromLoader = document.querySelector(`.${domIdFromLoader}`);
      if (findDomFromLoader) {
        const loaderId = findDomFromLoader.getAttribute("data-loader-id");
        const loader2 = document.querySelector(`.${loaderId}`);
        const { top, left, width, height } = findDomFromLoader.getBoundingClientRect();
        if (loader2) {
          loader2.style.width = `${width}px`;
          loader2.style.height = `${height}px`;
          loader2.style.top = `${top}px`;
          loader2.style.left = `${left}px`;
        }
      }
    });
  },
  removeImageLoader(media) {
    const loaderId = media.getAttribute("data-loader-id");
    const loader = document.querySelector(`.${loaderId}`);
    if (loader) {
      loader.classList.add("hvf-analyzed-loader-el");
    }
  },
  // Send media to the background script
  sendMedia: function() {
    let media = document.querySelectorAll(
      "body *:not(.hvf-analyzed):not(.hvf-analyzing):not(.hvf-unidentified-error):not(.hvf-too-many-render):not(.hvf-dom-checked):not(.hvf-ignored-image):not(.hvf-can-not-processed)"
    );
    this.removeUnUsedLoader();
    for (let i = 0; i < media.length; i++) {
      if (media[i].tagName === "SOURCE" && media[i].parentNode.tagName === "PICTURE") {
        media[i].remove();
      }
      const backgroundImage = window.getComputedStyle(media[i]).backgroundImage || media[i].style.backgroundImage;
      const backgroundImageUrl = backgroundImage.slice(5, -2);
      const hasBackgroundImage = backgroundImage?.startsWith("url(");
      if (!hasBackgroundImage && media[i].tagName !== "image" && media[i].tagName !== "IMG") {
        media[i].classList.add("hvf-dom-checked");
      }
      if (media[i].classList.contains("hvf-unidentified-error") || media[i].classList.contains("hvf-too-many-render") || media[i].classList.contains("hvf-analyzing") || media[i].classList.contains("hvf-analyzed") || this.isElementInViewport(media[i]) === false || !hasBackgroundImage && media[i].tagName !== "IMG" && media[i].tagName !== "image" || this.isDataSrcImage(media[i].src)) {
        continue;
      }
      const { width: imageWidth, height: imageHeight } = media[i].getBoundingClientRect();
      if (imageWidth <= this.ignoreImageSize || imageHeight <= this.ignoreImageSize || media[i].id.includes("captcha") || media[i].classList.contains("captcha")) {
        media[i].classList.add("hvf-ignored-image");
        continue;
      }
      let url = media[i].src;
      let srcAttr = "src";
      if (!url || url.length === 0) {
        url = media[i].getAttribute("xlink:href");
        srcAttr = "xlink:href";
      }
      if (hasBackgroundImage && media[i].tagName !== "IMG") {
        url = backgroundImageUrl;
      }
      if (url.startsWith("https://images.safegaze.com/annotated_image/")) {
        media[i].classList.add("hvf-analyzed");
        media[i].classList.remove("hvf-analyzing");
        continue;
      }
      if (this.getUrlExtension(url) == "svg" || // this.getUrlExtension(url) == "gif" ||
      this.getUrlExtension(url) == "ico" || url.includes("logo") || media[i].tagName === "IMG" && media[i].getAttribute("alt")?.includes("logo")) {
        media[i].classList.add("hvf-invalid-img");
        continue;
      }
      let isLoaded = media[i].complete && media[i].naturalHeight !== 0;
      if ((media[i].tagName == "image" || hasBackgroundImage || isLoaded) && url && url.length > 0) {
        let renderCycle = media[i].getAttribute("hvf-render-cycle");
        const loaderId = media[i].getAttribute("data-loader-id");
        if (renderCycle && +renderCycle > this.maxRenderItem) {
          media[i].classList.add("hvf-too-many-render");
          continue;
        }
        media[i].setAttribute("hvf-render-cycle", +renderCycle + 1 || 1);
        console.log("sending data to background script");
        this.domObjectIndex++;
        media[i].classList.remove("hvf-invalid");
        media[i].classList.add("hvf-analyzing");
        media[i].classList.add("hvf-dom-id-" + this.domObjectIndex);
        this.addImageLoader(media[i]);
        const loader = document.querySelector(`.${loaderId}`);
        if (loader) {
          loader.classList.add("hvf-analyzed-loader-el");
        }
        const that = this;
        let data = {
          mediaUrl: url,
          mediaType: hasBackgroundImage && media[i].tagName !== "IMG" && media[i].tagName !== "image" ? "backgroundImage" : "image",
          domObjectIndex: this.domObjectIndex,
          srcAttr,
          shouldMask: false,
          maskedUrl: null
        };
        let analyzer = new remoteAnalyzer_default(data);
        (async function() {
          const result = await that.getImageBase64(media[i].src);
          const base64Image = result.result;
          const imgElement = document.createElement("img");
          imgElement.src = base64Image;
          imgElement.crossOrigin = "anonymous";
          const detectPerson = await that.objectDetection(imgElement);
          if (!detectPerson) {
            media[i].classList.add("hvf-ignored-image");
            media[i].classList.add("hvf-human-not-included");
            return;
          }
          analyzer.analyze().then((result2) => {
            console.log("Media analysis complete");
            console.log(result2);
            that.receiveMediaV2({
              payload: Object.assign(data, result2)
            });
            chrome.runtime.sendMessage(
              {
                action: "HVF-TOTAL-COUNT",
                activate: result2?.activate
              },
              (result3) => {
                if (!chrome.runtime.lastError) {
                } else {
                }
              }
            );
          }).catch((err) => {
            console.log("Error analyzing media");
            console.log(err);
          });
        })();
      }
    }
  },
  receiveMediaV2: function(message) {
    let index = message.payload.domObjectIndex;
    let media = document.querySelector(".hvf-dom-id-" + index);
    let srcAttr = message.payload.srcAttr;
    let mediaUrl = message.payload.mediaUrl;
    if (!media)
      return;
    if (message.payload.shouldMask && message.payload.maskedUrl) {
      media.setAttribute(srcAttr, "");
      media.style.backgroundImage = "";
      media.classList.add("hvf-masked");
      if (message.payload.mediaType === "backgroundImage") {
        media.style.backgroundImage = `url(${message.payload.maskedUrl})`;
      } else {
        media.setAttribute(srcAttr, message.payload.maskedUrl);
        media.removeAttribute("srcset");
      }
      media.setAttribute("data-hvf-original-url", mediaUrl);
    }
    if (message.payload.invalidMedia === true) {
      media.classList.add("hvf-invalid");
    } else {
      media.classList.add("hvf-analyzed");
      media.classList.remove("hvf-invalid");
    }
    media.classList.remove("hvf-analyzing");
    let renderCycle = media.getAttribute("hvf-render-cycle") || 0;
    if (!message.payload.invalidMedia || renderCycle > this.maxRenderItem) {
      this.removeImageLoader(media);
    }
  },
  // Receive media from the background script
  receiveMedia: function() {
    chrome.runtime.onMessage.addListener((message, sender, sendResponse) => {
      if (message && message.action === "HVF-MEDIA-ANALYSIS-REPORT") {
        let index = message.payload.domObjectIndex;
        let media = document.querySelector(".hvf-dom-id-" + index);
        let srcAttr = message.payload.srcAttr;
        let mediaUrl = message.payload.mediaUrl;
        if (!media)
          return;
        if (message.payload.shouldMask && message.payload.maskedUrl) {
          media.setAttribute(srcAttr, "");
          media.style.backgroundImage = "";
          media.classList.add("hvf-masked");
          if (message.payload.mediaType === "backgroundImage") {
            media.style.backgroundImage = `url(${message.payload.maskedUrl})`;
          } else {
            media.setAttribute(srcAttr, message.payload.maskedUrl);
            media.removeAttribute("srcset");
          }
          media.setAttribute("data-hvf-original-url", mediaUrl);
        }
        if (message.payload.invalidMedia === true) {
          media.classList.add("hvf-invalid");
        } else {
          media.classList.add("hvf-analyzed");
          media.classList.remove("hvf-invalid");
        }
        media.classList.remove("hvf-analyzing");
        let renderCycle = media.getAttribute("hvf-render-cycle") || 0;
        if (!message.payload.invalidMedia || renderCycle > this.maxRenderItem) {
          this.removeImageLoader(media);
        }
      }
    });
  },
  listenUrlUpdate: function() {
    let observer = new MutationObserver((mutationList) => {
      if (!document.hasFocus()) {
        return;
      }
      if (this.is_scrolling() === true) {
        return;
      }
      for (const mutation of mutationList) {
        if (mutation.type !== "attributes") {
          if (mutation.addedNodes.length) {
            setTimeout(() => {
              this.triggerScanning();
            }, 1e3);
          }
          continue;
        }
        if (mutation.attributeName !== "src" && mutation.attributeName !== "xlink:href") {
          continue;
        }
        if (mutation.target.classList.contains("hvf-showed-original-image")) {
          continue;
        }
        let imgTargetSrc = mutation.target.src;
        if (mutation.target.tagName === "image") {
          imgTargetSrc = mutation.target.getAttribute("xlink:href");
        }
        if (mutation.target.getAttribute("data-hvf-masked-url") === imgTargetSrc) {
          continue;
        }
        if (mutation.type === "attributes" && (mutation.target.classList.contains("hvf-analyzed") || mutation.target.classList.contains("hvf-invalid"))) {
          mutation.target.classList.remove("hvf-analyzed");
          mutation.target.classList.remove("hvf-analyzing");
          mutation.target.classList.remove("hvf-invalid");
          mutation.target.classList.add("hvf-multi-time-analyzing");
          this.triggerScanning();
        }
      }
    });
    observer.observe(document.body, {
      childList: true,
      subtree: true,
      attributes: true
    });
    window.addEventListener("resize", () => {
      this.movePositionOfLoader();
    });
    document.addEventListener(
      "scroll",
      () => {
        this.movePositionOfLoader();
        hvf.triggerScanning();
      },
      true
    );
  },
  blankThumbnail: function() {
    return "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABLAAAAKjAQAAAAAlyMttAAABpUlEQVR42u3OMQEAAAwCIPuX1hjbAQlIX4qWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpbWmQEz1g2V4P8ycgAAAABJRU5ErkJggg==";
  }
};
function hvfInitObserver(callback) {
  const config = { childList: true, subtree: true, attributes: true };
  const observer = new MutationObserver(callback);
  observer.observe(document.body, config);
}
function hvgObserverCallback() {
  if (!document.querySelector("body").classList.contains("hvf-extension-loaded") && !document.querySelector("body").classList.contains("hvf-extension-power-off")) {
    hvf.init();
  }
}
hvfInitObserver(hvgObserverCallback);
hvgObserverCallback();
/*! Bundled license information:

@tensorflow/tfjs-core/dist/tf-core.node.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the 'License');
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an 'AS IS' BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (** @license See the LICENSE file. *)

@tensorflow/tfjs-backend-cpu/dist/tf-backend-cpu.node.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (** @license See the LICENSE file. *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-backend-webgl/dist/tf-backend-webgl.node.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (** @license See the LICENSE file. *)
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/tf-converter.node.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the 'License');
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an 'AS IS' BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (** @license See the LICENSE file. *)

@tensorflow-models/coco-ssd/dist/coco-ssd.node.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (*! *****************************************************************************
  Copyright (c) Microsoft Corporation.
  
  Permission to use, copy, modify, and/or distribute this software for any
  purpose with or without fee is hereby granted.
  
  THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
  REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
  AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
  INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
  LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
  OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
  PERFORMANCE OF THIS SOFTWARE.
  ***************************************************************************** *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (** @license See the LICENSE file. *)
*/
